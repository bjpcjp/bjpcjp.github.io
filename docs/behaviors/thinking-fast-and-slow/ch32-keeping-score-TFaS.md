# ch32-keeping-score-TFaS

Keeping Score
Except for the very poor, for whom income coincides with survival, the main
motivators of money-seeking are not necessarily economic. For the
billionaire looking for the extra billion, and indeed for the participant in an
experimental economics project looking for the extra dollar, money is a
proxy for points on a scale of self-regard and achievement. These rewards
and punishments, promises and threats, are all in our heads. We carefully
keep score of them. They shape o C Th5ur preferences and motivate our
actions, like the incentives provided in the social environment. As a result,
we refuse to cut losses when doing so would admit failure, we are biased
against actions that could lead to regret, and we draw an illusory but sharp
distinction between omission and commission, not doing and doing,
because the sense of responsibility is greater for one than for the other.
The ultimate currency that rewards or punishes is often emotional, a form
of mental self-dealing that inevitably creates conflicts of interest when the
individual acts as an agent on behalf of an organization.
Mental Accounts
Richard Thaler has been fascinated for many years by analogies between
the world of accounting and the mental accounts that we use to organize
and run our lives, with results that are sometimes foolish and sometimes
very helpful. Mental accounts come in several varieties. We hold our money
in different accounts, which are sometimes physical, sometimes only
mental. We have spending money, general savings, earmarked savings for
our children’s education or for medical emergencies. There is a clear
hierarchy in our willingness to draw on these accounts to cover current
needs. We use accounts for self-control purposes, as in making a
household budget, limiting the daily consumption of espressos, or
increasing the time spent exercising. Often we pay for self-control, for
instance simultaneously putting money in a savings account and
maintaining debt on credit cards. The Econs of the rational-agent model
do not resort to mental accounting: they have a comprehensive view of
outcomes and are driven by external incentives. For Humans, mental
accounts are a form of narrow framing; they keep things under control and
manageable by a finite mind.
Mental accounts are used extensively to keep score. Recall that
professional golfers putt more successfully when working to avoid a bogey
than to achieve a birdie. One conclusion we can draw is that the best
golfers create a separate account for each hole; they do not only maintain
a single account for their overall success. An ironic example that Thaler
related in an early article remains one of the best illustrations of how
mental accounting affects behavior:
Two avid sports fans plan to travel 40 miles to see a basketball
game. One of them paid for his ticket; the other was on his way to
purchase a ticket when he got one free from a friend. A blizzard is
announced for the night of the game. Which of the two ticket
holders is more likely to brave the blizzard to see the game?
The answer is immediate: we know that the fan who paid for his ticket is
more likely to drive. Mental accounting provides the explanation. We
assume that both fans set up an account for the game they hoped to see.
Missing the game will close the accounts with a negative balance.
Regardless of how they came by their ticket, both will be disappointed—
but the closing balance is distinctly more negative for the one who bought a
ticket and is now out of pocket as well as deprived of the game. Because
staying home is worse for this individual, he is more motivated to see the
game and therefore more likely to make the attempt to drive into a blizzard.
These are tacit calculations of emotional balance, of the kind that System 1
performs without deliberation. The emotions that people attach to the state
of their mental accounts are not acknowledged in standard economic
theory. An Econ would realize that the ticket has already been paid for and
cannot be returned. Its cost is “sunk” and the Econ would not care whether
he had bought the ticket to the game or got it from a friend (if Eco B
Th5motketns have friends). To implement this rational behavior, System 2
would have to be aware of the counterfactual possibility: “Would I still drive
into this snowstorm if I had gotten the ticket free from a friend?” It takes an
active and disciplined mind to raise such a difficult question.
A related mistake afflicts individual investors when they sell stocks from
their portfolio:
You need money to cover the costs of your daughter’s wedding
and will have to sell some stock. You remember the price at
which you bought each stock and can identify it as a “winner,”
currently worth more than you paid for it, or as a loser. Among the
stocks you own, Blueberry Tiles is a winner; if you sell it today you
will have achieved a gain of $5,000. You hold an equal
investment in Tiffany Motors, which is currently worth $5,000 less
than you paid for it. The value of both stocks has been stable in
recent weeks. Which are you more likely to sell?
A plausible way to formulate the choice is this: “I could close the Blueberry
Tiles account and score a success for my record as an investor.
Alternatively, I could close the Tiffany Motors account and add a failure to
my record. Which would I rather do?” If the problem is framed as a choice
between giving yourself pleasure and causing yourself pain, you will
certainly sell Blueberry Tiles and enjoy your investment prowess. As might
be expected, finance research has documented a massive preference for
selling winners rather than losers—a bias that has been given an opaque
label: the disposition effect.
The disposition effect is an instance of narrow framing. The investor has
set up an account for each share that she bought, and she wants to close
every account as a gain. A rational agent would have a comprehensive
view of the portfolio and sell the stock that is least likely to do well in the
future, without considering whether it is a winner or a loser. Amos told me
of a conversation with a financial adviser, who asked him for a complete
list of the stocks in his portfolio, including the price at which each had been
purchased. When Amos asked mildly, “Isn’t it supposed not to matter?” the
adviser looked astonished. He had apparently always believed that the
state of the mental account was a valid consideration.
Amos’s guess about the financial adviser’s beliefs was probably right,
but he was wrong to dismiss the buying price as irrelevant. The purchase
price does matter and should be considered, even by Econs. The
disposition effect is a costly bias because the question of whether to sell
winners or losers has a clear answer, and it is not that it makes no
difference. If you care about your wealth rather than your immediate
emotions, you will sell the loser Tiffany Motors and hang on to the winning
Blueberry Tiles. At least in the United States, taxes provide a strong
incentive: realizing losses reduces your taxes, while selling winners
exposes you to taxes. This elementary fact of financial life is actually known
to all American investors, and it determines the decisions they make
during one month of the year—investors sell more losers in December,
when taxes are on their mind. The tax advantage is available all year, of
course, but for 11 months of the year mental accounting prevails over
financial common sense. Another argument against selling winners is the
well-documented market anomaly that stocks that recently gained in value
are likely to go on gaining at least for a short while. The net effect is large:
the expected after-tax extra return of selling Tiffany rather than Blueberry is
3.4% over the next year. Cl B Th5inge liosing a mental account with a gain
is a pleasure, but it is a pleasure you pay for. The mistake is not one that
an Econ would ever make, and experienced investors, who are using their
System 2, are less susceptible to it than are novices.
A rational decision maker is interested only in the future consequences
of current investments. Justifying earlier mistakes is not among the Econ’s
concerns. The decision to invest additional resources in a losing account,
when better investments are available, is known as the sunk-cost fallacy, a
costly mistake that is observed in decisions large and small. Driving into
the blizzard because one paid for tickets is a sunk-cost error.
Imagine a company that has already spent $50 million on a project. The
project is now behind schedule and the forecasts of its ultimate returns are
less favorable than at the initial planning stage. An additional investment of
$60 million is required to give the project a chance. An alternative proposal
is to invest the same amount in a new project that currently looks likely to
bring higher returns. What will the company do? All too often a company
afflicted by sunk costs drives into the blizzard, throwing good money after
bad rather than accepting the humiliation of closing the account of a costly
failure. This situation is in the top-right cell of the fourfold pattern, where the
choice is between a sure loss and an unfavorable gamble, which is often
unwisely preferred.
The escalation of commitment to failing endeavors is a mistake from the
perspective of the firm but not necessarily from the perspective of the
executive who “owns” a floundering project. Canceling the project will leave
a permanent stain on the executive’s record, and his personal interests are
perhaps best served by gambling further with the organization’s resources
in the hope of recouping the original investment—or at least in an attempt
to postpone the day of reckoning. In the presence of sunk costs, the
manager’s incentives are misaligned with the objectives of the firm and its
shareholders, a familiar type of what is known as the agency problem.
Boards of directors are well aware of these conflicts and often replace a
CEO who is encumbered by prior decisions and reluctant to cut losses.
The members of the board do not necessarily believe that the new CEO is
more competent than the one she replaces. They do know that she does
not carry the same mental accounts and is therefore better able to ignore
the sunk costs of past investments in evaluating current opportunities.
The sunk-cost fallacy keeps people for too long in poor jobs, unhappy
marriages, and unpromising research projects. I have often observed
young scientists struggling to salvage a doomed project when they would
be better advised to drop it and start a new one. Fortunately, research
suggests that at least in some contexts the fallacy can be overcome. The
sunk-cost fallacy is identified and taught as a mistake in both economics
and business courses, apparently to good effect: there is evidence that
graduate students in these fields are more willing than others to walk away
from a failing project.
Regret
Regret is an emotion, and it is also a punishment that we administer to
ourselves. The fear of regret is a factor in many of the decisions that
people make (“Don’t do this, you will regret it” is a common warning), and
the actual experience of regret is familiar. The emotional state has been
well described by two Dutch psychologists, who noted that regret is
“accompanied by feelings that one should have known better, by a B
Th5="4ncesinking feeling, by thoughts about the mistake one has made
and the opportunities lost, by a tendency to kick oneself and to correct
one’s mistake, and by wanting to undo the event and to get a second
chance.” Intense regret is what you experience when you can most easily
imagine yourself doing something other than what you did.
Regret is one of the counterfactual emotions that are triggered by the
availability of alternatives to reality. After every plane crash there are
special stories about passengers who “should not” have been on the plane
—they got a seat at the last moment, they were transferred from another
airline, they were supposed to fly a day earlier but had had to postpone.
The common feature of these poignant stories is that they involve unusual
events—and unusual events are easier than normal events to undo in
imagination. Associative memory contains a representation of the normal
world and its rules. An abnormal event attracts attention, and it also
activates the idea of the event that would have been normal under the
same circumstances.
To appreciate the link of regret to normality, consider the following
scenario:
Mr. Brown almost never picks up hitchhikers. Yesterday he gave
a man a ride and was robbed.
Mr. Smith frequently picks up hitchhikers. Yesterday he gave a
man a ride and was robbed.
Who of the two will experience greater regret over the episode?
The results are not surprising: 88% of respondents said Mr. Brown, 12%
said Mr. Smith.
Regret is not the same as blame. Other participants were asked this
question about the same incident:
Who will be criticized most severely by others?
The results: Mr. Brown 23%, Mr. Smith 77%.
Regret and blame are both evoked by a comparison to a norm, but the
relevant norms are different. The emotions experienced by Mr. Brown and
Mr. Smith are dominated by what they usually do about hitchhikers. Taking
a hitchhiker is an abnormal event for Mr. Brown, and most people therefore
expect him to experience more intense regret. A judgmental observer,
however, will compare both men to conventional norms of reasonable
behavior and is likely to blame Mr. Smith for habitually taking unreasonable
risks. We are tempted to say that Mr. Smith deserved his fate and that Mr.
Brown was unlucky. But Mr. Brown is the one who is more likely to be
kicking himself, because he acted out of character in this one instance.
Decision makers know that they are prone to regret, and the anticipation
of that painful emotion plays a part in many decisions. Intuitions about
regret are remarkably uniform and compelling, as the next example
illustrates.
Paul owns shares in company A. During the past year he
considered switching to stock in company B, but he decided
against it. He now learns that he would have been better off by
$1,200 if he had switched to the stock of company B.
George owned shares in company B. During the past year he sw
B Th5 ne
Who feels greater regret?
The results are clear-cut: 8% of respondents say Paul, 92% say George.
This is curious, because the situations of the two investors are
objectively identical. They both now own stock A and both would have been
better off by the same amount if they owned stock B. The only difference is
that George got to where he is by acting, whereas Paul got to the same
place by failing to act. This short example illustrates a broad story: people
expect to have stronger emotional reactions (including regret) to an
outcome that is produced by action than to the same outcome when it is
produced by inaction. This has been verified in the context of gambling:
people expect to be happier if they gamble and win than if they refrain from
gambling and get the same amount. The asymmetry is at least as strong
for losses, and it applies to blame as well as to regret. The key is not the
difference between commission and omission but the distinction between
default options and actions that deviate from the default. When you deviate
from the default, you can easily imagine the norm—and if the default is
associated with bad consequences, the discrepancy between the two can
be the source of painful emotions. The default option when you own a stock
is not to sell it, but the default option when you meet your colleague in the
morning is to greet him. Selling a stock and failing to greet your coworker
are both departures from the default option and natural candidates for
regret or blame.
In a compelling demonstration of the power of default options,
participants played a computer simulation of blackjack. Some players
were asked “Do you wish to hit?” while others were asked “Do you wish to
stand?” Regardless of the question, saying yes was associated with much
more regret than saying no if the outcome was bad! The question evidently
suggests a default response, which is, “I don’t have a strong wish to do it.”
It is the departure from the default that produces regret. Another situation in
which action is the default is that of a coach whose team lost badly in their
last game. The coach is expected to make a change of personnel or
strategy, and a failure to do so will produce blame and regret.
The asymmetry in the risk of regret favors conventional and risk-averse
choices. The bias appears in many contexts. Consumers who are
reminded that they may feel regret as a result of their choices show an
increased preference for conventional options, favoring brand names over
generics. The behavior of the managers of financial funds as the year
approaches its end also shows an effect of anticipated evaluation: they
tend to clean up their portfolios of unconventional and otherwise
questionable stocks. Even life-or-death decisions can be affected. Imagine
a physician with a gravely ill patient. One treatment fits the normal standard
of care; another is unusual. The physician has some reason to believe that
the unconventional treatment improves the patient’s chances, but the
evidence is inconclusive. The physician who prescribes the unusual
treatment faces a substantial risk of regret, blame, and perhaps litigation.
In hindsight, it will be easier to imagine the normal choice; the abnormal
choice will be easy to undo. True, a good outcome will contribute to the
reputation of the physician who dared, but the potential benefit is smaller
than the potential cost because success is generally a more normal
outcome than is failure.
Responsib B Th5onche potenility
Losses are weighted about twice as much as gains in several contexts:
choice between gambles, the endowment effect, and reactions to price
changes. The loss-aversion coefficient is much higher in some situations.
In particular, you may be more loss averse for aspects of your life that are
more important than money, such as health. Furthermore, your reluctance
to “sell” important endowments increases dramatically when doing so
might make you responsible for an awful outcome. Richard Thaler’s early
classic on consumer behavior included a compelling example, slightly
modified in the following question:
You have been exposed to a disease which if contracted leads to
a quick and painless death within a week. The probability that you
have the disease is 1/1,000. There is a vaccine that is effective
only before any symptoms appear. What is the maximum you
would be willing to pay for the vaccine?
Most people are willing to pay a significant but limited amount. Facing the
possibility of death is unpleasant, but the risk is small and it seems
unreasonable to ruin yourself to avoid it. Now consider a slight variation:
Volunteers are needed for research on the above disease. All
that is required is that you expose yourself to a 1/1,000 chance of
contracting the disease. What is the minimum you would ask to
be paid in order to volunteer for this program? (You would not be
allowed to purchase the vaccine.)
As you might expect, the fee that volunteers set is far higher than the price
they were willing to pay for the vaccine. Thaler reported informally that a
typical ratio is about 50:1. The extremely high selling price reflects two
features of this problem. In the first place, you are not supposed to sell your
health; the transaction is not considered legitimate and the reluctance to
engage in it is expressed in a higher price. Perhaps most important, you
will be responsible for the outcome if it is bad. You know that if you wake
up one morning with symptoms indicating that you will soon be dead, you
will feel more regret in the second case than in the first, because you could
have rejected the idea of selling your health without even stopping to
consider the price. You could h