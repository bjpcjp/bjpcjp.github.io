# apxA-uncertainty-TFaS

Appendix A: Judgment Under Uncertainty:
Heuristics and Biases*
Amos Tversky and Daniel Kahneman
Many decisions are based on beliefs concerning the likelihood of uncertain
events such as the outcome of an election, the guilt of a defendant, or the
future value of the dollar. These beliefs are usually expressed in statements
such as “I think that…,” “chances are…,” “it is unlikely that…,” and so forth.
Occasionally, beliefs concerning uncertain events are expressed in
numerical form as odds or subjective probabilities. What determines such
beliefs? How do people assess the probability of an uncertain event or the
value of an uncertain quantity? This article shows that people rely on a
limited number of heuristic principles which reduce the complex tasks of
assessing probabilities and predicting values to simpler judgmental
operations. In general, these heuristics are quite useful, but sometimes
they lead to severe and systematic errors.
The subjective assessment of probability resembles the subjective
assessment of physical quantities such as distance or size. These
judgments are all based on data of limited validity, which are processed
according to heuristic rules. For example, the apparent distance of an
object is determined in part by its clarity. The more sharply the object is
seen, the closer it appears to be. This rule has some validity, because in
any given scene the more distant objects are seen less sharply than Vt
pofreak/>stimated when visibility is good because the objects are seen
sharply. Thus, the reliance on clarity as an indication of distance leads to
common biases. Such biases are also found in the intuitive judgment of
probability. This article describes three heuristics that are employed to
assess probabilities and to predict values. Biases to which these
heuristics lead are enumerated, and the applied and theoretical
implications of these observations are discussed.
Representativeness
Many of the probabilistic questions with which people are concerned
belong to one of the following types: What is the probability that object A
belongs to class B? What is the probability that event A originates from
process B? What is the probability that process B will generate event A? In
answering such questions, people typically rely on the representativeness
heuristic, in which probabilities are evaluated by the degree to which A is
representative of B, that is, by the degree to which A resembles B. For
example, when A is highly representative of B, the probability that A
originates from B is judged to be high. On the other hand, if A is not similar
to B, the probability that A originates from B is judged to be low.
For an illustration of judgment by representativeness, consider an
individual who has been described by a former neighbor as follows: “Steve
is very shy and withdrawn, invariably helpful, but with little interest in people,
or in the world of reality. A meek and tidy soul, he has a need for order and
structure, and a passion for detail.” How do people assess the probability
that Steve is engaged in a particular occupation from a list of possibilities
(for example, farmer, salesman, airline pilot, librarian, or physician)? How
do people order these occupations from most to least likely? In the
representativeness heuristic, the probability that Steve is a librarian, for
example, is assessed by the degree to which he is representative of, or
similar to, the stereotype of a librarian. Indeed, research with problems of
this type has shown that people order the occupations by probability and
by similarity in exactly the same way.1 This approach to the judgment of
probability 
leads 
to 
serious 
errors, 
because 
similarity, 
or
representativeness, is not influenced by several factors that should affect
judgments of probability.
Insensitivity to prior probability of outcomes. One of the factors that
have no effect on representativeness but should have a major effect on
probability is the prior probability, or base rate frequency, of the outcomes.
In the case of Steve, for example, the fact that there are many more
farmers than librarians in the population should enter into any reasonable
estimate of the probability that Steve is a librarian rather than a farmer.
Considerations of base-rate frequency, however, do not affect the
similarity of Steve to the stereotypes of librarians and farmers. If people
evaluate probability by representativeness, therefore, prior probabilities
will be neglected. This hypothesis was tested in an experiment where prior
probabilities were manipulated.2 Subjects were shown brief personality
descriptions of several individuals, allegedly sampled at random from a
group of 100 professionals—engineers and lawyers. The subjects were
asked to assess, for each description, the probability that it belonged to an
engineer rather than to a lawy [hanerser. In one experimental condition,
subjects were told that the group from which the descriptions had been
drawn consisted of 70 engineers and 30 lawyers. In another condition,
subjects were told that the group consisted of 30 engineers and 70
lawyers. The odds that any particular description belongs to an engineer
rather than to a lawyer should be higher in the first condition, where there is
a majority of engineers, than in the second condition, where there is a
majority of lawyers. Specifically, it can be shown by applying Bayes’ rule
that the ratio of these odds should be (.7/.3)2, or 5.44, for each description.
In a sharp violation of Bayes’ rule, the subjects in the two conditions
produced essentially the same probability judgments. Apparently, subjects
evaluated the likelihood that a particular description belonged to an
engineer rather than to a lawyer by the degree to which this description
was representative of the two stereotypes, with little or no regard for the
prior probabilities of the categories.
The subjects used prior probabilities correctly when they had no other
information. In the absence of a personality sketch, they judged the
probability that an unknown individual is an engineer to be .7 and .3,
respectively, in the two base-rate conditions. However, prior probabilities
were effectively ignored when a description was introduced, even when
this description was totally uninformative. The responses to the following
description illustrate this phenomenon:
Dick is a 30-year-old man. He is married with no children. A man
of high ability and high motivation, he promises to be quite
successful in his field. He is well liked by his colleagues.
This description was intended to convey no information relevant to the
question of whether Dick is an engineer or a lawyer. Consequently, the
probability that Dick is an engineer should equal the proportion of
engineers in the group, as if no description had been given. The subjects,
however, judged the probability of Dick being an engineer to be .5
regardless of whether the stated proportion of engineers in the group was
.7 or .3. Evidently, people respond differently when given no evidence and
when given worthless evidence. When no specific evidence is given, prior
probabilities are properly utilized; when worthless evidence is given, prior
probabilities are ignored.3
Insensitivity to sample size. To evaluate the probability of obtaining a
particular result in a sample drawn from a specified population, people
typically apply the representativeness heuristic. That is, they assess the
likelihood of a sample result, for example, that the average height in a
random sample often men will be 6 feet, by the similarity of this result to the
corresponding parameter (that is, to the average height in the population of
men). The similarity of a sample statistic to a population parameter does
not depend on the size of the sample. Consequently, if probabilities are
assessed by representativeness, then the judged probability of a sample
statistic will be essentially independent of sample size. Indeed, when
subjects assessed the distributions of average height for samples of
various sizes, they produced identical distributions. For example, the
probability of obtaining an average height greater than 6 feet was
assigned the same value for samples of 1,000, 100, and 10 men.4
Moreover, subjects failed to appreciate the role of sample size even when
it was emphasized in the formulation of the problem. Consider the
following question:
A certain town is s [ainquote wierved by two hospitals. In the
larger hospital about 45 babies are born each day, and in the
smaller hospital about 15 babies are born each day. As you
know, about 50% of all babies are boys. However, the exact
percentage varies from day to day.
Sometimes it may be higher than 50%, sometimes lower.
For a period of 1 year, each hospital recorded the days on
which more than 60% of the babies born were boys. Which
hospital do you think recorded more such days?
The larger hospital (21)
The smaller hospital (21)
About the same (that is, within 5% of each other) (53)
The values in parentheses are the number of undergraduate students who
chose each answer.
Most subjects judged the probability of obtaining more than 60% boys to
be the same in the small and in the large hospital, presumably because
these events are described by the same statistic and are therefore equally
representative of the general population. In contrast, sampling theory
entails that the expected number of days on which more than 60% of the
babies are boys is much greater in the small hospital than in the large one,
because a large sample is less likely to stray from 50%. This fundamental
notion of statistics is evidently not part of people’s repertoire of intuitions.
A similar insensitivity to sample size has been reported in judgments of
posterior probability, that is, of the probability that a sample has been
drawn from one population rather than from another. Consider the following
example:
Imagine an urn filled with balls, of which 2/3 are of one color and
1/3 of another. One individual has drawn 5 balls from the urn, and
found that 4 were red and 1 was white. Another individual has
drawn 20 balls and found that 12 were red and 8 were white.
Which of the two individuals should feel more confident that the
urn contains 2/3 red balls and 1/3 white balls, rather than the
opposite? What odds should each individual give?
In this problem, the correct posterior odds are 8 to 1 for the 4:1 sample
and 16 to 1 for the 12:8 sample, assuming equal prior probabilities.
However, most people feel that the first sample provides much stronger
evidence for the hypothesis that the urn is predominantly red, because the
proportion of red balls is larger in the first than in the second sample. Here
again, intuitive judgments are dominated by the sample proportion and are
essentially unaffected by the size of the sample, which plays a crucial role
in the determination of the actual posterior odds.5 In addition, intuitive
estimates of posterior odds are far less extreme than the correct values.
The underestimation of the impact of evidence has been observed
repeatedly in problems of this type.6 It has been labeled “conservatism.”
Misconceptions of chance. People expect that a sequence of events
generated by a random process will represent the essential characteristics
of that process even when the sequence is short. In considering tosses of
a coin for heads or tails, for example, people regard the sequence H-T-H-
T-T-H to be more likely than the sequence H-H-H-T- [enc. IT-T, which does
not appear random, and also more likely than the sequence H-H-H-H-T-H,
which does not represent the fairness of the coin.7 Thus, people expect
that the essential characteristics of the process will be represented, not
only globally in the entire sequence, but also locally in each of its parts. A
locally representative sequence, however, deviates systematically from
chance expectation: it contains too many alternations and too few runs.
Another consequence of the belief in local representativeness is the well-
known gambler’s fallacy. After observing a long run of red on the roulette
wheel, for example, most people erroneously believe that black is now due,
presumably because the occurrence of black will result in a more
representative sequence than the occurrence of an additional red. Chance
is commonly viewed as a self-correcting process in which a deviation in
one direction induces a deviation in the opposite direction to restore the
equilibrium. In fact, deviations are not “corrected” as a chance process
unfolds, they are merely diluted.
Misconceptions of chance are not limited to naive subjects. A study of
the statistical intuitions of experienced research psychologists8 revealed a
lingering belief in what may be called the “law of small numbers,” according
to which even small samples are highly representative of the populations
from which they are drawn. The responses of these investigators reflected
the expectation that a valid hypothesis about a population will be
represented by a statistically significant result in a sample with little regard
for its size. As a consequence, the researchers put too much faith in the
results of small samples and grossly overestimated the replicability of such
results. In the actual conduct of research, this bias leads to the selection of
samples of inadequate size and to overinterpretation of findings.
Insensitivity to predictability. People are sometimes called upon to
make such numerical predictions as the future value of a stock, the
demand for a commodity, or the outcome of a football game. Such
predictions are often made by representativeness. For example, suppose
one is given a description of a company and is asked to predict its future
profit. If the description of the company is very favorable, a very high profit
will appear most representative of that description; if the description is
mediocre, a mediocre performance will appear most representative. The
degree to which the description is favorable is unaffected by the reliability
of that description or by the degree to which it permits accurate prediction.
Hence, if people predict solely in terms of the favorableness of the
description, their predictions will be insensitive to the reliability of the
evidence and to the expected accuracy of the prediction.
This mode of judgment violates the normative statistical theory in which
the extremeness and the range of predictions are controlled by
considerations of predictability. When predictability is nil, the same
prediction should be made in all cases. For example, if the descriptions of
companies provide no information relevant to profit, then the same value
(such as average profit) should be predicted for all companies. If
predictability is perfect, of course, the values predicted will match the
actual values and the range of predictions will equal the range of
outcomes. In general, the higher the predictability, the wider the range of
predicted values.
Several studies of numerical prediction have demonstrated that intuitive
predictions violate this rule, and that subjects show little or no regard for
considerations of predictability.9 In one o [pand tf these studies, subjects
were presented with several paragraphs, each describing the performance
of a student teacher during a particular practice lesson. Some subjects
were asked to evaluate the quality of the lesson described in the
paragraph in percentile scores, relative to a specified population. Other
subjects were asked to predict, also in percentile scores, the standing of
each student teacher 5 years after the practice lesson. The judgments
made under the two conditions were identical. That is, the prediction of a
remote criterion (success of a teacher after 5 years) was identical to the
evaluation of the information on which the prediction was based (the quality
of the practice lesson). The students who made these predictions were
undoubtedly aware of the limited predictability of teaching competence on
the basis of a single trial lesson 5 years earlier; nevertheless, their
predictions were as extreme as their evaluations.
The illusion of validity. As we have seen, people often predict by
selecting the outcome (for example, an occupation) that is most
representative of the input (for example, the description of a person). The
confidence they have in their prediction depends primarily on the degree of
representativeness (that is, on the quality of the match between the
selected outcome and the input) with little or no regard for the factors that
limit predictive accuracy. Thus, people express great confidence in the
prediction that a person is a librarian when given a description of his
personality which matches the stereotype of librarians, even if the
description is scanty, unreliable, or outdated. The unwarranted confidence
which is produced by a good fit between the predicted outcome and the
input information may be called the illusion of validity. This illusion persists
even when the judge is aware of the factors that limit the accuracy of his
predictions. It is a common observation that psychologists who conduct
selection interviews often experience considerable confidence in their
predictions, even when they know of the vast literature that shows selection
interviews to be highly fallible. The continued reliance on the clinical
interview for selection, despite repeated demonstrations of its inadequacy,
amply attests to the strength of this effect.
The internal consistency of a pattern of inputs is a major determinant of
one’s confidence in predictions based on these inputs. For example,
people express more confidence in predicting the final grade point
average of a student whose first-year record consists entirely of B’s than in
predicting the grade point average of a student whose first-year record
includes many A’s and C’s. Highly consistent patterns are most often
observed when the input variables are highly redundant or correlated.
Hence, people tend to have great confidence in predictions based on
redundant input variables. However, an elementary result in the statistics of
correlation asserts that, given input variables of stated validity, a prediction
based on several such inputs can achieve higher accuracy when they are
independent of each other than when they are redundant or correlated.
Thus, redundancy among inputs decreases accuracy even as it increases
confidence, and people are often confident in predictions that are quite
likely to be off the mark.10
Misconceptions of regression. Suppose a large group of children has
been examined on two equivalent versions of an aptitude test. If one
selects ten children from among those who did best on one of the two
versions, he will usually find their performance on the second version to be
somewhat disappointing. Conversely, if one selects ten children from
among those who did worst on one version, they will be found, on the
average, to do somewhat better on the other version. Mo [r vs tre generally,
consider two variables X and Y which have the same distribution. If one
selects individuals whose average X score deviates from the mean of X by
k units, then the average of their Y scores will usually deviate from the
mean of Y by less than k units. These observations illustrate a general
phenomenon known as regression toward the mean, which was first
documented by Galton more than 100 years ago.
In the normal course of life, one encounters many instances of
regression toward the mean, in the comparison of the height of fathers and
sons, of the intelligence of husbands and wives, or of the performance of
individuals on consecutive examinations. Nevertheless, people do not
develop correct intuitions about this phenomenon. First, they do not expect
regression in many contexts where it is bound to occur. Second, when they
recognize the occurrence of regression, they often invent spurious causal
explanations for it.11 We suggest that the phenomenon of regre