---
title: "gradients"
layout: default-foundation-20210515
date: 2025-06-04
tags: [gradients]
---

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/foundation-sites@6.7.5/dist/css/foundation.min.css">

<div class="grid-container">
  <div class="callout">
    <h2>gradients</h2>
  </div>

  <div class="grid-x grid-margin-x small-up-1 medium-up-2 large-up-3">
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2025-04-30T16:15:03.622Z
        tags: machine-learning, gradients
        -->
        <div class="card-divider">
          <a href="https://poonai.xyz/posts/simplest-backpropagation-explainer-without-chain-rule/">Simplest backpropagation explainer without chain rule</a>
        </div>
        <div class="card-section">
          <p>Neural Networks learn to predict by backpropagation. This article aims to help you, build a solid intuition about the concept using a simple example. The ideas we learn here can be expanded for bigger nerual network. I assume that you already know how feed forward neural network works.
Before reading the article further, take a pen and paper. The calculation used in this article can be done in the head. But I still want you to do by hand.</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2017-12-18T03:22:54.000Z
        tags: deep-learning, gradients
        -->
        <div class="card-divider">
          <a href="https://machinelearningmastery.com/exploding-gradients-in-neural-networks">A Gentle Introduction to Exploding Gradients in Neural Networks</a>
        </div>
        <div class="card-image">
          <img src="https://machinelearningmastery.com/wp-content/uploads/2017/12/A-Gentle-Introduction-to-Exploding-Gradients-in-Recurrent-Neural-Networks.jpg" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>Exploding gradients are a problem where large error gradients accumulate and result in very large updates to neural network model weights during training. This has the effect of your model being unstable and unable to learn from your training data. In this post, you will discover the problem of exploding gradients with deep artificial neural networks. After completing this post,â€¦</p>
        </div>
      </div>
    </div>
  </div>
</div>
