---
title: "info-theory"
layout: default-foundation-20210515
date: 2025-06-04
tags: [info-theory]
---

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/foundation-sites@6.7.5/dist/css/foundation.min.css">

<div class="grid-container">
  <div class="callout">
    <h2>info-theory</h2>
  </div>

  <div class="grid-x grid-margin-x small-up-1 medium-up-2 large-up-3">
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2025-04-13T12:42:33.600Z
        tags: entropy, machine-learning, info-theory
        -->
        <div class="card-divider">
          <a href="https://eli.thegreenplace.net/2025/cross-entropy-and-kl-divergence/">Cross-entropy and KL divergence - Eli Bendersky's website</a>
        </div>
        <div class="card-image">
          <img src="https://eli.thegreenplace.net/images/2025/distrib-1-0s.png" alt="cover image" style="max-width: 100%;">
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2008-10-24T00:00:00.000Z
        tags: info-theory
        -->
        <div class="card-divider">
          <a href="https://towardsdatascience.com/understanding-kl-divergence-entropy-and-related-concepts-75e766a2fd9e?source=rss----7f60cf5620c9---4">Understanding KL Divergence Entropy and Related Concepts</a>
        </div>
        <div class="card-image">
          <img src="https://miro.medium.com/v2/resize:fit:1200/1*MDhu1KyK_OCx71Uuh8I59A.png" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>Important concepts in information theory, machine learning, and statistics</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2023-03-02T16:54:09.000Z
        tags: info-theory, machine-learning, prob-stats
        -->
        <div class="card-divider">
          <a href="https://towardsdatascience.com/how-to-understand-and-use-jensen-shannon-divergence-b10e11b03fd6?source=rss----7f60cf5620c9---4">How to Understand and Use the Jensen-Shannon Divergence</a>
        </div>
        <div class="card-image">
          <img src="https://miro.medium.com/v2/resize:fit:1020/1*iXqnpz9Rlxl2X83fAYxyLg.jpeg" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>A primer on  the math, logic, and pragmatic application of JS Divergence — including how it is best used in drift monitoring</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2021-06-29T20:10:21.000Z
        tags: info-theory
        -->
        <div class="card-divider">
          <a href="https://arxiv.org/pdf/1802.05968">1802</a>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2021-06-11T23:41:38.000Z
        tags: algorithms-math, info-theory
        -->
        <div class="card-divider">
          <a href="https://towardsdatascience.com/information-theory-a-gentle-introduction-6abaf99835ac?source=rss----7f60cf5620c9---4">Information Theory: A Gentle Introduction</a>
        </div>
        <div class="card-section">
          <p>This is the first in a series of articles about Information Theory and its relationship to data driven enterprises and strategy. While…</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2021-01-17T15:33:04.000Z
        tags: graphs, info-theory, machine-learning
        -->
        <div class="card-divider">
          <a href="https://towardsdatascience.com/link-prediction-and-information-theory-a-tutorial-a67ecc73e7f9?source=rss----7f60cf5620c9---4">Link Prediction and Information Theory: A Tutorial</a>
        </div>
        <div class="card-image">
          <img src="https://miro.medium.com/v2/resize:fit:1200/1*VK7jOqx6Vogs_-liMWe5cg.png" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>Using Mutual Information to measure the likelihood of candidate links in a graph.</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2020-12-18T11:21:57.000Z
        tags: info-theory
        -->
        <div class="card-divider">
          <a href="https://towardsdatascience.com/essential-math-for-data-science-information-theory-5d0380232ca1?source=rss----7f60cf5620c9---4">Essential Math for Data Science: Information Theory</a>
        </div>
        <div class="card-image">
          <img src="https://miro.medium.com/v2/resize:fit:967/1*7BxImLe30p6sT_UqwcDgNw.jpeg" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>Entropy, cross-entropy, log loss, and KL divergence</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2020-11-03T00:08:25.000Z
        tags: info-theory, machine-learning
        -->
        <div class="card-divider">
          <a href="https://machinelearningmastery.com/what-is-information-entropy">A Gentle Introduction to Information Entropy - MachineLearningMastery.com</a>
        </div>
        <div class="card-image">
          <img src="https://machinelearningmastery.com/wp-content/uploads/2019/10/Plot-of-Probability-Distribution-vs-Entropy.png" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>Information theory is a subfield of mathematics concerned with transmitting data across a noisy channel. A cornerstone of information theory is the idea of quantifying how much information there is in a message. More generally, this can be used to quantify the information in an event and a random variable, called entropy, and is calculated using probability. Calculating information and…</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2020-06-01T16:43:30.000Z
        tags: info-theory, machine-learning
        -->
        <div class="card-divider">
          <a href="https://towardsdatascience.com/entropy-and-information-gain-b738ca8abd2a?source=rss----7f60cf5620c9---4">Entropy and Information Gain</a>
        </div>
        <div class="card-image">
          <img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*i_v4XULShj9hU4nV" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>Yet another tool used to make Decision Tree splits.</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2020-05-10T18:51:14.000Z
        tags: info-theory, machine-learning
        -->
        <div class="card-divider">
          <a href="https://notamonadtutorial.com/a-brief-introduction-to-the-beauty-of-information-theory-8357f5b6a355">A brief introduction to the beauty of Information Theory</a>
        </div>
        <div class="card-section">
          <p>Lambdaclass's blog about distributed systems, machine learning, compilers, operating systems, security and cryptography.</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2020-02-09T19:33:12.000Z
        tags: info-theory
        -->
        <div class="card-divider">
          <a href="https://en.wikipedia.org/wiki/Gini_coefficient">Gini coefficient</a>
        </div>
        <div class="card-image">
          <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Map_of_countries_by_GINI_coefficient_%281990_to_2020%29.svg/1200px-Map_of_countries_by_GINI_coefficient_%281990_to_2020%29.svg.png" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>In economics, the Gini coefficient, also known as the Gini index or Gini ratio, is a measure of statistical dispersion intended to represent the income inequality, the wealth inequality, or the consumption inequality within a nation or a social group. It was developed by Italian statistician and sociologist Corrado Gini.</p>
        </div>
      </div>
    </div>
  </div>
</div>
