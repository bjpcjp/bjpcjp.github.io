---
title: "bandits"
layout: default-foundation-20210515
date: 2025-06-04
tags: [bandits]
---

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/foundation-sites@6.7.5/dist/css/foundation.min.css">

<div class="grid-container">
  <div class="callout">
    <h2>bandits</h2>
  </div>

  <div class="grid-x grid-margin-x small-up-1 medium-up-2 large-up-3">
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2024-02-03T03:02:05.000Z
        tags: bandits, machine-learning
        -->
        <div class="card-divider">
          <a href="https://towardsdatascience.com/an-overview-of-contextual-bandits-53ac3aa45034?source=rss----7f60cf5620c9---4">An Overview of Contextual Bandits</a>
        </div>
        <div class="card-image">
          <img src="https://miro.medium.com/v2/resize:fit:1200/1*YOsWxbHyU-J7C0s9KOyUDw.png" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>A dynamic approach to treatment personalization</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2023-08-19T13:36:19.000Z
        tags: bandits, machine-learning, pricing, prodmgmt
        -->
        <div class="card-divider">
          <a href="https://towardsdatascience.com/dynamic-pricing-with-multi-armed-bandit-learning-by-doing-3e4550ed02ac">Dynamic Pricing with Multi-Armed Bandit: Learning by Doing!</a>
        </div>
        <div class="card-image">
          <img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*PtB_85QrbCPNJXXb" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>Applying Reinforcement Learning strategies to real-world use cases, especially in dynamic pricing, can reveal many surprises</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2023-01-07T20:33:29.000Z
        tags: algorithms-math, bandits, machine-learning
        -->
        <div class="card-divider">
          <a href="https://www.kdnuggets.com/2023/01/introduction-multiarmed-bandit-problems.html">Introduction to Multi-Armed Bandit Problems</a>
        </div>
        <div class="card-image">
          <img src="https://www.kdnuggets.com/wp-content/uploads/popovic_introduction_multiarmed_bandit_problems_1.png" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>Delve deeper into the concept of multi-armed bandits, reinforcement learning, and exploration vs. exploitation dilemma.</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2022-07-19T00:29:00.000Z
        tags: algorithms-math, analytics, bandits
        -->
        <div class="card-divider">
          <a href="https://blog.thedataincubator.com/2016/07/multi-armed-bandits-2">The Data Incubator is Now Pragmatic Data | Pragmatic Institute</a>
        </div>
        <div class="card-image">
          <img src="https://www.pragmaticinstitute.com/resources/wp-content/uploads/sites/6/2024/01/tditopragmatic.jpg" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>As of 2024, The Data Incubator is now Pragmatic Data! Explore Pragmatic Institute’s new offerings, learn about team training opportunities, and more.</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2022-07-18T15:02:21.000Z
        tags: bandits, recommenders
        -->
        <div class="card-divider">
          <a href="https://blog.insightdatascience.com/multi-armed-bandits-for-dynamic-movie-recommendations-5eb8f325ed1d">Multi-armed bandits for dynamic movie recommendations</a>
        </div>
        <div class="card-image">
          <img src="https://miro.medium.com/v2/resize:fit:1200/0*k3FsfPU592DBgMfx." alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>Making the best recommendations to anonymous audiences</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2022-03-27T19:06:08.000Z
        tags: bandits, machine-learning
        -->
        <div class="card-divider">
          <a href="https://towardsdatascience.com/multi-armed-bandit-algorithms-thompson-sampling-6d91a88145db?source=rss----7f60cf5620c9---4">Multi-Armed Bandit Algorithms: Thompson Sampling</a>
        </div>
        <div class="card-image">
          <img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*9YMbE-00b8VRceig" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>Intuition, Bayes, and an example</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2021-03-20T10:53:46.000Z
        tags: bandits, golang, machine-learning
        -->
        <div class="card-divider">
          <a href="https://github.com/stitchfix/mab">stitchfix/mab: Library for multi-armed bandit selection strategies, including efficient deterministic implementations of Thompson sampling and epsilon-greedy.</a>
        </div>
        <div class="card-image">
          <img src="https://repository-images.githubusercontent.com/340162521/d1711100-774c-11eb-86cb-e4a5c793ebc8" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>Library for multi-armed bandit selection strategies, including efficient deterministic implementations of Thompson sampling and epsilon-greedy. - stitchfix/mab</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2021-03-10T10:29:56.000Z
        tags: bandits, machine-learning
        -->
        <div class="card-divider">
          <a href="https://towardsdatascience.com/thompson-sampling-using-conjugate-priors-e0a18348ea2d">Thompson Sampling using Conjugate Priors</a>
        </div>
        <div class="card-image">
          <img src="https://miro.medium.com/v2/da:true/resize:fit:712/1*_Gqr8su3G4inxRnEuTbC4Q.gif" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>Multi-Armed Bandits: Part 5b</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2020-11-10T17:51:02.000Z
        tags: algorithms-math, bandits, machine-learning
        -->
        <div class="card-divider">
          <a href="https://towardsdatascience.com/a-comparison-of-bandit-algorithms-24b4adfcabb?source=rss----7f60cf5620c9---4">A Comparison of Bandit Algorithms</a>
        </div>
        <div class="card-image">
          <img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*e7T9wQtgE2cro-mC" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>Multi-Armed Bandits: Part 6</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2020-11-03T00:31:42.000Z
        tags: bandits, prodmgmt
        -->
        <div class="card-divider">
          <a href="https://multithreaded.stitchfix.com/blog/2020/08/05/bandits">Multi-Armed Bandits and the Stitch Fix Experimentation Platform</a>
        </div>
        <div class="card-image">
          <img src="https://multithreaded.stitchfix.com/assets/posts/2020-08-05-bandits/multi_armed_bandit.png" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>We've recently built support for multi-armed bandits into the Stitch Fix experimentation platform. This post will explain how and why.</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2020-11-02T23:50:11.000Z
        tags: bandits
        -->
        <div class="card-divider">
          <a href="https://towardsdatascience.com/bandit-algorithms-34fd7890cb18?source=rss----7f60cf5620c9---4">Bandit Algorithms</a>
        </div>
        <div class="card-image">
          <img src="https://miro.medium.com/v2/da:true/resize:fit:1200/0*Qh6b6kmOXe6Z87sG" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>Multi-Armed Bandits: Part 3</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2020-05-15T11:29:27.000Z
        tags: bandits
        -->
        <div class="card-divider">
          <a href="https://medium.com/expedia-group-tech/how-we-optimized-hero-images-on-hotels-com-using-multi-armed-bandit-algorithms-4503c2c32eae">How We Optimized Hero Images on Hotels.com using Multi-Armed Bandit Algorithms</a>
        </div>
        <div class="card-image">
          <img src="https://miro.medium.com/v2/resize:fit:770/1*4u5qpI-eOTFBbUnH6dVH9w.png" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>Introducing the multi-armed bandit (MAB) optimization used for hero images on hotels.com</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2020-03-09T20:16:47.000Z
        tags: bandits, machine-learning
        -->
        <div class="card-divider">
          <a href="https://www.microsoft.com/en-us/research/blog/exploring-the-fundamentals-of-multi-armed-bandits">Exploring the fundamentals of multi-armed bandits</a>
        </div>
        <div class="card-image">
          <img src="https://www.microsoft.com/en-us/research/uploads/prod/2020/02/MSFT_Research_MultiarmedBandit_final_1400X788_final.png" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>Multi-armed bandits are a simple but very powerful framework for algorithms that make decisions over time under uncertainty. “Introduction to Multi-Armed Bandits” by Alex Slivkins provides an accessible, textbook-like treatment of the subject.</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2020-02-19T20:09:34.000Z
        tags: bandits, bayes
        -->
        <div class="card-divider">
          <a href="https://mlwhiz.com/blog/2019/07/21/bandits">Bayesian Bandits explained simply - MLWhiz</a>
        </div>
        <div class="card-image">
          <img src="https://mlwhiz.com/images/bandits/1.png" alt="cover image" style="max-width: 100%;">
        </div>
        <div class="card-section">
          <p>There are multiple ways to doing the same thing in Pandas, and that might make it troublesome for the beginner user.This post is about handling most of the data manipulation cases in Python using a straightforward, simple, and matter of fact way.</p>
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2018-08-31T20:23:22.000Z
        tags: bandits
        -->
        <div class="card-divider">
          <a href="http://banditalgs.com">Bandit Algorithms</a>
        </div>
        <div class="card-image">
          <img src="https://banditalgs.com/wp-content/uploads/2019/03/cropped-bandit-1.png" alt="cover image" style="max-width: 100%;">
        </div>
      </div>
    </div>
    <div class="cell">
      <div class="card" style="margin-bottom: 1rem; border-radius: 5px;">
        <!--
        created: 2017-10-23T00:08:25.000Z
        tags: bandits
        -->
        <div class="card-divider">
          <a href="https://support.google.com/analytics/answer/2844870">https://support.google.com/analytics/answer/2844870</a>
        </div>
      </div>
    </div>
  </div>
</div>
