{"status": 1, "complete": 1, "list": {"3906633794": {"item_id": "3906633794", "resolved_id": "3906633797", "given_url": "http://d.repec.org/n?u=RePEc:arx:papers:2306.07709&r=gth", "given_title": "Coordinated Dynamic Bidding in Repeated Second-Price Auctions with Budgets", "favorite": "0", "status": "1", "time_added": "1689881161", "time_updated": "1690067593", "time_read": "1690067593", "time_favorited": "0", "sort_id": 0, "resolved_title": "", "resolved_url": "http://arxiv.org/pdf/2306.07709", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"arxiv": {"item_id": "3906633794", "tag": "arxiv"}, "auctions": {"item_id": "3906633794", "tag": "auctions"}, "game-theory": {"item_id": "3906633794", "tag": "game-theory"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "1617384831": {"item_id": "1617384831", "resolved_id": "1617384831", "given_url": "https://arxiv.org/abs/1702.04680v1", "given_title": "[1702.04680v1] Visual Discovery at Pinterest", "favorite": "0", "status": "1", "time_added": "1671647709", "time_updated": "1671648672", "time_read": "1671648672", "time_favorited": "0", "sort_id": 1, "resolved_title": "Title:Visual Discovery at Pinterest", "resolved_url": "https://arxiv.org/abs/1702.04680v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"arxiv": {"item_id": "1617384831", "tag": "arxiv"}, "discovery": {"item_id": "1617384831", "tag": "discovery"}, "images": {"item_id": "1617384831", "tag": "images"}, "pinterest": {"item_id": "1617384831", "tag": "pinterest"}, "search": {"item_id": "1617384831", "tag": "search"}, "vision": {"item_id": "1617384831", "tag": "vision"}}, "authors": {"63380980": {"item_id": "1617384831", "author_id": "63380980", "name": "cs", "url": "https://arxiv.org/abs/1702.04680?context=cs"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3328921155": {"item_id": "3328921155", "resolved_id": "3329137732", "given_url": "https://arxiv.org/abs/2105.04026", "given_title": "", "favorite": "0", "status": "1", "time_added": "1651363883", "time_updated": "1651418266", "time_read": "1651418265", "time_favorited": "0", "sort_id": 2, "resolved_title": "Title:The Modern Mathematics of Deep Learning", "resolved_url": "https://arxiv.org/abs/2105.04026v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"arxiv": {"item_id": "3328921155", "tag": "arxiv"}, "deep-learning": {"item_id": "3328921155", "tag": "deep-learning"}}, "authors": {"63380735": {"item_id": "3328921155", "author_id": "63380735", "name": "cs stat stat.ML", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3465800320": {"item_id": "3465800320", "resolved_id": "3465800328", "given_url": "https://arxiv.org/abs/2110.13041#", "given_title": "", "favorite": "0", "status": "1", "time_added": "1635294687", "time_updated": "1635468996", "time_read": "1635468996", "time_favorited": "0", "sort_id": 3, "resolved_title": "Title:Applications and Techniques for Fast Machine Learning in Science", "resolved_url": "https://arxiv.org/abs/2110.13041v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"arxiv": {"item_id": "3465800320", "tag": "arxiv"}, "deep-learning": {"item_id": "3465800320", "tag": "deep-learning"}, "machine-learning": {"item_id": "3465800320", "tag": "machine-learning"}}, "authors": {"152897030": {"item_id": "3465800320", "author_id": "152897030", "name": "cs cs.AR physics", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3526769589": {"item_id": "3526769589", "resolved_id": "3526769589", "given_url": "https://arxiv.org/abs/2201.02605v2", "given_title": "", "favorite": "0", "status": "1", "time_added": "1642022243", "time_updated": "1642028814", "time_read": "1642028813", "time_favorited": "0", "sort_id": 4, "resolved_title": "Title:Detecting Twenty-thousand Classes using Image-level Supervision", "resolved_url": "https://arxiv.org/abs/2201.02605v2", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"arxiv": {"item_id": "3526769589", "tag": "arxiv"}, "deep-learning": {"item_id": "3526769589", "tag": "deep-learning"}, "machine-vision": {"item_id": "3526769589", "tag": "machine-vision"}}, "authors": {"162218028": {"item_id": "3526769589", "author_id": "162218028", "name": "cs", "url": "https://arxiv.org/abs/2201.02605?context=cs"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3616331693": {"item_id": "3616331693", "resolved_id": "3616331700", "given_url": "https://arxiv.org/abs/2205.02302", "given_title": "", "favorite": "0", "status": "1", "time_added": "1657419529", "time_updated": "1660827285", "time_read": "1657675878", "time_favorited": "0", "sort_id": 5, "resolved_title": "Title:Machine Learning Operations (MLOps): Overview, Definition, and Architecture", "resolved_url": "https://arxiv.org/abs/2205.02302v2", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"arxiv": {"item_id": "3616331693", "tag": "arxiv"}, "devops": {"item_id": "3616331693", "tag": "devops"}, "machine-learning": {"item_id": "3616331693", "tag": "machine-learning"}}, "authors": {"167453314": {"item_id": "3616331693", "author_id": "167453314", "name": "cs", "url": "https://arxiv.org/abs/2205.02302?context=cs"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3670662051": {"item_id": "3670662051", "resolved_id": "3670662069", "given_url": "https://arxiv.org/abs/2206.14007", "given_title": "[2206.14007] The Importance of (Exponentially More) Computing Power", "favorite": "0", "status": "1", "time_added": "1659184443", "time_updated": "1659212726", "time_read": "1659212726", "time_favorited": "0", "sort_id": 6, "resolved_title": "Title:The Importance of (Exponentially More) Computing Power", "resolved_url": "https://arxiv.org/abs/2206.14007v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"arxiv": {"item_id": "3670662051", "tag": "arxiv"}}, "authors": {"136498419": {"item_id": "3670662051", "author_id": "136498419", "name": "cs cs.CY cs.PF", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3655631329": {"item_id": "3655631329", "resolved_id": "3655523951", "given_url": "https://arxiv.org/abs/2207.02696", "given_title": "", "favorite": "0", "status": "1", "time_added": "1658149840", "time_updated": "1658187784", "time_read": "1658187784", "time_favorited": "0", "sort_id": 7, "resolved_title": "Title:YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors", "resolved_url": "https://arxiv.org/abs/2207.02696v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"arxiv": {"item_id": "3655631329", "tag": "arxiv"}, "machine-learning": {"item_id": "3655631329", "tag": "machine-learning"}, "machine-vision": {"item_id": "3655631329", "tag": "machine-vision"}}, "authors": {"169614829": {"item_id": "3655631329", "author_id": "169614829", "name": "cs", "url": "https://arxiv.org/abs/2207.02696?context=cs"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3778853523": {"item_id": "3778853523", "resolved_id": "3778853525", "given_url": "https://arxiv.org/abs/2301.00774", "given_title": "", "favorite": "0", "status": "1", "time_added": "1683204357", "time_updated": "1683253509", "time_read": "1683253509", "time_favorited": "0", "sort_id": 8, "resolved_title": "Title:Massive Language Models Can Be Accurately Pruned in One-Shot", "resolved_url": "https://arxiv.org/abs/2301.00774v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"arxiv": {"item_id": "3778853523", "tag": "arxiv"}, "llms": {"item_id": "3778853523", "tag": "llms"}}, "authors": {"176565962": {"item_id": "3778853523", "author_id": "176565962", "name": "cs", "url": "https://arxiv.org/abs/2301.00774?context=cs"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3800647893": {"item_id": "3800647893", "resolved_id": "3797920240", "given_url": "https://arxiv.org/abs/2301.03881?utm_source=substack&utm_medium=email", "given_title": "", "favorite": "0", "status": "1", "time_added": "1675591867", "time_updated": "1679781251", "time_read": "1675948854", "time_favorited": "0", "sort_id": 9, "resolved_title": "Title:Why People Skip Music? On Predicting Music Skips using Deep Reinforcement Learning", "resolved_url": "https://arxiv.org/abs/2301.03881v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"arxiv": {"item_id": "3800647893", "tag": "arxiv"}, "music": {"item_id": "3800647893", "tag": "music"}, "reinforcement-learning": {"item_id": "3800647893", "tag": "reinforcement-learning"}}, "authors": {"177703994": {"item_id": "3800647893", "author_id": "177703994", "name": "cs", "url": "https://arxiv.org/abs/2301.03881?context=cs"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3807601744": {"item_id": "3807601744", "resolved_id": "3807601748", "given_url": "https://arxiv.org/abs/2302.07730", "given_title": "[2302.07730] Transformer models: an introduction and catalog", "favorite": "0", "status": "1", "time_added": "1696342638", "time_updated": "1696545966", "time_read": "1696545966", "time_favorited": "0", "sort_id": 10, "resolved_title": "Title:Transformer models: an introduction and catalog", "resolved_url": "https://arxiv.org/abs/2302.07730v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"arxiv": {"item_id": "3807601744", "tag": "arxiv"}, "llms": {"item_id": "3807601744", "tag": "llms"}, "transformers": {"item_id": "3807601744", "tag": "transformers"}}, "authors": {"178290250": {"item_id": "3807601744", "author_id": "178290250", "name": "cs", "url": "https://arxiv.org/abs/2302.07730?context=cs"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3838345443": {"item_id": "3838345443", "resolved_id": "3838332429", "given_url": "https://arxiv.org/abs/2303.18223#", "given_title": "", "favorite": "0", "status": "1", "time_added": "1680575326", "time_updated": "1681439192", "time_read": "1681439192", "time_favorited": "0", "sort_id": 11, "resolved_title": "Title:A Survey of Large Language Models", "resolved_url": "https://arxiv.org/abs/2303.18223v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "72", "lang": "en", "top_image_url": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png", "tags": {"arxiv": {"item_id": "3838345443", "tag": "arxiv"}, "deep-learning": {"item_id": "3838345443", "tag": "deep-learning"}, "llms": {"item_id": "3838345443", "tag": "llms"}}, "authors": {"180127060": {"item_id": "3838345443", "author_id": "180127060", "name": "Wayne Xin Zhao", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 28}, "3839259196": {"item_id": "3839259196", "resolved_id": "3839259201", "given_url": "https://arxiv.org/abs/2304.00612", "given_title": "", "favorite": "0", "status": "1", "time_added": "1681265983", "time_updated": "1682120635", "time_read": "1682120635", "time_favorited": "0", "sort_id": 12, "resolved_title": "Title:Eight Things to Know about Large Language Models", "resolved_url": "https://arxiv.org/abs/2304.00612v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "72", "lang": "en", "top_image_url": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png", "tags": {"arxiv": {"item_id": "3839259196", "tag": "arxiv"}, "llms": {"item_id": "3839259196", "tag": "llms"}}, "authors": {"67155460": {"item_id": "3839259196", "author_id": "67155460", "name": "cs   cs.AI", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 28}, "3842743357": {"item_id": "3842743357", "resolved_id": "3842743363", "given_url": "https://arxiv.org/abs/2304.03262", "given_title": "", "favorite": "0", "status": "1", "time_added": "1681138519", "time_updated": "1681562877", "time_read": "1681562877", "time_favorited": "0", "sort_id": 13, "resolved_title": "Title:When do you need Chain-of-Thought Prompting for ChatGPT?", "resolved_url": "https://arxiv.org/abs/2304.03262v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "72", "lang": "en", "top_image_url": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png", "tags": {"arxiv": {"item_id": "3842743357", "tag": "arxiv"}, "chatgpt": {"item_id": "3842743357", "tag": "chatgpt"}}, "authors": {"180375531": {"item_id": "3842743357", "author_id": "180375531", "name": "Jiuhai Chen", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 28}, "3853149840": {"item_id": "3853149840", "resolved_id": "3853149846", "given_url": "https://arxiv.org/abs/2304.12210", "given_title": "", "favorite": "0", "status": "1", "time_added": "1682424863", "time_updated": "1682439365", "time_read": "1682439364", "time_favorited": "0", "sort_id": 14, "resolved_title": "Title:A Cookbook of Self-Supervised Learning", "resolved_url": "https://arxiv.org/abs/2304.12210v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "72", "lang": "en", "top_image_url": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png", "tags": {"arxiv": {"item_id": "3853149840", "tag": "arxiv"}, "self-supervised": {"item_id": "3853149840", "tag": "self-supervised"}}, "authors": {"110546513": {"item_id": "3853149840", "author_id": "110546513", "name": "Randall Balestriero", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 28}, "3858856237": {"item_id": "3858856237", "resolved_id": "3858843495", "given_url": "https://arxiv.org/abs/2305.02301", "given_title": "", "favorite": "0", "status": "1", "time_added": "1683204097", "time_updated": "1683253521", "time_read": "1683253521", "time_favorited": "0", "sort_id": 15, "resolved_title": "Title:Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes", "resolved_url": "https://arxiv.org/abs/2305.02301v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "72", "lang": "en", "top_image_url": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png", "tags": {"arxiv": {"item_id": "3858856237", "tag": "arxiv"}, "llms": {"item_id": "3858856237", "tag": "llms"}}, "authors": {"102565068": {"item_id": "3858856237", "author_id": "102565068", "name": "cs   cs.AI   cs.LG", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 28}, "30959224": {"item_id": "30959224", "resolved_id": "30959224", "given_url": "https://arxiv.org/list/cs.GT/recent", "given_title": "Computer Science and Game Theory authors/titles recent submissions", "favorite": "0", "status": "1", "time_added": "1643916870", "time_updated": "1643917238", "time_read": "1643917238", "time_favorited": "0", "sort_id": 16, "resolved_title": "Computer Science and Game Theory authors/titles recent submissions", "resolved_url": "https://arxiv.org/list/cs.GT/recent", "excerpt": "Links to: arXiv, form interface, find, cs, new, 2208, contact, help (Access key information)", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "13", "lang": "en", "tags": {"arxiv": {"item_id": "30959224", "tag": "arxiv"}, "game-theory": {"item_id": "30959224", "tag": "game-theory"}}, "authors": {"171366748": {"item_id": "30959224", "author_id": "171366748", "name": "Nika Haghtalab", "url": "https://arxiv.org/search/cs?searchtype=author&query=Haghtalab%2C+N"}, "171366749": {"item_id": "30959224", "author_id": "171366749", "name": "Thodoris Lykouris", "url": "https://arxiv.org/search/cs?searchtype=author&query=Lykouris%2C+T"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 5}, "2420681424": {"item_id": "2420681424", "resolved_id": "2420681424", "given_url": "https://arxiv.org/pdf/1811.12808.pdf", "given_title": "1811.12808.pdf", "favorite": "0", "status": "1", "time_added": "1678978558", "time_updated": "1678979878", "time_read": "1678979878", "time_favorited": "0", "sort_id": 17, "resolved_title": "", "resolved_url": "https://arxiv.org/pdf/1811.12808.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"arxiv": {"item_id": "2420681424", "tag": "arxiv"}, "machine-learning": {"item_id": "2420681424", "tag": "machine-learning"}, "model-selection": {"item_id": "2420681424", "tag": "model-selection"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "2914864485": {"item_id": "2914864485", "resolved_id": "2914864485", "given_url": "https://arxiv.org/pdf/2003.05689.pdf", "given_title": "2003.05689.pdf", "favorite": "0", "status": "1", "time_added": "1678978527", "time_updated": "1678979884", "time_read": "1678979884", "time_favorited": "0", "sort_id": 18, "resolved_title": "", "resolved_url": "https://arxiv.org/pdf/2003.05689.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"arxiv": {"item_id": "2914864485", "tag": "arxiv"}, "hyperparameters": {"item_id": "2914864485", "tag": "hyperparameters"}, "machine-learning": {"item_id": "2914864485", "tag": "machine-learning"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3298432611": {"item_id": "3298432611", "resolved_id": "3298432611", "given_url": "https://arxiv.org/pdf/2012.03854.pdf", "given_title": "2012.03854.pdf", "favorite": "0", "status": "1", "time_added": "1678978504", "time_updated": "1691367788", "time_read": "1678979908", "time_favorited": "0", "sort_id": 19, "resolved_title": "", "resolved_url": "https://arxiv.org/pdf/2012.03854.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"arxiv": {"item_id": "3298432611", "tag": "arxiv"}, "forecasting-predictions": {"item_id": "3298432611", "tag": "forecasting-predictions"}, "machine-learning": {"item_id": "3298432611", "tag": "machine-learning"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3400994309": {"item_id": "3400994309", "resolved_id": "3400994309", "given_url": "https://arxiv.org/pdf/2108.02497.pdf", "given_title": "2108.02497.pdf", "favorite": "0", "status": "1", "time_added": "1678978581", "time_updated": "1678979871", "time_read": "1678979871", "time_favorited": "0", "sort_id": 20, "resolved_title": "", "resolved_url": "https://arxiv.org/pdf/2108.02497.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"arxiv": {"item_id": "3400994309", "tag": "arxiv"}, "best-practices": {"item_id": "3400994309", "tag": "best-practices"}, "machine-learning": {"item_id": "3400994309", "tag": "machine-learning"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3556954695": {"item_id": "3556954695", "resolved_id": "3556954695", "given_url": "https://arxiv.org/pdf/2202.06512.pdf", "given_title": "A Comprehensive Benchmark of Deep Learning Libraries on Mobile DevicesA Com", "favorite": "0", "status": "1", "time_added": "1645365754", "time_updated": "1645367131", "time_read": "1645367131", "time_favorited": "0", "sort_id": 21, "resolved_title": "", "resolved_url": "https://arxiv.org/pdf/2202.06512.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"arxiv": {"item_id": "3556954695", "tag": "arxiv"}, "deep-learning": {"item_id": "3556954695", "tag": "deep-learning"}, "mobile": {"item_id": "3556954695", "tag": "mobile"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3579342899": {"item_id": "3579342899", "resolved_id": "3579342899", "given_url": "https://arxiv.org/pdf/2203.10716.pdf", "given_title": "Forecast Evaluation for Data Scientists: Common Pitfalls and Best Practices", "favorite": "0", "status": "1", "time_added": "1678978626", "time_updated": "1691367788", "time_read": "1678979850", "time_favorited": "0", "sort_id": 22, "resolved_title": "", "resolved_url": "https://arxiv.org/pdf/2203.10716.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"arxiv": {"item_id": "3579342899", "tag": "arxiv"}, "best-practices": {"item_id": "3579342899", "tag": "best-practices"}, "forecasting-predictions": {"item_id": "3579342899", "tag": "forecasting-predictions"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3763435562": {"item_id": "3763435562", "resolved_id": "3763435562", "given_url": "https://arxiv.org/pdf/2212.03551.pdf", "given_title": "2212.03551.pdf", "favorite": "0", "status": "1", "time_added": "1670772971", "time_updated": "1675817032", "time_read": "1670778218", "time_favorited": "0", "sort_id": 23, "resolved_title": "", "resolved_url": "https://arxiv.org/pdf/2212.03551.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"arxiv": {"item_id": "3763435562", "tag": "arxiv"}, "chatgpt": {"item_id": "3763435562", "tag": "chatgpt"}, "deep-learning": {"item_id": "3763435562", "tag": "deep-learning"}, "nlp": {"item_id": "3763435562", "tag": "nlp"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "2933220996": {"item_id": "2933220996", "resolved_id": "2933220996", "given_url": "https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf", "given_title": "language_understanding_paper.pdf", "favorite": "0", "status": "1", "time_added": "1706542969", "time_updated": "1707015414", "time_read": "1707015414", "time_favorited": "0", "sort_id": 24, "resolved_title": "", "resolved_url": "https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"arxiv": {"item_id": "2933220996", "tag": "arxiv"}, "gpt": {"item_id": "2933220996", "tag": "gpt"}}, "listen_duration_estimate": 0}, "3475172610": {"item_id": "3475172610", "resolved_id": "3475172610", "given_url": "https://github.com/louisfb01/best_AI_papers_2021", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638485938", "time_updated": "1638535484", "time_read": "1638535484", "time_favorited": "0", "sort_id": 25, "resolved_title": "2021: A Year Full of Amazing AI papers- A Review 📌", "resolved_url": "https://github.com/louisfb01/best_AI_papers_2021", "excerpt": "2021: A Year Full of Amazing AI papers- A Review 📌 A curated list of the latest breakthroughs in AI by release date with a clear video explanation, link to a more in-depth article, and code.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "5411", "lang": "en", "time_to_read": 25, "top_image_url": "https://opengraph.githubassets.com/fb1c6973f8eb18430fea4be9eab642f453e3e0009d93f18cfb391113886be941/louisfb01/best_AI_papers_2021", "tags": {"arxiv": {"item_id": "3475172610", "tag": "arxiv"}, "deep-learning": {"item_id": "3475172610", "tag": "deep-learning"}, "paperswithcode": {"item_id": "3475172610", "tag": "paperswithcode"}}, "authors": {"145487610": {"item_id": "3475172610", "author_id": "145487610", "name": "StyleGAN Interpolation Optimization", "url": ""}}, "image": {"item_id": "3475172610", "src": "https://camo.githubusercontent.com/ac03d4551fb2b24c33e58bcfdde1be521e68380bdb674ff734bdc53a18406028/68747470733a2f2f696d6775722e636f6d2f334f6f4e4f67312e706e67", "width": "512", "height": "0"}, "images": {"1": {"item_id": "3475172610", "image_id": "1", "src": "https://camo.githubusercontent.com/ac03d4551fb2b24c33e58bcfdde1be521e68380bdb674ff734bdc53a18406028/68747470733a2f2f696d6775722e636f6d2f334f6f4e4f67312e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3475172610", "image_id": "2", "src": "https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3475172610", "image_id": "3", "src": "https://camo.githubusercontent.com/654857df9fd7bf3491c650549e85a5f0885ec643b769c97d0d4e8f060e0964f0/68747470733a2f2f696d6775722e636f6d2f437a64797563652e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3475172610", "image_id": "4", "src": "https://camo.githubusercontent.com/9cdda4947f8b5d0c94c7ea663fbee70969323d1fb5c9efecb81411a1bb426f51/68747470733a2f2f696d6775722e636f6d2f46514c396277552e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3475172610", "image_id": "5", "src": "https://camo.githubusercontent.com/43e4dedbd953f8705325634e9653f79ed075ae9754bce1faf0e9dc04b1f89fca/68747470733a2f2f696d6775722e636f6d2f307a555931746d2e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3475172610", "image_id": "6", "src": "https://camo.githubusercontent.com/a89999da84f042015aefc440eadd3f666b4fe5545ae5f225d72a2c18270d6af5/68747470733a2f2f696d6775722e636f6d2f48385835386c622e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3475172610", "image_id": "7", "src": "https://camo.githubusercontent.com/659f7904f8db16bf47e074e150f211a4ae143e69bd7dc2eaae4432a87d195f1f/68747470733a2f2f696d6775722e636f6d2f4d6d6c59626c562e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3475172610", "image_id": "8", "src": "https://camo.githubusercontent.com/70b56c1f96eeb4545b9822178608e71e95c4ba6eca0e74661ed90d456cebd6d9/68747470733a2f2f696d6775722e636f6d2f5756366c7135732e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3475172610", "image_id": "9", "src": "https://camo.githubusercontent.com/1d972300e6ec5b53428c42f081b48b72ed8c11f1c5d0bd14ab1b81d94bd765cd/68747470733a2f2f696d6775722e636f6d2f434a7a474878612e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3475172610", "image_id": "10", "src": "https://camo.githubusercontent.com/383c783dd9d928a7eebcb6f422d0c0c0accc5dab6811005db33c0d75416734b4/68747470733a2f2f696d6775722e636f6d2f564b5a725442482e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3475172610", "image_id": "11", "src": "https://camo.githubusercontent.com/0129edc64e51857cb185698e4ce94853faf28cd777ee0c7f16c59e4354d151d2/68747470733a2f2f696d6775722e636f6d2f7239614c3269552e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3475172610", "image_id": "12", "src": "https://camo.githubusercontent.com/ec90296a1bb5788b3817397cebbb4be4f5f59f459d6ec5306ee409a6a015d971/68747470733a2f2f696d6775722e636f6d2f4a4a35554145702e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3475172610", "image_id": "13", "src": "https://camo.githubusercontent.com/c8a620db88e78103508e944188a852f8d6d01368b8d8fda33054a0b96454760b/68747470733a2f2f696d6775722e636f6d2f5051583850686a2e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "3475172610", "image_id": "14", "src": "https://camo.githubusercontent.com/f27cc7b02ef17b773f39a4dca6c339aad787b90ecafa4ade4d12cadc60f58edf/68747470733a2f2f696d6775722e636f6d2f657a49596365372e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "3475172610", "image_id": "15", "src": "https://camo.githubusercontent.com/1799545a9f506b342726ffb45498f02b2266763ad3ea59d93cfab5685729451d/68747470733a2f2f696d6775722e636f6d2f3037736f736c722e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "3475172610", "image_id": "16", "src": "https://camo.githubusercontent.com/719dd38c489e64bc37d714b8a1bd527745d10c2613d975c75acd882c106342e0/68747470733a2f2f696d6775722e636f6d2f61344b434368662e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "3475172610", "image_id": "17", "src": "https://camo.githubusercontent.com/2a732979092e161e3610861b716916dd21f5460a245566db5c21480431f2aeab/68747470733a2f2f696d6775722e636f6d2f39506d496232652e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "3475172610", "image_id": "18", "src": "https://camo.githubusercontent.com/8fadb1a40cd7c4b39bd756d5140b7f7d73cbba2900f264eeee0316ea947edd97/68747470733a2f2f696d6775722e636f6d2f4d4e705943566a2e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "3475172610", "image_id": "19", "src": "https://camo.githubusercontent.com/4243f9b89748d74686dd526793f07d9e786214f6afb5eeb359d7b1e271efcc52/68747470733a2f2f696d6775722e636f6d2f5a73794a79654a2e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "3475172610", "image_id": "20", "src": "https://camo.githubusercontent.com/64103240ceaabf26d438e00cee5b619e7ad1b366f9ffae069d8d88b0568182a5/68747470733a2f2f696d6775722e636f6d2f365a324f76426d2e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "3475172610", "image_id": "21", "src": "https://camo.githubusercontent.com/971403ac75caf3a1b2c67e0b4273bda3285e588632b77ec7e2ce23a58cb92e25/68747470733a2f2f696d6775722e636f6d2f54597a586351302e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "3475172610", "image_id": "22", "src": "https://camo.githubusercontent.com/2c13237dcd04b625825a9e64e5619053dd204bc29857ab5625aaa2ba48e3d54d/68747470733a2f2f696d6775722e636f6d2f4a444271726c762e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "23": {"item_id": "3475172610", "image_id": "23", "src": "https://camo.githubusercontent.com/cf45ef790fe21210bab5a71a184c9e9b540f00bf53cb5b9134721a00f957699b/68747470733a2f2f696d6775722e636f6d2f4a7961727042762e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "3475172610", "image_id": "24", "src": "https://camo.githubusercontent.com/2f23a1f6b7b3192b3184fd52b2696ca4da7446e3848bd0dd4bbb881c01332f3d/68747470733a2f2f696d6775722e636f6d2f5a5036463953462e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "3475172610", "image_id": "25", "src": "https://camo.githubusercontent.com/6abffd9ec16ea2d1f1446cc83b846b801c8794ad62dce006c2cb69d4e501ed3c/68747470733a2f2f696d6775722e636f6d2f67464f6e686d562e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "26": {"item_id": "3475172610", "image_id": "26", "src": "https://camo.githubusercontent.com/58614835afe0cab6705e2335215929299cb1cfff5c7bc0f85cee6c0c7ce5a714/68747470733a2f2f696d6775722e636f6d2f4842754f7a72472e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "27": {"item_id": "3475172610", "image_id": "27", "src": "https://camo.githubusercontent.com/0d515e5c027e91ca9a3ce38e92650afe10ed26c60e5acb89dba8f3987ed390a5/68747470733a2f2f696d6775722e636f6d2f496472527869782e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "28": {"item_id": "3475172610", "image_id": "28", "src": "https://camo.githubusercontent.com/047bec95179af250d03e9cc03baa95a3b7fa24a39874c4110cbf6f1ae57f3104/68747470733a2f2f696d6775722e636f6d2f7a6244395438652e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "29": {"item_id": "3475172610", "image_id": "29", "src": "https://camo.githubusercontent.com/23dd4026b7d9a2ede1da93294cb74de58f9190d689b2efdfec048a056f2aeac4/68747470733a2f2f696d6775722e636f6d2f4c6f37733764622e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "30": {"item_id": "3475172610", "image_id": "30", "src": "https://camo.githubusercontent.com/795acc254e67b6f906dae08ab4c8111a58bf4d40696ab662100198bfc1ccdf48/68747470733a2f2f696d6775722e636f6d2f4b4a49706d79732e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "31": {"item_id": "3475172610", "image_id": "31", "src": "https://camo.githubusercontent.com/5242fcbc195f2ab112bbf42254747cdb6e3e7713cf826278bf2a15854ad73cd9/68747470733a2f2f696d6775722e636f6d2f5a4634664b33312e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "32": {"item_id": "3475172610", "image_id": "32", "src": "https://camo.githubusercontent.com/3f21ffab234e5a3738df7eb22bcf5012cf0f813d3c8b8c66d61110c860b9223f/68747470733a2f2f696d6775722e636f6d2f344f45373157492e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "33": {"item_id": "3475172610", "image_id": "33", "src": "https://camo.githubusercontent.com/0d8d5092ff44236e53184c2126e27322ab3368a8a1333013f6cc34b04771d70c/68747470733a2f2f696d6775722e636f6d2f6445374d5136452e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "34": {"item_id": "3475172610", "image_id": "34", "src": "https://camo.githubusercontent.com/77352880dbd32838037a25ad40b999aec202c1b51397672e7a123a5b8c25df12/68747470733a2f2f696d6775722e636f6d2f336851655769472e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "35": {"item_id": "3475172610", "image_id": "35", "src": "https://camo.githubusercontent.com/589c4fdb1b3197109bdc4666b6bb7541c3be87b0abd850b3c6e8aadf6700a54a/68747470733a2f2f696d6775722e636f6d2f614d41577a4a552e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "36": {"item_id": "3475172610", "image_id": "36", "src": "https://camo.githubusercontent.com/24be2c1fbc8759c470b5571b499fcdeb7b22dc86ba2cded8adee663af79ce115/68747470733a2f2f696d6775722e636f6d2f57495a597830642e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "37": {"item_id": "3475172610", "image_id": "37", "src": "https://camo.githubusercontent.com/9b6ad6c5d7d20df9c1057ebb01da003d034c33bd2bcfb16242a92f7ed36ffb35/68747470733a2f2f696d6775722e636f6d2f71447976626b762e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "38": {"item_id": "3475172610", "image_id": "38", "src": "https://camo.githubusercontent.com/926ee26b5cd328a7cc13fe25dcb6b4afb5fb15fd339d1a5ae41418ad2d078fb5/68747470733a2f2f696d6775722e636f6d2f454d363875554a2e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "39": {"item_id": "3475172610", "image_id": "39", "src": "https://camo.githubusercontent.com/b7857bc05491e1fa7a6c1a0fe434f21741837cc25e722b8819eb2f5278e8004c/68747470733a2f2f696d6775722e636f6d2f747672304c59392e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "40": {"item_id": "3475172610", "image_id": "40", "src": "https://camo.githubusercontent.com/dc9f4ae97c839138e06915f0cea3d38040b3978dad08bfafa49bb1a256057767/68747470733a2f2f696d6775722e636f6d2f51747a366850412e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 2095}, "3987130320": {"item_id": "3987130320", "resolved_id": "3987130320", "given_url": "https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023", "given_title": "10 Noteworthy AI Research Papers of 2023", "favorite": "0", "status": "1", "time_added": "1704585683", "time_updated": "1704663279", "time_read": "1704663279", "time_favorited": "0", "sort_id": 26, "resolved_title": "Ten Noteworthy AI Research Papers of 2023", "resolved_url": "https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023", "excerpt": "This year has felt distinctly different. I've been working in, on, and with machine learning and AI for over a decade, yet I can't recall a time when these fields were as popular and rapidly evolving as they have been this year.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4179", "lang": "en", "time_to_read": 19, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0046298-1059-4538-bcd8-dfcfc863d7c5_1254x810.png", "tags": {"arxiv": {"item_id": "3987130320", "tag": "arxiv"}, "llms": {"item_id": "3987130320", "tag": "llms"}, "machine-learning": {"item_id": "3987130320", "tag": "machine-learning"}}, "authors": {"177301683": {"item_id": "3987130320", "author_id": "177301683", "name": "Sebastian Raschka, PhD", "url": ""}}, "image": {"item_id": "3987130320", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35f86db1-771a-4b2f-82cd-5daa732dbe4f_1190x828.png", "width": "500", "height": "348"}, "images": {"1": {"item_id": "3987130320", "image_id": "1", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35f86db1-771a-4b2f-82cd-5daa732dbe4f_1190x828.png", "width": "500", "height": "348", "credit": "https://arxiv.org/abs/2307.09288", "caption": "Annotated figure from Llama 2 paper"}, "2": {"item_id": "3987130320", "image_id": "2", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29b1ac66-ff44-461d-95f3-8a9fb07b6562_1384x764.png", "width": "596", "height": "329", "credit": "https://arxiv.org/abs/2307.09288", "caption": "Annotated figure from Llama 2 paper"}, "3": {"item_id": "3987130320", "image_id": "3", "src": "https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe06a33c8-cdbd-4f5e-8380-86fb71a075c8_2216x1232.png", "width": "140", "height": "140", "credit": "", "caption": "LLM Training: RLHF and Its Alternatives"}, "4": {"item_id": "3987130320", "image_id": "4", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe57930b6-afd0-48e6-90a6-97b5dcacb89f_1560x662.png", "width": "616", "height": "261", "credit": "", "caption": "A short visual summary of regular LoRA"}, "5": {"item_id": "3987130320", "image_id": "5", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39daaf2c-4e5c-4075-8697-3c0a636f2144_1226x578.png", "width": "618", "height": "291", "credit": "", "caption": "Among the many efficient finetuning methods for LLMs, LoRA is among the most popular and widely used ones. Annotated figure from the excellent Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning survey. "}, "6": {"item_id": "3987130320", "image_id": "6", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09755a6f-ceb5-4011-8651-45ffffd260e5_1290x928.png", "width": "348", "height": "250", "credit": "", "caption": "Example of two training examples from a dataset for the supervised instruction finetuning step. Note that the \"input\" is optional."}, "7": {"item_id": "3987130320", "image_id": "7", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e8d2822-a23b-4e52-8ab7-ab2f513dcc06_1276x1034.png", "width": "496", "height": "402", "credit": "", "caption": "Annotated figures from the DPO paper, https://arxiv.org/abs/2305.18290"}, "8": {"item_id": "3987130320", "image_id": "8", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F830e5a05-663c-4b4b-9bbd-6d4f33a78c5b_1600x933.png", "width": "682", "height": "398", "credit": "", "caption": "Annotated figure from https://arxiv.org/abs/2310.06825 comparing Mistral 7B and Llama 13B performances"}, "9": {"item_id": "3987130320", "image_id": "9", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb36dd723-2a61-46aa-9020-e033e6fe31be_1600x858.png", "width": "588", "height": "315", "credit": "", "caption": "Annotated figure from https://arxiv.org/abs/2310.06825 explaining sliding window attention."}, "10": {"item_id": "3987130320", "image_id": "10", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F492d455d-9f0f-4c15-a0c7-0a3dec6f59a6_792x796.png", "width": "430", "height": "432", "credit": "", "caption": "OpenCompass benchmarks via https://github.com/open-compass/MixtralKit. Blue boxes highlight the best results in each row."}, "11": {"item_id": "3987130320", "image_id": "11", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5e379db-3f34-4733-854a-f90987181118_844x726.png", "width": "286", "height": "246", "credit": "", "caption": "Mixtral architecture overview based on the param.json file that the Mistral team originally shared via a magnet link on social media"}, "12": {"item_id": "3987130320", "image_id": "12", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77ee34dd-be4f-4d04-b898-9a1b32209023_1356x816.png", "width": "556", "height": "335", "credit": "https://arxiv.org/abs/2101.03961", "caption": "Annotated figure from Switch Transformers paper"}, "13": {"item_id": "3987130320", "image_id": "13", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc505ad21-66db-4e98-977c-76da3098c1bf_1492x816.png", "width": "502", "height": "274", "credit": "https://arxiv.org/abs/2310.16764", "caption": "Annotated figure from ConvNets Match Vision Transformers at Scale"}, "14": {"item_id": "3987130320", "image_id": "14", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F041ee20a-f6dc-4759-9291-efb5d4b48212_870x1026.jpeg", "width": "250", "height": "295", "credit": "top", "caption": "Object detection"}, "15": {"item_id": "3987130320", "image_id": "15", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfa09c5e-0b4f-4984-95c2-13ce9cf8de1d_1304x670.jpeg", "width": "592", "height": "304", "credit": "SAM", "caption": "The Segment Anything Model"}, "16": {"item_id": "3987130320", "image_id": "16", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4387528-dadb-4b4d-8617-7af85571460a_1046x862.png", "width": "422", "height": "348", "credit": "", "caption": "Performance comparison between Emu and other text-to-video models via https://arxiv.org/abs/2311.10709"}, "17": {"item_id": "3987130320", "image_id": "17", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1392a9e3-bf81-406d-a688-acfad261c79f_355x439.jpeg", "width": "265", "height": "328", "credit": "", "caption": "Build a Large Language Model book cover"}}, "listen_duration_estimate": 1618}, "3825489839": {"item_id": "3825489839", "resolved_id": "3824217216", "given_url": "https://nlpnews.substack.com/p/top-ml-papers-of-the-week-8f6?publication_id=103238&post_id=107962254&isFreemail=true", "given_title": "?Top ML Papers of the Week - by elvis - NLP Newsletter", "favorite": "0", "status": "1", "time_added": "1678814572", "time_updated": "1678824314", "time_read": "1678824313", "time_favorited": "0", "sort_id": 27, "resolved_title": "🥇Top ML Papers of the Week", "resolved_url": "https://nlpnews.substack.com/p/top-ml-papers-of-the-week-8f6", "excerpt": "1). PaLM-E - incorporates real-world continuous sensor modalities resulting in an embodied LM that performs tasks such as robotic manipulation planning, visual QA, and other embodied reasoning tasks. (paper | demo) 2).", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "641", "lang": "en", "time_to_read": 3, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFqvskpvXsAEIy5u.jpg", "tags": {"arxiv": {"item_id": "3825489839", "tag": "arxiv"}, "deep-learning": {"item_id": "3825489839", "tag": "deep-learning"}, "machine-learning": {"item_id": "3825489839", "tag": "machine-learning"}}, "authors": {"173922699": {"item_id": "3825489839", "author_id": "173922699", "name": "elvis", "url": "https://substack.com/profile/16905758-elvis"}}, "image": {"item_id": "3825489839", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFqo3xncaAAAWQnE.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3825489839", "image_id": "1", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFqo3xncaAAAWQnE.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3825489839", "image_id": "2", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFqvdJqxX0AAU9MW.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3825489839", "image_id": "3", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFqvskpvXsAEIy5u.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3825489839", "image_id": "4", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFquHXhkaEAEsLe-.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3825489839", "image_id": "5", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFqtxK6kaMAAl8lT.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3825489839", "image_id": "6", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFqorspragAAqGFu.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3825489839", "image_id": "7", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFqladuZX0AAB4S1.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3825489839", "image_id": "8", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFq0tzrNWcAI5ge8.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3825489839", "image_id": "9", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFq0nlVMaMAECs3a.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "3825489839", "video_id": "1", "src": "https://video.twimg.com/ext_tw_video/1632902055030398976/pu/vid/360x270/JL4DHxz9ymrT-6pa.mp4?tag=12", "width": "0", "height": "0", "type": "5", "vid": "", "length": "0"}}, "listen_duration_estimate": 248}, "3836493744": {"item_id": "3836493744", "resolved_id": "3827410791", "given_url": "https://www.kdnuggets.com/2023/03/top-machine-learning-papers-read-2023.html?utm_campaign=Artificial+Intelligence+Weekly&utm_medium=email&utm_source=Artificial_Intelligence_Weekly_325", "given_title": "", "favorite": "0", "status": "1", "time_added": "1680224632", "time_updated": "1680286599", "time_read": "1680286599", "time_favorited": "0", "sort_id": 28, "resolved_title": "Top Machine Learning Papers to Read in 2023", "resolved_url": "https://www.kdnuggets.com/top-machine-learning-papers-to-read-in-2023.html", "excerpt": "Machine Learning is a big field with new research coming out frequently. It is a hot field where academia and industry keep experimenting with new things to improve our daily lives. In recent years, generative AI has been changing the world due to the application of machine learning.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "902", "lang": "en", "time_to_read": 4, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/wijaya_top_machine_learning_papers_read_2023_1.jpg", "tags": {"arxiv": {"item_id": "3836493744", "tag": "arxiv"}, "machine-learning": {"item_id": "3836493744", "tag": "machine-learning"}}, "authors": {"176621344": {"item_id": "3836493744", "author_id": "176621344", "name": "Cornellius Yudha Wijaya", "url": "https://www.kdnuggets.com/author/cornelliusyudha-wijaya"}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 349}, "3609218254": {"item_id": "3609218254", "resolved_id": "3609218254", "given_url": "https://www.nytimes.com/2022/05/02/technology/google-fires-ai-researchers.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1651493319", "time_updated": "1656167906", "time_read": "1651496130", "time_favorited": "0", "sort_id": 29, "resolved_title": "Another Firing Among Google’s A.I. Brain Trust, and More Discord", "resolved_url": "https://www.nytimes.com/2022/05/02/technology/google-fires-ai-researchers.html", "excerpt": "Less than two years after Google dismissed two researchers who criticized the biases built into artificial intelligence systems, the company has fired a researcher who questioned a paper it published on the abilities of a specialized type of artificial intelligence used in making computer chips.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1373", "lang": "en", "time_to_read": 6, "top_image_url": "https://static01.nyt.com/images/2022/04/25/business/00aiexodus1/00aiexodus1-facebookJumbo.jpg?year=2022&h=550&w=1050&s=04b9a6403606dfe18eed4b6d3fa17795aa738498fba759d59bbca6e5e03b5696&k=ZQJBKqZ0VN", "tags": {"arxiv": {"item_id": "3609218254", "tag": "arxiv"}, "chip-design": {"item_id": "3609218254", "tag": "chip-design"}, "deep-learning": {"item_id": "3609218254", "tag": "deep-learning"}, "semiconductors": {"item_id": "3609218254", "tag": "semiconductors"}}, "authors": {"82689593": {"item_id": "3609218254", "author_id": "82689593", "name": "Cade Metz", "url": "https://www.nytimes.com/by/cade-metz"}, "89773737": {"item_id": "3609218254", "author_id": "89773737", "name": "Daisuke Wakabayashi", "url": "https://www.nytimes.com/by/daisuke-wakabayashi"}}, "image": {"item_id": "3609218254", "src": "https://static01.nyt.com/images/2022/04/25/business/00aiexodus1/merlin_178423734_12da72a6-6b6b-495e-b905-a3c7cba1d7a4-articleLarge.jpg?quality=75&auto=webp&disable=upscale", "width": "600", "height": "400"}, "images": {"1": {"item_id": "3609218254", "image_id": "1", "src": "https://static01.nyt.com/images/2022/04/25/business/00aiexodus1/merlin_178423734_12da72a6-6b6b-495e-b905-a3c7cba1d7a4-articleLarge.jpg?quality=75&auto=webp&disable=upscale", "width": "600", "height": "400", "credit": "", "caption": ""}, "2": {"item_id": "3609218254", "image_id": "2", "src": "https://static01.nyt.com/images/2018/07/30/multimedia/author-daisuke-wakabayashi/author-daisuke-wakabayashi-thumbLarge.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3609218254", "image_id": "3", "src": "https://static01.nyt.com/images/2018/11/26/multimedia/author-cade-metz/author-cade-metz-thumbLarge.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The New York Times", "logo": "https://logo.clearbit.com/nytimes.com?size=800", "greyscale_logo": "https://logo.clearbit.com/nytimes.com?size=800&greyscale=true"}, "listen_duration_estimate": 531}, "3524778400": {"item_id": "3524778400", "resolved_id": "3524778400", "given_url": "https://www.scientificamerican.com/article/arxiv-org-reaches-a-milestone-and-a-reckoning/", "given_title": "ArXiv.org Reaches a Milestone and a Reckoning", "favorite": "0", "status": "1", "time_added": "1641835584", "time_updated": "1641837420", "time_read": "1641837419", "time_favorited": "0", "sort_id": 30, "resolved_title": "", "resolved_url": "https://www.scientificamerican.com/article/arxiv-org-reaches-a-milestone-and-a-reckoning/", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"arxiv": {"item_id": "3524778400", "tag": "arxiv"}, "paperswithcode": {"item_id": "3524778400", "tag": "paperswithcode"}}, "domain_metadata": {"name": "Scientific American", "logo": "https://logo.clearbit.com/scientificamerican.com?size=800", "greyscale_logo": "https://logo.clearbit.com/scientificamerican.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3817269280": {"item_id": "3817269280", "resolved_id": "3817269280", "given_url": "https://www.zeta-alpha.com/post/must-read-the-100-most-cited-ai-papers-in-2022", "given_title": "", "favorite": "0", "status": "1", "time_added": "1678016255", "time_updated": "1679307360", "time_read": "1679307360", "time_favorited": "0", "sort_id": 31, "resolved_title": "Must read: the 100 most cited AI papers in 2022", "resolved_url": "https://www.zeta-alpha.com/post/must-read-the-100-most-cited-ai-papers-in-2022", "excerpt": "Who Is publishing the most Impactful AI research right now? With the breakneck pace of innovation in AI, it is crucial to pick up some signal as soon as possible. No one has the time to read everything, but these 100 papers are sure to bend the road as to where our AI technology is going.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1385", "lang": "en", "time_to_read": 6, "top_image_url": "https://static.wixstatic.com/media/111555_f4dabd45181244a89a61cc2abc1c7785~mv2.jpg/v1/fill/w_1000,h_618,al_c,q_85,usm_0.66_1.00_0.01/111555_f4dabd45181244a89a61cc2abc1c7785~mv2.jpg", "tags": {"arxiv": {"item_id": "3817269280", "tag": "arxiv"}, "deep-learning": {"item_id": "3817269280", "tag": "deep-learning"}}, "authors": {"150098771": {"item_id": "3817269280", "author_id": "150098771", "name": "Sergi Castella i Sapé", "url": ""}}, "image": {"item_id": "3817269280", "src": "https://static.wixstatic.com/media/111555_f4dabd45181244a89a61cc2abc1c7785~mv2.jpg/v1/fill/w_980,h_606,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/111555_f4dabd45181244a89a61cc2abc1c7785~mv2.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3817269280", "image_id": "1", "src": "https://static.wixstatic.com/media/111555_f4dabd45181244a89a61cc2abc1c7785~mv2.jpg/v1/fill/w_980,h_606,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/111555_f4dabd45181244a89a61cc2abc1c7785~mv2.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3817269280", "image_id": "2", "src": "https://static.wixstatic.com/media/cfb1e3_748c6102f00c45678b75b0d4e2f62224~mv2.png/v1/fill/w_600,h_371,al_c,q_85,enc_auto/cfb1e3_748c6102f00c45678b75b0d4e2f62224~mv2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3817269280", "image_id": "3", "src": "https://static.wixstatic.com/media/cfb1e3_b4137b6a08e743fc95c00eba04c74ee1~mv2.png/v1/fill/w_938,h_585,al_c,q_90,enc_auto/cfb1e3_b4137b6a08e743fc95c00eba04c74ee1~mv2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3817269280", "image_id": "4", "src": "https://static.wixstatic.com/media/cfb1e3_e725943182924653a717da3b31363a73~mv2.png/v1/fill/w_600,h_371,al_c,q_85,enc_auto/cfb1e3_e725943182924653a717da3b31363a73~mv2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3817269280", "image_id": "5", "src": "https://static.wixstatic.com/media/cfb1e3_68723c87523f47f7aa4ddf60ec590aab~mv2.png/v1/fill/w_735,h_454,al_c,q_85,enc_auto/cfb1e3_68723c87523f47f7aa4ddf60ec590aab~mv2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3817269280", "image_id": "6", "src": "https://static.wixstatic.com/media/cfb1e3_846aa367a6094ccc96b0e1e16556fb91~mv2.png/v1/fill/w_927,h_572,al_c,q_90,enc_auto/cfb1e3_846aa367a6094ccc96b0e1e16556fb91~mv2.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 536}}, "error": nil, "search_meta": {"search_type": "normal"}, "since": 1709419157}