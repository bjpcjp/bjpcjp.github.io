{"status": 1, "complete": 1, "list": {"3890702129": {"item_id": "3890702129", "resolved_id": "3890702129", "given_url": "https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/", "given_title": "Emerging Architectures for LLM Applications", "favorite": "0", "status": "1", "time_added": "1687777111", "time_updated": "1690160691", "time_read": "1690160691", "time_favorited": "0", "sort_id": 0, "resolved_title": "Emerging Architectures for LLM Applications", "resolved_url": "https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/", "excerpt": "Large language models are a powerful new primitive for building software. But since they are so new—and behave so differently from normal computing resources—it’s not always obvious how to use them. In this post, we’re sharing a reference architecture for the emerging LLM app stack.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3117", "lang": "en", "time_to_read": 14, "top_image_url": "https://a16z.com/wp-content/uploads/2023/06/2657_-LLM-Architecture-Yoast-1200x630-1.png", "tags": {"llms": {"item_id": "3890702129", "tag": "llms"}}, "authors": {"128530988": {"item_id": "3890702129", "author_id": "128530988", "name": "Matt Bornstein", "url": "https://a16z.com/author/matt-bornstein/"}, "182994745": {"item_id": "3890702129", "author_id": "182994745", "name": "Rajko Radovanovic", "url": "https://a16z.com/author/rajko-radovanovic/"}}, "image": {"item_id": "3890702129", "src": "https://i0.wp.com/a16z.com/wp-content/uploads/2023/06/2657-Emerging-LLM-App-Stack-R2-1-of-4-2.png?ssl=1", "width": "1024", "height": "717"}, "images": {"1": {"item_id": "3890702129", "image_id": "1", "src": "https://i0.wp.com/a16z.com/wp-content/uploads/2023/06/2657-Emerging-LLM-App-Stack-R2-1-of-4-2.png?ssl=1", "width": "1024", "height": "717", "credit": "", "caption": ""}, "2": {"item_id": "3890702129", "image_id": "2", "src": "https://i2.wp.com/a16z.com/wp-content/uploads/2023/06/2657-Emerging-LLM-App-Stack-R2-2-of-4-2.png?ssl=1", "width": "1024", "height": "717", "credit": "", "caption": ""}, "3": {"item_id": "3890702129", "image_id": "3", "src": "https://i1.wp.com/a16z.com/wp-content/uploads/2023/06/2657-Emerging-LLM-App-Stack-R2-3-of-4-2.png?ssl=1", "width": "1024", "height": "717", "credit": "", "caption": ""}, "4": {"item_id": "3890702129", "image_id": "4", "src": "https://i1.wp.com/a16z.com/wp-content/uploads/2023/06/2657-Emerging-LLM-App-Stack-R2-4-of-4-2.png?ssl=1", "width": "1024", "height": "717", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Andreessen Horowitz", "logo": "https://logo.clearbit.com/a16z.com?size=800", "greyscale_logo": "https://logo.clearbit.com/a16z.com?size=800&greyscale=true"}, "listen_duration_estimate": 1207}, "3989978407": {"item_id": "3989978407", "resolved_id": "3989978407", "given_url": "https://arstechnica.com/information-technology/2024/01/a-crazy-update-midjourney-v6-upgrade-heaps-on-ai-generated-detail/", "given_title": "How much detail is too much? Midjourney v6 attempts to find out", "favorite": "0", "status": "1", "time_added": "1704665175", "time_updated": "1704665197", "time_read": "1704665197", "time_favorited": "0", "sort_id": 1, "resolved_title": "How much detail is too much? Midjourney v6 attempts to find out", "resolved_url": "https://arstechnica.com/information-technology/2024/01/a-crazy-update-midjourney-v6-upgrade-heaps-on-ai-generated-detail/", "excerpt": "In December, just before Christmas, Midjourney launched an alpha version of its latest image synthesis model, Midjourney v6. Over winter break, Midjourney fans put the new AI model through its paces, with the results shared on social media. So far, fans have noted much more detail than v5.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1284", "lang": "en", "time_to_read": 6, "top_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_v6_queen_of_the_universe-640x359.jpg", "tags": {"llms": {"item_id": "3989978407", "tag": "llms"}, "midjourney": {"item_id": "3989978407", "tag": "midjourney"}}, "authors": {"171668034": {"item_id": "3989978407", "author_id": "171668034", "name": "Benj Edwards", "url": "https://arstechnica.com/author/benjedwards/"}}, "image": {"item_id": "3989978407", "src": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_v6_queen_of_the_universe-800x448.jpg", "width": "640", "height": "358"}, "images": {"1": {"item_id": "3989978407", "image_id": "1", "src": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_v6_queen_of_the_universe-800x448.jpg", "width": "640", "height": "358", "credit": "Midjourney", "caption": "An AI-generated image of a \"Beautiful queen of the universe looking at the camera in sci-fi armor, snow and particles flowing, fire in the background\" created using alpha Midjourney v6."}, "2": {"item_id": "3989978407", "image_id": "2", "src": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_v6_nurse.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3989978407", "image_id": "3", "src": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_v6_nurse-640x359.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3989978407", "image_id": "4", "src": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_v6_astronaut_spacewalk-640x359.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3989978407", "image_id": "5", "src": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/v6_midjourney_flaming_cheeseburger-640x359.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3989978407", "image_id": "6", "src": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_v6_asian_man-640x359.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3989978407", "image_id": "7", "src": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_v6_apple2-640x359.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3989978407", "image_id": "8", "src": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_v6_cat_beer-640x359.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3989978407", "image_id": "9", "src": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_6_path-640x359.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3989978407", "image_id": "10", "src": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_v6_woman_plants-640x359.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3989978407", "image_id": "11", "src": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_v6_pickles-640x359.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3989978407", "image_id": "12", "src": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_v6_barbarian_crt_ars-640x359.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3989978407", "image_id": "13", "src": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_v6_abraham_lincoln_sign-640x359.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "3989978407", "image_id": "14", "src": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_v6_mickey_mouse_gun-640x359.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "3989978407", "image_id": "15", "src": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/midjourney_v3_v4_v5_v52_v6_comparison-scaled.jpg", "width": "640", "height": "127", "credit": "Midjourney", "caption": "Enlarge / A comparison between output from Midjourney versions"}, "16": {"item_id": "3989978407", "image_id": "16", "src": "https://cdn.arstechnica.net/wp-content/uploads/2024/01/dalle_vs_midjourney_1.jpg", "width": "640", "height": "318", "credit": "OpenAI, Midjourney", "caption": "Enlarge / An AI-generated comparison of Abraham Lincoln using a computer at his desk using DALL-E 3"}}, "domain_metadata": {"name": "Ars Technica", "logo": "https://logo.clearbit.com/arstechnica.com?size=800", "greyscale_logo": "https://logo.clearbit.com/arstechnica.com?size=800&greyscale=true"}, "listen_duration_estimate": 497}, "3778853523": {"item_id": "3778853523", "resolved_id": "3778853525", "given_url": "https://arxiv.org/abs/2301.00774", "given_title": "", "favorite": "0", "status": "1", "time_added": "1683204357", "time_updated": "1683253509", "time_read": "1683253509", "time_favorited": "0", "sort_id": 2, "resolved_title": "Title:Massive Language Models Can Be Accurately Pruned in One-Shot", "resolved_url": "https://arxiv.org/abs/2301.00774v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"arxiv": {"item_id": "3778853523", "tag": "arxiv"}, "llms": {"item_id": "3778853523", "tag": "llms"}}, "authors": {"176565962": {"item_id": "3778853523", "author_id": "176565962", "name": "cs", "url": "https://arxiv.org/abs/2301.00774?context=cs"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3807601744": {"item_id": "3807601744", "resolved_id": "3807601748", "given_url": "https://arxiv.org/abs/2302.07730", "given_title": "[2302.07730] Transformer models: an introduction and catalog", "favorite": "0", "status": "1", "time_added": "1696342638", "time_updated": "1696545966", "time_read": "1696545966", "time_favorited": "0", "sort_id": 3, "resolved_title": "Title:Transformer models: an introduction and catalog", "resolved_url": "https://arxiv.org/abs/2302.07730v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"arxiv": {"item_id": "3807601744", "tag": "arxiv"}, "llms": {"item_id": "3807601744", "tag": "llms"}, "transformers": {"item_id": "3807601744", "tag": "transformers"}}, "authors": {"178290250": {"item_id": "3807601744", "author_id": "178290250", "name": "cs", "url": "https://arxiv.org/abs/2302.07730?context=cs"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3836484887": {"item_id": "3836484887", "resolved_id": "3836484910", "given_url": "https://arxiv.org/abs/2303.17564", "given_title": "Title:BloombergGPT: A Large Language Model for Finance", "favorite": "0", "status": "1", "time_added": "1706543303", "time_updated": "1707015410", "time_read": "1707015410", "time_favorited": "0", "sort_id": 4, "resolved_title": "Title:BloombergGPT: A Large Language Model for Finance", "resolved_url": "https://arxiv.org/abs/2303.17564v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "72", "lang": "en", "top_image_url": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png", "tags": {"gpt": {"item_id": "3836484887", "tag": "gpt"}, "llms": {"item_id": "3836484887", "tag": "llms"}}, "authors": {"1795444": {"item_id": "3836484887", "author_id": "1795444", "name": "Shijie Wu", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 28}, "3838345443": {"item_id": "3838345443", "resolved_id": "3838332429", "given_url": "https://arxiv.org/abs/2303.18223#", "given_title": "", "favorite": "0", "status": "1", "time_added": "1680575326", "time_updated": "1681439192", "time_read": "1681439192", "time_favorited": "0", "sort_id": 5, "resolved_title": "Title:A Survey of Large Language Models", "resolved_url": "https://arxiv.org/abs/2303.18223v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "72", "lang": "en", "top_image_url": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png", "tags": {"arxiv": {"item_id": "3838345443", "tag": "arxiv"}, "deep-learning": {"item_id": "3838345443", "tag": "deep-learning"}, "llms": {"item_id": "3838345443", "tag": "llms"}}, "authors": {"180127060": {"item_id": "3838345443", "author_id": "180127060", "name": "Wayne Xin Zhao", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 28}, "3839259196": {"item_id": "3839259196", "resolved_id": "3839259201", "given_url": "https://arxiv.org/abs/2304.00612", "given_title": "", "favorite": "0", "status": "1", "time_added": "1681265983", "time_updated": "1682120635", "time_read": "1682120635", "time_favorited": "0", "sort_id": 6, "resolved_title": "Title:Eight Things to Know about Large Language Models", "resolved_url": "https://arxiv.org/abs/2304.00612v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "72", "lang": "en", "top_image_url": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png", "tags": {"arxiv": {"item_id": "3839259196", "tag": "arxiv"}, "llms": {"item_id": "3839259196", "tag": "llms"}}, "authors": {"67155460": {"item_id": "3839259196", "author_id": "67155460", "name": "cs   cs.AI", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 28}, "3858856237": {"item_id": "3858856237", "resolved_id": "3858843495", "given_url": "https://arxiv.org/abs/2305.02301", "given_title": "", "favorite": "0", "status": "1", "time_added": "1683204097", "time_updated": "1683253521", "time_read": "1683253521", "time_favorited": "0", "sort_id": 7, "resolved_title": "Title:Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes", "resolved_url": "https://arxiv.org/abs/2305.02301v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "72", "lang": "en", "top_image_url": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png", "tags": {"arxiv": {"item_id": "3858856237", "tag": "arxiv"}, "llms": {"item_id": "3858856237", "tag": "llms"}}, "authors": {"102565068": {"item_id": "3858856237", "author_id": "102565068", "name": "cs   cs.AI   cs.LG", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 28}, "4014829602": {"item_id": "4014829602", "resolved_id": "4014829603", "given_url": "https://arxiv.org/abs/2402.17764", "given_title": "Title:The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits", "favorite": "0", "status": "1", "time_added": "1709214330", "time_updated": "1709244726", "time_read": "1709244726", "time_favorited": "0", "sort_id": 8, "resolved_title": "Title:The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits", "resolved_url": "https://arxiv.org/abs/2402.17764v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "72", "lang": "en", "top_image_url": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png", "tags": {"llms": {"item_id": "4014829602", "tag": "llms"}}, "authors": {"183695695": {"item_id": "4014829602", "author_id": "183695695", "name": "Shuming Ma", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 28}, "3813135366": {"item_id": "3813135366", "resolved_id": "3813135366", "given_url": "https://arxiv.org/pdf/2302.11382.pdf", "given_title": "2302.11382.pdf", "favorite": "0", "status": "1", "time_added": "1696174927", "time_updated": "1696362362", "time_read": "1696362362", "time_favorited": "0", "sort_id": 9, "resolved_title": "", "resolved_url": "https://arxiv.org/pdf/2302.11382.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"llms": {"item_id": "3813135366", "tag": "llms"}, "prompt-engineering": {"item_id": "3813135366", "tag": "prompt-engineering"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3937502083": {"item_id": "3937502083", "resolved_id": "3829994799", "given_url": "https://bard.google.com/chat", "given_title": "Bard", "favorite": "0", "status": "1", "time_added": "1696286131", "time_updated": "1706199845", "time_read": "1696355979", "time_favorited": "0", "sort_id": 10, "resolved_title": "‎Bard - Chat Based AI Tool from Google, Powered by PaLM 2", "resolved_url": "https://bard.google.com", "excerpt": "Sign in Google apps Main menu", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "6", "lang": "en", "top_image_url": "https://www.gstatic.com/lamda/images/bard_thumbnail.png", "tags": {"chatgpt": {"item_id": "3937502083", "tag": "chatgpt"}, "llms": {"item_id": "3937502083", "tag": "llms"}}, "listen_duration_estimate": 2}, "3932663706": {"item_id": "3932663706", "resolved_id": "3932663706", "given_url": "https://benchmarks.llmonitor.com/", "given_title": "Asking 60+ LLMs a set of 20 questions", "favorite": "0", "status": "1", "time_added": "1694287457", "time_updated": "1695684042", "time_read": "1695684042", "time_favorited": "0", "sort_id": 11, "resolved_title": "Asking 60+ LLMs a set of 20 questions", "resolved_url": "https://benchmarks.llmonitor.com", "excerpt": "Benchmarks like HellaSwag are a bit too abstract for me to get a sense of how well they perform in real-world workflows. The script stored all the answers in a SQLite database, and those are the raw results.", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "74", "lang": "en", "tags": {"benchmarks": {"item_id": "3932663706", "tag": "benchmarks"}, "llms": {"item_id": "3932663706", "tag": "llms"}}, "listen_duration_estimate": 29}, "3916798910": {"item_id": "3916798910", "resolved_id": "3916798910", "given_url": "https://blog.briankitano.com/llama-from-scratch/", "given_title": "Llama from scratch", "favorite": "0", "status": "1", "time_added": "1691588426", "time_updated": "1695684191", "time_read": "1695684191", "time_favorited": "0", "sort_id": 12, "resolved_title": "Llama from scratch (or how to implement a paper without crying)", "resolved_url": "https://blog.briankitano.com/llama-from-scratch/", "excerpt": "I want to provide some tips from my experience implementing a paper. I'm going to cover my tips so far from implementing a dramatically scaled-down version of Llama for training TinyShakespeare. This post is heavily inspired by Karpathy's Makemore series, which I highly recommend.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "5689", "lang": "en", "time_to_read": 26, "tags": {"llama": {"item_id": "3916798910", "tag": "llama"}, "llms": {"item_id": "3916798910", "tag": "llms"}}, "image": {"item_id": "3916798910", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_23_2.png?raw=true", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3916798910", "image_id": "1", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_23_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3916798910", "image_id": "2", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_25_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3916798910", "image_id": "3", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_35_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3916798910", "image_id": "4", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_39_0.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3916798910", "image_id": "5", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_50_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3916798910", "image_id": "6", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_54_1.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3916798910", "image_id": "7", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_57_1.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3916798910", "image_id": "8", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_60_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3916798910", "image_id": "9", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_62_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3916798910", "image_id": "10", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_65_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3916798910", "image_id": "11", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_69_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3916798910", "image_id": "12", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_71_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3916798910", "image_id": "13", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_73_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 2202}, "3869843478": {"item_id": "3869843478", "resolved_id": "3869843478", "given_url": "https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c", "given_title": "The Secret Sauce behind 100K context window in LLMs: all tricks in one plac", "favorite": "0", "status": "1", "time_added": "1687046006", "time_updated": "1690156789", "time_read": "1690156789", "time_favorited": "0", "sort_id": 13, "resolved_title": "The Secret Sauce behind 100K context window in LLMs: all tricks in one place", "resolved_url": "https://blog.gopenai.com/how-to-speed-up-llms-and-use-100k-context-window-all-tricks-in-one-place-ffd40577b4c", "excerpt": "Recently there were several announcements about new Large Language Models (LLMs) that can consume an extremely large context window, such as 65K tokens (MPT-7B-StoryWriter-65k+ by MosaicML) or even 100K tokens (Introducing 100K Context Windows by Antropic).", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3874", "lang": "en", "time_to_read": 18, "top_image_url": "https://miro.medium.com/v2/resize:fit:534/0*x80ZcJl_2zLbyvCE.jpg", "tags": {"llms": {"item_id": "3869843478", "tag": "llms"}}, "authors": {"178766791": {"item_id": "3869843478", "author_id": "178766791", "name": "Galina Alperovich", "url": "https://medium.com/@galperovich"}}, "image": {"item_id": "3869843478", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*-U-ORAxPqddcngZnd77JVw.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3869843478", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*-U-ORAxPqddcngZnd77JVw.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3869843478", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*LUSEiP1BHPkkmH75e8eg_A.png", "width": "24", "height": "24", "credit": "", "caption": ""}}, "listen_duration_estimate": 1500}, "3957098399": {"item_id": "3957098399", "resolved_id": "3953445786", "given_url": "https://blog.llamaindex.ai/mastering-pdfs-extracting-sections-headings-paragraphs-and-tables-with-cutting-edge-parser-faea18870125?source=rss----d7683ed5043e---4", "given_title": "Mastering PDFs: Extracting Sections, Headings, Paragraphs, and Tables with ", "favorite": "0", "status": "1", "time_added": "1698527359", "time_updated": "1705475508", "time_read": "1705475508", "time_favorited": "0", "sort_id": 14, "resolved_title": "Mastering PDFs: Extracting Sections, Headings, Paragraphs, and Tables with Cutting-Edge Parser", "resolved_url": "https://blog.llamaindex.ai/mastering-pdfs-extracting-sections-headings-paragraphs-and-tables-with-cutting-edge-parser-faea18870125", "excerpt": "Despite recent motivation to utilize NLP for wider range of real world applications, most NLP papers, tasks and pipelines assume raw, clean texts. However, many texts we encounter in the wild, including a vast majority of legal documents (e.g.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1151", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/v2/resize:fit:820/1*3X_McbzikW3Uty6qaQKYgw.jpeg", "tags": {"llms": {"item_id": "3957098399", "tag": "llms"}, "pdfs": {"item_id": "3957098399", "tag": "pdfs"}, "python": {"item_id": "3957098399", "tag": "python"}}, "authors": {"185860014": {"item_id": "3957098399", "author_id": "185860014", "name": "Kiran Neelakanda Panicker", "url": "https://medium.com/@kirankurup"}}, "image": {"item_id": "3957098399", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*-QRF-e6LE2Z6iG7exhjd3Q.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3957098399", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*-QRF-e6LE2Z6iG7exhjd3Q.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3957098399", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*_mrG8FG_LiD23x0-mEtUkw.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "listen_duration_estimate": 446}, "4003307733": {"item_id": "4003307733", "resolved_id": "4003307733", "given_url": "https://claude.ai/chat/a77c0bb5-3e7c-4a91-9ced-5314df193759", "given_title": "Claude", "favorite": "0", "status": "1", "time_added": "1707051309", "time_updated": "1708582810", "time_read": "1708582810", "time_favorited": "0", "sort_id": 15, "resolved_title": "Claude", "resolved_url": "https://claude.ai/chat/a77c0bb5-3e7c-4a91-9ced-5314df193759", "excerpt": "Loading...", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1", "lang": "en", "top_image_url": "https://claude.ai/images/opengraph-image@2x.png", "tags": {"llms": {"item_id": "4003307733", "tag": "llms"}}, "listen_duration_estimate": 0}, "3824783465": {"item_id": "3824783465", "resolved_id": "3824783465", "given_url": "https://crfm.stanford.edu/2023/03/13/alpaca.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1681069528", "time_updated": "1687908764", "time_read": "1682120654", "time_favorited": "0", "sort_id": 16, "resolved_title": "Overview", "resolved_url": "https://crfm.stanford.edu/2023/03/13/alpaca.html", "excerpt": "Instruction-following models such as GPT-3.5 (text-davinci-003), ChatGPT, Claude, and Bing Chat have become increasingly powerful. Many users now interact with these models regularly and even use them for work.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1641", "lang": "en", "time_to_read": 7, "tags": {"llms": {"item_id": "3824783465", "tag": "llms"}}, "image": {"item_id": "3824783465", "src": "https://crfm.stanford.edu/static/img/posts/2023-03-13-alpaca/alpaca_main.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3824783465", "image_id": "1", "src": "https://crfm.stanford.edu/static/img/posts/2023-03-13-alpaca/alpaca_main.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3824783465", "image_id": "2", "src": "https://crfm.stanford.edu/static/img/posts/2023-03-13-alpaca/alpaca_right_llama.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3824783465", "image_id": "3", "src": "https://crfm.stanford.edu/static/img/posts/2023-03-13-alpaca/alpaca_right_email.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3824783465", "image_id": "4", "src": "https://crfm.stanford.edu/static/img/posts/2023-03-13-alpaca/alpaca_wrong_capital.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3824783465", "image_id": "5", "src": "https://crfm.stanford.edu/static/img/posts/2023-03-13-alpaca/alpaca_wrong_42.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 635}, "3903938604": {"item_id": "3903938604", "resolved_id": "3903938604", "given_url": "https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=table&utm_source=www.turingpost.com&utm_medium=newsletter&utm_campaign=the-secret-sauce-behind-chatgpt-and-other-important-llms", "given_title": "Ecosystem Graphs for Foundation Models", "favorite": "0", "status": "1", "time_added": "1689429304", "time_updated": "1690156781", "time_read": "1690156781", "time_favorited": "0", "sort_id": 17, "resolved_title": "Ecosystem Graphs for Foundation Models", "resolved_url": "https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=table&utm_source=www.turingpost.com&utm_medium=newsletter&utm_campaign=the-secret-sauce-behind-chatgpt-and-other-important-llms", "excerpt": "", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"llms": {"item_id": "3903938604", "tag": "llms"}}, "listen_duration_estimate": 0}, "3902323617": {"item_id": "3902323617", "resolved_id": "3902323617", "given_url": "https://dataconomy.com/2023/07/12/midjourney-pricing-and-free-alternatives/", "given_title": "Midjourney pricing plans and free alternatives to try", "favorite": "0", "status": "1", "time_added": "1689161352", "time_updated": "1690571808", "time_read": "1690571808", "time_favorited": "0", "sort_id": 18, "resolved_title": "Midjourney pricing plans and free alternatives to try", "resolved_url": "https://dataconomy.com/2023/07/12/midjourney-pricing-and-free-alternatives/", "excerpt": "Navigating the maze of pricing plans for digital services can sometimes be a daunting task. Today, we are unveiling Midjourney pricing, breaking down each tier to give you a detailed understanding of what each offers.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1621", "lang": "en", "time_to_read": 7, "top_image_url": "https://dataconomy.com/wp-content/uploads/2023/07/Midjourney-pricing-plans-and-free-alternatives-to-try.jpg", "tags": {"generative": {"item_id": "3902323617", "tag": "generative"}, "image-generation": {"item_id": "3902323617", "tag": "image-generation"}, "llms": {"item_id": "3902323617", "tag": "llms"}, "midjourney": {"item_id": "3902323617", "tag": "midjourney"}}, "authors": {"166594375": {"item_id": "3902323617", "author_id": "166594375", "name": "Kerem Gülen", "url": "https://dataconomy.com/author/kerem-gulen/"}}, "listen_duration_estimate": 627}, "3939295599": {"item_id": "3939295599", "resolved_id": "3939295599", "given_url": "https://dataconomy.com/2023/09/22/comparison-dall-e-3-vs-midjourney/", "given_title": "Comparison: DALL-E 3 vs Midjourney", "favorite": "0", "status": "1", "time_added": "1695399523", "time_updated": "1706652652", "time_read": "1695566506", "time_favorited": "0", "sort_id": 19, "resolved_title": "Comparison: DALL-E 3 vs Midjourney", "resolved_url": "https://dataconomy.com/2023/09/22/comparison-dall-e-3-vs-midjourney/", "excerpt": "DALL-E 3, the latest version of OpenAI’s ground-breaking generative AI visual art platform, was just announced with groundbreaking features, including ChatGPT integration. While the announcement is quite assertive, we decided to put it in a ring to see how it will be performing.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1019", "lang": "en", "time_to_read": 5, "top_image_url": "https://dataconomy.com/wp-content/uploads/2023/09/Comparison-DALL-E-3-vs-Midjourney-1111.jpg", "tags": {"generative": {"item_id": "3939295599", "tag": "generative"}, "image-generation": {"item_id": "3939295599", "tag": "image-generation"}, "llms": {"item_id": "3939295599", "tag": "llms"}, "midjourney": {"item_id": "3939295599", "tag": "midjourney"}}, "authors": {"165528159": {"item_id": "3939295599", "author_id": "165528159", "name": "Eray Eliaçık", "url": "https://dataconomy.com/author/eray-eliacik/"}}, "listen_duration_estimate": 394}, "3999322282": {"item_id": "3999322282", "resolved_id": "3999322282", "given_url": "https://dataconomy.com/2024/01/25/how-to-use-google-lumiere/", "given_title": "Meet Google Lumiere AI, Bard’s video maker cousin", "favorite": "0", "status": "1", "time_added": "1706236829", "time_updated": "1709250402", "time_read": "1709250402", "time_favorited": "0", "sort_id": 20, "resolved_title": "Meet Google Lumiere AI, Bard’s video maker cousin", "resolved_url": "https://dataconomy.com/2024/01/25/how-to-use-google-lumiere/", "excerpt": "Step into the future of video creation with Google Lumiere, the latest breakthrough from Google Research that promises to redefine our approach to generating and experiencing video content.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1072", "lang": "en", "time_to_read": 5, "top_image_url": "https://dataconomy.com/wp-content/uploads/2024/01/How-to-use-Google-Lumiere.jpg", "tags": {"llms": {"item_id": "3999322282", "tag": "llms"}, "video": {"item_id": "3999322282", "tag": "video"}}, "authors": {"165528159": {"item_id": "3999322282", "author_id": "165528159", "name": "Eray Eliaçık", "url": "https://dataconomy.com/author/eray-eliacik/"}}, "listen_duration_estimate": 415}, "4005237202": {"item_id": "4005237202", "resolved_id": "4005237202", "given_url": "https://dataconomy.com/2024/02/08/bard-is-now-gemini-here-are-gemini-advanced-features/", "given_title": "Bard is now Gemini and Gemini Advanced is amazing", "favorite": "0", "status": "1", "time_added": "1707420686", "time_updated": "1707960141", "time_read": "1707960141", "time_favorited": "0", "sort_id": 21, "resolved_title": "Bard is now Gemini and Gemini Advanced is amazing", "resolved_url": "https://dataconomy.com/2024/02/08/bard-is-now-gemini-here-are-gemini-advanced-features/", "excerpt": "AI community is once again filled with excitement as Bard is now Gemini and Gemini Advanced offering users an exceptional experience.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "947", "lang": "en", "time_to_read": 4, "top_image_url": "https://dataconomy.com/wp-content/uploads/2024/02/Bard-is-now-Gemini-Advanced_2.jpg", "tags": {"llms": {"item_id": "4005237202", "tag": "llms"}}, "authors": {"3518135": {"item_id": "4005237202", "author_id": "3518135", "name": "Emre", "url": ""}}, "image": {"item_id": "4005237202", "src": "http://img.youtube.com/vi/b5Fh7TaTkEU/0.jpg", "width": "480", "height": "360"}, "images": {"1": {"item_id": "4005237202", "image_id": "1", "src": "http://img.youtube.com/vi/b5Fh7TaTkEU/0.jpg", "width": "480", "height": "360", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "4005237202", "video_id": "1", "src": "https://www.youtube.com/embed/b5Fh7TaTkEU?feature=oembed", "width": "500", "height": "281", "type": "1", "vid": "b5Fh7TaTkEU", "length": "0"}}, "listen_duration_estimate": 367}, "4013949046": {"item_id": "4013949046", "resolved_id": "4013949046", "given_url": "https://dataconomy.com/2024/02/26/sora-early-access/", "given_title": "Sora early access: Your guide to securing a spot", "favorite": "0", "status": "1", "time_added": "1708971382", "time_updated": "1709183126", "time_read": "1709183126", "time_favorited": "0", "sort_id": 22, "resolved_title": "Sora early access: Your guide to securing a spot", "resolved_url": "https://dataconomy.com/2024/02/26/sora-early-access/", "excerpt": "Are you looking for the news everyday for Sora early access like us? Well you are absolutely right because OpenAI’s unveiling of Sora model capable of generating photorealistic videos from simple text descriptions, has sent shockwaves through the tech and creative industries.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "653", "lang": "en", "time_to_read": 3, "top_image_url": "https://dataconomy.com/wp-content/uploads/2024/02/Sora-early-access_02.jpg", "tags": {"llms": {"item_id": "4013949046", "tag": "llms"}, "video": {"item_id": "4013949046", "tag": "video"}}, "authors": {"166594375": {"item_id": "4013949046", "author_id": "166594375", "name": "Kerem Gülen", "url": "https://dataconomy.com/author/kerem-gulen/"}}, "listen_duration_estimate": 253}, "3852072775": {"item_id": "3852072775", "resolved_id": "3852072783", "given_url": "https://datamachina.substack.com/p/data-machina-198?utm_medium=email", "given_title": "", "favorite": "0", "status": "1", "time_added": "1682258766", "time_updated": "1682439496", "time_read": "1682439496", "time_favorited": "0", "sort_id": 23, "resolved_title": "Data Machina #198", "resolved_url": "https://datamachina.substack.com/p/data-machina-198", "excerpt": "“My Own LLM:” The LLM Marathon. I’m certainly not intending to run the London Marathon today. Training & fine-tuning your own LLM, and running your own LLMOps is a bit like running a marathon :-) Here is a list of aspects you should consider before running the LLM Marathon:", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "190", "lang": "en", "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F212c16cd-1315-43b1-9dda-6e09235ce41d_1006x1006.png", "tags": {"llms": {"item_id": "3852072775", "tag": "llms"}}, "authors": {"2539878": {"item_id": "3852072775", "author_id": "2539878", "name": "Carlos", "url": ""}}, "image": {"item_id": "3852072775", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fec469393-b985-448e-a271-37958ca12ed3_1790x956.png", "width": "584", "height": "312"}, "images": {"1": {"item_id": "3852072775", "image_id": "1", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fec469393-b985-448e-a271-37958ca12ed3_1790x956.png", "width": "584", "height": "312", "credit": "", "caption": ""}, "2": {"item_id": "3852072775", "image_id": "2", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3db932ef-0ce4-4382-9bd3-597f4a36d2ad_1478x924.png", "width": "552", "height": "345", "credit": "", "caption": ""}}, "listen_duration_estimate": 74}, "3903087125": {"item_id": "3903087125", "resolved_id": "3903087125", "given_url": "https://dev.to/bitohq/claude-2-vs-claude-13-vs-gpt-4-ai-coding-comparison-k29", "given_title": "Is Anthropic's Claude 2 model ready to take down GPT-4? We put them to the ", "favorite": "0", "status": "1", "time_added": "1689278678", "time_updated": "1690505919", "time_read": "1690505919", "time_favorited": "0", "sort_id": 24, "resolved_title": "Is Anthropic's Claude 2 model ready to take down GPT-4? We put them to the test", "resolved_url": "https://dev.to/bitohq/claude-2-vs-claude-13-vs-gpt-4-ai-coding-comparison-k29", "excerpt": "Anthropic released Claude 2, a new iteration of its AI model, to take on ChatGPT and Google Bard head-to-head. In this article, I’ve compared Claude 2 with Claude 1.3 and GPT-4 to find out which one has better coding capabilities.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "3294", "lang": "en", "time_to_read": 15, "top_image_url": "https://dev.to/social_previews/article/1536188.png", "tags": {"gpt": {"item_id": "3903087125", "tag": "gpt"}, "llms": {"item_id": "3903087125", "tag": "llms"}}, "domain_metadata": {"name": "The Practical Dev", "logo": "https://logo.clearbit.com/dev.to?size=800", "greyscale_logo": "https://logo.clearbit.com/dev.to?size=800&greyscale=true"}, "listen_duration_estimate": 1275}, "3927421417": {"item_id": "3927421417", "resolved_id": "3927421417", "given_url": "https://dev.to/pavanbelagatti/a-beginners-guide-to-building-llm-powered-applications-with-langchain-2d6e", "given_title": "A Beginner’s Guide to Building LLM-Powered Applications with LangChain!", "favorite": "0", "status": "1", "time_added": "1693390474", "time_updated": "1694562796", "time_read": "1694562796", "time_favorited": "0", "sort_id": 25, "resolved_title": "A Beginner’s Guide to Building LLM-Powered Applications with LangChain!", "resolved_url": "https://dev.to/pavanbelagatti/a-beginners-guide-to-building-llm-powered-applications-with-langchain-2d6e", "excerpt": "If you're a developer or simply someone passionate about technology, you've likely encountered AI tools such as ChatGPT. These utilities are powered by advanced large language models (LLMs).", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1418", "lang": "en", "time_to_read": 6, "top_image_url": "https://res.cloudinary.com/practicaldev/image/fetch/s--CfideRdO--/c_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/so3pj9juipg7i3bvrwjb.png", "tags": {"langchain": {"item_id": "3927421417", "tag": "langchain"}, "llms": {"item_id": "3927421417", "tag": "llms"}}, "image": {"item_id": "3927421417", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--QN3pm29e--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/so3pj9juipg7i3bvrwjb.png", "width": "1000", "height": "420"}, "images": {"1": {"item_id": "3927421417", "image_id": "1", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--QN3pm29e--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/so3pj9juipg7i3bvrwjb.png", "width": "1000", "height": "420", "credit": "", "caption": ""}, "2": {"item_id": "3927421417", "image_id": "2", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--Zs57ZZfo--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/6lrpjbdclbghbk74mhdb.png", "width": "800", "height": "881", "credit": "", "caption": ""}, "3": {"item_id": "3927421417", "image_id": "3", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--UbwXks1d--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/49k2o2rc2cvtgzwfa187.png", "width": "800", "height": "911", "credit": "", "caption": ""}, "4": {"item_id": "3927421417", "image_id": "4", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--ghO5nskJ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ei0x0uh7z2kjevp6iz47.png", "width": "800", "height": "400", "credit": "", "caption": ""}, "5": {"item_id": "3927421417", "image_id": "5", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--Myvb0tbI--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/uxnfpct01cb9pgit0u9z.png", "width": "800", "height": "309", "credit": "", "caption": ""}, "6": {"item_id": "3927421417", "image_id": "6", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--S25EcECw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ug1scnnwrz9ar1op5yji.png", "width": "592", "height": "832", "credit": "", "caption": ""}, "7": {"item_id": "3927421417", "image_id": "7", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--EwcKnmfM--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/99l9xf5hltflrjbl8qlx.png", "width": "800", "height": "961", "credit": "", "caption": ""}, "8": {"item_id": "3927421417", "image_id": "8", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--NvkD06D1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/wk3s4wcsgl5tw3alfxa9.png", "width": "800", "height": "546", "credit": "", "caption": ""}, "9": {"item_id": "3927421417", "image_id": "9", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--yalJKEsv--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/c3of4moqy9ecgf27zqpy.png", "width": "762", "height": "452", "credit": "", "caption": ""}, "10": {"item_id": "3927421417", "image_id": "10", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--miWV0CSp--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/2drnsrwl8qe8pgyy3vpq.png", "width": "800", "height": "576", "credit": "", "caption": ""}, "11": {"item_id": "3927421417", "image_id": "11", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--fJwj9fLK--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/j17vhzo4atqm1s931j4e.png", "width": "800", "height": "817", "credit": "", "caption": ""}, "12": {"item_id": "3927421417", "image_id": "12", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--BTrrZUtS--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/35127owu4y3j68jt8pov.png", "width": "800", "height": "218", "credit": "", "caption": ""}, "13": {"item_id": "3927421417", "image_id": "13", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--XgSsNwoN--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/mp1zxwsjkiw8r3qsklv2.png", "width": "746", "height": "180", "credit": "", "caption": ""}, "14": {"item_id": "3927421417", "image_id": "14", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--0cF4MDL8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/fs7tf0as9r98qhtbpq9r.png", "width": "800", "height": "393", "credit": "", "caption": ""}, "15": {"item_id": "3927421417", "image_id": "15", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--IhTbkMn3--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/zsclp2ccrxs0bhe6ghmn.png", "width": "800", "height": "441", "credit": "", "caption": ""}, "16": {"item_id": "3927421417", "image_id": "16", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--GqieGJLh--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/p1njxnof769m1xp6s510.png", "width": "800", "height": "302", "credit": "", "caption": ""}, "17": {"item_id": "3927421417", "image_id": "17", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s---nNLGlf0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/06ghwqt87jekt2bl7ie3.png", "width": "632", "height": "902", "credit": "", "caption": ""}, "18": {"item_id": "3927421417", "image_id": "18", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--KWIjb81l--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/q8s56xn38rjwwfpjqhw2.png", "width": "800", "height": "346", "credit": "", "caption": ""}, "19": {"item_id": "3927421417", "image_id": "19", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--y6hquUs3--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/bmn5vi630g4j50qojnwn.png", "width": "800", "height": "204", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The Practical Dev", "logo": "https://logo.clearbit.com/dev.to?size=800", "greyscale_logo": "https://logo.clearbit.com/dev.to?size=800&greyscale=true"}, "listen_duration_estimate": 549}, "3935874788": {"item_id": "3935874788", "resolved_id": "3935874788", "given_url": "https://devblogs.microsoft.com/ise/2023/06/27/gpt-summary-prompt-engineering/", "given_title": "Large Language Model Prompt Engineering for Complex Summarization - ISE Dev", "favorite": "0", "status": "1", "time_added": "1694808519", "time_updated": "1706802574", "time_read": "1695684336", "time_favorited": "0", "sort_id": 26, "resolved_title": "Large Language Model Prompt Engineering for Complex Summarization", "resolved_url": "https://devblogs.microsoft.com/ise/2023/06/27/gpt-summary-prompt-engineering/", "excerpt": "In this post we’ll demonstrate some prompt engineering techniques to create summaries of medical research publications.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "2132", "lang": "en", "time_to_read": 10, "top_image_url": "https://devblogs.microsoft.com/ise/wp-content/uploads/sites/55/2023/06/prompt-engineering-may23.png", "tags": {"llms": {"item_id": "3935874788", "tag": "llms"}, "prompt-engineering": {"item_id": "3935874788", "tag": "prompt-engineering"}}, "authors": {"152347": {"item_id": "3935874788", "author_id": "152347", "name": "John Stewart", "url": ""}}, "listen_duration_estimate": 825}, "4012449499": {"item_id": "4012449499", "resolved_id": "4012449499", "given_url": "https://every.to/chain-of-thought/i-spent-a-week-with-gemini-pro-1-5-it-s-fantastic", "given_title": "I Spent a Week With Gemini Pro 1.5—It’s Fantastic", "favorite": "0", "status": "1", "time_added": "1708716272", "time_updated": "1709245430", "time_read": "1709245430", "time_favorited": "0", "sort_id": 27, "resolved_title": "I Spent a Week With Gemini Pro 1.5—It’s Fantastic", "resolved_url": "https://every.to/chain-of-thought/i-spent-a-week-with-gemini-pro-1-5-it-s-fantastic", "excerpt": "I got access to Gemini Pro 1.5 this week, a new private beta LLM from Google that is significantly better than previous models the company has released. (This is not the same as the publicly available version of Gemini that made headlines for refusing to create pictures of white people.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2218", "lang": "", "top_image_url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/social_media_image/2987/unnamed__1_.png", "tags": {"llms": {"item_id": "4012449499", "tag": "llms"}}, "authors": {"145988006": {"item_id": "4012449499", "author_id": "145988006", "name": "Dan Shipper", "url": "https://every.to/@danshipper"}}, "image": {"item_id": "4012449499", "src": "https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_SKrl7Ap8_CshyMPZzU6g5BYJQiO4qovUOxHxtEwsnMKgt3hyE62jLlphOGOnymq3IWijCRw52Qa2CHLCV0P2ayN_vW0Ty3vKQCvEHUJjyMTwFDwOlRTmvu3vzELxeBX3KmMyk0rEGD3-OJbprsbWClo.jpeg?link=true", "width": "0", "height": "0"}, "images": {"1": {"item_id": "4012449499", "image_id": "1", "src": "https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_SKrl7Ap8_CshyMPZzU6g5BYJQiO4qovUOxHxtEwsnMKgt3hyE62jLlphOGOnymq3IWijCRw52Qa2CHLCV0P2ayN_vW0Ty3vKQCvEHUJjyMTwFDwOlRTmvu3vzELxeBX3KmMyk0rEGD3-OJbprsbWClo.jpeg?link=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "4012449499", "image_id": "2", "src": "https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_5m9XaeCjJatECMsZPWfHiETRxcnEuqNzAsS-7tLNXfldqs5t4B5cFb69KayzRsHqDp7ILGdT7_Bm4e2r47Rk2l157vTp-upj0hxz4Uv25qGIRbQW5CJgaxsqIqNcITFUT4IcVxRaY8UF8yAK2Yz7nUg.png?link=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "4012449499", "image_id": "3", "src": "https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_RzVSwQXYEzkc1-jRgMbJI0w_MORMnpOxiUxuFsor9W8aQc89Kg2rNQwUbISr2tZYhoMoY3ytH3PzyChjzWCAeosSW-gSs3-cQ7eWVmKGoOVJWBYajK2sq_pSAY7-VWKT5nEYvCc7AhirdVZo8tkDOV4.png?link=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "4012449499", "image_id": "4", "src": "https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_aiJO3PEKKuKHmxH_2-kkiz_dU--g3ziZiYLtVKnEdo0_DEW-cSQpAGanVh6zXG3hKbG9p-h0DTj7WPxBFw0xmg95Db1R0NbQcSjCJWES8ZLacB7zzJfcwK0uqP7Swn69urVtlj2Bv5mIaywHiRq1e58.png?link=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "4012449499", "image_id": "5", "src": "https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_5ndXV70ZOkhbkKS_SwjPvGjuGthtO8PtByUrwwegnG6mowFMMaL7gPszZywK2evsc0dbcDcT3SGzDlRfHsC-KSJg0CgNDjMXuSZSfD-gYkcH17guW3WCsCw5VxDhbumEuRjgpgUwDiBPs1dhP5W_v2s.png?link=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "4012449499", "image_id": "6", "src": "https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_XR6ONC4CxNAXqwkjLonwUfQ6JM7Z5TfgaxIuxg9Vty2U9lTW3In_mYypbLbW4j6Uz_hROYJMCKvw6Dn_VYEmycnQzI0WknHp98cC1qaWJVd8mFamw8F0GRbSEPCwjeemoc-9J_qEdvD69bKpV60A-0A.png?link=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "4012449499", "image_id": "7", "src": "https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_2guBdWnLlBm7smAIdqUFYI_wGMqFBIq_Qpg04ujMgd7kl0P12I1pybXHe80ayLjaeG-2MF7AdGx74i0EcRGOqEG9tTioDP_J5BvF9QdTn-4aUG-gdIygvJQoYRZaOSfK8PCRbXlN04r8C320o3eO4vk.png?link=true", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 859}, "3949131276": {"item_id": "3949131276", "resolved_id": "3949131276", "given_url": "https://flyte.org/blog/getting-started-with-large-language-models-key-things-to-know#what-are-llms", "given_title": "Getting Started with Large Language Models: Key Things to Know", "favorite": "0", "status": "1", "time_added": "1697133127", "time_updated": "1697764416", "time_read": "1697764416", "time_favorited": "0", "sort_id": 28, "resolved_title": "Getting Started with Large Language Models: Key Things to Know", "resolved_url": "https://flyte.org/blog/getting-started-with-large-language-models-key-things-to-know#what-are-llms", "excerpt": "As a machine learning engineer who has witnessed the rise of Large Language Models (LLMs), I find it daunting to comprehend how the ecosystem surrounding LLMs is developing. Every week, I come across new tools and techniques related to LLMs on my Twitter feed.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4630", "lang": "en", "time_to_read": 21, "top_image_url": "https://assets-global.website-files.com/63bc83b29094ec80844b6dd5/6526dc79dea0f080d2d61d6f_Starting-with-large-language-models.webp", "tags": {"llms": {"item_id": "3949131276", "tag": "llms"}}, "image": {"item_id": "3949131276", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7acad02c40d777c57e_vhiySUD-e-bRSZISk2VyN92nxWrMQGP9AqqiDPVsTm2_sWaccjGWkxihFg4DKiL2lfhbg3xonfvMRpzDnvwuvIuiJhto8cPiltZgjhY4Y6vL6-yzH-f4-eqNApwrO8z6lqmy9iRyzNMuqHq6gkAeYX4.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3949131276", "image_id": "1", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7acad02c40d777c57e_vhiySUD-e-bRSZISk2VyN92nxWrMQGP9AqqiDPVsTm2_sWaccjGWkxihFg4DKiL2lfhbg3xonfvMRpzDnvwuvIuiJhto8cPiltZgjhY4Y6vL6-yzH-f4-eqNApwrO8z6lqmy9iRyzNMuqHq6gkAeYX4.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3949131276", "image_id": "2", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526df6b5c3a19649d0943e5_circular-wiggle.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3949131276", "image_id": "3", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7abdca412177ebf5e0_MJ7kAA472mdMZpxlpZdCkp5SHefoHsDt2LGS6hRCHHeZ0Wp-_4R0iNMl08HfYWcbwpcEGZHhAhjdCKArL3wfEX_qydata-WmQt_fI-M9DeBTAiUkie5RFqwsqKhdqtcTt6YZ4n8YtYP4Khpm2urtgV8.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3949131276", "image_id": "4", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7a973293482c53741a_QerwpukKzVys4dS78_GFbu9M6RzbRxsKpZN2LtqoJzfl2KWyTlnM3oLUcvW0YDepcKDXbNhcdKkcEXBaVRNzPm5dVfvJGOFC6rn1ueApLkW_ZZgcOtUFG2B7jECca-kbycfXBNMN6PmY9WQT9ZzD41E.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3949131276", "image_id": "5", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7b523a12e5ee41a97e_t1qNIPgILazRwUbuIKISqiEZ1ePUqd_hEQan3gLP3WQhxSRuP1LMTu_MLzxjEgkdWVB119SPF_rlwicEHzIB8OLFANzaMVpGLVZD901dbzj9vGAvybZCOGlD_WBJmvR2BtQB8g8_ebZHJhWaeHOrBgw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3949131276", "image_id": "6", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7acad02c40d777c5be_uQsLsVTB6uSL-VfRzivujHxja8-wvSF2OL4GptGM_4FTvSkaJ2CjmZMvOYqyIV2wSmMT5rfdtN3DXrgbJuLmU5T7O5A8dDvm2kSMVJoSyySV5-9IGfz1zFX4qbq66rftK6JX9LjwR7T_FCZJYMXW0hI.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3949131276", "image_id": "7", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7ad98b0710b7a4b5bd_p5FGHZ4oQhjv46aTd2pkBcLbOrTpljqqFuCLK1nYDxkjO-vkC-B2YQ0vHD26xp4qibYyYyYvcmK4N5Zvtd6R_Qtg--JoomGJpj0AkW0LbYOSeft-k-pZanHyGIe2TVB6rhP0Y5HOgTAy2x7uNu4R-xs.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3949131276", "image_id": "8", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7a9e5946ce6be0da2f_JaZuPahPaKwejaT7XxcHuWed6EEiXwNjAmmaFxEA0utxXiSlaPNis24cARKD2iJnVytBTmgE34r9WPikAssIl2v2HATndM3mP_COb1B2bzCd1xTW6jhjd53X8-N1vQVgdeOGOB3FPZ2Lzs8t1Z4arC8.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3949131276", "image_id": "9", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7a2ef13c9c9ea4e49a_0DUqKmq_GlbM6o3Mo-T19l-lwOKhwHNdqPkz9Tv6NmkLxAYVRIdN1K-WIZJtyX5RLUBYdalFjrxkX5EAYd4kWJgjVcyRe-j9YOLNELdTr4wHv2gDhBgYdFVxYEuWHTwPgaEkh6jMZbeEM536d_00fyc.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3949131276", "image_id": "10", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7a2c0d5b9fc0b70522_sYkpR7MFfYX27TGzGSHXvAqeaNR_A3uc-SfHOfdB6ghzJCXz0zO1INi3QzlxXXkSslSud78f3u3zCCVuxHug09D5s4GoQlormtm0unE61sO-Q8iQTJmAAuIql_ceeVvOiEZASNej4K_hWBnruFpR8lk.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3949131276", "image_id": "11", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7b00210dacf8dbaba5_prxmosontgXmGuQJ0WxEkacJwbStS50flJkzX13eJmTG1HbGiDkXzJ4pTMM1uEuu8epop2pRhNDnWA-kvJJgBSiQJHqt3g1wwLMunYF_21_t1w_t26BhzJgrmj-TwlnD9MyR_lB9rruBm-iTqmFscC4.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3949131276", "image_id": "12", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7ac957a70292c794f4_598lLYbp9pdY6jShouCZuXQK_X_FxnWPxbFP_kkIv1WYnaispQMazodOxpKamY4jxYlvxAykrDIUFfLoFktBhlakfaIzsm1vCdpMfZp4ymOvSue0paxBzJte9QBCuXfr7ImAxTnarX5PRma9sc_cX44.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3949131276", "image_id": "13", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7a9358df9297a745c3_VcuXY6_891-FjYOPlzxwIQPzmMo4oLOfJE8vKFpK_Jo45mEuy6zTkmK0QoXKFoYqcQ7-8A8t43tOks7Xa1gicD6NZxmJRF4e7fICOmUG41PnaGASjezWGi9NbRZIZQGre3_BvIUs2-AqfWUEG5CMPTc.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "3949131276", "image_id": "14", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7a58abce2cf80c7ec4_3xuGN41Y7YS_FrN2v4e_OuSrPloFU9IR0BQCRDsrR6f6tzParykxZ31uazO5Z1njqicoXsfPWdmOBcmK3p5EGffZSKC_mT6AoBTJhD8r6Eobbkeu0MUYJ52aUPXixE2gqQ7g--T8lXCSHCiV5boZX08.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "3949131276", "image_id": "15", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7a85ec36671da4beed_LFlGG_lEIghK6EDT9JX6eRFV0OCeg5V3XU55bK6KOWfyK587162XIwJWp4qUwgSo6Maq2sELAh7x4lYmmwxB4rxwYZdti5WWVx4e-7amly4G-PQ-xFryT8ypOcwa5HIjlcIpGm92GutgTxd_bJgn61w.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "3949131276", "image_id": "16", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7a3a01cebbc6fede41_3kV3_EHVsIsvhqHiDvj68BpsPSwvyFIOv7RV8ZB6zfxJdulGqzsWT2kZDJHwZMc99Zhrstw29L3vEDyC7YiRSQC1AlS4KdvEf_AvzLRS002MFUD2El5-YnmS13FgiNhbgJF9HCOgcx6II0tjFRvIJJw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "3949131276", "image_id": "17", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7a85ec36671da4bee9_XFLTneVrI20STsazT3u69bQJtnNhytvSSqjYFNh5DXc9SHjnxgBsxnfPBuIHtvK0WL8No9Z835qaXq826WF48TtUQ7g-_CubAHjb69UvEErXoR7pKAsaRDn6CwVRA1QpS4XoFkfFWGCHCthGk80o0Rs.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "3949131276", "image_id": "18", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7ab6869df20b2f7310_L1lzUbREy9_abXbHFOfWJvvoC3-j1QySAl5JkpmLlhrwQt58VxGJ3ixT_xvTUcgIwbP_2WBesT_xkCELMKE3gQTztlcCEiMOlWY9N1Av4ugXO1OVuo7MUuv1jPM1gVJWfXL9C3d67wutg1y_GhYIqak.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "3949131276", "image_id": "19", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7aafb7a686d8643a80_VTe0h3y2KO_ScFQ4BweoovzGq_nm_xdECSxbcp4ynct9HtgwQu_uYm09j5RVIcSqYW8xErsn1nujOp50k8XeyzwfWgdtFkOZ_ybBcJzFeblbvVb1jgWB_FpTy1PlIHSde84RBNjp7CbSX1WBAXdp7mI.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "3949131276", "image_id": "20", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7aa204e991feec3a9a_SgR3MGQN8PV_rxDdoPawloL1aMOrdfU-kutd96ihVc4-EBKG-XA-dFCsZYbZAI-1bM4_jM60mpOXLEWUTpYmek7IjP2s3Cx6oSCWo-Qvodr_bcc2oXcL6Ww1E8os-scKENqu6FTFIuVq65vlFBsytXs.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "3949131276", "image_id": "21", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7a3a01cebbc6fede47_VyYrZ4BkcSSJxHHcnfsfZr4UUETO1JcliFMEr1bBkRXGjw-g-0kM_BtQN9golSFOESm1uLjlsxNVlYbJHriSCJUX-XDIgd_CSh4k37XyMPazzF-203QHagbLY8An0lwNbO4XUYG3WnsgBxnNFZxgTiE.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "3949131276", "image_id": "22", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7a7583bb32b0bb9207_fmaeYH7UD8eOrpmDv55DuubnHoj9kXUFkKWN2dKt4g1qvFMSsyZhKF92eicJfCryhoLuwiAKp5EyP9stqFYiM-nz0bp6DBo-u9pqHUFMKQUOIJwvLjTlGzFB8CE7uRrPqhjQBSCixHWg37A5YmWvKXg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "23": {"item_id": "3949131276", "image_id": "23", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7a9358df9297a7459f_0aW9iRLuTbXJ9QyE35YRzXID3pjvD59afhrq1U_9_9AA2gvlGKera8SDiGMRYU6bbKzLwtoIwJo18GWU74xuEJ3szLOWt1YCtUAZXqF32unos4K3qAlG4yw2iqaypNwQoLAvJvTQUDe8Dl6XDGYkM8k.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "3949131276", "image_id": "24", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7a87a474ff8229fb12_138XdFxUt2Ok4xbwlf46-k7bHYFLKjAYo63p8E-19o7W51m3aZEHNb3zFfb75cQqQlfr0WSDbINgNsy76DCfY6GMy5E_5jTLSESRAn8zLXi36wog1VXzrTotVyQdiaNSue-vIsKTXkICklq-shNfM7Y.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "3949131276", "image_id": "25", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7a98bd2645ac8cb546_2oYfMA1IYxhebWoUqcNNgifKRQz0dovbka_dE8SfAfSr9GfcENkc0DoxcvbaN9eQL-vNa5XBbzV8wWb_51wwEU7nuljL02RjsG3phGSbOkyZjYZPwfN3WQBlsx5hCzoVvzTzbkQFnCMeh990LxGCMBU.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "26": {"item_id": "3949131276", "image_id": "26", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7a2c0d5b9fc0b70519_WftY87s-mCLRQ2vZLh2vlb05ZEmhFNAHbSBmMV88SkK6RmrT7HT_NT94F7Zo6ePrKy0eP72oXIxEkMznNQU-EGaK8N7j07aNio93WsxqG18mvRYdRPGAKxCbe5CAeRgRLHIRhzpH_m6XSSyWDa-pRUc.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "27": {"item_id": "3949131276", "image_id": "27", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7ada8b9b0182bf5fd7_BPQqPJjzyeKnknmYc4z9UKdfa-kyBOgQKFjOYl4OlTJ6DIN7MgxXNsDNuU6Ah2XGVxoLeAK_HUcsZWJFyTm0SESPLVy4ZllNa4lYROoaljzC43SXFE6yqpiBgWG7sBey21WfdwpiicntBVxkig8YTDE.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "28": {"item_id": "3949131276", "image_id": "28", "src": "https://assets.website-files.com/63bc83b29094ec80844b6dd5/6526dc7b7cf1df604e4a5c23_35MRswvSORpeJB6VZMfGzoOn85yxbufQWQJgP7klZHsoTvxUZijkv0juf-mwQZGeZ0i1-fc3K-CyVw4KH5GTzj8OikV3AQzweML2Ufr3-AKNXTaAx3FB3N3USM_uGxTftgL97x5a_gYhw-EsDSc_NPs.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1792}, "3868163027": {"item_id": "3868163027", "resolved_id": "3868163027", "given_url": "https://github.com/iryna-kondr/scikit-llm", "given_title": "iryna-kondr/scikit-llm: Seamlessly integrate LLMs into scikit-learn.", "favorite": "0", "status": "1", "time_added": "1692880993", "time_updated": "1693515317", "time_read": "1693515317", "time_favorited": "0", "sort_id": 29, "resolved_title": "iryna-kondr/scikit-llm", "resolved_url": "https://github.com/iryna-kondr/scikit-llm", "excerpt": "Seamlessly integrate powerful language models like ChatGPT into scikit-learn for enhanced text analysis tasks. At the moment Scikit-LLM is only compatible with some of the OpenAI models. Hence, a user-provided OpenAI API key is required.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "660", "lang": "en", "time_to_read": 3, "top_image_url": "https://opengraph.githubassets.com/b74aa95fbb308658619a1665712015463f2af5e06e212c483f013594da03c3ee/iryna-kondr/scikit-llm", "tags": {"llms": {"item_id": "3868163027", "tag": "llms"}, "scikit-learn": {"item_id": "3868163027", "tag": "scikit-learn"}}, "authors": {"181878295": {"item_id": "3868163027", "author_id": "181878295", "name": "iryna-kondr", "url": "https://github.com/iryna-kondr/scikit-llm/commits?author=iryna-kondr"}}, "image": {"item_id": "3868163027", "src": "https://github.com/iryna-kondr/scikit-llm/blob/main/logo.png?raw=true", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3868163027", "image_id": "1", "src": "https://github.com/iryna-kondr/scikit-llm/blob/main/logo.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 255}, "3883502993": {"item_id": "3883502993", "resolved_id": "3868163027", "given_url": "https://github.com/iryna-kondr/scikit-llm/issues", "given_title": "iryna-kondr/scikit-llm", "favorite": "0", "status": "1", "time_added": "1686244531", "time_updated": "1686264139", "time_read": "1686264139", "time_favorited": "0", "sort_id": 30, "resolved_title": "iryna-kondr/scikit-llm", "resolved_url": "https://github.com/iryna-kondr/scikit-llm", "excerpt": "Seamlessly integrate powerful language models like ChatGPT into scikit-learn for enhanced text analysis tasks. At the moment Scikit-LLM is only compatible with some of the OpenAI models. Hence, a user-provided OpenAI API key is required.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "660", "lang": "en", "time_to_read": 3, "top_image_url": "https://opengraph.githubassets.com/b74aa95fbb308658619a1665712015463f2af5e06e212c483f013594da03c3ee/iryna-kondr/scikit-llm", "tags": {"llms": {"item_id": "3883502993", "tag": "llms"}}, "authors": {"181878295": {"item_id": "3883502993", "author_id": "181878295", "name": "iryna-kondr", "url": "https://github.com/iryna-kondr/scikit-llm/commits?author=iryna-kondr"}}, "image": {"item_id": "3883502993", "src": "https://github.com/iryna-kondr/scikit-llm/blob/main/logo.png?raw=true", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3883502993", "image_id": "1", "src": "https://github.com/iryna-kondr/scikit-llm/blob/main/logo.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 255}, "3844165915": {"item_id": "3844165915", "resolved_id": "3844165915", "given_url": "https://github.com/microsoft/guidance", "given_title": "", "favorite": "0", "status": "1", "time_added": "1683074180", "time_updated": "1683112678", "time_read": "1683112678", "time_favorited": "0", "sort_id": 31, "resolved_title": "microsoft/guidance", "resolved_url": "https://github.com/microsoft/guidance", "excerpt": "Where there is no guidance, a model fails, but in an abundance of instructions there is safety.- GPT 11:14 Guidance enables you to control modern language models more effectively and efficiently than traditional prompting or chaining.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "4521", "lang": "en", "time_to_read": 21, "top_image_url": "https://opengraph.githubassets.com/17a70b48e28560b11326eab4431bf21d602bc2cbc93c9ca3dd7cbf2f98334a44/microsoft/guidance", "tags": {"llms": {"item_id": "3844165915", "tag": "llms"}}, "authors": {"180459746": {"item_id": "3844165915", "author_id": "180459746", "name": "slundberg", "url": "https://github.com/microsoft/guidance/commits?author=slundberg"}}, "image": {"item_id": "3844165915", "src": "https://camo.githubusercontent.com/c1200a1e1c13d2e74f186e2c7497ca3941858a3b8f0158fccf06fbda431b4ef2/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f67756964616e63652f62616467652f3f76657273696f6e3d6c6174657374267374796c653d666c6174", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3844165915", "image_id": "1", "src": "https://camo.githubusercontent.com/c1200a1e1c13d2e74f186e2c7497ca3941858a3b8f0158fccf06fbda431b4ef2/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f67756964616e63652f62616467652f3f76657273696f6e3d6c6174657374267374796c653d666c6174", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3844165915", "image_id": "2", "src": "https://github.com/microsoft/guidance/raw/main/docs/figures/guidance_logo_blue.svg", "width": "300", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3844165915", "image_id": "3", "src": "https://github.com/microsoft/guidance/raw/main/docs/figures/proverb_animation.gif", "width": "404", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3844165915", "image_id": "4", "src": "https://github.com/microsoft/guidance/raw/main/docs/figures/chat_animation.gif", "width": "619", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3844165915", "image_id": "5", "src": "https://github.com/microsoft/guidance/raw/main/docs/figures/json_animation.gif", "width": "565", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3844165915", "image_id": "6", "src": "https://github.com/microsoft/guidance/blob/main/docs/figures/url_with_space.png", "width": "372", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3844165915", "image_id": "7", "src": "https://github.com/microsoft/guidance/blob/main/docs/figures/url_without_space.png", "width": "362", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3844165915", "image_id": "8", "src": "https://github.com/microsoft/guidance/blob/main/docs/figures/anachronism.png", "width": "837", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3844165915", "image_id": "9", "src": "https://github.com/microsoft/guidance/blob/main/docs/figures/perfect_syntax.png", "width": "657", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3844165915", "image_id": "10", "src": "https://github.com/microsoft/guidance/blob/main/docs/figures/json_syntax_variables.png", "width": "714", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3844165915", "image_id": "11", "src": "https://github.com/microsoft/guidance/blob/main/docs/figures/chat_reading.png", "width": "935", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3844165915", "image_id": "12", "src": "https://github.com/microsoft/guidance/blob/main/docs/figures/template_objs.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3844165915", "image_id": "13", "src": "https://github.com/microsoft/guidance/blob/main/docs/figures/generation1.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "3844165915", "image_id": "14", "src": "https://github.com/microsoft/guidance/blob/main/docs/figures/select.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "3844165915", "image_id": "15", "src": "https://github.com/microsoft/guidance/blob/main/docs/figures/generate_select.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "3844165915", "image_id": "16", "src": "https://github.com/microsoft/guidance/blob/main/docs/figures/hidden1.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "3844165915", "image_id": "17", "src": "https://github.com/microsoft/guidance/blob/main/docs/figures/function.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "3844165915", "image_id": "18", "src": "https://github.com/microsoft/guidance/blob/main/docs/figures/await1.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "3844165915", "image_id": "19", "src": "https://github.com/microsoft/guidance/blob/main/docs/figures/await2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "3844165915", "image_id": "20", "src": "https://github.com/microsoft/guidance/blob/main/docs/figures/chat1.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 1750}, "3854410627": {"item_id": "3854410627", "resolved_id": "3854410627", "given_url": "https://github.com/Mooler0410/LLMsPracticalGuide", "given_title": "GitHub - Mooler0410/LLMsPracticalGuide: A curated list of practical guide r", "favorite": "0", "status": "1", "time_added": "1688746827", "time_updated": "1689188521", "time_read": "1689188521", "time_favorited": "0", "sort_id": 32, "resolved_title": "Mooler0410/LLMsPracticalGuide", "resolved_url": "https://github.com/Mooler0410/LLMsPracticalGuide", "excerpt": "A curated (still actively updated) list of practical guide resources of LLMs. It's based on our survey paper: Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond. The survey is partially based on the second half of this Blog.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1659", "lang": "en", "time_to_read": 8, "top_image_url": "https://opengraph.githubassets.com/03755618a97a612c58e1f1de70c3131a2db969669d382afff5ab58b5aab8c371/Mooler0410/LLMsPracticalGuide", "tags": {"llms": {"item_id": "3854410627", "tag": "llms"}}, "authors": {"181306449": {"item_id": "3854410627", "author_id": "181306449", "name": "JingfengYang", "url": "https://github.com/Mooler0410/LLMsPracticalGuide/commits?author=JingfengYang"}}, "image": {"item_id": "3854410627", "src": "https://camo.githubusercontent.com/64f8905651212a80869afbecbf0a9c52a5d1e70beab750dea40a994fa9a9f3c6/68747470733a2f2f617765736f6d652e72652f62616467652e737667", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3854410627", "image_id": "1", "src": "https://camo.githubusercontent.com/64f8905651212a80869afbecbf0a9c52a5d1e70beab750dea40a994fa9a9f3c6/68747470733a2f2f617765736f6d652e72652f62616467652e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3854410627", "image_id": "2", "src": "https://github.com/Mooler0410/LLMsPracticalGuide/blob/main/imgs/models-colorgrey.jpg", "width": "600", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3854410627", "image_id": "3", "src": "https://github.com/Mooler0410/LLMsPracticalGuide/blob/main/imgs/decision.png", "width": "500", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3854410627", "image_id": "4", "src": "https://camo.githubusercontent.com/6781c25d32adc865976fa3aaecd15b59dcef911fc46d2cb61a6f885c11933804/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d4d6f6f6c6572303431302f4c4c4d7350726163746963616c477569646526747970653d44617465", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 642}, "3858019045": {"item_id": "3858019045", "resolved_id": "3858019045", "given_url": "https://github.com/openlm-research/open_llama", "given_title": "", "favorite": "0", "status": "1", "time_added": "1683204149", "time_updated": "1683253499", "time_read": "1683253499", "time_favorited": "0", "sort_id": 33, "resolved_title": "openlm-research/open_llama", "resolved_url": "https://github.com/openlm-research/open_llama", "excerpt": "In this repo, we release a permissively licensed open source reproduction of Meta AI's LLaMA large language model. In this release, we're releasing a public preview of the 7B OpenLLaMA model that has been trained with 200 billion tokens.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "859", "lang": "en", "time_to_read": 4, "top_image_url": "https://opengraph.githubassets.com/1cd8bf7a9be65c937b1507d2c9c81bd7283e16c6cd256ceaebb78981d16d3bcc/openlm-research/open_llama", "tags": {"llms": {"item_id": "3858019045", "tag": "llms"}}, "image": {"item_id": "3858019045", "src": "https://github.com/openlm-research/open_llama/blob/main/media/loss_200bt.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3858019045", "image_id": "1", "src": "https://github.com/openlm-research/open_llama/blob/main/media/loss_200bt.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 333}, "3978375822": {"item_id": "3978375822", "resolved_id": "3978375822", "given_url": "https://github.com/rasbt/LLMs-from-scratch", "given_title": "rasbt/LLMs-from-scratch", "favorite": "0", "status": "1", "time_added": "1706400539", "time_updated": "1709250558", "time_read": "1709250558", "time_favorited": "0", "sort_id": 34, "resolved_title": "rasbt/LLMs-from-scratch", "resolved_url": "https://github.com/rasbt/LLMs-from-scratch", "excerpt": "Implementing a ChatGPT-like LLM from scratch, step by step - GitHub - rasbt/LLMs-from-scratch: Implementing a ChatGPT-like LLM from scratch, step by step", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "top_image_url": "https://opengraph.githubassets.com/2a7f6b37bb6161384780f6df9b6155612b0c684083b430662c62c55e7b800ea8/rasbt/LLMs-from-scratch", "tags": {"github": {"item_id": "3978375822", "tag": "github"}, "llms": {"item_id": "3978375822", "tag": "llms"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3909837477": {"item_id": "3909837477", "resolved_id": "3909837477", "given_url": "https://github.com/weaviate/recipes/blob/main/integrations/llama2-demo/notebook.ipynb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1691255618", "time_updated": "1692744555", "time_read": "1692744555", "time_favorited": "0", "sort_id": 35, "resolved_title": "", "resolved_url": "https://github.com/weaviate/recipes/blob/main/integrations/llama2-demo/notebook.ipynb", "excerpt": "{\"payload\":{\"allShortcutsEnabled\":false,\"fileTree\":{\"integrations/llama2-demo\":{\"items\":[{\"name\":\"data\",\"path\":\"integrations/llama2-demo/data\",\"contentType\":\"directory\"},{\"name\":\"notebook.ipynb\",\"path\":\"integrations/llama2-demo/notebook.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1355", "lang": "", "tags": {"llama": {"item_id": "3909837477", "tag": "llama"}, "llms": {"item_id": "3909837477", "tag": "llms"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 525}, "3905368976": {"item_id": "3905368976", "resolved_id": "3905368976", "given_url": "https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad", "given_title": "ELI5: FlashAttention", "favorite": "0", "status": "1", "time_added": "1690067652", "time_updated": "1706235131", "time_read": "1690159036", "time_favorited": "0", "sort_id": 36, "resolved_title": "ELI5: FlashAttention", "resolved_url": "https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad", "excerpt": "We’ll start from the first principles. We’ll first understand how the standard/vanilla attention is implemented and then we’ll address the inefficiencies one by one — as if we were to independently discover flash attention ourselves.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4678", "lang": "en", "time_to_read": 21, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*i4tDdwgvGtXuTIyJpFUn8A.png", "tags": {"deep-learning": {"item_id": "3905368976", "tag": "deep-learning"}, "llms": {"item_id": "3905368976", "tag": "llms"}}, "authors": {"143673938": {"item_id": "3905368976", "author_id": "143673938", "name": "Aleksa Gordić", "url": "https://gordicaleksa.medium.com"}}, "image": {"item_id": "3905368976", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*iFzlYkf9g8binsKxI66few.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3905368976", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*iFzlYkf9g8binsKxI66few.png", "width": "44", "height": "44", "credit": "", "caption": ""}}, "listen_duration_estimate": 1811}, "3863694724": {"item_id": "3863694724", "resolved_id": "3863694724", "given_url": "https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard", "given_title": "Open LLM Leaderboard : a Hugging Face Space by HuggingFaceH4", "favorite": "0", "status": "1", "time_added": "1694531300", "time_updated": "1695684742", "time_read": "1695684241", "time_favorited": "0", "sort_id": 37, "resolved_title": "Open LLM Leaderboard : a Hugging Face Space by HuggingFaceH4", "resolved_url": "https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard", "excerpt": "/ open_llm_leaderboard", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "3", "lang": "", "top_image_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/spaces/HuggingFaceH4/open_llm_leaderboard.png", "tags": {"benchmarks": {"item_id": "3863694724", "tag": "benchmarks"}, "llms": {"item_id": "3863694724", "tag": "llms"}}, "listen_duration_estimate": 1}, "3866437178": {"item_id": "3866437178", "resolved_id": "3866437178", "given_url": "https://informationisbeautiful.net/2023/the-non-silence-of-the-llms/", "given_title": "The Non-Silence of the LLMs", "favorite": "0", "status": "1", "time_added": "1684274834", "time_updated": "1684532228", "time_read": "1684526571", "time_favorited": "0", "sort_id": 38, "resolved_title": "The Non-Silence of the LLMs", "resolved_url": "https://informationisbeautiful.net/2023/the-non-silence-of-the-llms/", "excerpt": "AI is getting very chatty! Here’s a visualisation charting the rise of Large Language Models like GPT4, LaMDA, LLaMa, PaLM and their bots like ChatGPT. There’s also a revealing little data-story that arises when you plot all the LLMs.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "45", "lang": "en", "top_image_url": "https://infobeautiful4.s3.amazonaws.com/2023/05/IIB-LLM-decorative-blog-blog-1400x400-1-960x274.png", "tags": {"llms": {"item_id": "3866437178", "tag": "llms"}}, "authors": {"10729138": {"item_id": "3866437178", "author_id": "10729138", "name": "Information Is Beautiful", "url": ""}}, "listen_duration_estimate": 17}, "3997965889": {"item_id": "3997965889", "resolved_id": "3997965889", "given_url": "https://lightning.ai/lightning-ai/studios/code-lora-from-scratch", "given_title": "Code LoRA from Scratch - a Lightning Studio by sebastian", "favorite": "0", "status": "1", "time_added": "1707050278", "time_updated": "1707960606", "time_read": "1707960606", "time_favorited": "0", "sort_id": 39, "resolved_title": "Code LoRA from Scratch - a Lightning Studio by sebastian", "resolved_url": "https://lightning.ai/lightning-ai/studios/code-lora-from-scratch", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "top_image_url": "https://lightning.ai/v1/thumbnail/cloudspace/01hm9hypqc6y1hrapb5prmtz0h?t=1705951020", "tags": {"llms": {"item_id": "3997965889", "tag": "llms"}}, "listen_duration_estimate": 0}, "3949588593": {"item_id": "3949588593", "resolved_id": "3949588593", "given_url": "https://lightning.ai/pages/community/lora-insights/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1697235754", "time_updated": "1697764423", "time_read": "1697764423", "time_favorited": "0", "sort_id": 40, "resolved_title": "Finetuning LLMs with LoRA and QLoRA: Insights from Hundreds of Experiments", "resolved_url": "https://lightning.ai/pages/community/lora-insights/", "excerpt": "LoRA is one of the most widely used, parameter-efficient finetuning techniques for training custom LLMs. From saving memory with QLoRA to selecting the optimal LoRA settings, this article provides practical insights for those interested in applying it.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3074", "lang": "en", "time_to_read": 14, "top_image_url": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage7.png", "tags": {"llms": {"item_id": "3949588593", "tag": "llms"}}, "authors": {"179934693": {"item_id": "3949588593", "author_id": "179934693", "name": "Sebastian Raschka", "url": "https://lightning.ai/pages/author/sebastian-raschka/"}}, "image": {"item_id": "3949588593", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage7.png", "width": "684", "height": "404"}, "images": {"1": {"item_id": "3949588593", "image_id": "1", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage7.png", "width": "684", "height": "404", "credit": "", "caption": ""}, "2": {"item_id": "3949588593", "image_id": "2", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage1.jpg", "width": "643", "height": "482", "credit": "", "caption": ""}, "3": {"item_id": "3949588593", "image_id": "3", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage5.jpg", "width": "570", "height": "425", "credit": "", "caption": ""}, "4": {"item_id": "3949588593", "image_id": "4", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage2.jpg", "width": "1764", "height": "322", "credit": "", "caption": ""}, "5": {"item_id": "3949588593", "image_id": "5", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage12.jpg", "width": "899", "height": "577", "credit": "", "caption": ""}, "6": {"item_id": "3949588593", "image_id": "6", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage10.jpg", "width": "1424", "height": "260", "credit": "", "caption": ""}, "7": {"item_id": "3949588593", "image_id": "7", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage9.jpg", "width": "618", "height": "218", "credit": "", "caption": ""}, "8": {"item_id": "3949588593", "image_id": "8", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage3.jpg", "width": "1728", "height": "356", "credit": "", "caption": ""}, "9": {"item_id": "3949588593", "image_id": "9", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage11.jpg", "width": "603", "height": "452", "credit": "", "caption": ""}, "10": {"item_id": "3949588593", "image_id": "10", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage18.jpg", "width": "395", "height": "335", "credit": "", "caption": ""}, "11": {"item_id": "3949588593", "image_id": "11", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage17.jpg", "width": "1756", "height": "322", "credit": "", "caption": ""}, "12": {"item_id": "3949588593", "image_id": "12", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage8.jpg", "width": "1768", "height": "380", "credit": "", "caption": ""}, "13": {"item_id": "3949588593", "image_id": "13", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage4.jpg", "width": "1770", "height": "574", "credit": "", "caption": ""}, "14": {"item_id": "3949588593", "image_id": "14", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage14.jpg", "width": "1764", "height": "774", "credit": "", "caption": ""}, "15": {"item_id": "3949588593", "image_id": "15", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/lora-expimage15.jpg", "width": "1758", "height": "472", "credit": "", "caption": ""}, "16": {"item_id": "3949588593", "image_id": "16", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/10/Screenshot-2023-10-12-at-8.52.49%E2%80%AFPM.png", "width": "471", "height": "174", "credit": "", "caption": ""}}, "listen_duration_estimate": 1190}, "3897712130": {"item_id": "3897712130", "resolved_id": "3897712130", "given_url": "https://lightning.ai/pages/community/tutorial/pytorch-memory-vit-llm/", "given_title": "Optimizing Memory Usage for Training LLMs and Vision Transformers in PyTorc", "favorite": "0", "status": "1", "time_added": "1688429038", "time_updated": "1690156786", "time_read": "1690156786", "time_favorited": "0", "sort_id": 41, "resolved_title": "Optimizing Memory Usage for Training LLMs and Vision Transformers in PyTorch", "resolved_url": "https://lightning.ai/pages/community/tutorial/pytorch-memory-vit-llm/", "excerpt": "Key takeaway Peak memory consumption is a common bottleneck when training deep learning models such as vision transformers and LLMs.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2795", "lang": "en", "time_to_read": 13, "top_image_url": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/07/pytorch-memory-hero.png", "tags": {"llms": {"item_id": "3897712130", "tag": "llms"}, "pytorch": {"item_id": "3897712130", "tag": "pytorch"}, "transformers": {"item_id": "3897712130", "tag": "transformers"}}, "authors": {"179934693": {"item_id": "3897712130", "author_id": "179934693", "name": "Sebastian Raschka", "url": "https://lightning.ai/pages/author/sebastian-raschka/"}}, "image": {"item_id": "3897712130", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/07/8_mixed-training-1024x339.png", "width": "622", "height": "206"}, "images": {"1": {"item_id": "3897712130", "image_id": "1", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/07/8_mixed-training-1024x339.png", "width": "622", "height": "206", "credit": "", "caption": ""}, "2": {"item_id": "3897712130", "image_id": "2", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/07/bfloat16.png", "width": "634", "height": "493", "credit": "", "caption": ""}, "3": {"item_id": "3897712130", "image_id": "3", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/07/data-para-new.png", "width": "674", "height": "239", "credit": "", "caption": ""}, "4": {"item_id": "3897712130", "image_id": "4", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/07/tensor-para-1-new.png", "width": "647", "height": "262", "credit": "", "caption": ""}, "5": {"item_id": "3897712130", "image_id": "5", "src": "https://lightningaidev.wpengine.com/wp-content/uploads/2023/07/tensor-para-2-new.png", "width": "687", "height": "295", "credit": "", "caption": ""}}, "listen_duration_estimate": 1082}, "3828369493": {"item_id": "3828369493", "resolved_id": "3828369493", "given_url": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1680180511", "time_updated": "1681439271", "time_read": "1681439270", "time_favorited": "0", "sort_id": 42, "resolved_title": "Prompt Engineering", "resolved_url": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/", "excerpt": "Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4053", "lang": "en", "time_to_read": 18, "tags": {"llms": {"item_id": "3828369493", "tag": "llms"}, "prompt-engineering": {"item_id": "3828369493", "tag": "prompt-engineering"}}, "authors": {"76470090": {"item_id": "3828369493", "author_id": "76470090", "name": "Lilian Weng", "url": ""}}, "image": {"item_id": "3828369493", "src": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/SelfAsk-search.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3828369493", "image_id": "1", "src": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/SelfAsk-search.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3828369493", "image_id": "2", "src": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/tree-of-thoughts.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3828369493", "image_id": "3", "src": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/PoT.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3828369493", "image_id": "4", "src": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/TALM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3828369493", "image_id": "5", "src": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/TALM-iteration.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3828369493", "image_id": "6", "src": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/toolformer.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3828369493", "image_id": "7", "src": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/toolformer-annotation.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1569}, "3883991320": {"item_id": "3883991320", "resolved_id": "3883991320", "given_url": "https://llm.garden/", "given_title": "LMM Garden | Discover, search, and compare LLMs", "favorite": "0", "status": "1", "time_added": "1686314395", "time_updated": "1686348000", "time_read": "1686348000", "time_favorited": "0", "sort_id": 43, "resolved_title": "LMM Garden | Discover, search, and compare LLMs", "resolved_url": "https://llm.garden/", "excerpt": "With so many Large Language Models (LLMs) released daily, we put together a list of everything available so we can easily search and compare our options. Have an LLM to add or update? Let us know!", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "42", "lang": "en", "top_image_url": "https://llm.garden/wp-content/uploads/2023/05/Social-share_LLM-Garden-1024x535.png", "tags": {"llms": {"item_id": "3883991320", "tag": "llms"}}, "image": {"item_id": "3883991320", "src": "https://llm.garden/wp-content/uploads/2023/05/bg-stars-mobile.svg", "width": "374", "height": "205"}, "images": {"1": {"item_id": "3883991320", "image_id": "1", "src": "https://llm.garden/wp-content/uploads/2023/05/bg-stars-mobile.svg", "width": "374", "height": "205", "credit": "", "caption": ""}}, "listen_duration_estimate": 16}, "3987130320": {"item_id": "3987130320", "resolved_id": "3987130320", "given_url": "https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023", "given_title": "10 Noteworthy AI Research Papers of 2023", "favorite": "0", "status": "1", "time_added": "1704585683", "time_updated": "1704663279", "time_read": "1704663279", "time_favorited": "0", "sort_id": 44, "resolved_title": "Ten Noteworthy AI Research Papers of 2023", "resolved_url": "https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023", "excerpt": "This year has felt distinctly different. I've been working in, on, and with machine learning and AI for over a decade, yet I can't recall a time when these fields were as popular and rapidly evolving as they have been this year.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4179", "lang": "en", "time_to_read": 19, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0046298-1059-4538-bcd8-dfcfc863d7c5_1254x810.png", "tags": {"arxiv": {"item_id": "3987130320", "tag": "arxiv"}, "llms": {"item_id": "3987130320", "tag": "llms"}, "machine-learning": {"item_id": "3987130320", "tag": "machine-learning"}}, "authors": {"177301683": {"item_id": "3987130320", "author_id": "177301683", "name": "Sebastian Raschka, PhD", "url": ""}}, "image": {"item_id": "3987130320", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35f86db1-771a-4b2f-82cd-5daa732dbe4f_1190x828.png", "width": "500", "height": "348"}, "images": {"1": {"item_id": "3987130320", "image_id": "1", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35f86db1-771a-4b2f-82cd-5daa732dbe4f_1190x828.png", "width": "500", "height": "348", "credit": "https://arxiv.org/abs/2307.09288", "caption": "Annotated figure from Llama 2 paper"}, "2": {"item_id": "3987130320", "image_id": "2", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29b1ac66-ff44-461d-95f3-8a9fb07b6562_1384x764.png", "width": "596", "height": "329", "credit": "https://arxiv.org/abs/2307.09288", "caption": "Annotated figure from Llama 2 paper"}, "3": {"item_id": "3987130320", "image_id": "3", "src": "https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe06a33c8-cdbd-4f5e-8380-86fb71a075c8_2216x1232.png", "width": "140", "height": "140", "credit": "", "caption": "LLM Training: RLHF and Its Alternatives"}, "4": {"item_id": "3987130320", "image_id": "4", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe57930b6-afd0-48e6-90a6-97b5dcacb89f_1560x662.png", "width": "616", "height": "261", "credit": "", "caption": "A short visual summary of regular LoRA"}, "5": {"item_id": "3987130320", "image_id": "5", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39daaf2c-4e5c-4075-8697-3c0a636f2144_1226x578.png", "width": "618", "height": "291", "credit": "", "caption": "Among the many efficient finetuning methods for LLMs, LoRA is among the most popular and widely used ones. Annotated figure from the excellent Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning survey. "}, "6": {"item_id": "3987130320", "image_id": "6", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09755a6f-ceb5-4011-8651-45ffffd260e5_1290x928.png", "width": "348", "height": "250", "credit": "", "caption": "Example of two training examples from a dataset for the supervised instruction finetuning step. Note that the \"input\" is optional."}, "7": {"item_id": "3987130320", "image_id": "7", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e8d2822-a23b-4e52-8ab7-ab2f513dcc06_1276x1034.png", "width": "496", "height": "402", "credit": "", "caption": "Annotated figures from the DPO paper, https://arxiv.org/abs/2305.18290"}, "8": {"item_id": "3987130320", "image_id": "8", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F830e5a05-663c-4b4b-9bbd-6d4f33a78c5b_1600x933.png", "width": "682", "height": "398", "credit": "", "caption": "Annotated figure from https://arxiv.org/abs/2310.06825 comparing Mistral 7B and Llama 13B performances"}, "9": {"item_id": "3987130320", "image_id": "9", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb36dd723-2a61-46aa-9020-e033e6fe31be_1600x858.png", "width": "588", "height": "315", "credit": "", "caption": "Annotated figure from https://arxiv.org/abs/2310.06825 explaining sliding window attention."}, "10": {"item_id": "3987130320", "image_id": "10", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F492d455d-9f0f-4c15-a0c7-0a3dec6f59a6_792x796.png", "width": "430", "height": "432", "credit": "", "caption": "OpenCompass benchmarks via https://github.com/open-compass/MixtralKit. Blue boxes highlight the best results in each row."}, "11": {"item_id": "3987130320", "image_id": "11", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5e379db-3f34-4733-854a-f90987181118_844x726.png", "width": "286", "height": "246", "credit": "", "caption": "Mixtral architecture overview based on the param.json file that the Mistral team originally shared via a magnet link on social media"}, "12": {"item_id": "3987130320", "image_id": "12", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77ee34dd-be4f-4d04-b898-9a1b32209023_1356x816.png", "width": "556", "height": "335", "credit": "https://arxiv.org/abs/2101.03961", "caption": "Annotated figure from Switch Transformers paper"}, "13": {"item_id": "3987130320", "image_id": "13", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc505ad21-66db-4e98-977c-76da3098c1bf_1492x816.png", "width": "502", "height": "274", "credit": "https://arxiv.org/abs/2310.16764", "caption": "Annotated figure from ConvNets Match Vision Transformers at Scale"}, "14": {"item_id": "3987130320", "image_id": "14", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F041ee20a-f6dc-4759-9291-efb5d4b48212_870x1026.jpeg", "width": "250", "height": "295", "credit": "top", "caption": "Object detection"}, "15": {"item_id": "3987130320", "image_id": "15", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcfa09c5e-0b4f-4984-95c2-13ce9cf8de1d_1304x670.jpeg", "width": "592", "height": "304", "credit": "SAM", "caption": "The Segment Anything Model"}, "16": {"item_id": "3987130320", "image_id": "16", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4387528-dadb-4b4d-8617-7af85571460a_1046x862.png", "width": "422", "height": "348", "credit": "", "caption": "Performance comparison between Emu and other text-to-video models via https://arxiv.org/abs/2311.10709"}, "17": {"item_id": "3987130320", "image_id": "17", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1392a9e3-bf81-406d-a688-acfad261c79f_355x439.jpeg", "width": "265", "height": "328", "credit": "", "caption": "Build a Large Language Model book cover"}}, "listen_duration_estimate": 1618}, "3851452749": {"item_id": "3851452749", "resolved_id": "3851452749", "given_url": "https://magazine.sebastianraschka.com/p/finetuning-large-language-models", "given_title": "", "favorite": "0", "status": "1", "time_added": "1682344935", "time_updated": "1682423967", "time_read": "1682423967", "time_favorited": "0", "sort_id": 45, "resolved_title": "Finetuning Large Language Models", "resolved_url": "https://magazine.sebastianraschka.com/p/finetuning-large-language-models", "excerpt": "Note: Last week, I was experimenting with posting articles outside the monthly Ahead of AI series that discusses the latest research and trends. Your positive response was very flattering.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2424", "lang": "en", "time_to_read": 11, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa534808e-9284-47eb-9b4d-3e3aedc0b5da_1180x842.png", "tags": {"llms": {"item_id": "3851452749", "tag": "llms"}}, "authors": {"10017863": {"item_id": "3851452749", "author_id": "10017863", "name": "Sebastian Raschka", "url": ""}}, "image": {"item_id": "3851452749", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffea460ea-84d5-4973-9bc7-dc0e53a13ae0_1340x680.png", "width": "583", "height": "296"}, "images": {"1": {"item_id": "3851452749", "image_id": "1", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffea460ea-84d5-4973-9bc7-dc0e53a13ae0_1340x680.png", "width": "583", "height": "296", "credit": "", "caption": "An example of in-context learning."}, "2": {"item_id": "3851452749", "image_id": "2", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4063347e-8920-40c6-86b3-c520084b303c_1272x998.jpeg", "width": "451", "height": "354", "credit": "", "caption": "An illustration of indexing."}, "3": {"item_id": "3851452749", "image_id": "3", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5b3254c-9b09-43a9-a975-68d41e3f12ae_1242x826.png", "width": "245", "height": "163", "credit": "", "caption": "https://sebastianraschka.com/books"}}, "listen_duration_estimate": 938}, "3994042168": {"item_id": "3994042168", "resolved_id": "3993994031", "given_url": "https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention?publication_id=1174659&post_id=140464659&isFreemail=true&r=oc5d", "given_title": "Understanding and Coding Self-Attention, Multi-Head Attention, Cross-Attent", "favorite": "0", "status": "1", "time_added": "1705247239", "time_updated": "1706235121", "time_read": "1705394604", "time_favorited": "0", "sort_id": 46, "resolved_title": "Understanding and Coding Self-Attention, Multi-Head Attention, Cross-Attention, and Causal-Attention in LLMs", "resolved_url": "https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention", "excerpt": "This article will teach you about self-attention mechanisms used in transformer architectures and large language models (LLMs) such as GPT-4 and Llama. Self-attention and related mechanisms are core components of LLMs, making them a useful topic to understand when working with these models.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4775", "lang": "en", "time_to_read": 22, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69bfee26-ea3b-42a6-8a1a-6b8187852082_738x564.png", "tags": {"deep-learning": {"item_id": "3994042168", "tag": "deep-learning"}, "llms": {"item_id": "3994042168", "tag": "llms"}}, "authors": {"66098": {"item_id": "3994042168", "author_id": "66098", "name": "DK", "url": ""}}, "image": {"item_id": "3994042168", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97567e7b-f8b9-4dea-a678-162378609a75_1304x1150.png", "width": "426", "height": "376"}, "images": {"1": {"item_id": "3994042168", "image_id": "1", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97567e7b-f8b9-4dea-a678-162378609a75_1304x1150.png", "width": "426", "height": "376", "credit": "", "caption": "The original transformer architecture from https://arxiv.org/abs/1706.03762"}, "2": {"item_id": "3994042168", "image_id": "2", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d632b81-5bd6-432a-a456-37f20788be20_1180x614.png", "width": "432", "height": "225", "credit": "top", "caption": "An incorrect word-by-word translation"}, "3": {"item_id": "3994042168", "image_id": "3", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecef3e00-4c0e-4c7a-9a9f-42ac4e4ada69_366x786.png", "width": "174", "height": "374", "credit": "", "caption": "Computing the query, key, and value vectors via the input x and weights W."}, "4": {"item_id": "3994042168", "image_id": "4", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9774001-ea9d-48bf-9857-3c911b0a279d_588x962.png", "width": "192", "height": "314", "credit": "2", "caption": "For the following sections below, we focus on the second input, x"}, "5": {"item_id": "3994042168", "image_id": "5", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbaf9e308-223b-429e-8527-a7b868003e8c_814x912.png", "width": "296", "height": "332", "credit": "omega", "caption": "Computing the unnormalized attention weights ω"}, "6": {"item_id": "3994042168", "image_id": "6", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42da287a-18e8-45c7-860c-46e8a3a534fc_1400x798.png", "width": "578", "height": "329", "credit": "", "caption": "Computing the normalized attention weights α"}, "7": {"item_id": "3994042168", "image_id": "7", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e1dcdeb-e096-4ff9-bdf9-3338e4efa4b4_1916x1048.png", "width": "664", "height": "363", "credit": "2", "caption": "The attention weights are specific to a certain input element. Here, we chose input element x"}, "8": {"item_id": "3994042168", "image_id": "8", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57269a7a-8ecc-4ed6-b6d7-79a9982dd776_918x1152.png", "width": "384", "height": "482", "credit": "", "caption": "The multi-head attention modules in the original transformer architecture from https://arxiv.org/abs/1706.03762"}, "9": {"item_id": "3994042168", "image_id": "9", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7651e279-01ed-4316-91dc-d6be8ef4e947_1836x1116.png", "width": "500", "height": "304", "credit": "", "caption": "Summarizing the self-attention mechanism implemented previously"}, "10": {"item_id": "3994042168", "image_id": "10", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff406d55e-990a-4e3b-be82-d966eb74a3e7_1766x1154.png", "width": "526", "height": "344", "credit": "", "caption": "Multi-head attention: self-attention with multiple heads"}, "11": {"item_id": "3994042168", "image_id": "11", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb75a8df1-0a82-4f79-8e68-4fe16587063d_1474x1108.png", "width": "636", "height": "478", "credit": "", "caption": "Another view of the self-attention mechanism implemented previously, with a focus on the matrix dimensions"}, "12": {"item_id": "3994042168", "image_id": "12", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9057444e-4934-4253-bc91-9e768d23b0c2_846x972.png", "width": "354", "height": "407", "credit": "", "caption": ""}, "13": {"item_id": "3994042168", "image_id": "13", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa16d2bd0-984d-4224-9c4c-2f0cc144a599_1520x1108.png", "width": "624", "height": "455", "credit": "", "caption": ""}, "14": {"item_id": "3994042168", "image_id": "14", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4dfd356-1cfa-4601-a05d-57bc15024970_1204x590.png", "width": "620", "height": "304", "credit": "", "caption": ""}, "15": {"item_id": "3994042168", "image_id": "15", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc51bfe11-c2cf-4ce5-95d4-4f8a57eac997_1026x1148.png", "width": "372", "height": "416", "credit": "via “Attention Is All You Need”, https://arxiv.org/abs/1706.03762", "caption": "The causal self-attention module in the original transformer architecture"}, "16": {"item_id": "3994042168", "image_id": "16", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7dd5ec8-4912-4e0d-8265-b335c08d2958_1760x1126.png", "width": "518", "height": "332", "credit": "", "caption": ""}, "17": {"item_id": "3994042168", "image_id": "17", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1317a05-3542-4158-94bf-085109a5793a_1220x702.png", "width": "516", "height": "297", "credit": "", "caption": "Attention weights above the diagonal should be masked out"}, "18": {"item_id": "3994042168", "image_id": "18", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fffe26c66-1da3-44fa-972b-7a2d4c9c6bf2_355x439.jpeg", "width": "219", "height": "271", "credit": "", "caption": "Build a Large Language Model book cover"}}, "listen_duration_estimate": 1848}, "3847407095": {"item_id": "3847407095", "resolved_id": "3847407095", "given_url": "https://magazine.sebastianraschka.com/p/understanding-large-language-models", "given_title": "Hacker News", "favorite": "0", "status": "1", "time_added": "1681682667", "time_updated": "1681865163", "time_read": "1681865163", "time_favorited": "0", "sort_id": 47, "resolved_title": "Understanding Large Language Models", "resolved_url": "https://magazine.sebastianraschka.com/p/understanding-large-language-models", "excerpt": "Note: Next to the monthly Ahead of AI series that discusses the latest research and trends, I plan to post some additional articles related to machine learning and AI once in a while.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3551", "lang": "en", "time_to_read": 16, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9a0766d-2e52-4af0-96c5-3e07a30d6ecb_1868x1130.png", "tags": {"llms": {"item_id": "3847407095", "tag": "llms"}, "transformers": {"item_id": "3847407095", "tag": "transformers"}}, "authors": {"10017863": {"item_id": "3847407095", "author_id": "10017863", "name": "Sebastian Raschka", "url": ""}}, "image": {"item_id": "3847407095", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff907c364-b179-4112-a2b9-50c389d0377b_904x396.png", "width": "595", "height": "261"}, "images": {"1": {"item_id": "3847407095", "image_id": "1", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff907c364-b179-4112-a2b9-50c389d0377b_904x396.png", "width": "595", "height": "261", "credit": "", "caption": "Source: https://arxiv.org/abs/1409.0473"}, "2": {"item_id": "3847407095", "image_id": "2", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc820b36a-8e07-4eea-8975-d7e391006d52_824x690.png", "width": "515", "height": "431", "credit": "", "caption": "Source: https://arxiv.org/abs/1706.03762"}, "3": {"item_id": "3847407095", "image_id": "3", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2217256f-c000-49bf-878e-7a3e062c7fb8_884x894.png", "width": "266", "height": "269", "credit": "", "caption": "Source: Annotated figure based on https://people.idsia.ch//~juergen/fast-weight-programmer-1991-transformer.html#sec2"}, "4": {"item_id": "3847407095", "image_id": "4", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89243595-9867-4420-b753-802ca1226518_1368x830.png", "width": "543", "height": "329", "credit": "", "caption": "Source: https://arxiv.org/abs/1810.04805"}, "5": {"item_id": "3847407095", "image_id": "5", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F573a9c49-2ff3-4a14-98b6-6b8a44333601_1314x658.png", "width": "565", "height": "283", "credit": "", "caption": "Source: https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035"}, "6": {"item_id": "3847407095", "image_id": "6", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F659f5e23-5641-406f-9a08-a2461ffff345_1068x614.png", "width": "553", "height": "318", "credit": "", "caption": "Source: https://arxiv.org/abs/2205.14135"}, "7": {"item_id": "3847407095", "image_id": "7", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd5b3254c-9b09-43a9-a975-68d41e3f12ae_1242x826.png", "width": "245", "height": "163", "credit": "", "caption": "https://sebastianraschka.com/books"}}, "listen_duration_estimate": 1375}, "4011180167": {"item_id": "4011180167", "resolved_id": "4011180167", "given_url": "https://media.licdn.com/dms/image/D4D22AQElBF0kmo1tgA/feedshare-shrink_1280/0/1708022141659?e=1711584000&v=beta&t=9UxcdrylfOu5hKIS-OZBr4aqeF-Gue26r84_GgTWV0g", "given_title": "1708022141659 (JPEG Image, 1280 × 1600 pixels) — Scaled (56%)", "favorite": "0", "status": "1", "time_added": "1708525625", "time_updated": "1708567297", "time_read": "1708567297", "time_favorited": "0", "sort_id": 48, "resolved_title": "", "resolved_url": "https://media.licdn.com/dms/image/D4D22AQElBF0kmo1tgA/feedshare-shrink_1280/0/1708022141659?e=1711584000&v=beta&t=9UxcdrylfOu5hKIS-OZBr4aqeF-Gue26r84_GgTWV0g", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "2", "word_count": "0", "lang": "", "tags": {"llms": {"item_id": "4011180167", "tag": "llms"}}, "image": {"item_id": "4011180167", "src": "https://media.licdn.com/dms/image/D4D22AQElBF0kmo1tgA/feedshare-shrink_1280/0/1708022141659?e=1711584000&v=beta&t=9UxcdrylfOu5hKIS-OZBr4aqeF-Gue26r84_GgTWV0g", "width": "0", "height": "0"}, "images": {"1": {"item_id": "4011180167", "image_id": "1", "src": "https://media.licdn.com/dms/image/D4D22AQElBF0kmo1tgA/feedshare-shrink_1280/0/1708022141659?e=1711584000&v=beta&t=9UxcdrylfOu5hKIS-OZBr4aqeF-Gue26r84_GgTWV0g", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 0}, "4013914065": {"item_id": "4013914065", "resolved_id": "4013914065", "given_url": "https://mistral.ai/news/mistral-large/", "given_title": "Au Large | Mistral AI | Frontier AI in your hands", "favorite": "0", "status": "1", "time_added": "1709002246", "time_updated": "1709182289", "time_read": "1709182289", "time_favorited": "0", "sort_id": 49, "resolved_title": "Au Large", "resolved_url": "https://mistral.ai/news/mistral-large/", "excerpt": "We are releasing Mistral Large, our latest and most advanced language model. Mistral Large is available through la Plateforme. We are also making it available through Azure AI, our first distribution partner. Mistral Large is our new cutting-edge text generation model.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "845", "lang": "", "top_image_url": "https://mistral.ai/images/icons/mistral-supersonic-boat.jpg", "tags": {"llms": {"item_id": "4013914065", "tag": "llms"}}, "authors": {"185376390": {"item_id": "4013914065", "author_id": "185376390", "name": "Mistral AI", "url": ""}}, "image": {"item_id": "4013914065", "src": "https://mistral.ai/images/news/mistral-large/mistral-large-bar-plot.png", "width": "100", "height": "0"}, "images": {"1": {"item_id": "4013914065", "image_id": "1", "src": "https://mistral.ai/images/news/mistral-large/mistral-large-bar-plot.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "4013914065", "image_id": "2", "src": "https://mistral.ai/images/news/mistral-large/large-bench-reasoning-table.svg", "width": "100", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "4013914065", "image_id": "3", "src": "https://mistral.ai/images/news/mistral-large/large-bench-multilingual-table.svg", "width": "100", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "4013914065", "image_id": "4", "src": "https://mistral.ai/images/news/mistral-large/large-bench-coding-maths-table.svg", "width": "100", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 327}, "3912475302": {"item_id": "3912475302", "resolved_id": "3912475302", "given_url": "https://nanonets.com/blog/chat-with-pdfs-using-chatgpt-and-openai-gpt-api/", "given_title": "How to use LLMs for PDF parsing", "favorite": "0", "status": "1", "time_added": "1691264722", "time_updated": "1691367674", "time_read": "1691365853", "time_favorited": "0", "sort_id": 50, "resolved_title": "Chat with PDFs using ChatGPT & OpenAI GPT API - A Detailed Tutorial", "resolved_url": "https://nanonets.com/blog/chat-with-pdfs-using-chatgpt-and-openai-gpt-api/", "excerpt": "In this blog post, we explore Language Learning Models (LLMs) and their astounding ability to chat with PDF files. To start, we will show you how to chat with PDF files via the ChatGPT website. Next, we dive into a detailed code tutorial on how to chat with all kinds of PDF files.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "10008", "lang": "en", "time_to_read": 45, "amp_url": "https://nanonets.com/blog/chat-with-pdfs-using-chatgpt-and-openai-gpt-api/amp/", "top_image_url": "https://images.unsplash.com/photo-1545239351-ef35f43d514b?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDh8fGxhcHRvcCUyMHxlbnwwfHx8fDE2OTAzOTU2NDh8MA&ixlib=rb-4.0.3&q=80&w=2000", "tags": {"chatgpt": {"item_id": "3912475302", "tag": "chatgpt"}, "llms": {"item_id": "3912475302", "tag": "llms"}, "pdfs": {"item_id": "3912475302", "tag": "pdfs"}}, "authors": {"175131668": {"item_id": "3912475302", "author_id": "175131668", "name": "Karan Kalra", "url": "https://nanonets.com/blog/author/karan/"}}, "image": {"item_id": "3912475302", "src": "https://nanonets.com/blog/content/images/2023/07/Screenshot-2023-07-21-at-4.34.45-PM.png", "width": "2000", "height": "1146"}, "images": {"1": {"item_id": "3912475302", "image_id": "1", "src": "https://nanonets.com/blog/content/images/2023/07/Screenshot-2023-07-21-at-4.34.45-PM.png", "width": "2000", "height": "1146", "credit": "", "caption": ""}, "2": {"item_id": "3912475302", "image_id": "2", "src": "https://nanonets.com/blog/content/images/2023/07/Screenshot-2023-07-21-at-4.36.08-PM.png", "width": "2000", "height": "1143", "credit": "", "caption": ""}, "3": {"item_id": "3912475302", "image_id": "3", "src": "https://nanonets.com/blog/content/images/2023/07/Screenshot-2023-07-21-at-4.39.31-PM.png", "width": "2000", "height": "1144", "credit": "", "caption": ""}, "4": {"item_id": "3912475302", "image_id": "4", "src": "https://nanonets.com/blog/content/images/2023/07/image-98.png", "width": "1934", "height": "1216", "credit": "", "caption": ""}, "5": {"item_id": "3912475302", "image_id": "5", "src": "https://nanonets.com/blog/content/images/2023/07/image-99.png", "width": "1988", "height": "1064", "credit": "", "caption": ""}, "6": {"item_id": "3912475302", "image_id": "6", "src": "https://nanonets.com/blog/content/images/2023/07/image-100.png", "width": "1962", "height": "1130", "credit": "", "caption": ""}, "7": {"item_id": "3912475302", "image_id": "7", "src": "https://nanonets.com/blog/content/images/2023/07/image-101.png", "width": "1960", "height": "774", "credit": "", "caption": ""}, "8": {"item_id": "3912475302", "image_id": "8", "src": "https://nanonets.com/blog/content/images/2023/07/image-103.png", "width": "1974", "height": "562", "credit": "", "caption": ""}, "9": {"item_id": "3912475302", "image_id": "9", "src": "https://nanonets.com/blog/content/images/2023/07/image-105.png", "width": "1906", "height": "692", "credit": "", "caption": ""}, "10": {"item_id": "3912475302", "image_id": "10", "src": "https://nanonets.com/blog/content/images/2023/07/image-106.png", "width": "1982", "height": "920", "credit": "", "caption": ""}, "11": {"item_id": "3912475302", "image_id": "11", "src": "https://nanonets.com/blog/content/images/2023/07/image-107.png", "width": "1992", "height": "424", "credit": "", "caption": ""}, "12": {"item_id": "3912475302", "image_id": "12", "src": "https://nanonets.com/blog/content/images/2023/07/image-108.png", "width": "1982", "height": "512", "credit": "", "caption": ""}, "13": {"item_id": "3912475302", "image_id": "13", "src": "https://nanonets.com/blog/content/images/2023/07/image-46.png", "width": "2000", "height": "1250", "credit": "", "caption": ""}, "14": {"item_id": "3912475302", "image_id": "14", "src": "https://nanonets.com/blog/content/images/2023/07/image-109.png", "width": "1926", "height": "1270", "credit": "", "caption": ""}, "15": {"item_id": "3912475302", "image_id": "15", "src": "https://nanonets.com/blog/content/images/2023/07/image-110.png", "width": "1980", "height": "1086", "credit": "", "caption": ""}, "16": {"item_id": "3912475302", "image_id": "16", "src": "https://nanonets.com/blog/content/images/2023/07/image-54.png", "width": "2000", "height": "1250", "credit": "", "caption": ""}, "17": {"item_id": "3912475302", "image_id": "17", "src": "https://nanonets.com/blog/content/images/2023/07/image-55.png", "width": "2000", "height": "1250", "credit": "", "caption": ""}, "18": {"item_id": "3912475302", "image_id": "18", "src": "https://nanonets.com/blog/content/images/2023/07/image-111.png", "width": "1978", "height": "1406", "credit": "", "caption": ""}, "19": {"item_id": "3912475302", "image_id": "19", "src": "https://nanonets.com/blog/content/images/2023/07/image-112.png", "width": "1936", "height": "1094", "credit": "", "caption": ""}, "20": {"item_id": "3912475302", "image_id": "20", "src": "https://nanonets.com/blog/content/images/2023/07/Screenshot-2023-07-31-at-3.19.55-PM.png", "width": "2000", "height": "1146", "credit": "", "caption": ""}, "21": {"item_id": "3912475302", "image_id": "21", "src": "https://nanonets.com/blog/content/images/2023/07/image-122.png", "width": "2000", "height": "1146", "credit": "", "caption": ""}, "22": {"item_id": "3912475302", "image_id": "22", "src": "https://nanonets.com/blog/content/images/2023/07/Screenshot-2023-07-31-at-3.27.03-PM.png", "width": "2000", "height": "1144", "credit": "", "caption": ""}, "23": {"item_id": "3912475302", "image_id": "23", "src": "https://nanonets.com/blog/content/images/2023/07/Screenshot-2023-07-31-at-3.50.26-PM.png", "width": "1668", "height": "1094", "credit": "", "caption": ""}, "24": {"item_id": "3912475302", "image_id": "24", "src": "https://nanonets.com/blog/content/images/2023/07/Screenshot-2023-07-31-at-3.53.09-PM.png", "width": "1804", "height": "1028", "credit": "", "caption": ""}, "25": {"item_id": "3912475302", "image_id": "25", "src": "https://nanonets.com/blog/content/images/2023/07/image-123.png", "width": "2000", "height": "1199", "credit": "", "caption": ""}, "26": {"item_id": "3912475302", "image_id": "26", "src": "https://nanonets.com/blog/content/images/2023/07/image-81.png", "width": "1524", "height": "1308", "credit": "", "caption": ""}, "27": {"item_id": "3912475302", "image_id": "27", "src": "https://nanonets.com/blog/content/images/2023/07/Screenshot-2023-07-27-at-1.47.42-PM.png", "width": "2000", "height": "1536", "credit": "", "caption": ""}, "28": {"item_id": "3912475302", "image_id": "28", "src": "https://nanonets.com/blog/content/images/2023/07/Screenshot-2022-11-16-at-12.13.32-PM.png", "width": "2000", "height": "1451", "credit": "", "caption": ""}, "29": {"item_id": "3912475302", "image_id": "29", "src": "https://nanonets.com/blog/content/images/2023/07/image-82.png", "width": "1676", "height": "1194", "credit": "", "caption": ""}, "30": {"item_id": "3912475302", "image_id": "30", "src": "https://nanonets.com/blog/content/images/2023/07/image-113.png", "width": "1998", "height": "1370", "credit": "", "caption": ""}, "31": {"item_id": "3912475302", "image_id": "31", "src": "https://nanonets.com/blog/content/images/2023/07/image-23.png", "width": "2000", "height": "1126", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "3912475302", "video_id": "1", "src": "https://www.youtube.com/embed/n3-QzeDSlF8?start=38&feature=oembed", "width": "200", "height": "113", "type": "1", "vid": "n3-QzeDSlF8", "length": "0"}}, "listen_duration_estimate": 3874}, "4003839004": {"item_id": "4003839004", "resolved_id": "4003839004", "given_url": "https://news.ycombinator.com/item?id=39263664", "given_title": "Ask HN: What have you built with LLMs?", "favorite": "0", "status": "1", "time_added": "1707363325", "time_updated": "1707673181", "time_read": "1707673181", "time_favorited": "0", "sort_id": 51, "resolved_title": "Ask HN: What have you built with LLMs?", "resolved_url": "https://news.ycombinator.com/item?id=39263664", "excerpt": "I worked on a chrome extension a few weeks ago that skips sponsorship sections in YouTube videos by reading through the transcript. Also was trying to experiment with an LLM to explain a function call chain across languages (in this case MakeFile, Python, Bash).", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "244", "lang": "en", "tags": {"llms": {"item_id": "4003839004", "tag": "llms"}}, "domain_metadata": {"name": "Y Combinator", "logo": "https://logo.clearbit.com/ycombinator.com?size=800", "greyscale_logo": "https://logo.clearbit.com/ycombinator.com?size=800&greyscale=true"}, "listen_duration_estimate": 94}, "4003549453": {"item_id": "4003549453", "resolved_id": "4003395265", "given_url": "https://open.substack.com/pub/nintyzeros/p/how-do-transformer-workdesign-a-multi?utm_campaign=post&utm_medium=web", "given_title": "How do transformers work?+Design a Multi-class Sentiment Analysis for Custo", "favorite": "0", "status": "1", "time_added": "1707101546", "time_updated": "1708582767", "time_read": "1708582767", "time_favorited": "0", "sort_id": 52, "resolved_title": "How do transformers work?+Design a Multi-class Sentiment Analysis for Customer Reviews", "resolved_url": "https://nintyzeros.substack.com/p/how-do-transformer-workdesign-a-multi", "excerpt": "👋 Hi, this is Venkat and here with a free, full issue of the The ZenMode Engineer Newsletter. In every issue, I cover one topic explained in a simpler terms in areas related to computer technologies and beyond.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1797", "lang": "en", "time_to_read": 8, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1b143728-e85e-4a5e-af07-98662aa67d5a_727x1024.png", "tags": {"attention": {"item_id": "4003549453", "tag": "attention"}, "llms": {"item_id": "4003549453", "tag": "llms"}}, "authors": {"2484155": {"item_id": "4003549453", "author_id": "2484155", "name": "Venkat", "url": ""}}, "image": {"item_id": "4003549453", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9be7be14-7e28-432a-9857-c2eefbb52793_405x537.png", "width": "255", "height": "338"}, "images": {"1": {"item_id": "4003549453", "image_id": "1", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9be7be14-7e28-432a-9857-c2eefbb52793_405x537.png", "width": "255", "height": "338", "credit": "", "caption": ""}, "2": {"item_id": "4003549453", "image_id": "2", "src": "https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd9fb706d-5faf-4431-b11a-2dc9f6302714_480x322.gif", "width": "480", "height": "322", "credit": "", "caption": "image source: pillow lab blog"}}, "listen_duration_estimate": 696}, "4008248652": {"item_id": "4008248652", "resolved_id": "4008248652", "given_url": "https://openai.com/sora", "given_title": "Sora", "favorite": "0", "status": "1", "time_added": "1708083199", "time_updated": "1708189350", "time_read": "1708189350", "time_favorited": "0", "sort_id": 53, "resolved_title": "Creating video from text", "resolved_url": "https://openai.com/sora", "excerpt": "Sora is a diffusion model, which generates a video by starting off with one that looks like static noise and gradually transforms it by removing the noise over many steps. Sora is capable of generating entire videos all at once or extending generated videos to make them longer.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "284", "lang": "en", "top_image_url": "https://images.openai.com/blob/8264d3d7-922c-4343-b43d-6665e44bcb91/paper-airplanes.jpg?trim=0%2C0%2C0%2C0&width=1000&quality=80", "tags": {"llms": {"item_id": "4008248652", "tag": "llms"}, "video": {"item_id": "4008248652", "tag": "video"}}, "domain_metadata": {"name": "OpenAI", "logo": "https://logo.clearbit.com/openai.com?size=800", "greyscale_logo": "https://logo.clearbit.com/openai.com?size=800&greyscale=true"}, "listen_duration_estimate": 110}, "3797313802": {"item_id": "3797313802", "resolved_id": "3014311316", "given_url": "https://platform.openai.com/overview", "given_title": "", "favorite": "0", "status": "1", "time_added": "1675727390", "time_updated": "1706652652", "time_read": "1676070530", "time_favorited": "0", "sort_id": 54, "resolved_title": "OpenAI API", "resolved_url": "https://beta.openai.com", "excerpt": "An API for accessing new AI models developed by OpenAI", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "top_image_url": "https://beta.openai.com/curl.png", "tags": {"llms": {"item_id": "3797313802", "tag": "llms"}}, "listen_duration_estimate": 0}, "3929162830": {"item_id": "3929162830", "resolved_id": "3929162830", "given_url": "https://scisummary.com/dashboard/signed-up", "given_title": "Dashboard - SciSummary", "favorite": "0", "status": "1", "time_added": "1705356841", "time_updated": "1706833159", "time_read": "1705393484", "time_favorited": "0", "sort_id": 55, "resolved_title": "SciSummary", "resolved_url": "https://scisummary.com/dashboard/signed-up", "excerpt": "SciSummary", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1", "lang": "en", "top_image_url": "https://scisummary.com/img/social.webp", "tags": {"llms": {"item_id": "3929162830", "tag": "llms"}, "programming": {"item_id": "3929162830", "tag": "programming"}}, "listen_duration_estimate": 0}, "3854426538": {"item_id": "3854426538", "resolved_id": "3854426538", "given_url": "https://sebastianraschka.com/blog/2023/llm-finetuning-lora.html", "given_title": "Parameter-Efficient LLM Finetuning With Low-Rank Adaptation (LoRA)", "favorite": "0", "status": "1", "time_added": "1682595138", "time_updated": "1682764939", "time_read": "1682764938", "time_favorited": "0", "sort_id": 56, "resolved_title": "Redirecting", "resolved_url": "https://sebastianraschka.com/blog/2023/llm-finetuning-lora.html", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"llms": {"item_id": "3854426538", "tag": "llms"}}, "listen_duration_estimate": 0}, "3944064910": {"item_id": "3944064910", "resolved_id": "3944064910", "given_url": "https://serce.me/posts/02-10-2023-hey-computer-make-me-a-font", "given_title": "Hey, Computer, Make Me a Font", "favorite": "0", "status": "1", "time_added": "1696380836", "time_updated": "1696381991", "time_read": "1696381991", "time_favorited": "0", "sort_id": 57, "resolved_title": "Hey, Computer, Make Me a Font", "resolved_url": "https://serce.me/posts/02-10-2023-hey-computer-make-me-a-font", "excerpt": "This is a story of my journey learning to build generative ML models from scratch and teaching a computer to create fonts in the process. Yes, genuine true type fonts, with a capital-only set of glyphs. The model takes a font description as an input, and produces a font file as an output.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1351", "lang": "en", "time_to_read": 6, "top_image_url": "https://serce.me/images/make-me-a-font/bender.jpeg", "tags": {"fonts-typography": {"item_id": "3944064910", "tag": "fonts-typography"}, "llms": {"item_id": "3944064910", "tag": "llms"}, "python": {"item_id": "3944064910", "tag": "python"}}, "authors": {"29162812": {"item_id": "3944064910", "author_id": "29162812", "name": "Sergey Tselovalnikov", "url": ""}}, "image": {"item_id": "3944064910", "src": "https://serce.me/images/make-me-a-font/bender.jpeg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3944064910", "image_id": "1", "src": "https://serce.me/images/make-me-a-font/bender.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3944064910", "image_id": "2", "src": "https://serce.me/images/make-me-a-font/fontogen.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3944064910", "image_id": "3", "src": "https://serce.me/images/make-me-a-font/embeddings.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3944064910", "image_id": "4", "src": "https://serce.me/images/make-me-a-font/glyphs.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3944064910", "image_id": "5", "src": "https://serce.me/images/make-me-a-font/font-encoding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3944064910", "image_id": "6", "src": "https://serce.me/images/make-me-a-font/bigbird.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3944064910", "image_id": "7", "src": "https://serce.me/images/make-me-a-font/calfailure.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 523}, "4003433946": {"item_id": "4003433946", "resolved_id": "4003433946", "given_url": "https://shyam.blog/posts/beyond-self-attention/", "given_title": "Beyond Self-Attention: How a Small Language Model Predicts the Next Token", "favorite": "0", "status": "1", "time_added": "1707098922", "time_updated": "1708582784", "time_read": "1708582784", "time_favorited": "0", "sort_id": 58, "resolved_title": "Beyond Self-Attention: How a Small Language Model Predicts the Next Token", "resolved_url": "https://shyam.blog/posts/beyond-self-attention", "excerpt": "I trained a small (~10 million parameter) transformer following Andrej Karpathy’s excellent tutorial, Let’s build GPT: from scratch, in code, spelled out. After getting it working, I wanted to understand, as deeply as possible, what it was doing internally and how it produced its results.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "19701", "lang": "", "tags": {"llms": {"item_id": "4003433946", "tag": "llms"}, "nlp": {"item_id": "4003433946", "tag": "nlp"}}, "image": {"item_id": "4003433946", "src": "https://shyam.blog/posts/images/a9f2adc6c1c25ebb263caf42df37f4429c4ed44eda0a0a228cba52b7a00aeb9d.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "4003433946", "image_id": "1", "src": "https://shyam.blog/posts/images/a9f2adc6c1c25ebb263caf42df37f4429c4ed44eda0a0a228cba52b7a00aeb9d.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "4003433946", "image_id": "2", "src": "https://shyam.blog/posts/images/72a30adc39ebf5f278c0a257fb46f26e6d666d113736e36ce394db587110260c.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "4003433946", "image_id": "3", "src": "https://shyam.blog/posts/images/b8214cdd1f6c9466bb984529984c757d780148fb4fe44bfed7714216e12bff73.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "4003433946", "image_id": "4", "src": "https://shyam.blog/posts/images/170aed320bd4ab2e2647d8d1ef50b499b215ce1905cff1b5db6fe78dd83c3df3.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "4003433946", "image_id": "5", "src": "https://shyam.blog/posts/images/c04c3fbe83a543ea834691f8ef6c5ecdee18522f3e3e456cd9ea81209eb60b00.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "4003433946", "image_id": "6", "src": "https://shyam.blog/posts/images/e9c543696d0748c74bccfac0780e9e6a5cd7610dafc6e650fb5dab2192fc8399.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "4003433946", "image_id": "7", "src": "https://shyam.blog/posts/images/d01e3755f6278cc6f19ae5656ab3ba6fd7b4ecb59c69303db814b6cc43fb0435.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "4003433946", "image_id": "8", "src": "https://shyam.blog/posts/images/02bddd27aedd082ab84a2b5dd45dacae4e745dc49ed363df5725916e4b370844.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "4003433946", "image_id": "9", "src": "https://shyam.blog/posts/images/d82fe84ec51461c861f5fbc1c2c273935d4d8ac8ceceaeeb292d79cd5fb9ee19.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "4003433946", "image_id": "10", "src": "https://shyam.blog/posts/images/c0b6c591002c7e1f931a0bcc794b88454aab02158d1125bef2f8422dbc0e8264.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "4003433946", "image_id": "11", "src": "https://shyam.blog/posts/images/12e04e2fdd477aaa55660b4020a4ae6b9a72c55038f98009049330cfecfc4291.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "4003433946", "image_id": "12", "src": "https://shyam.blog/posts/images/24b90fb31e5e330043b12b6a3b0bf9e8bed15bbd4cd57e98f0cbdc4b393fc71f.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "4003433946", "image_id": "13", "src": "https://shyam.blog/posts/images/7fff50753ede8a54541e69eaf00215ea285f523817e8361d1fe08ac5e0c6cd8a.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "4003433946", "image_id": "14", "src": "https://shyam.blog/posts/images/a90c56ba1e72733d29a614671ad61789b5196562087c1464273da469843cb54d.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "4003433946", "image_id": "15", "src": "https://shyam.blog/posts/images/ecc30428196c016ef2970ee406b6ea46a79a2a24c1521d8843c2dc90f83ffc83.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "4003433946", "image_id": "16", "src": "https://shyam.blog/posts/images/4c4339d5f6612480cf52b0d34f2c1732c99485033c1196076543f86ec0925af5.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "4003433946", "image_id": "17", "src": "https://shyam.blog/posts/images/0dce2cb6b27518fe0a1a26685995c9050cf791b48cc4e407a080182039905dca.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "4003433946", "image_id": "18", "src": "https://shyam.blog/posts/images/37991d03eeb45809255009149e32de771715221bb9d315efb6e2aa78b26a897c.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "4003433946", "image_id": "19", "src": "https://shyam.blog/posts/images/04a243b63386cc0e853d350cb0177eeb33f2c15d2aacdaf59ddb4dc38f48b444.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "4003433946", "image_id": "20", "src": "https://shyam.blog/posts/images/a32cb4b311513c8c1bbb0af5cae1d68b1e96efeddfbde076f8e9fca02772d605.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "4003433946", "image_id": "21", "src": "https://shyam.blog/posts/images/211fa3aed3f5cbbe1a5adf41e014e27068c39ffaf21aff36c833a851b500e211.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "4003433946", "image_id": "22", "src": "https://shyam.blog/posts/images/0a46316fd1ec97000bed4b44242e7aad0809b16acd65a98507ff1b987e313291.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "23": {"item_id": "4003433946", "image_id": "23", "src": "https://shyam.blog/posts/images/fb2e608eb48c085de00f28831641ff4d49f7f3fd63b198fc3fc08d02a3cc7c45.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "4003433946", "image_id": "24", "src": "https://shyam.blog/posts/images/ec5755d7859f77e55c3bf34a432c33226741616e9b493b5eec96c716ac1e7fe5.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "4003433946", "image_id": "25", "src": "https://shyam.blog/posts/images/968e8e424522937d5366586abd902715e1cdf771fddbb2d4a36144cbe07746e2.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 7626}, "4011317556": {"item_id": "4011317556", "resolved_id": "4011317556", "given_url": "https://simonwillison.net/2024/Feb/21/gemini-pro-video/", "given_title": "The killer app of Gemini Pro 1.5 is video", "favorite": "0", "status": "1", "time_added": "1708606122", "time_updated": "1709246506", "time_read": "1709246506", "time_favorited": "0", "sort_id": 59, "resolved_title": "The killer app of Gemini Pro 1.5 is video", "resolved_url": "https://simonwillison.net/2024/Feb/21/gemini-pro-video/", "excerpt": "Last week Google introduced Gemini Pro 1.5, an enormous upgrade to their Gemini series of AI models. Gemini Pro 1.5 has a 1,000,000 token context size. This is huge—previously that record was held by Claude 2.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "1438", "lang": "en", "time_to_read": 7, "top_image_url": "https://static.simonwillison.net/static/2024/gemini-pro-card.jpg", "tags": {"llms": {"item_id": "4011317556", "tag": "llms"}, "video": {"item_id": "4011317556", "tag": "video"}}, "image": {"item_id": "4011317556", "src": "https://static.simonwillison.net/static/2024/gemini-refusal.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "4011317556", "image_id": "1", "src": "https://static.simonwillison.net/static/2024/gemini-refusal.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "4011317556", "video_id": "1", "src": "https://www.youtube.com/embed/jAlySrZqJqE", "width": "560", "height": "315", "type": "1", "vid": "jAlySrZqJqE", "length": "0"}, "2": {"item_id": "4011317556", "video_id": "2", "src": "https://www.youtube.com/embed/6m8sNercyNU", "width": "560", "height": "315", "type": "1", "vid": "6m8sNercyNU", "length": "0"}}, "listen_duration_estimate": 557}, "3948067178": {"item_id": "3948067178", "resolved_id": "3948067178", "given_url": "https://smashingmagazine.com/2023/10/overview-large-language-model-concepts-use-cases-tools/", "given_title": "A High-Level Overview Of Large Language Model Concepts, Use Cases, And Tool", "favorite": "0", "status": "1", "time_added": "1696951096", "time_updated": "1697764324", "time_read": "1697764324", "time_favorited": "0", "sort_id": 60, "resolved_title": "A High-Level Overview Of Large Language Model Concepts, Use Cases, And Tools", "resolved_url": "https://www.smashingmagazine.com/2023/10/overview-large-language-model-concepts-use-cases-tools/", "excerpt": "21 min read AI, Tools, Apps Share on Twitter, LinkedIn Customer-Centric Product Strategy Workshop, with Debbie Levitt SmashingConf UX & Design: Antwerp 2023 SmashingConf UX & Design: Antwerp 2023 Accessible Components from Design to Development, with Carie Fisher Prepare for today’s communication", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4212", "lang": "en", "time_to_read": 19, "top_image_url": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/overview-large-language-model-concepts-use-cases-tools.jpg", "tags": {"llms": {"item_id": "3948067178", "tag": "llms"}}, "authors": {"183041613": {"item_id": "3948067178", "author_id": "183041613", "name": "Joas Pambou", "url": "https://www.smashingmagazine.com/author/joas-pambou/"}}, "image": {"item_id": "3948067178", "src": "https://files.smashing.media/partners/smashing/debbie-levitt.png", "width": "300", "height": "250"}, "images": {"1": {"item_id": "3948067178", "image_id": "1", "src": "https://files.smashing.media/partners/smashing/debbie-levitt.png", "width": "300", "height": "250", "credit": "", "caption": ""}, "2": {"item_id": "3948067178", "image_id": "2", "src": "https://files.smashing.media/partners/smashing/carie-fisher.png", "width": "300", "height": "250", "credit": "", "caption": ""}, "3": {"item_id": "3948067178", "image_id": "3", "src": "https://files.smashing.media/partners/netlify/netlify-compose.png", "width": "300", "height": "250", "credit": "", "caption": ""}, "4": {"item_id": "3948067178", "image_id": "4", "src": "https://archive.smashing.media/assets/344dbf88-fdf9-42bb-adb4-46f01eedd629/87fd0cfa-692e-459c-b2f3-15209a1f6aa7/image-optimization-shop-cover-opt.png", "width": "480", "height": "697", "credit": "", "caption": ""}, "5": {"item_id": "3948067178", "image_id": "5", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/stack-llm.png", "width": "800", "height": "610", "credit": "", "caption": ""}, "6": {"item_id": "3948067178", "image_id": "6", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/stack-ai-screenshot.png", "width": "800", "height": "378", "credit": "", "caption": ""}, "7": {"item_id": "3948067178", "image_id": "7", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/flowiseai-full-workflow.png", "width": "800", "height": "392", "credit": "", "caption": ""}, "8": {"item_id": "3948067178", "image_id": "8", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/flowiseai-start-screen.png", "width": "800", "height": "550", "credit": "", "caption": ""}, "9": {"item_id": "3948067178", "image_id": "9", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/flowiseai-chatflow-canvas.png", "width": "800", "height": "599", "credit": "", "caption": ""}, "10": {"item_id": "3948067178", "image_id": "10", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/flowiseai-prompt-retriever.png", "width": "800", "height": "599", "credit": "", "caption": ""}, "11": {"item_id": "3948067178", "image_id": "11", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/flowiseai-prompt-retriever-add.png", "width": "800", "height": "599", "credit": "", "caption": ""}, "12": {"item_id": "3948067178", "image_id": "12", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/flowiseai-prompt-retrievers-all.png", "width": "800", "height": "536", "credit": "", "caption": ""}, "13": {"item_id": "3948067178", "image_id": "13", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/flowiseai-multi-chain-prompt.png", "width": "800", "height": "536", "credit": "", "caption": ""}, "14": {"item_id": "3948067178", "image_id": "14", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/flowiseai-multi-chain-prompt-add.png", "width": "800", "height": "539", "credit": "", "caption": ""}, "15": {"item_id": "3948067178", "image_id": "15", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/flowiseai-anthropic-claude.png", "width": "800", "height": "539", "credit": "", "caption": ""}, "16": {"item_id": "3948067178", "image_id": "16", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/flowiseai-anthropic-claude-add.png", "width": "800", "height": "539", "credit": "", "caption": ""}, "17": {"item_id": "3948067178", "image_id": "17", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/flowiseai-anthropic-claude-api.png", "width": "800", "height": "555", "credit": "", "caption": ""}, "18": {"item_id": "3948067178", "image_id": "18", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/flowiseai-conversational-agent.png", "width": "800", "height": "555", "credit": "", "caption": ""}, "19": {"item_id": "3948067178", "image_id": "19", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/flowiseai-conversational-agent-add.png", "width": "800", "height": "631", "credit": "", "caption": ""}, "20": {"item_id": "3948067178", "image_id": "20", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/flowiseai-serpapi.png", "width": "800", "height": "507", "credit": "", "caption": ""}, "21": {"item_id": "3948067178", "image_id": "21", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/flowiseai-serpapi-add.png", "width": "800", "height": "631", "credit": "", "caption": ""}, "22": {"item_id": "3948067178", "image_id": "22", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/flowiseai-buffer-memory.png", "width": "800", "height": "656", "credit": "", "caption": ""}, "23": {"item_id": "3948067178", "image_id": "23", "src": "https://files.smashing.media/articles/overview-large-language-model-concepts-use-cases-tools/flowiseai-final-workflow.png", "width": "800", "height": "704", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Smashing Magazine", "logo": "https://logo.clearbit.com/smashingmagazine.com?size=800", "greyscale_logo": "https://logo.clearbit.com/smashingmagazine.com?size=800&greyscale=true"}, "listen_duration_estimate": 1630}, "3878343531": {"item_id": "3878343531", "resolved_id": "3878343531", "given_url": "https://spectrum.ieee.org/ai-cpu", "given_title": "", "favorite": "0", "status": "1", "time_added": "1685635267", "time_updated": "1685664105", "time_read": "1685664105", "time_favorited": "0", "sort_id": 61, "resolved_title": "The Case for Running AI on CPUs Isn't Dead Yet", "resolved_url": "https://spectrum.ieee.org/ai-cpu", "excerpt": "It’s time to give the humble CPU another crack at AI. That’s the conclusion reached by a small but increasingly vocal group of AI researchers.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "935", "lang": "en", "time_to_read": 4, "amp_url": "https://spectrum.ieee.org/amp/ai-cpu-2660616835", "top_image_url": "https://spectrum.ieee.org/media-library/an-intel-xeon-processor-on-a-black-backdrop-the-processor-is-shown-from-both-above-and-below-displaying-the-thousands-of-conta.jpg?id=33743986&width=1200&height=600&coordinates=0%2C698%2C0%2C698", "tags": {"cpus": {"item_id": "3878343531", "tag": "cpus"}, "deep-learning": {"item_id": "3878343531", "tag": "deep-learning"}, "gpus": {"item_id": "3878343531", "tag": "gpus"}, "llms": {"item_id": "3878343531", "tag": "llms"}, "semiconductors": {"item_id": "3878343531", "tag": "semiconductors"}}, "domain_metadata": {"name": "IEEE", "logo": "https://logo.clearbit.com/ieee.org?size=800", "greyscale_logo": "https://logo.clearbit.com/ieee.org?size=800&greyscale=true"}, "listen_duration_estimate": 362}, "3902826700": {"item_id": "3902826700", "resolved_id": "3902826700", "given_url": "https://tech.slashdot.org/story/23/07/12/2334234/google-launches-ai-powered-notes-app-called-notebooklm", "given_title": "Google Launches AI-Powered Notes App Called NotebookLM", "favorite": "0", "status": "1", "time_added": "1689247730", "time_updated": "1690156782", "time_read": "1690156782", "time_favorited": "0", "sort_id": 62, "resolved_title": "Google Launches AI-Powered Notes App Called NotebookLM", "resolved_url": "https://tech.slashdot.org/story/23/07/12/2334234/google-launches-ai-powered-notes-app-called-notebooklm", "excerpt": "Google is launching its AI-backed note-taking tool to \"a small group of users in the US,\" the company said in a blog post. Formerly referred to as Project Tailwind at Google I/O earlier this year, the new app is now known as NotebookLM (the LM stands for Language Model).", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "385", "lang": "en", "top_image_url": "https://a.fsdn.com/sd/topics/ai_64.png", "tags": {"llms": {"item_id": "3902826700", "tag": "llms"}}, "authors": {"47802700": {"item_id": "3902826700", "author_id": "47802700", "name": "BeauHD", "url": "https://twitter.com/BeauHD"}}, "domain_metadata": {"name": "Slashdot", "logo": "https://logo.clearbit.com/slashdot.org?size=800", "greyscale_logo": "https://logo.clearbit.com/slashdot.org?size=800&greyscale=true"}, "listen_duration_estimate": 149}, "3901838461": {"item_id": "3901838461", "resolved_id": "3901838461", "given_url": "https://techcrunch.com/2023/07/11/anthropic-releases-claude-2-the-second-generation-of-its-ai-chatbot/", "given_title": "Anthropic releases Claude 2, its second-gen AI chatbot", "favorite": "0", "status": "1", "time_added": "1689085644", "time_updated": "1690156783", "time_read": "1690156783", "time_favorited": "0", "sort_id": 63, "resolved_title": "Anthropic releases Claude 2, its second-gen AI chatbot", "resolved_url": "https://techcrunch.com/2023/07/11/anthropic-releases-claude-2-the-second-generation-of-its-ai-chatbot/", "excerpt": "Anthropic, the AI startup co-founded by ex-OpenAI execs, today announced the release of a new text-generating AI model, Claude 2. The successor to Anthropic’s first commercial model, Claude 2 is available in beta starting today in the U.S. and U.K.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1742", "lang": "en", "time_to_read": 8, "amp_url": "https://techcrunch.com/2023/07/11/anthropic-releases-claude-2-the-second-generation-of-its-ai-chatbot/amp/", "top_image_url": "https://techcrunch.com/wp-content/uploads/2023/05/anthropic-header.jpg?resize=1200,675", "tags": {"llms": {"item_id": "3901838461", "tag": "llms"}}, "authors": {"165625342": {"item_id": "3901838461", "author_id": "165625342", "name": "Kyle Wiggers", "url": "https://techcrunch.com/author/kyle-wiggers/"}}, "image": {"item_id": "3901838461", "src": "https://techcrunch.com/wp-content/uploads/2023/05/anthropic-header.jpg?w=711", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3901838461", "image_id": "1", "src": "https://techcrunch.com/wp-content/uploads/2023/05/anthropic-header.jpg?w=711", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "TechCrunch", "logo": "https://logo.clearbit.com/techcrunch.com?size=800", "greyscale_logo": "https://logo.clearbit.com/techcrunch.com?size=800&greyscale=true"}, "listen_duration_estimate": 674}, "3846998241": {"item_id": "3846998241", "resolved_id": "3846998241", "given_url": "https://thegradient.pub/grounding-large-language-models-in-a-cognitive-foundation/", "given_title": "Grounding Large Language Models in a Cognitive Foundation: How to Build Som", "favorite": "1", "status": "1", "time_added": "1681606191", "time_updated": "1709152706", "time_read": "1682540123", "time_favorited": "1681609064", "sort_id": 64, "resolved_title": "Grounding Large Language Models in a Cognitive Foundation: How to Build Someone We Can Talk To", "resolved_url": "https://thegradient.pub/grounding-large-language-models-in-a-cognitive-foundation/", "excerpt": "Many intelligent robots have come and gone, failing to become a commercial success. We’ve lost Aibo, Romo, Jibo, Baxter—even Alexa is reducing staff. Perhaps they failed to reach their potential because you can’t have a meaningful conversation with them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "4663", "lang": "en", "time_to_read": 21, "top_image_url": "https://thegradient.pub/content/images/2023/04/header-5.svg", "tags": {"llms": {"item_id": "3846998241", "tag": "llms"}, "neurology": {"item_id": "3846998241", "tag": "neurology"}}, "listen_duration_estimate": 1805}, "3854738725": {"item_id": "3854738725", "resolved_id": "3854656295", "given_url": "https://thesequence.substack.com/p/edge-286-vicuna-the-llama-based-model?utm_medium=email", "given_title": "", "favorite": "0", "status": "1", "time_added": "1682602648", "time_updated": "1682764926", "time_read": "1682764926", "time_favorited": "0", "sort_id": 65, "resolved_title": "Edge 286: Vicuna, the LLaMA-Based Model that Matches ChatGPT Performance", "resolved_url": "https://thesequence.substack.com/p/edge-286-vicuna-the-llama-based-model", "excerpt": "Since its release, Meta AI’s Llama has become the foundation to all sorts of conversational AI models. Stanford’s Alpaca and Databricks’ Dolly are some of the new foundational models built on top of Llama. They all seem to have names related to…we… llamas.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "67", "lang": "en", "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37f4993d-660a-44f2-af55-b40a5b870e8c_1024x1024.png", "tags": {"llms": {"item_id": "3854738725", "tag": "llms"}}, "authors": {"86252": {"item_id": "3854738725", "author_id": "86252", "name": "Jesus Rodriguez", "url": ""}}, "listen_duration_estimate": 26}, "3866468993": {"item_id": "3866468993", "resolved_id": "3866431202", "given_url": "https://thesequence.substack.com/p/edge-291-reinforcement-learning-with?utm_medium=email", "given_title": "", "favorite": "0", "status": "1", "time_added": "1684240747", "time_updated": "1706821793", "time_read": "1684404949", "time_favorited": "0", "sort_id": 66, "resolved_title": "Edge 291: Reinforcement Learning with Human Feedback", "resolved_url": "https://thesequence.substack.com/p/edge-291-reinforcement-learning-with", "excerpt": "The RLHF paper. The transformer reinforcement learning framework.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "100", "lang": "en", "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd1aaa4cc-10d6-4ada-bba0-f1f2f0793427_1024x1024.png", "tags": {"chatgpt": {"item_id": "3866468993", "tag": "chatgpt"}, "llms": {"item_id": "3866468993", "tag": "llms"}, "reinforcement-learning": {"item_id": "3866468993", "tag": "reinforcement-learning"}, "transformers": {"item_id": "3866468993", "tag": "transformers"}}, "authors": {"86252": {"item_id": "3866468993", "author_id": "86252", "name": "Jesus Rodriguez", "url": ""}}, "listen_duration_estimate": 39}, "3887631990": {"item_id": "3887631990", "resolved_id": "3887631990", "given_url": "https://thesequence.substack.com/p/edge-300-meet-falcon-llm-the-most", "given_title": "Edge 300: Meet Falcon LLM: The Most Powerful Open Source LLM Released to Da", "favorite": "0", "status": "1", "time_added": "1686837686", "time_updated": "1690158941", "time_read": "1690158941", "time_favorited": "0", "sort_id": 67, "resolved_title": "Edge 300: Meet Falcon LLM: The Most Powerful Open Source LLM Released to Date", "resolved_url": "https://thesequence.substack.com/p/edge-300-meet-falcon-llm-the-most", "excerpt": "The open-source foundation model space is experiencing tremendous momentum with incredibly innovative releases. One of the latest additions to the space is Falcon LLM, a model created by the Technology Innovation Institute(TII) in Abu Dhabi, and released under the Apache 2.0 license.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "108", "lang": "", "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa405bc1-2701-410e-8b87-53c72a5c84af_1024x1024.png", "tags": {"llms": {"item_id": "3887631990", "tag": "llms"}}, "authors": {"86252": {"item_id": "3887631990", "author_id": "86252", "name": "Jesus Rodriguez", "url": ""}}, "listen_duration_estimate": 42}, "3843525269": {"item_id": "3843525269", "resolved_id": "3843525269", "given_url": "https://thesequence.substack.com/p/guest-post-caching-llm-queries-for", "given_title": "", "favorite": "0", "status": "1", "time_added": "1681173913", "time_updated": "1681265771", "time_read": "1681265771", "time_favorited": "0", "sort_id": 68, "resolved_title": "📝 Guest Post: Caching LLM Queries for Improved Performance and Cost Savings*", "resolved_url": "https://thesequence.substack.com/p/guest-post-caching-llm-queries-for", "excerpt": "If you're looking for a way to improve the performance of your large language model (LLM) application while reducing costs, consider utilizing a semantic cache to store LLM responses.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "773", "lang": "en", "time_to_read": 4, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1763eb47-236b-4dfd-851c-2a388c7a5671_3200x1454.png", "tags": {"caching": {"item_id": "3843525269", "tag": "caching"}, "deep-learning": {"item_id": "3843525269", "tag": "deep-learning"}, "llms": {"item_id": "3843525269", "tag": "llms"}}, "authors": {"173331956": {"item_id": "3843525269", "author_id": "173331956", "name": "Ksenia Se", "url": ""}}, "listen_duration_estimate": 299}, "3848232825": {"item_id": "3848232825", "resolved_id": "3848057939", "given_url": "https://thesequence.substack.com/p/guest-post-how-to-enhance-the-usefulness?utm_medium=email", "given_title": "", "favorite": "0", "status": "1", "time_added": "1681753017", "time_updated": "1681766949", "time_read": "1681766949", "time_favorited": "0", "sort_id": 69, "resolved_title": "📝 Guest Post: How to Enhance the Usefulness of Large Language Models*", "resolved_url": "https://thesequence.substack.com/p/guest-post-how-to-enhance-the-usefulness", "excerpt": "In this guest post, Filip Haltmayer, a Software Engineer at Zilliz, explains how LangChain and Milvus can enhance the usefulness of Large Language Models (LLMs) by allowing for the storage and retrieval of relevant documents.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1254", "lang": "en", "time_to_read": 6, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F644b606d-622a-4a15-acb7-02b97ad843a9_3200x1454.png", "tags": {"langchain": {"item_id": "3848232825", "tag": "langchain"}, "llms": {"item_id": "3848232825", "tag": "llms"}}, "authors": {"173331956": {"item_id": "3848232825", "author_id": "173331956", "name": "Ksenia Se", "url": ""}}, "listen_duration_estimate": 485}, "3903968566": {"item_id": "3903968566", "resolved_id": "3902863444", "given_url": "https://thesequence.substack.com/p/meet-lmql-an-open-source-query-language?utm_medium=email", "given_title": "Meet LMQL: An Open Source Query Language for LLMs", "favorite": "0", "status": "1", "time_added": "1689434071", "time_updated": "1690156781", "time_read": "1690156781", "time_favorited": "0", "sort_id": 70, "resolved_title": "Meet LMQL: An Open Source Query Language for LLMs", "resolved_url": "https://thesequence.substack.com/p/meet-lmql-an-open-source-query-language", "excerpt": "In the realm of technology, large language models(LLMs) have exhibited exceptional capabilities across diverse tasks, including question answering and code generation. At its core, a LLM excels in automatically generating coherent sequences based on given inputs, relying on statistical likelihood.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "197", "lang": "en", "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb64cfd32-2483-4d99-9c2b-d4cc34017c0f_1024x1024.png", "tags": {"llms": {"item_id": "3903968566", "tag": "llms"}, "sql": {"item_id": "3903968566", "tag": "sql"}}, "authors": {"87998": {"item_id": "3903968566", "author_id": "87998", "name": "ETH Zurich", "url": ""}}, "listen_duration_estimate": 76}, "3842651311": {"item_id": "3842651311", "resolved_id": "3842651311", "given_url": "https://thesequence.substack.com/p/the-llama-effect-how-an-accidental", "given_title": "The LLama Effect: How an Accidental Leak Sparked a Series of Impressive Ope", "favorite": "1", "status": "1", "time_added": "1681068939", "time_updated": "1682120660", "time_read": "1682120660", "time_favorited": "1681069741", "sort_id": 71, "resolved_title": "The LLama Effect: How an Accidental Leak Sparked a Series of Impressive Open Source Alternatives to ChatGPT", "resolved_url": "https://thesequence.substack.com/p/the-llama-effect-how-an-accidental", "excerpt": "Edge 281: Our series about federated learning(FL) continues with an overview of cross-device FL, Google’s research about FL and differential privacy and the FedLab framework for FL simulation. Edge 282: We deep dive into LangChain, the uber popular framework for LLM-based development.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "705", "lang": "en", "time_to_read": 3, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef03b36c-e5da-49d6-af96-e1ad9a078c0d_1024x1024.png", "tags": {"chatgpt": {"item_id": "3842651311", "tag": "chatgpt"}, "llama": {"item_id": "3842651311", "tag": "llama"}, "llms": {"item_id": "3842651311", "tag": "llms"}}, "authors": {"86252": {"item_id": "3842651311", "author_id": "86252", "name": "Jesus Rodriguez", "url": ""}}, "listen_duration_estimate": 273}, "3937249466": {"item_id": "3937249466", "resolved_id": "3937249466", "given_url": "https://towardsdatascience.com/10-ways-to-improve-the-performance-of-retrieval-augmented-generation-systems-5fa2cee7cd5c", "given_title": "10 Ways to Improve the Performance of Retrieval Augmented Generation System", "favorite": "0", "status": "1", "time_added": "1695080191", "time_updated": "1695684631", "time_read": "1695684631", "time_favorited": "0", "sort_id": 72, "resolved_title": "10 Ways to Improve the Performance of Retrieval Augmented Generation Systems", "resolved_url": "https://towardsdatascience.com/10-ways-to-improve-the-performance-of-retrieval-augmented-generation-systems-5fa2cee7cd5c", "excerpt": "LLMs are an amazing invention, prone to one key issue. They make stuff up. RAG makes LLMs far more useful by giving them factual context to use while answering queries.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2028", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*J16KiNF4M_XxPkALZFUJHw.jpeg", "tags": {"llms": {"item_id": "3937249466", "tag": "llms"}}, "authors": {"143234606": {"item_id": "3937249466", "author_id": "143234606", "name": "Matt Ambrogi", "url": "https://mattambrogi.medium.com"}}, "image": {"item_id": "3937249466", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*3m5IL8hqXTVgYqW492Bs5w@2x.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3937249466", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*3m5IL8hqXTVgYqW492Bs5w@2x.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3937249466", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 785}, "3927459104": {"item_id": "3927459104", "resolved_id": "3927459104", "given_url": "https://towardsdatascience.com/a-beginners-guide-to-llm-fine-tuning-4bae7d4da672", "given_title": "A Beginner’s Guide to LLM Fine-Tuning", "favorite": "0", "status": "1", "time_added": "1693390383", "time_updated": "1693399685", "time_read": "1693399685", "time_favorited": "0", "sort_id": 73, "resolved_title": "A Beginner’s Guide to LLM Fine-Tuning", "resolved_url": "https://towardsdatascience.com/a-beginners-guide-to-llm-fine-tuning-4bae7d4da672", "excerpt": "The growing interest in Large Language Models (LLMs) has led to a surge in tools and wrappers designed to streamline their training process. Popular options include FastChat from LMSYS (used to train Vicuna) and Hugging Face’s transformers/trl libraries (used in my previous article).", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "308", "lang": "en", "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*GLWNOUjJ-a863PMJ0FvDeA.jpeg", "tags": {"llms": {"item_id": "3927459104", "tag": "llms"}}, "authors": {"164625121": {"item_id": "3927459104", "author_id": "164625121", "name": "Maxime Labonne", "url": "https://medium.com/@mlabonne"}}, "image": {"item_id": "3927459104", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*4DZEZLsIpQAI7efBPvYUxw.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3927459104", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*4DZEZLsIpQAI7efBPvYUxw.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3927459104", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 119}, "3925060327": {"item_id": "3925060327", "resolved_id": "3903060640", "given_url": "https://towardsdatascience.com/a-practical-introduction-to-llms-65194dda1148?utm_source=pocket_reader", "given_title": "A Practical Introduction to LLMs", "favorite": "0", "status": "1", "time_added": "1692962196", "time_updated": "1693003963", "time_read": "1693003963", "time_favorited": "0", "sort_id": 74, "resolved_title": "A Practical Introduction to LLMs", "resolved_url": "https://towardsdatascience.com/a-practical-introduction-to-llms-65194dda1148", "excerpt": "This is the first article in a series on using Large Language Models (LLMs) in practice. Here I will give an introduction to LLMs and present 3 levels of working with them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1544", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/0*Nl-5C1WBW4XdGkNI", "tags": {"llms": {"item_id": "3925060327", "tag": "llms"}, "prompt-engineering": {"item_id": "3925060327", "tag": "prompt-engineering"}}, "authors": {"143628755": {"item_id": "3925060327", "author_id": "143628755", "name": "Shawhin Talebi", "url": "https://shawhin.medium.com"}}, "image": {"item_id": "3925060327", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*mhVX2L2LGQM4XZNwvU7H5A.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3925060327", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*mhVX2L2LGQM4XZNwvU7H5A.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3925060327", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 598}, "3912316287": {"item_id": "3912316287", "resolved_id": "3912309666", "given_url": "https://towardsdatascience.com/all-large-language-models-llms-you-should-know-in-2023-5858efb5db32?source=rss----7f60cf5620c9---4", "given_title": "All Large Language Models (LLMs) You Should Know in 2023", "favorite": "0", "status": "1", "time_added": "1690844752", "time_updated": "1690904427", "time_read": "1690904427", "time_favorited": "0", "sort_id": 75, "resolved_title": "All Large Language Models (LLMs) You Should Know in 2023", "resolved_url": "https://towardsdatascience.com/all-large-language-models-llms-you-should-know-in-2023-5858efb5db32", "excerpt": "In my last article, we dived into the world of machine learning models, understanding their working principles and how they fit into various practical applications. Today, we’ll venture into something that has quite literally taken over the entire tech space, large language models.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "263", "lang": "en", "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*KLMDBgR79ebIyIr66h9mew.png", "tags": {"llms": {"item_id": "3912316287", "tag": "llms"}}, "authors": {"144310779": {"item_id": "3912316287", "author_id": "144310779", "name": "Terence Shin", "url": "https://terenceshin.medium.com"}}, "image": {"item_id": "3912316287", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*o8zl9Jez_-CjLayYbWMoxw.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3912316287", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*o8zl9Jez_-CjLayYbWMoxw.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3912316287", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 102}, "3891501727": {"item_id": "3891501727", "resolved_id": "3891501727", "given_url": "https://towardsdatascience.com/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac", "given_title": "All You Need to Know to Build Your First LLM App", "favorite": "0", "status": "1", "time_added": "1687518972", "time_updated": "1690156788", "time_read": "1690156788", "time_favorited": "0", "sort_id": 76, "resolved_title": "All You Need to Know to Build Your First LLM App", "resolved_url": "https://towardsdatascience.com/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac", "excerpt": "If you are just looking for a short tutorial that explains how to build a simple LLM application, you can skip to section “6. Creating a Vector store”, there you have all the code snippets you need to build up a minimalistic LLM app with vector store, prompt template and LLM call.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "257", "lang": "en", "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*njagJOgiT-VTJjQ18bugcw.png", "tags": {"llms": {"item_id": "3891501727", "tag": "llms"}}, "authors": {"144893776": {"item_id": "3891501727", "author_id": "144893776", "name": "Dominik Polzer", "url": "https://dmnkplzr.medium.com"}}, "image": {"item_id": "3891501727", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*KqpicOFO7jh7FXGjoJ2Bcg.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3891501727", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*KqpicOFO7jh7FXGjoJ2Bcg.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3891501727", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 99}, "3948139625": {"item_id": "3948139625", "resolved_id": "3948139638", "given_url": "https://towardsdatascience.com/augmenting-llms-with-rag-f79de914e672?source=rss----7f60cf5620c9---4", "given_title": "Augmenting LLMs with RAG", "favorite": "0", "status": "1", "time_added": "1696961685", "time_updated": "1706647408", "time_read": "1697764308", "time_favorited": "0", "sort_id": 77, "resolved_title": "Augmenting LLMs with RAG", "resolved_url": "https://towardsdatascience.com/augmenting-llms-with-rag-f79de914e672", "excerpt": "I’ve written quite a few blogs on Medium around different technical topics, and more heavily around Machine Learning (ML) Model Hosting on Amazon SageMaker.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "338", "lang": "en", "top_image_url": "https://miro.medium.com/v2/resize:fit:1000/0*2I08qvic82JOQIuA", "tags": {"llms": {"item_id": "3948139625", "tag": "llms"}}, "authors": {"142680095": {"item_id": "3948139625", "author_id": "142680095", "name": "Ram Vegiraju", "url": "https://ram-vegiraju.medium.com"}}, "image": {"item_id": "3948139625", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*brMlNn0wRUT0G19S3L-QPQ@2x.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3948139625", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*brMlNn0wRUT0G19S3L-QPQ@2x.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3948139625", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 131}, "3905383702": {"item_id": "3905383702", "resolved_id": "3905383702", "given_url": "https://towardsdatascience.com/beyond-llama-the-power-of-open-llms-cef807a54a4f", "given_title": "Beyond LLaMA: The Power of Open LLMs", "favorite": "0", "status": "1", "time_added": "1689687148", "time_updated": "1690067596", "time_read": "1690067596", "time_favorited": "0", "sort_id": 78, "resolved_title": "Beyond LLaMA: The Power of Open LLMs", "resolved_url": "https://towardsdatascience.com/beyond-llama-the-power-of-open-llms-cef807a54a4f", "excerpt": "Despite recent advances in large language models (LLMs), many of the most powerful models are only accessible via paid APIs and trained using large amounts of proprietary data, thus limiting the research community from accessing or reproducing such models.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "340", "lang": "en", "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*c3XC-3-pgvtxakXTmKubUA.jpeg", "tags": {"llms": {"item_id": "3905383702", "tag": "llms"}}, "authors": {"125209980": {"item_id": "3905383702", "author_id": "125209980", "name": "Cameron R. Wolfe", "url": ""}}, "image": {"item_id": "3905383702", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*wv4savxpgdp3RXjMrCYrXQ.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3905383702", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*wv4savxpgdp3RXjMrCYrXQ.png", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3905383702", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 132}, "3877310871": {"item_id": "3877310871", "resolved_id": "3877310871", "given_url": "https://towardsdatascience.com/build-industry-specific-llms-using-retrieval-augmented-generation-af9e98bb6f68", "given_title": "Build Industry-Specific LLMs Using Retrieval Augmented Generation", "favorite": "0", "status": "1", "time_added": "1685529754", "time_updated": "1691367467", "time_read": "1690159030", "time_favorited": "0", "sort_id": 79, "resolved_title": "Build Industry-Specific LLMs Using Retrieval Augmented Generation", "resolved_url": "https://towardsdatascience.com/build-industry-specific-llms-using-retrieval-augmented-generation-af9e98bb6f68", "excerpt": "Companies stand to gain a lot of productivity improvements through LLMs like ChatGPT. But try asking ChatGPT “what is the current inflation in the U.S.” and it gives: I apologize for the confusion, but as an AI language model, I don’t have real-time data or browsing capabilities.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2137", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*tJYmd5EGacd-7ld5PFgdHg.png", "tags": {"generative": {"item_id": "3877310871", "tag": "generative"}, "llms": {"item_id": "3877310871", "tag": "llms"}}, "authors": {"149115506": {"item_id": "3877310871", "author_id": "149115506", "name": "Skanda Vivek", "url": "https://skanda-vivek.medium.com"}}, "image": {"item_id": "3877310871", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*Dz4TBz6PpVo5-B1kv7cI7g.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3877310871", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*Dz4TBz6PpVo5-B1kv7cI7g.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3877310871", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 827}, "3908493553": {"item_id": "3908493553", "resolved_id": "3908493573", "given_url": "https://towardsdatascience.com/chain-of-thought-prompting-for-llms-33c963eead38?source=rss----7f60cf5620c9---4", "given_title": "Chain of Thought Prompting for LLMs", "favorite": "0", "status": "1", "time_added": "1690211392", "time_updated": "1690550594", "time_read": "1690550594", "time_favorited": "0", "sort_id": 80, "resolved_title": "Chain of Thought Prompting for LLMs", "resolved_url": "https://towardsdatascience.com/chain-of-thought-prompting-for-llms-33c963eead38", "excerpt": "The success of large language models (LLMs) stems from our ability to pre-train (using a language modeling objective) decoder-only transformer models across massive textual corpora. Given that we pre-train sufficiently large models, LLMs are incredibly capable few-shot learners.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "308", "lang": "en", "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*g5Q-4lGt9UySnOK0JRQiPg.jpeg", "tags": {"llms": {"item_id": "3908493553", "tag": "llms"}, "prompt-engineering": {"item_id": "3908493553", "tag": "prompt-engineering"}}, "authors": {"125209980": {"item_id": "3908493553", "author_id": "125209980", "name": "Cameron R. Wolfe", "url": ""}}, "image": {"item_id": "3908493553", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*wv4savxpgdp3RXjMrCYrXQ.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3908493553", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*wv4savxpgdp3RXjMrCYrXQ.png", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3908493553", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 119}, "3925060102": {"item_id": "3925060102", "resolved_id": "3914681247", "given_url": "https://towardsdatascience.com/cracking-open-the-hugging-face-transformers-library-350aa0ef0161?utm_source=pocket_reader", "given_title": "Cracking Open the Hugging Face Transformers Library", "favorite": "0", "status": "1", "time_added": "1692962164", "time_updated": "1695684141", "time_read": "1695684141", "time_favorited": "0", "sort_id": 81, "resolved_title": "Cracking Open the Hugging Face Transformers Library", "resolved_url": "https://towardsdatascience.com/cracking-open-the-hugging-face-transformers-library-350aa0ef0161", "excerpt": "This is the 3rd article in a series on using large language models (LLMs) in practice. Here I will give a beginner-friendly guide to the Hugging Face Transformers library, which provides an easy and cost-free way to work with a wide variety of open-source language models.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2295", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/0*Rkoquyw55K6qbFWF", "tags": {"generative": {"item_id": "3925060102", "tag": "generative"}, "llms": {"item_id": "3925060102", "tag": "llms"}, "transformers": {"item_id": "3925060102", "tag": "transformers"}}, "authors": {"143628755": {"item_id": "3925060102", "author_id": "143628755", "name": "Shawhin Talebi", "url": "https://shawhin.medium.com"}}, "image": {"item_id": "3925060102", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*mhVX2L2LGQM4XZNwvU7H5A.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3925060102", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*mhVX2L2LGQM4XZNwvU7H5A.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3925060102", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 888}, "3925060210": {"item_id": "3925060210", "resolved_id": "3907105003", "given_url": "https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971?utm_source=pocket_reader", "given_title": "Cracking Open the OpenAI (Python) API", "favorite": "0", "status": "1", "time_added": "1692962176", "time_updated": "1706652652", "time_read": "1695684173", "time_favorited": "0", "sort_id": 82, "resolved_title": "Cracking Open the OpenAI (Python) API", "resolved_url": "https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971", "excerpt": "This is the 2nd article in a series on using Large Language Models (LLMs) in practice. Here I present a beginner-friendly introduction to the OpenAI API. This allows you to go beyond restrictive chat interfaces like ChatGPT and to get more out of LLMs for your unique use cases.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2662", "lang": "en", "time_to_read": 12, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/0*QzoGN7Zhi3m21yU0", "tags": {"apis": {"item_id": "3925060210", "tag": "apis"}, "llms": {"item_id": "3925060210", "tag": "llms"}, "python": {"item_id": "3925060210", "tag": "python"}}, "authors": {"143628755": {"item_id": "3925060210", "author_id": "143628755", "name": "Shawhin Talebi", "url": "https://shawhin.medium.com"}}, "image": {"item_id": "3925060210", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*mhVX2L2LGQM4XZNwvU7H5A.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3925060210", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*mhVX2L2LGQM4XZNwvU7H5A.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3925060210", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1030}, "3899617825": {"item_id": "3899617825", "resolved_id": "3899617842", "given_url": "https://towardsdatascience.com/deploying-falcon-7b-into-production-6dd28bb79373?source=rss----7f60cf5620c9---4", "given_title": "Deploying Falcon-7B Into Production", "favorite": "0", "status": "1", "time_added": "1688729141", "time_updated": "1690156785", "time_read": "1690156785", "time_favorited": "0", "sort_id": 83, "resolved_title": "Deploying Falcon-7B Into Production", "resolved_url": "https://towardsdatascience.com/deploying-falcon-7b-into-production-6dd28bb79373", "excerpt": "By now, we’ve seen the capabilities of ChatGPT and what it has to offer. However, for enterprise use, closed-source models like ChatGPT may pose a risk as enterprises have no control over their data.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3664", "lang": "en", "time_to_read": 17, "top_image_url": "https://miro.medium.com/v2/resize:fit:1024/1*mJeCCGWnhNg3albw4UqCjg.png", "tags": {"llms": {"item_id": "3899617825", "tag": "llms"}}, "authors": {"159436936": {"item_id": "3899617825", "author_id": "159436936", "name": "Het Trivedi", "url": "https://medium.com/@het.trivedi05"}}, "image": {"item_id": "3899617825", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*3EfA7c5YuyQhBXYkfYkVaw@2x.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3899617825", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*3EfA7c5YuyQhBXYkfYkVaw@2x.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3899617825", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1418}, "3938878112": {"item_id": "3938878112", "resolved_id": "3938878126", "given_url": "https://towardsdatascience.com/how-to-build-an-llm-from-scratch-8c477768f1f9?source=rss----7f60cf5620c9---4", "given_title": "How to Build an LLM from Scratch", "favorite": "0", "status": "1", "time_added": "1695329808", "time_updated": "1695684377", "time_read": "1695684377", "time_favorited": "0", "sort_id": 84, "resolved_title": "How to Build an LLM from Scratch", "resolved_url": "https://towardsdatascience.com/how-to-build-an-llm-from-scratch-8c477768f1f9", "excerpt": "This is the 6th article in a series on using large language models (LLMs) in practice. Previous articles explored how to leverage pre-trained LLMs via prompt engineering and fine-tuning.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "314", "lang": "en", "top_image_url": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*kNzeztfZxg8IsXA4", "tags": {"llms": {"item_id": "3938878112", "tag": "llms"}}, "authors": {"187015379": {"item_id": "3938878112", "author_id": "187015379", "name": "Shaw Talebi", "url": "https://shawhin.medium.com"}}, "image": {"item_id": "3938878112", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*mhVX2L2LGQM4XZNwvU7H5A.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3938878112", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*mhVX2L2LGQM4XZNwvU7H5A.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3938878112", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 122}, "4002250413": {"item_id": "4002250413", "resolved_id": "4002250417", "given_url": "https://towardsdatascience.com/how-to-build-an-llm-powered-app-to-chat-with-paperswithcode-09ddd9ee753a?source=rss----7f60cf5620c9---4", "given_title": "How To Build an LLM-Powered App To Chat with PapersWithCode", "favorite": "0", "status": "1", "time_added": "1706835424", "time_updated": "1709248412", "time_read": "1709248412", "time_favorited": "0", "sort_id": 85, "resolved_title": "How To Build an LLM-Powered App To Chat with PapersWithCode", "resolved_url": "https://towardsdatascience.com/how-to-build-an-llm-powered-app-to-chat-with-paperswithcode-09ddd9ee753a", "excerpt": "Do you find it difficult to keep up with the latest ML research? Are you overwhelmed with the massive amount of papers about LLMs, vector databases, or RAGs? In this post, I will show how to build an AI assistant that mines this large amount of information easily.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "286", "lang": "en", "top_image_url": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*0AW3FGe41K7h3E0p", "tags": {"llms": {"item_id": "4002250413", "tag": "llms"}, "paperswithcode": {"item_id": "4002250413", "tag": "paperswithcode"}}, "authors": {"154826635": {"item_id": "4002250413", "author_id": "154826635", "name": "Ahmed Besbes", "url": "https://ahmedbesbes.medium.com"}}, "image": {"item_id": "4002250413", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*SC35wIudR_HF3sA8F_n0yA.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "4002250413", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*SC35wIudR_HF3sA8F_n0yA.png", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "4002250413", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 111}, "3914727689": {"item_id": "3914727689", "resolved_id": "3914727699", "given_url": "https://towardsdatascience.com/how-to-chat-with-any-file-from-pdfs-to-images-using-large-language-models-with-code-4bcfd7e440bc?source=rss----7f60cf5620c9---4", "given_title": "How to Chat With Any File from PDFs to Images Using Large Language Models —", "favorite": "0", "status": "1", "time_added": "1691234000", "time_updated": "1691367674", "time_read": "1691365785", "time_favorited": "0", "sort_id": 86, "resolved_title": "How to Chat With Any File from PDFs to Images Using Large Language Models — With Code", "resolved_url": "https://towardsdatascience.com/how-to-chat-with-any-file-from-pdfs-to-images-using-large-language-models-with-code-4bcfd7e440bc", "excerpt": "So much valuable information is trapped in PDF and image files. Luckily, we have these powerful brains capable of processing those files to find specific information, which in fact is great.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "264", "lang": "en", "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*jMAGouB3s_LA1YoslX5Z_A.png", "tags": {"llms": {"item_id": "3914727689", "tag": "llms"}, "pdfs": {"item_id": "3914727689", "tag": "pdfs"}}, "authors": {"147066353": {"item_id": "3914727689", "author_id": "147066353", "name": "Zoumana Keita", "url": "https://zoumanakeita.medium.com"}}, "image": {"item_id": "3914727689", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*Se9SLHlvVxMoYooDaI91uA.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3914727689", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*Se9SLHlvVxMoYooDaI91uA.png", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3914727689", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 102}, "3909131946": {"item_id": "3909131946", "resolved_id": "3909131946", "given_url": "https://towardsdatascience.com/how-to-extract-text-from-any-pdf-and-image-for-large-language-model-2d17f02875e6", "given_title": "How to Extract Text from Any PDF and Image for Large Language Model | by Zo", "favorite": "0", "status": "1", "time_added": "1690674549", "time_updated": "1691369042", "time_read": "1691369042", "time_favorited": "0", "sort_id": 87, "resolved_title": "How to Extract Text from Any PDF and Image for Large Language Model", "resolved_url": "https://towardsdatascience.com/how-to-extract-text-from-any-pdf-and-image-for-large-language-model-2d17f02875e6", "excerpt": "Large language models have taken the internet by storm, leading more people to not pay close attention to the most important part of using these models: quality data! This article aims to provide a few techniques to efficiently extract text from any type of document.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "263", "lang": "en", "top_image_url": "https://miro.medium.com/v2/resize:fit:1000/0*hsHhE00e_S__ITtI", "tags": {"llms": {"item_id": "3909131946", "tag": "llms"}, "pdfs": {"item_id": "3909131946", "tag": "pdfs"}, "python": {"item_id": "3909131946", "tag": "python"}}, "authors": {"147066353": {"item_id": "3909131946", "author_id": "147066353", "name": "Zoumana Keita", "url": "https://zoumanakeita.medium.com"}}, "image": {"item_id": "3909131946", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*Se9SLHlvVxMoYooDaI91uA.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3909131946", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*Se9SLHlvVxMoYooDaI91uA.png", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3909131946", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 102}, "3882874439": {"item_id": "3882874439", "resolved_id": "3882874446", "given_url": "https://towardsdatascience.com/introduction-to-the-open-llm-falcon-40b-performance-training-data-and-architecture-98388fa40226?source=rss----7f60cf5620c9---4", "given_title": "Introduction to the Open LLM Falcon-40B: Performance, Training Data, and Ar", "favorite": "0", "status": "1", "time_added": "1686166280", "time_updated": "1687171764", "time_read": "1687171764", "time_favorited": "0", "sort_id": 88, "resolved_title": "Introduction to the Open LLM Falcon-40B: Performance, Training Data, and Architecture", "resolved_url": "https://towardsdatascience.com/introduction-to-the-open-llm-falcon-40b-performance-training-data-and-architecture-98388fa40226", "excerpt": "The Falcon models have drawn a lot of attention since they have been released in May 2023. They are causal large language models (LLM), or so-called “decoder-only” models, very much like GPT.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1440", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/0*nlOvoxsWqgObj_Jj", "tags": {"llms": {"item_id": "3882874439", "tag": "llms"}}, "authors": {"170386071": {"item_id": "3882874439", "author_id": "170386071", "name": "Benjamin Marie", "url": "https://medium.com/@bnjmn_marie"}}, "image": {"item_id": "3882874439", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*7y2Fqcbl3GRPgB3LfwKFdw.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3882874439", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*7y2Fqcbl3GRPgB3LfwKFdw.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3882874439", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 557}, "3924954789": {"item_id": "3924954789", "resolved_id": "3924954789", "given_url": "https://towardsdatascience.com/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f", "given_title": "Prompt Engineering — How to trick AI into solving your problems", "favorite": "0", "status": "1", "time_added": "1692960717", "time_updated": "1693512231", "time_read": "1693512231", "time_favorited": "0", "sort_id": 89, "resolved_title": "Prompt Engineering — How to trick AI into solving your problems", "resolved_url": "https://towardsdatascience.com/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f", "excerpt": "This is the fourth article in a series on using large language models (LLMs) in practice. Here, I will discuss prompt engineering (PE) and how to use it to build LLM-enabled applications.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3441", "lang": "en", "time_to_read": 16, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/0*ZcfH-qxXT4AYAqwr", "tags": {"llms": {"item_id": "3924954789", "tag": "llms"}, "prompt-engineering": {"item_id": "3924954789", "tag": "prompt-engineering"}}, "authors": {"143628755": {"item_id": "3924954789", "author_id": "143628755", "name": "Shawhin Talebi", "url": "https://shawhin.medium.com"}}, "image": {"item_id": "3924954789", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*mhVX2L2LGQM4XZNwvU7H5A.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3924954789", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*mhVX2L2LGQM4XZNwvU7H5A.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3924954789", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1332}, "3924760457": {"item_id": "3924760457", "resolved_id": "3924760457", "given_url": "https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7", "given_title": "RAG vs Finetuning: Which Is the Best Tool to Boost Your LLM Application?", "favorite": "0", "status": "1", "time_added": "1697038231", "time_updated": "1706647408", "time_read": "1697764349", "time_favorited": "0", "sort_id": 90, "resolved_title": "RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application?", "resolved_url": "https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7", "excerpt": "As the wave of interest in Large Language Models (LLMs) surges, many developers and organisations are busy building applications harnessing their power.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "297", "lang": "en", "top_image_url": "https://miro.medium.com/v2/resize:fit:1127/1*Jq9bEbitg1Pv4oASwEQwJg.png", "tags": {"llms": {"item_id": "3924760457", "tag": "llms"}}, "authors": {"149050306": {"item_id": "3924760457", "author_id": "149050306", "name": "Heiko Hotz", "url": "https://heiko-hotz.medium.com"}}, "image": {"item_id": "3924760457", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*5VifPxEG2ZkTxCK2m4JcLQ.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3924760457", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*5VifPxEG2ZkTxCK2m4JcLQ.png", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3924760457", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 115}, "3861597253": {"item_id": "3861597253", "resolved_id": "3861597253", "given_url": "https://towardsdatascience.com/the-art-of-prompt-design-prompt-boundaries-and-token-healing-3b2448b0be38", "given_title": "The Art of Prompt Design: Prompt Boundaries and Token Healing", "favorite": "0", "status": "1", "time_added": "1683561803", "time_updated": "1685270299", "time_read": "1685270298", "time_favorited": "0", "sort_id": 91, "resolved_title": "The Art of Prompt Design: Prompt Boundaries and Token Healing", "resolved_url": "https://towardsdatascience.com/the-art-of-prompt-design-prompt-boundaries-and-token-healing-3b2448b0be38", "excerpt": "This (written jointly with Marco Tulio Ribeiro) is part 2 of a series on the art of prompt design (part 1 here), where we talk about controlling large language models (LLMs) with guidance.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1402", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*PPLOArQM0wXZ5V55VbTNYA.png", "tags": {"gpt": {"item_id": "3861597253", "tag": "gpt"}, "llms": {"item_id": "3861597253", "tag": "llms"}, "prompt-engineering": {"item_id": "3861597253", "tag": "prompt-engineering"}}, "authors": {"92213802": {"item_id": "3861597253", "author_id": "92213802", "name": "Scott Lundberg", "url": "https://medium.com/@scottmlundberg"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 543}, "3949084896": {"item_id": "3949084896", "resolved_id": "3949084896", "given_url": "https://towardsdatascience.com/the-ins-and-outs-of-retrieval-augmented-generation-rag-56f470ccda4", "given_title": "The Ins and Outs of Retrieval-Augmented Generation (RAG)", "favorite": "0", "status": "1", "time_added": "1697128796", "time_updated": "1706647408", "time_read": "1697764387", "time_favorited": "0", "sort_id": 92, "resolved_title": "The Ins and Outs of Retrieval-Augmented Generation (RAG)", "resolved_url": "https://towardsdatascience.com/the-ins-and-outs-of-retrieval-augmented-generation-rag-56f470ccda4", "excerpt": "When accessible large language models first came on the scene, the excitement was impossible to miss: beyond their sheer novelty, they came with the promise to completely transform numerous fields and lines of work.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "635", "lang": "en", "time_to_read": 3, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/0*z44aRSEAwZ93fOqB", "tags": {"llms": {"item_id": "3949084896", "tag": "llms"}}, "authors": {"143504410": {"item_id": "3949084896", "author_id": "143504410", "name": "TDS Editors", "url": "https://towardsdatascience.medium.com"}}, "image": {"item_id": "3949084896", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*W8dhinLQHGYmwipTuH0k3A.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3949084896", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*W8dhinLQHGYmwipTuH0k3A.png", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3949084896", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 246}, "3845251749": {"item_id": "3845251749", "resolved_id": "3845251760", "given_url": "https://towardsdatascience.com/the-magic-of-llms-prompt-engineering-9c3e46130131?source=rss----7f60cf5620c9---4", "given_title": "The Magic of LLMs — Prompt Engineering", "favorite": "0", "status": "1", "time_added": "1681384846", "time_updated": "1681426047", "time_read": "1681426047", "time_favorited": "0", "sort_id": 93, "resolved_title": "The Magic of LLMs — Prompt Engineering", "resolved_url": "https://towardsdatascience.com/the-magic-of-llms-prompt-engineering-9c3e46130131", "excerpt": "Large language models (LLMs) are able to conversationally provide an unprecedented level of ML-generated information when asked the right question.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1263", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/0*ri0kB_t9WfNZtpLe", "tags": {"llms": {"item_id": "3845251749", "tag": "llms"}, "prompt-engineering": {"item_id": "3845251749", "tag": "prompt-engineering"}}, "authors": {"146668156": {"item_id": "3845251749", "author_id": "146668156", "name": "Frank Neugebauer", "url": "https://franklyai.medium.com"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 489}, "4012635188": {"item_id": "4012635188", "resolved_id": "4012635201", "given_url": "https://towardsdatascience.com/understanding-the-implications-of-direct-preference-optimization-a4bbd2d85841?source=rss----7f60cf5620c9---4", "given_title": "Understanding Direct Preference Optimization", "favorite": "0", "status": "1", "time_added": "1708730060", "time_updated": "1709245797", "time_read": "1709245797", "time_favorited": "0", "sort_id": 94, "resolved_title": "Understanding Direct Preference Optimization", "resolved_url": "https://towardsdatascience.com/understanding-the-implications-of-direct-preference-optimization-a4bbd2d85841", "excerpt": "This blog post was inspired by a discussion I recently had with some friends about the Direct Preference Optimization (DPO) paper. The discussion was lively and went over many important topics in LLMs and Machine Learning in general.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1597", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/v2/resize:fit:1024/1*L5Fx8l3DZ5LxZVSwBzlEdg.png", "tags": {"llms": {"item_id": "4012635188", "tag": "llms"}}, "authors": {"187626659": {"item_id": "4012635188", "author_id": "187626659", "name": "Matthew Gunton", "url": "https://medium.com/@mgunton7"}}, "image": {"item_id": "4012635188", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*F8sHS2ai6w95qbGIZ9qM_g.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "4012635188", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*F8sHS2ai6w95qbGIZ9qM_g.png", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "4012635188", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 618}, "3905524552": {"item_id": "3905524552", "resolved_id": "3905524552", "given_url": "https://venturebeat.com/ai/facebook-parent-meta-unveils-llama-2-open-source-ai-model-for-commercial-use/", "given_title": "Facebook parent Meta unveils LLaMA 2 open-source AI model for commercial us", "favorite": "0", "status": "1", "time_added": "1689709230", "time_updated": "1690067595", "time_read": "1690067595", "time_favorited": "0", "sort_id": 95, "resolved_title": "Facebook parent Meta unveils LLaMA 2 open-source AI model for commercial use ", "resolved_url": "https://venturebeat.com/ai/facebook-parent-meta-unveils-llama-2-open-source-ai-model-for-commercial-use/", "excerpt": "Head over to our on-demand library to view sessions from VB Transform 2023. Register Here In a blockbuster announcement today designed to coincide with the Microsoft Inspire conference, Meta announced its new AI model, LLaMA 2 (Large Language Model Meta AI).", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "734", "lang": "en", "time_to_read": 3, "top_image_url": "https://venturebeat.com/wp-content/uploads/2023/07/cfr0z3n_vector_art_cybernetic_llama_wearing_sunglasses_synthwav_d3f82260-2c47-4abd-9599-b91751711f5b.png?w=1200&strip=all", "tags": {"llms": {"item_id": "3905524552", "tag": "llms"}}, "authors": {"167390767": {"item_id": "3905524552", "author_id": "167390767", "name": "Sean Michael Kerner", "url": "https://venturebeat.com/author/sean-michael-kerner/"}}, "image": {"item_id": "3905524552", "src": "https://venturebeat.com/wp-content/uploads/2023/07/cfr0z3n_vector_art_cybernetic_llama_wearing_sunglasses_synthwav_d3f82260-2c47-4abd-9599-b91751711f5b.png?fit=750%2C420&strip=all", "width": "750", "height": "420"}, "images": {"1": {"item_id": "3905524552", "image_id": "1", "src": "https://venturebeat.com/wp-content/uploads/2023/07/cfr0z3n_vector_art_cybernetic_llama_wearing_sunglasses_synthwav_d3f82260-2c47-4abd-9599-b91751711f5b.png?fit=750%2C420&strip=all", "width": "750", "height": "420", "credit": "VentureBeat made with Midjourney", "caption": ""}}, "domain_metadata": {"name": "VentureBeat", "logo": "https://logo.clearbit.com/venturebeat.com?size=800", "greyscale_logo": "https://logo.clearbit.com/venturebeat.com?size=800&greyscale=true"}, "listen_duration_estimate": 284}, "3862985644": {"item_id": "3862985644", "resolved_id": "3862985644", "given_url": "https://venturebeat.com/ai/google-dives-into-the-supercomputer-game-knitting-together-purpose-built-gpus-for-llm-training/", "given_title": "Google dives into the ‘supercomputer’ game by knitting together purpose-bui", "favorite": "0", "status": "1", "time_added": "1683743169", "time_updated": "1683897436", "time_read": "1683897436", "time_favorited": "0", "sort_id": 96, "resolved_title": "Google dives into the ‘supercomputer’ game by knitting together purpose-built GPUs for large language model training", "resolved_url": "https://venturebeat.com/ai/google-dives-into-the-supercomputer-game-knitting-together-purpose-built-gpus-for-llm-training/", "excerpt": "Join top executives in San Francisco on July 11-12, to hear how leaders are integrating and optimizing AI investments for success. Learn More", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "643", "lang": "en", "time_to_read": 3, "amp_url": "https://venturebeat.com/ai/google-dives-into-the-supercomputer-game-knitting-together-purpose-built-gpus-for-llm-training/amp/", "top_image_url": "https://venturebeat.com/wp-content/uploads/2022/12/VB_dictionary-page_romain-vignes-ywqa9IZB-dU-unsplash.jpg?w=1200&strip=all", "tags": {"gpus": {"item_id": "3862985644", "tag": "gpus"}, "interconnects": {"item_id": "3862985644", "tag": "interconnects"}, "llms": {"item_id": "3862985644", "tag": "llms"}, "semiconductors": {"item_id": "3862985644", "tag": "semiconductors"}}, "authors": {"144717245": {"item_id": "3862985644", "author_id": "144717245", "name": "Peter Wayner", "url": "https://venturebeat.com/author/Peter%20Wayner/"}}, "image": {"item_id": "3862985644", "src": "https://venturebeat.com/wp-content/uploads/2022/12/VB_dictionary-page_romain-vignes-ywqa9IZB-dU-unsplash.jpg?fit=750%2C498&strip=all", "width": "750", "height": "498"}, "images": {"1": {"item_id": "3862985644", "image_id": "1", "src": "https://venturebeat.com/wp-content/uploads/2022/12/VB_dictionary-page_romain-vignes-ywqa9IZB-dU-unsplash.jpg?fit=750%2C498&strip=all", "width": "750", "height": "498", "credit": "Image   Jeremy Bishop on Unsplash", "caption": "Image Credit: Photo by Jeremy Bishop on Unsplash"}}, "domain_metadata": {"name": "VentureBeat", "logo": "https://logo.clearbit.com/venturebeat.com?size=800", "greyscale_logo": "https://logo.clearbit.com/venturebeat.com?size=800&greyscale=true"}, "listen_duration_estimate": 249}, "3906127577": {"item_id": "3906127577", "resolved_id": "3906127577", "given_url": "https://venturebeat.com/ai/llama-2-how-to-access-and-use-metas-versatile-open-source-chatbot-right-now/", "given_title": "LLaMA 2: How to access and use Meta’s versatile open-source chatbot right n", "favorite": "0", "status": "1", "time_added": "1689807692", "time_updated": "1690115145", "time_read": "1690115145", "time_favorited": "0", "sort_id": 97, "resolved_title": "LLaMA 2: How to access and use Meta’s versatile open-source chatbot right now", "resolved_url": "https://venturebeat.com/ai/llama-2-how-to-access-and-use-metas-versatile-open-source-chatbot-right-now/", "excerpt": "Head over to our on-demand library to view sessions from VB Transform 2023. Register Here", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "947", "lang": "en", "time_to_read": 4, "top_image_url": "https://venturebeat.com/wp-content/uploads/2023/07/nuneybits_vector_art_of_a_llama_programming_8c825672-172b-4e69-a6f1-b7c9e8bf5294.png?w=1200&strip=all", "tags": {"llms": {"item_id": "3906127577", "tag": "llms"}}, "authors": {"179416092": {"item_id": "3906127577", "author_id": "179416092", "name": "Michael Nuñez", "url": "https://venturebeat.com/author/michael_nunez/"}}, "image": {"item_id": "3906127577", "src": "https://venturebeat.com/wp-content/uploads/2023/07/nuneybits_vector_art_of_a_llama_programming_8c825672-172b-4e69-a6f1-b7c9e8bf5294.png?fit=750%2C600&strip=all", "width": "750", "height": "600"}, "images": {"1": {"item_id": "3906127577", "image_id": "1", "src": "https://venturebeat.com/wp-content/uploads/2023/07/nuneybits_vector_art_of_a_llama_programming_8c825672-172b-4e69-a6f1-b7c9e8bf5294.png?fit=750%2C600&strip=all", "width": "750", "height": "600", "credit": "VentureBeat made with Midjourney", "caption": ""}}, "domain_metadata": {"name": "VentureBeat", "logo": "https://logo.clearbit.com/venturebeat.com?size=800", "greyscale_logo": "https://logo.clearbit.com/venturebeat.com?size=800&greyscale=true"}, "listen_duration_estimate": 367}, "3906047120": {"item_id": "3906047120", "resolved_id": "3906047120", "given_url": "https://venturebeat.com/ai/mosaicml-launches-mpt-7b-8k-a-7b-parameter-open-source-llm/", "given_title": "MosaicML launches MPT-7B-8K, a 7B-parameter open-source LLM with 8k context", "favorite": "0", "status": "1", "time_added": "1689789784", "time_updated": "1690067594", "time_read": "1690067594", "time_favorited": "0", "sort_id": 98, "resolved_title": "MosaicML launches MPT-7B-8K, a 7B-parameter open-source LLM with 8k context length", "resolved_url": "https://venturebeat.com/ai/mosaicml-launches-mpt-7b-8k-a-7b-parameter-open-source-llm/", "excerpt": "Head over to our on-demand library to view sessions from VB Transform 2023. Register Here According to the company, the model is trained on the MosaicML platform and underwent a pretraining process commencing from the MPT-7B checkpoint.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "539", "lang": "en", "top_image_url": "https://venturebeat.com/wp-content/uploads/2023/07/Mosaic-ML.jpg?w=1200&strip=all", "tags": {"llms": {"item_id": "3906047120", "tag": "llms"}}, "authors": {"170973531": {"item_id": "3906047120", "author_id": "170973531", "name": "Victor Dey", "url": "https://venturebeat.com/author/victordey/"}}, "image": {"item_id": "3906047120", "src": "https://venturebeat.com/wp-content/uploads/2023/07/Mosaic-ML.jpg?fit=750%2C392&strip=all", "width": "750", "height": "392"}, "images": {"1": {"item_id": "3906047120", "image_id": "1", "src": "https://venturebeat.com/wp-content/uploads/2023/07/Mosaic-ML.jpg?fit=750%2C392&strip=all", "width": "750", "height": "392", "credit": "", "caption": ""}}, "domain_metadata": {"name": "VentureBeat", "logo": "https://logo.clearbit.com/venturebeat.com?size=800", "greyscale_logo": "https://logo.clearbit.com/venturebeat.com?size=800&greyscale=true"}, "listen_duration_estimate": 209}, "3890572890": {"item_id": "3890572890", "resolved_id": "3890572890", "given_url": "https://venturebeat.com/ai/observe-ai-unveils-30-billion-parameter-contact-center-llm-and-a-generative-ai-product-suite/", "given_title": "Observe.ai unveils 30-billion-parameter contact center LLM and a generative", "favorite": "0", "status": "1", "time_added": "1687285354", "time_updated": "1690156788", "time_read": "1690156788", "time_favorited": "0", "sort_id": 99, "resolved_title": "Observe.ai unveils 30-billion-parameter contact center LLM and a generative AI product suite", "resolved_url": "https://venturebeat.com/ai/observe-ai-unveils-30-billion-parameter-contact-center-llm-and-a-generative-ai-product-suite/", "excerpt": "Join top executives in San Francisco on July 11-12, to hear how leaders are integrating and optimizing AI investments for success. Learn More Conversation intelligence platform Observe.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1088", "lang": "en", "time_to_read": 5, "top_image_url": "https://venturebeat.com/wp-content/uploads/2023/06/ObserveAI-Banner-Image.jpeg?w=1200&strip=all", "tags": {"generative": {"item_id": "3890572890", "tag": "generative"}, "llms": {"item_id": "3890572890", "tag": "llms"}}, "authors": {"170973531": {"item_id": "3890572890", "author_id": "170973531", "name": "Victor Dey", "url": "https://venturebeat.com/author/victordey/"}}, "image": {"item_id": "3890572890", "src": "https://venturebeat.com/wp-content/uploads/2023/06/ObserveAI-Banner-Image.jpeg?fit=750%2C422&strip=all", "width": "750", "height": "422"}, "images": {"1": {"item_id": "3890572890", "image_id": "1", "src": "https://venturebeat.com/wp-content/uploads/2023/06/ObserveAI-Banner-Image.jpeg?fit=750%2C422&strip=all", "width": "750", "height": "422", "credit": "", "caption": ""}}, "domain_metadata": {"name": "VentureBeat", "logo": "https://logo.clearbit.com/venturebeat.com?size=800", "greyscale_logo": "https://logo.clearbit.com/venturebeat.com?size=800&greyscale=true"}, "listen_duration_estimate": 421}, "3888968031": {"item_id": "3888968031", "resolved_id": "3888968031", "given_url": "https://www-marktechpost-com.cdn.ampproject.org/c/s/www.marktechpost.com/2023/06/16/meet-fingpt-an-open-source-financial-large-language-model-llms/?amp", "given_title": "Meet FinGPT: An Open-Source Financial Large Language Model (LLMs)", "favorite": "0", "status": "1", "time_added": "1687020507", "time_updated": "1687104164", "time_read": "1687104164", "time_favorited": "0", "sort_id": 100, "resolved_title": "Meet FinGPT: An Open-Source Financial Large Language Model (LLMs)", "resolved_url": "https://www-marktechpost-com.cdn.ampproject.org/c/s/www.marktechpost.com/2023/06/16/meet-fingpt-an-open-source-financial-large-language-model-llms/?amp", "excerpt": "Large language models have increased due to the ongoing development and advancement of artificial intelligence, which has profoundly impacted the state of natural language processing in various fields.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "567", "lang": "", "top_image_url": "https://www.marktechpost.com/wp-content/uploads/2023/06/Screenshot-2023-06-15-at-10.50.11-PM.png", "tags": {"finance": {"item_id": "3888968031", "tag": "finance"}, "llms": {"item_id": "3888968031", "tag": "llms"}}, "authors": {"167076149": {"item_id": "3888968031", "author_id": "167076149", "name": "Aneesh Tickoo", "url": "https://www.marktechpost.com/author/aneesh-tickoo/?amp"}}, "image": {"item_id": "3888968031", "src": "https://www-marktechpost-com.cdn.ampproject.org/i/s/www.marktechpost.com/wp-content/uploads/2023/06/TinyEinstein-700x-300.png", "width": "700", "height": "300"}, "images": {"1": {"item_id": "3888968031", "image_id": "1", "src": "https://www-marktechpost-com.cdn.ampproject.org/i/s/www.marktechpost.com/wp-content/uploads/2023/06/TinyEinstein-700x-300.png", "width": "700", "height": "300", "credit": "", "caption": ""}}, "listen_duration_estimate": 219}, "3934672234": {"item_id": "3934672234", "resolved_id": "3934672234", "given_url": "https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1", "given_title": "Building RAG-based LLM Applications for Production (Part 1)", "favorite": "0", "status": "1", "time_added": "1696878375", "time_updated": "1706647408", "time_read": "1697764356", "time_favorited": "0", "sort_id": 101, "resolved_title": "Building RAG-based LLM Applications for Production", "resolved_url": "https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1", "excerpt": "Note: Check out newly added sections in this guide on fine-tuning, prompt engineering, lexical search, reranking and data flywheel — all with evaluation reports! Large language models (LLMs) have undoubtedly changed the way we interact with information.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "11358", "lang": "en", "time_to_read": 52, "top_image_url": "https://images.ctfassets.net/xjan103pcp94/1vCYZeIqmd03ECO3UXcCSi/374c494a8be6000ccb7570afe40ff182/social-rag-based-llm.png", "tags": {"llms": {"item_id": "3934672234", "tag": "llms"}}, "authors": {"183941148": {"item_id": "3934672234", "author_id": "183941148", "name": "Goku Mohandas", "url": "https://www.anyscale.com/blog?author=goku-mohandas"}}, "image": {"item_id": "3934672234", "src": "https://images.ctfassets.net/xjan103pcp94/4PX0l1ruKqfH17YvUiMFPw/c60a7a665125cb8056bebcc146c23b76/image8.png", "width": "1352", "height": "906"}, "images": {"1": {"item_id": "3934672234", "image_id": "1", "src": "https://images.ctfassets.net/xjan103pcp94/4PX0l1ruKqfH17YvUiMFPw/c60a7a665125cb8056bebcc146c23b76/image8.png", "width": "1352", "height": "906", "credit": "", "caption": ""}, "2": {"item_id": "3934672234", "image_id": "2", "src": "https://images.ctfassets.net/xjan103pcp94/1eFnKmG5xqPIFtPupZ327X/f6152723e18322b90aaa8be5d2d5a6e4/image5.png", "width": "1838", "height": "1022", "credit": "", "caption": ""}, "3": {"item_id": "3934672234", "image_id": "3", "src": "https://images.ctfassets.net/xjan103pcp94/6cLXmFm90OnDxXme5JzkLQ/03af428f0d78959a72ae162230745260/image7.png", "width": "1038", "height": "297", "credit": "", "caption": ""}, "4": {"item_id": "3934672234", "image_id": "4", "src": "https://images.ctfassets.net/xjan103pcp94/3z1ryYkOtUjj6N1IuavJPf/ae60dc4a10c94e2cc928c38701befb51/image2.png", "width": "1362", "height": "352", "credit": "", "caption": ""}, "5": {"item_id": "3934672234", "image_id": "5", "src": "https://images.ctfassets.net/xjan103pcp94/38I8en8Tyf0cM4LUhjygoq/739d456c80841b4c28fe80f73ea5856b/image16.png", "width": "525", "height": "412", "credit": "", "caption": ""}, "6": {"item_id": "3934672234", "image_id": "6", "src": "https://images.ctfassets.net/xjan103pcp94/17UQdsEImsXOOdDlT06bvi/4a9b9e46e157541a1178b6938624176a/llm_evaluations.png", "width": "871", "height": "303", "credit": "", "caption": ""}, "7": {"item_id": "3934672234", "image_id": "7", "src": "https://images.ctfassets.net/xjan103pcp94/3QR9zkjtpgeqK8XKPteTav/76aa9e7743330e7fcf73b07332a7ddf2/image10.png", "width": "837", "height": "186", "credit": "", "caption": ""}, "8": {"item_id": "3934672234", "image_id": "8", "src": "https://images.ctfassets.net/xjan103pcp94/2LlTUhNFzfLM775IVSxjkX/af49d7b4e0fdd4a482d29cf6eab5067f/image13.png", "width": "964", "height": "575", "credit": "", "caption": ""}, "9": {"item_id": "3934672234", "image_id": "9", "src": "https://images.ctfassets.net/xjan103pcp94/2lhpSUNrMmi7WAHpd3wslR/15facf649e30571e8d806d354f475f0b/image6.png", "width": "869", "height": "502", "credit": "", "caption": ""}, "10": {"item_id": "3934672234", "image_id": "10", "src": "https://images.ctfassets.net/xjan103pcp94/2wIdEOjnqOdKgfJ0lsjtpU/abfdf1aac22689c3ca4fff584977576b/rag-based-llm-applications-chart-1.png", "width": "641", "height": "114", "credit": "", "caption": ""}, "11": {"item_id": "3934672234", "image_id": "11", "src": "https://images.ctfassets.net/xjan103pcp94/2eYCWhMfcAfIxtzAj9gPBg/d64ad0a2e32fabb84ab68db343a27598/Screenshot_2023-10-25_at_4.19.49_AM.png", "width": "1675", "height": "592", "credit": "", "caption": ""}, "12": {"item_id": "3934672234", "image_id": "12", "src": "https://images.ctfassets.net/xjan103pcp94/01aNFUf55ZK3A1CKBChWs1/d71bc439f94d45d89d4fd4bdd94c20f0/Screenshot_2023-10-25_at_4.21.55_AM.png", "width": "1598", "height": "524", "credit": "", "caption": ""}, "13": {"item_id": "3934672234", "image_id": "13", "src": "https://images.ctfassets.net/xjan103pcp94/3VmgDxxQ4S2iLGgm4EPZ7X/b8c5b67c7f927014ac09a6940b48affa/Screenshot_2023-10-25_at_4.22.57_AM.png", "width": "1749", "height": "600", "credit": "", "caption": ""}, "14": {"item_id": "3934672234", "image_id": "14", "src": "https://images.ctfassets.net/xjan103pcp94/3M98QuzJYy1nFyKV6DrSIu/885fb0df278c93e0910fbb2992f311dd/Screenshot_2023-10-25_at_4.24.04_AM.png", "width": "1353", "height": "437", "credit": "", "caption": ""}, "15": {"item_id": "3934672234", "image_id": "15", "src": "https://images.ctfassets.net/xjan103pcp94/7w0ds7dhEGJ0puJIWaLOYu/ce76b06aad282d76fc7faba442537fb0/Screenshot_2023-10-25_at_4.24.41_AM.png", "width": "1685", "height": "583", "credit": "", "caption": ""}, "16": {"item_id": "3934672234", "image_id": "16", "src": "https://images.ctfassets.net/xjan103pcp94/7Ge0MJvmR2jnVc5ygvrudm/a72d87077995f442151bd0a4eabb9ce9/Screenshot_2023-10-25_at_4.27.06_AM.png", "width": "1138", "height": "314", "credit": "", "caption": ""}, "17": {"item_id": "3934672234", "image_id": "17", "src": "https://images.ctfassets.net/xjan103pcp94/qwRH5dUSGkHO4rJssScUL/097ff8954ba54a327acbceba1cd7e644/Screenshot_2023-10-25_at_4.27.32_AM.png", "width": "1780", "height": "620", "credit": "", "caption": ""}, "18": {"item_id": "3934672234", "image_id": "18", "src": "https://images.ctfassets.net/xjan103pcp94/7BLld0Wq27tnlxVKBjx0iH/68739b7ee900959ccbd798c46379ef2d/Screenshot_2023-10-26_at_10.38.24_AM.png", "width": "2174", "height": "1012", "credit": "", "caption": ""}, "19": {"item_id": "3934672234", "image_id": "19", "src": "https://images.ctfassets.net/xjan103pcp94/4G5324lsDZwq0jES7uBH0l/a715cd50af7061e1b3c57ec3e8038f05/rag-based-llm-applications-finetune-embeddings.png", "width": "1420", "height": "465", "credit": "", "caption": ""}, "20": {"item_id": "3934672234", "image_id": "20", "src": "https://images.ctfassets.net/xjan103pcp94/5mdtIeKZYrw9SePXztdAoS/1e2a588a648d7359753b59fe24120bf1/Screenshot_2023-10-25_at_4.51.11_AM.png", "width": "1334", "height": "488", "credit": "", "caption": ""}, "21": {"item_id": "3934672234", "image_id": "21", "src": "https://images.ctfassets.net/xjan103pcp94/6nMOu5sm3jploFUXeKxog2/a6272a581ddece641e21be391bead79f/rag-based-llm-applications-prompt-engineering.png", "width": "1422", "height": "491", "credit": "", "caption": ""}, "22": {"item_id": "3934672234", "image_id": "22", "src": "https://images.ctfassets.net/xjan103pcp94/9eBIE4iw7SmTtVvANbkAq/8913fcbd10fc66fd8b59278642155609/rag-based-llm-applications-lexical-search.png", "width": "1503", "height": "461", "credit": "", "caption": ""}, "23": {"item_id": "3934672234", "image_id": "23", "src": "https://images.ctfassets.net/xjan103pcp94/5c1LqQV0zvLACmnzjGy2P/f6fc18173d10db271d95a24755c8846d/Screenshot_2023-10-25_at_4.59.45_AM.png", "width": "1855", "height": "408", "credit": "", "caption": ""}, "24": {"item_id": "3934672234", "image_id": "24", "src": "https://images.ctfassets.net/xjan103pcp94/5j1maMWR6Y3jEldhP2P4Mp/3fde4c957f7a210380b43dd8f8c9aa92/Screenshot_2023-10-25_at_5.00.34_AM.png", "width": "1608", "height": "519", "credit": "", "caption": ""}, "25": {"item_id": "3934672234", "image_id": "25", "src": "https://images.ctfassets.net/xjan103pcp94/4bmoRNSzxtOyfToCtl68xq/d9727c41a3d435d1821eea5ab67c1e97/rag-based-llm-applications-reranking.png", "width": "1132", "height": "513", "credit": "", "caption": ""}, "26": {"item_id": "3934672234", "image_id": "26", "src": "https://images.ctfassets.net/xjan103pcp94/79UfzYrstWPbejWQrEELvh/c89e7a50e53afa0a6c8bfef0f128c618/Screenshot_2023-10-25_at_5.03.54_AM.png", "width": "1729", "height": "289", "credit": "", "caption": ""}, "27": {"item_id": "3934672234", "image_id": "27", "src": "https://images.ctfassets.net/xjan103pcp94/3kFWxgkTOpvOcCq8OqmfPC/3d4ab1de950da214e34bd267f9a2fb47/Screenshot_2023-10-25_at_5.07.41_AM.png", "width": "1106", "height": "870", "credit": "", "caption": ""}, "28": {"item_id": "3934672234", "image_id": "28", "src": "https://images.ctfassets.net/xjan103pcp94/4uYWteKRpiLIe09qKgCKcq/372b509c60abe38e3f48e885c895ff7b/Screenshot_2023-10-25_at_5.08.48_AM.png", "width": "958", "height": "758", "credit": "", "caption": ""}, "29": {"item_id": "3934672234", "image_id": "29", "src": "https://images.ctfassets.net/xjan103pcp94/3bO1dwjC3xZJxHh742gA9k/8040b9f9f837113645d22105663f083d/Screenshot_2023-10-25_at_5.12.47_AM.png", "width": "1384", "height": "441", "credit": "", "caption": ""}, "30": {"item_id": "3934672234", "image_id": "30", "src": "https://images.ctfassets.net/xjan103pcp94/3zhKMELVTQrOgFkPyexcZW/0a5f7a29dc9297c44f1fa8301fd99e15/Screenshot_2023-10-25_at_5.13.04_AM.png", "width": "1543", "height": "537", "credit": "", "caption": ""}, "31": {"item_id": "3934672234", "image_id": "31", "src": "https://images.ctfassets.net/xjan103pcp94/5CB2ko9SaTlJh3jKGLACyl/60b66a7d88333230eeab609b4d14875c/Screenshot_2023-10-25_at_5.16.16_AM.png", "width": "1194", "height": "626", "credit": "", "caption": ""}, "32": {"item_id": "3934672234", "image_id": "32", "src": "https://images.ctfassets.net/xjan103pcp94/45fxzb9vq8sh68avHdfTX2/650af07c85fc2ac3d6d2d82fd4ad9e6c/Screenshot_2023-10-25_at_5.16.30_AM.png", "width": "1602", "height": "508", "credit": "", "caption": ""}, "33": {"item_id": "3934672234", "image_id": "33", "src": "https://images.ctfassets.net/xjan103pcp94/5ZvcGQakiRvZhhWQ5MvbXp/5f5c5a4195e412727296ae0fb8034717/Screenshot_2023-10-25_at_5.21.32_AM.png", "width": "1161", "height": "516", "credit": "", "caption": ""}, "34": {"item_id": "3934672234", "image_id": "34", "src": "https://images.ctfassets.net/xjan103pcp94/7FWrvPPlIdz5fs8wQgxLFz/acbf21595b9401be677484c0de90a06f/routing-diagram.png", "width": "1385", "height": "582", "credit": "", "caption": ""}, "35": {"item_id": "3934672234", "image_id": "35", "src": "https://images.ctfassets.net/xjan103pcp94/7ftBOM7mhwcLvfYyUdnrlr/ccd35a5c6833045e2a200483288f5a67/image9.png", "width": "1618", "height": "676", "credit": "", "caption": ""}, "36": {"item_id": "3934672234", "image_id": "36", "src": "https://images.ctfassets.net/xjan103pcp94/7pyW8T7La5T51C8iXEwmAO/706dc8ed0ca75cdcbf971d9e74cd67b3/Screenshot_2023-10-24_at_12.56.39_PM.png", "width": "2014", "height": "1684", "credit": "", "caption": ""}, "37": {"item_id": "3934672234", "image_id": "37", "src": "https://images.ctfassets.net/xjan103pcp94/2UF2tSV3kmXtrzmqMsYrLF/76bcc71b481986eb6cb3b06d60582ec5/image18.png", "width": "1740", "height": "848", "credit": "", "caption": ""}}, "listen_duration_estimate": 4397}, "3844237347": {"item_id": "3844237347", "resolved_id": "3844237347", "given_url": "https://www.anyscale.com/blog/how-to-fine-tune-and-serve-llms-simply-quickly-and-cost-effectively-using", "given_title": "", "favorite": "0", "status": "1", "time_added": "1682374727", "time_updated": "1682764963", "time_read": "1682764963", "time_favorited": "0", "sort_id": 102, "resolved_title": "How to fine tune and serve LLMs simply, quickly and cost effectively using Ray + DeepSpeed + HuggingFace", "resolved_url": "https://www.anyscale.com/blog/how-to-fine-tune-and-serve-llms-simply-quickly-and-cost-effectively-using", "excerpt": "In this blog, we share a  practical approach on how you can use the combination of HuggingFace, DeepSpeed, and Ray to build a system for fine-tuning and serving LLMs, in 40 minutes for less than $7 for a 6 billion parameter model. In particular, we illustrate the following:", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1876", "lang": "en", "time_to_read": 9, "top_image_url": "https://images.ctfassets.net/xjan103pcp94/19zr72hDLSKFt8vQMz3hb6/fd9f6b83a9fe5b66456ae54ecf9bb04d/fine-tune-stack.png", "tags": {"llms": {"item_id": "3844237347", "tag": "llms"}}, "authors": {"154820987": {"item_id": "3844237347", "author_id": "154820987", "name": "Waleed Kadous", "url": "https://www.anyscale.com/blog?author=waleed-kadous"}}, "image": {"item_id": "3844237347", "src": "https://images.ctfassets.net/xjan103pcp94/70GhsrIVrh0Qz0fNDUp4A8/458e076a02c4745369c683851c378536/Screenshot_2023-04-07_at_10.17.23_AM.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3844237347", "image_id": "1", "src": "https://images.ctfassets.net/xjan103pcp94/70GhsrIVrh0Qz0fNDUp4A8/458e076a02c4745369c683851c378536/Screenshot_2023-04-07_at_10.17.23_AM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3844237347", "image_id": "2", "src": "https://images.ctfassets.net/xjan103pcp94/3C7MbWRZ8oYJoE00IW4mIi/93f686b238a84d2ef64abe3aa7670791/Screenshot_2023-04-11_at_12.44.46_PM.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 726}, "3848198656": {"item_id": "3848198656", "resolved_id": "3848198660", "given_url": "https://www.kdnuggets.com/2023/04/baby-agi-birth-fully-autonomous-ai.html?utm_source=rss&utm_medium=rss&utm_campaign=baby-agi-the-birth-of-a-fully-autonomous-ai", "given_title": "Baby AGI: The Birth of a Fully Autonomous AI", "favorite": "0", "status": "1", "time_added": "1681759433", "time_updated": "1706652652", "time_read": "1681941097", "time_favorited": "0", "sort_id": 103, "resolved_title": "Baby AGI: The Birth of a Fully Autonomous AI", "resolved_url": "https://www.kdnuggets.com/baby-agi-the-birth-of-a-fully-autonomous-ai.html", "excerpt": "Task management is a very important element to every business. It is used in marketing pipelines, to tech and fashion. It is the process of monitoring tasks in a project from start to finish.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1028", "lang": "en", "time_to_read": 5, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/arya_baby_agi_birth_fully_autonomous_ai_3.png", "tags": {"langchain": {"item_id": "3848198656", "tag": "langchain"}, "llms": {"item_id": "3848198656", "tag": "llms"}}, "authors": {"161909818": {"item_id": "3848198656", "author_id": "161909818", "name": "Nisha Arya", "url": "https://www.kdnuggets.com/author/nisha-arya"}}, "image": {"item_id": "3848198656", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500"}, "images": {"1": {"item_id": "3848198656", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 398}, "3838634673": {"item_id": "3838634673", "resolved_id": "3838634675", "given_url": "https://www.kdnuggets.com/2023/04/langchain-101-build-gptpowered-applications.html", "given_title": "LangChain 101: Build Your Own GPT-Powered Applications", "favorite": "0", "status": "1", "time_added": "1690916853", "time_updated": "1691367445", "time_read": "1690993480", "time_favorited": "0", "sort_id": 104, "resolved_title": "LangChain 101: Build Your Own GPT-Powered Applications", "resolved_url": "https://www.kdnuggets.com/langchain-101-build-your-own-gpt-powered-applications.html", "excerpt": "The success of ChatGPT and GPT-4 have shown how large language models trained with reinforcement can result in scalable and powerful NLP applications.  However, the usefulness of the response depends on the prompt, which led to users exploring the prompt engineering space.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1277", "lang": "en", "time_to_read": 6, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/c_langchain_101_build_gptpowered_applications_2.png", "tags": {"langchain": {"item_id": "3838634673", "tag": "langchain"}, "llms": {"item_id": "3838634673", "tag": "llms"}}, "authors": {"177136738": {"item_id": "3838634673", "author_id": "177136738", "name": "Bala Priya C", "url": "https://www.kdnuggets.com/author/bala-priya"}}, "image": {"item_id": "3838634673", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500"}, "images": {"1": {"item_id": "3838634673", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 494}, "3868013354": {"item_id": "3868013354", "resolved_id": "3868004599", "given_url": "https://www.kdnuggets.com/2023/05/super-bard-ai-better.html", "given_title": "Super Bard: The AI That Can Do It All and Better", "favorite": "0", "status": "1", "time_added": "1684432193", "time_updated": "1691365265", "time_read": "1684526534", "time_favorited": "0", "sort_id": 105, "resolved_title": "Super Bard: The AI That Can Do It All and Better", "resolved_url": "https://www.kdnuggets.com/super-bard-the-ai-that-can-do-it-all-and-better.html", "excerpt": "The Pathways Language Model (PaLM) has been updated with improved multilingual, reasoning, and coding capabilities. This new model is more capable of understanding and generating text in multiple languages, as well as reasoning and coding.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "726", "lang": "en", "time_to_read": 3, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/awan_super_bard_ai_better_1.png", "tags": {"llms": {"item_id": "3868013354", "tag": "llms"}}, "authors": {"158758449": {"item_id": "3868013354", "author_id": "158758449", "name": "Abid Ali Awan", "url": "https://www.kdnuggets.com/author/abidali-awan"}}, "image": {"item_id": "3868013354", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500"}, "images": {"1": {"item_id": "3868013354", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 281}, "3882924696": {"item_id": "3882924696", "resolved_id": "3882924697", "given_url": "https://www.kdnuggets.com/2023/06/falcon-llm-new-king-llms.html", "given_title": "Falcon LLM: The New King of Open-Source LLMs", "favorite": "0", "status": "1", "time_added": "1686170063", "time_updated": "1687171764", "time_read": "1687171764", "time_favorited": "0", "sort_id": 106, "resolved_title": "Falcon LLM: The New King of Open-Source LLMs", "resolved_url": "https://www.kdnuggets.com/falcon-llm-the-new-king-of-open-source-llms.html", "excerpt": "We’ve been seeing large language models (LLMs) spitting out every week, with more and more chatbots for us to use. However, it can be hard to figure out which is the best, the progress on each and which one is most useful. ", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "937", "lang": "en", "time_to_read": 4, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/arya_falcon_llm_new_king_llms_3.png", "tags": {"llms": {"item_id": "3882924696", "tag": "llms"}}, "authors": {"161909818": {"item_id": "3882924696", "author_id": "161909818", "name": "Nisha Arya", "url": "https://www.kdnuggets.com/author/nisha-arya"}}, "image": {"item_id": "3882924696", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500"}, "images": {"1": {"item_id": "3882924696", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 363}, "3887060150": {"item_id": "3887060150", "resolved_id": "3887060153", "given_url": "https://www.kdnuggets.com/2023/06/free-full-stack-llm-bootcamp.html", "given_title": "Free Full Stack LLM Bootcamp", "favorite": "0", "status": "1", "time_added": "1686746938", "time_updated": "1690158944", "time_read": "1690158944", "time_favorited": "0", "sort_id": 107, "resolved_title": "Free Full Stack LLM Bootcamp", "resolved_url": "https://www.kdnuggets.com/free-full-stack-llm-bootcamp.html", "excerpt": "Large Language Models (LLMs) and LLM applications are the talk of the town! Whether you're interested in exploring them for personal projects, using them at work to maximize productivity, or quickly summarize search results and research papers—LLMs offer something for everyone across the spectrum.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1038", "lang": "en", "time_to_read": 5, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/c_free_full_stack_llm_bootcamp_2.png", "tags": {"llms": {"item_id": "3887060150", "tag": "llms"}}, "authors": {"177136738": {"item_id": "3887060150", "author_id": "177136738", "name": "Bala Priya C", "url": "https://www.kdnuggets.com/author/bala-priya"}}, "image": {"item_id": "3887060150", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500"}, "images": {"1": {"item_id": "3887060150", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 402}, "3912219081": {"item_id": "3912219081", "resolved_id": "3912219085", "given_url": "https://www.kdnuggets.com/2023/07/introducing-openllm-open-source-library-llms.html", "given_title": "Introducing OpenLLM: Open Source Library for LLMs", "favorite": "0", "status": "1", "time_added": "1690845468", "time_updated": "1691368998", "time_read": "1691368998", "time_favorited": "0", "sort_id": 108, "resolved_title": "Introducing OpenLLM: Open Source Library for LLMs", "resolved_url": "https://www.kdnuggets.com/introducing-openllm-open-source-library-for-llms.html", "excerpt": "At this point, we’re all thinking the same thing. Is the world of LLMs really taking over? Some of you may have expected the hype to plateau, but it is still on the continuous rise. More resources are going into LLMs as it has shown a huge demand.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "659", "lang": "en", "time_to_read": 3, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/arya_introducing_openllm_open_source_library_llms_1.png", "tags": {"llms": {"item_id": "3912219081", "tag": "llms"}}, "authors": {"161909818": {"item_id": "3912219081", "author_id": "161909818", "name": "Nisha Arya", "url": "https://www.kdnuggets.com/author/nisha-arya"}}, "image": {"item_id": "3912219081", "src": "https://www.kdnuggets.com/wp-content/uploads/arya_introducing_openllm_open_source_library_llms_1.png", "width": "100", "height": "0"}, "images": {"1": {"item_id": "3912219081", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/uploads/arya_introducing_openllm_open_source_library_llms_1.png", "width": "100", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 255}, "3899421887": {"item_id": "3899421887", "resolved_id": "3899414414", "given_url": "https://www.kdnuggets.com/2023/07/power-chain-thought-prompting-large-language-models.html", "given_title": "Unraveling the Power of Chain-of-Thought Prompting in Large Language Models", "favorite": "0", "status": "1", "time_added": "1688670475", "time_updated": "1689188727", "time_read": "1689188727", "time_favorited": "0", "sort_id": 109, "resolved_title": "Unraveling the Power of Chain-of-Thought Prompting in Large Language Models", "resolved_url": "https://www.kdnuggets.com/unraveling-the-power-of-chain-of-thought-prompting-in-large-language-models.html", "excerpt": "Large Language Models (LLMs) have revolutionized the field of artificial intelligence, offering unprecedented capabilities in natural language understanding and generation. However, their ability to perform complex reasoning tasks has been a subject of intense research.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "854", "lang": "en", "time_to_read": 4, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/cot-brain-model-chains.jpg", "tags": {"llms": {"item_id": "3899421887", "tag": "llms"}, "prompt-engineering": {"item_id": "3899421887", "tag": "prompt-engineering"}}, "authors": {"77311567": {"item_id": "3899421887", "author_id": "77311567", "name": "Matthew Mayo", "url": "https://www.kdnuggets.com/author/matt-mayo"}}, "image": {"item_id": "3899421887", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500"}, "images": {"1": {"item_id": "3899421887", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 331}, "3951961915": {"item_id": "3951961915", "resolved_id": "3951961922", "given_url": "https://www.kdnuggets.com/7-steps-to-mastering-large-language-models-llms", "given_title": "7 Steps to Mastering Large Language Models (LLMs)", "favorite": "0", "status": "1", "time_added": "1697631515", "time_updated": "1697764848", "time_read": "1697764848", "time_favorited": "0", "sort_id": 110, "resolved_title": "7 Steps to Mastering Large Language Models (LLMs)", "resolved_url": "https://www.kdnuggets.com/7-steps-to-mastering-large-language-models-llms.html", "excerpt": "GPT-4, Llama, Falcon, and many more—Large Language Models—LLMs—are literally the talk of the town year. And if you’re reading this chances are you’ve already used one or more of these large language models through a chat interface or an API. ", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2020", "lang": "en", "time_to_read": 9, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/c_7_steps_mastering_large_language_models_llms_2.png", "tags": {"llms": {"item_id": "3951961915", "tag": "llms"}}, "authors": {"177136738": {"item_id": "3951961915", "author_id": "177136738", "name": "Bala Priya C", "url": "https://www.kdnuggets.com/author/bala-priya"}}, "image": {"item_id": "3951961915", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500"}, "images": {"1": {"item_id": "3951961915", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 782}, "3997763024": {"item_id": "3997763024", "resolved_id": "3997763024", "given_url": "https://www.kdnuggets.com/exploring-the-zephyr-7b-a-comprehensive-guide-to-the-latest-large-language-model", "given_title": "Exploring the Zephyr 7B: A Comprehensive Guide to the Latest Large Language", "favorite": "0", "status": "1", "time_added": "1705936007", "time_updated": "1706073256", "time_read": "1706073256", "time_favorited": "0", "sort_id": 111, "resolved_title": "Exploring the Zephyr 7B: A Comprehensive Guide to the Latest Large Language Model", "resolved_url": "https://www.kdnuggets.com/exploring-the-zephyr-7b-a-comprehensive-guide-to-the-latest-large-language-model", "excerpt": "2023 was the year of Large Language Models and Open Source. Many startups and companies open-sourced their models and weights to combat proprietary LLMs such as ChatGPT and Claude. Some of the important companies and models (open source) for 2023 were:", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1004", "lang": "en", "time_to_read": 5, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/anis_exploring_zephyr_7b_comprehensive_guide_latest_large_language_model_9-scaled.jpg", "tags": {"llms": {"item_id": "3997763024", "tag": "llms"}}, "authors": {"135129769": {"item_id": "3997763024", "author_id": "135129769", "name": "Ahmad Anis", "url": "https://www.kdnuggets.com/author/ahmad-anis"}}, "image": {"item_id": "3997763024", "src": "https://www.kdnuggets.com/wp-content/uploads/anis_exploring_zephyr_7b_comprehensive_guide_latest_large_language_model_9-scaled.jpg", "width": "100", "height": "0"}, "images": {"1": {"item_id": "3997763024", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/uploads/anis_exploring_zephyr_7b_comprehensive_guide_latest_large_language_model_9-scaled.jpg", "width": "100", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3997763024", "image_id": "2", "src": "https://www.kdnuggets.com/wp-content/uploads/anis_exploring_zephyr_7b_comprehensive_guide_latest_large_language_model_7.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3997763024", "image_id": "3", "src": "https://www.kdnuggets.com/wp-content/uploads/anis_exploring_zephyr_7b_comprehensive_guide_latest_large_language_model_8.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3997763024", "image_id": "4", "src": "https://www.kdnuggets.com/wp-content/uploads/anis_exploring_zephyr_7b_comprehensive_guide_latest_large_language_model_6.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3997763024", "image_id": "5", "src": "https://www.kdnuggets.com/wp-content/uploads/anis_exploring_zephyr_7b_comprehensive_guide_latest_large_language_model_3.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3997763024", "image_id": "6", "src": "https://www.kdnuggets.com/wp-content/uploads/anis_exploring_zephyr_7b_comprehensive_guide_latest_large_language_model_4.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3997763024", "image_id": "7", "src": "https://www.kdnuggets.com/wp-content/uploads/anis_exploring_zephyr_7b_comprehensive_guide_latest_large_language_model_1.png", "width": "100", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 389}, "3944068200": {"item_id": "3944068200", "resolved_id": "3944035126", "given_url": "https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique", "given_title": "Parallel Processing in Prompt Engineering: The Skeleton-of-Thought Techniqu", "favorite": "0", "status": "1", "time_added": "1696294456", "time_updated": "1706802574", "time_read": "1696699742", "time_favorited": "0", "sort_id": 112, "resolved_title": "Parallel Processing in Prompt Engineering: The Skeleton-of-Thought Technique", "resolved_url": "https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique.html", "excerpt": "Skeleton-of-Thought (SoT) is an innovative prompt engineering technique that minimizes generation latency in Large Language Models (LLMs), enhancing their efficiency By creating a skeleton of the answer and then parallelly elaborating on each point, SoT emulates human thinking, promoting more reliab", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "631", "lang": "en", "time_to_read": 3, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/skeleton-of-thought-header.png", "tags": {"llms": {"item_id": "3944068200", "tag": "llms"}, "prompt-engineering": {"item_id": "3944068200", "tag": "prompt-engineering"}}, "authors": {"77311567": {"item_id": "3944068200", "author_id": "77311567", "name": "Matthew Mayo", "url": "https://www.kdnuggets.com/author/matt-mayo"}}, "image": {"item_id": "3944068200", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500"}, "images": {"1": {"item_id": "3944068200", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 244}, "3947488893": {"item_id": "3947488893", "resolved_id": "3947488897", "given_url": "https://www.kdnuggets.com/unlocking-gpt-4-summarization-with-chain-of-density-prompting", "given_title": "Unlocking GPT-4 Summarization with Chain of Density Prompting", "favorite": "0", "status": "1", "time_added": "1696852013", "time_updated": "1706802574", "time_read": "1697764404", "time_favorited": "0", "sort_id": 113, "resolved_title": "Unlocking GPT-4 Summarization with Chain of Density Prompting", "resolved_url": "https://www.kdnuggets.com/unlocking-gpt-4-summarization-with-chain-of-density-prompting.html", "excerpt": "Chain of Density (CoD) is a novel prompt engineering technique designed for optimizing summarization tasks in Large Language Models like GPT-4 The technique deals with controlling the information density in the generated summary, providing a balanced output that is neither too sparse nor too dense C", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "835", "lang": "en", "time_to_read": 4, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/chain-of-density-header-3.png", "tags": {"llms": {"item_id": "3947488893", "tag": "llms"}, "prompt-engineering": {"item_id": "3947488893", "tag": "prompt-engineering"}}, "authors": {"77311567": {"item_id": "3947488893", "author_id": "77311567", "name": "Matthew Mayo", "url": "https://www.kdnuggets.com/author/matt-mayo"}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 323}, "3906381881": {"item_id": "3906381881", "resolved_id": "3906381881", "given_url": "https://www.linkedin.com/posts/lvwerra_it-crazy-how-far-the-ml-field-has-come-when-activity-7087699813009383425-Sr1y", "given_title": "Leandro von Werra’s Post", "favorite": "0", "status": "1", "time_added": "1689861541", "time_updated": "1690121887", "time_read": "1690121887", "time_favorited": "0", "sort_id": 114, "resolved_title": "Leandro von Werra’s Post", "resolved_url": "https://www.linkedin.com/posts/lvwerra_it-crazy-how-far-the-ml-field-has-come-when-activity-7087699813009383425-Sr1y", "excerpt": "See more comments To view or add a comment, sign in", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "11", "lang": "en", "top_image_url": "https://media.licdn.com/dms/image/D4E22AQGGzP26Zn7lSg/feedshare-shrink_2048_1536/0/1689839317534?e=1692835200&v=beta&t=397dqncAqMkqjHsHHQ1AFFW2oiGldqqdQR0gfGu8d5g", "tags": {"llms": {"item_id": "3906381881", "tag": "llms"}}, "domain_metadata": {"name": "LinkedIn", "logo": "https://logo.clearbit.com/linkedin.com?size=800", "greyscale_logo": "https://logo.clearbit.com/linkedin.com?size=800&greyscale=true"}, "listen_duration_estimate": 4}, "3864902107": {"item_id": "3864902107", "resolved_id": "3864787305", "given_url": "https://www.linkedin.com/posts/sonali-pattnaik_generativeai-ai-activity-7063160223967973376-3K0P?utm_source=share&utm_medium=member_ios", "given_title": "", "favorite": "0", "status": "1", "time_added": "1684268559", "time_updated": "1684679437", "time_read": "1684679437", "time_favorited": "0", "sort_id": 115, "resolved_title": "Sonali Pattnaik’s Post", "resolved_url": "https://www.linkedin.com/posts/sonali-pattnaik_generativeai-ai-activity-7063160223967973376-3K0P", "excerpt": "To view or add a comment, sign in", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "8", "lang": "en", "top_image_url": "https://static.licdn.com/aero-v1/sc/h/c45fy346jw096z9pbphyyhdz7", "tags": {"langchain": {"item_id": "3864902107", "tag": "langchain"}, "llms": {"item_id": "3864902107", "tag": "llms"}}, "domain_metadata": {"name": "LinkedIn", "logo": "https://logo.clearbit.com/linkedin.com?size=800", "greyscale_logo": "https://logo.clearbit.com/linkedin.com?size=800&greyscale=true"}, "listen_duration_estimate": 3}, "3914198430": {"item_id": "3914198430", "resolved_id": "3914198430", "given_url": "https://www.marktechpost.com/2023/08/03/abacus-ai-introduces-a-new-open-long-context-large-language-model-llm-meet-giraffe/", "given_title": "Abacus AI Introduces A New Open Long-Context Large Language Model LLM: Meet", "favorite": "0", "status": "1", "time_added": "1691264663", "time_updated": "1691368993", "time_read": "1691368993", "time_favorited": "0", "sort_id": 116, "resolved_title": "Abacus AI Introduces A New Open Long-Context Large Language Model LLM: Meet Giraffe", "resolved_url": "https://www.marktechpost.com/2023/08/03/abacus-ai-introduces-a-new-open-long-context-large-language-model-llm-meet-giraffe/", "excerpt": "Recent language models can take long contexts as input; more is needed to know about how well they use longer contexts. Can LLMs be extended to longer contexts? This is an unanswered question.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "550", "lang": "en", "time_to_read": 3, "top_image_url": "https://www.marktechpost.com/wp-content/uploads/2023/08/F2cyQhvXAAAJk8y.jpeg", "tags": {"llms": {"item_id": "3914198430", "tag": "llms"}}, "authors": {"183632254": {"item_id": "3914198430", "author_id": "183632254", "name": "Mohammad Arshad", "url": "https://www.marktechpost.com/author/mohammadarshad/"}}, "image": {"item_id": "3914198430", "src": "https://www.marktechpost.com/wp-content/uploads/2023/08/F2cyQhvXAAAJk8y.jpeg", "width": "696", "height": "424"}, "images": {"1": {"item_id": "3914198430", "image_id": "1", "src": "https://www.marktechpost.com/wp-content/uploads/2023/08/F2cyQhvXAAAJk8y.jpeg", "width": "696", "height": "424", "credit": "", "caption": "https://blog.abacus.ai/blog/2023/07/27/treating-attention-deficit-disorder-in-llms/"}}, "listen_duration_estimate": 213}, "3922005052": {"item_id": "3922005052", "resolved_id": "3922005052", "given_url": "https://www.marktechpost.com/2023/08/19/meet-chroma-an-ai-native-open-source-vector-database-for-llms-a-faster-way-to-build-python-or-javascript-llm-apps-with-memory/", "given_title": "Meet Chroma: An AI-Native Open-Source Vector Database For LLMs: A Faster Wa", "favorite": "0", "status": "1", "time_added": "1692451180", "time_updated": "1692528985", "time_read": "1692528985", "time_favorited": "0", "sort_id": 117, "resolved_title": "Meet Chroma: An AI-Native Open-Source Vector Database For LLMs: A Faster Way to Build Python or JavaScript LLM Apps with Memory", "resolved_url": "https://www.marktechpost.com/2023/08/19/meet-chroma-an-ai-native-open-source-vector-database-for-llms-a-faster-way-to-build-python-or-javascript-llm-apps-with-memory/", "excerpt": "Word embedding vector databases have become increasingly popular due to the proliferation of massive language models. Using the power of sophisticated machine learning techniques, data is stored in a vector database.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "504", "lang": "en", "top_image_url": "https://www.marktechpost.com/wp-content/uploads/2023/08/Screenshot-2023-08-19-at-3.55.16-AM.png", "tags": {"llms": {"item_id": "3922005052", "tag": "llms"}, "vector-databases": {"item_id": "3922005052", "tag": "vector-databases"}}, "authors": {"174215351": {"item_id": "3922005052", "author_id": "174215351", "name": "Dhanshree Shripad Shenwai", "url": "https://www.marktechpost.com/author/dhanshree0078/"}}, "image": {"item_id": "3922005052", "src": "https://www.marktechpost.com/wp-content/uploads/2023/08/Screenshot-2023-08-19-at-3.55.16-AM.png", "width": "696", "height": "363"}, "images": {"1": {"item_id": "3922005052", "image_id": "1", "src": "https://www.marktechpost.com/wp-content/uploads/2023/08/Screenshot-2023-08-19-at-3.55.16-AM.png", "width": "696", "height": "363", "credit": "", "caption": "https://www.trychroma.com/"}}, "listen_duration_estimate": 195}, "3923244601": {"item_id": "3923244601", "resolved_id": "3923244601", "given_url": "https://www.marktechpost.com/2023/08/21/together-ai-unveils-llama-2-7b-32k-instruct-a-breakthrough-in-extended-context-language-processing/", "given_title": "Together AI Unveils Llama-2-7B-32K-Instruct: A Breakthrough in Extended-Con", "favorite": "0", "status": "1", "time_added": "1692671099", "time_updated": "1693167730", "time_read": "1693167730", "time_favorited": "0", "sort_id": 118, "resolved_title": "Together AI Unveils Llama-2-7B-32K-Instruct: A Breakthrough in Extended-Context Language Processing", "resolved_url": "https://www.marktechpost.com/2023/08/21/together-ai-unveils-llama-2-7b-32k-instruct-a-breakthrough-in-extended-context-language-processing/", "excerpt": "A multifaceted challenge has arisen in the expansive realm of natural language processing: the ability to adeptly comprehend and respond to intricate and lengthy instructions.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "505", "lang": "en", "top_image_url": "https://www.marktechpost.com/wp-content/uploads/2023/08/F301xvJW0AARkdL.jpeg", "tags": {"llama": {"item_id": "3923244601", "tag": "llama"}, "llms": {"item_id": "3923244601", "tag": "llms"}}, "authors": {"184016858": {"item_id": "3923244601", "author_id": "184016858", "name": "Madhur Garg", "url": "https://www.marktechpost.com/author/madhurgarg/"}}, "image": {"item_id": "3923244601", "src": "https://www.marktechpost.com/wp-content/uploads/2023/08/F301xvJW0AARkdL.jpeg", "width": "696", "height": "464"}, "images": {"1": {"item_id": "3923244601", "image_id": "1", "src": "https://www.marktechpost.com/wp-content/uploads/2023/08/F301xvJW0AARkdL.jpeg", "width": "696", "height": "464", "credit": "", "caption": "https://together.ai/blog/llama-2-7b-32k-instruct"}, "2": {"item_id": "3923244601", "image_id": "2", "src": "https://lh4.googleusercontent.com/DKa1MESYqnclDlwUrdWVLmhulWHA7N3HSshXSbnz1fcRWJocnh3kvPuwZI-lu7p0ZS7dAsvh6KXkffV8C9_M64tvlR1X9zg5pFkxJq1Fvj37GY9Ecm30p2vi7FIe0xLP9rHM62a3pCToVXRVp1ZmNws", "width": "413", "height": "263", "credit": "", "caption": "https://together.ai/blog/llama-2-7b-32k-instruct"}}, "listen_duration_estimate": 195}, "3938544845": {"item_id": "3938544845", "resolved_id": "3938544845", "given_url": "https://www.marktechpost.com/2023/09/20/openai-unveils-dall%c2%b7e-3-a-revolutionary-leap-in-text-to-image-generation/", "given_title": "OpenAI Unveils DALL·E 3: A Revolutionary Leap in Text-to-Image Generation", "favorite": "0", "status": "1", "time_added": "1695294847", "time_updated": "1706652652", "time_read": "1695566726", "time_favorited": "0", "sort_id": 119, "resolved_title": "OpenAI Unveils DALL·E 3: A Revolutionary Leap in Text-to-Image Generation", "resolved_url": "https://www.marktechpost.com/2023/09/20/openai-unveils-dall%c2%b7e-3-a-revolutionary-leap-in-text-to-image-generation/", "excerpt": "In a significant technological leap, OpenAI has announced the launch of DALL·E 3, the latest iteration in their groundbreaking text-to-image generation technology.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "476", "lang": "en", "amp_url": "https://www.marktechpost.com/2023/09/20/openai-unveils-dall%c2%b7e-3-a-revolutionary-leap-in-text-to-image-generation/?amp", "top_image_url": "https://www.marktechpost.com/wp-content/uploads/2023/09/Screenshot-2023-09-20-at-10.40.15-PM.png", "tags": {"generative": {"item_id": "3938544845", "tag": "generative"}, "image-generation": {"item_id": "3938544845", "tag": "image-generation"}, "llms": {"item_id": "3938544845", "tag": "llms"}}, "authors": {"156002156": {"item_id": "3938544845", "author_id": "156002156", "name": "Shobha Kakkar", "url": "https://www.marktechpost.com/author/shobha-kakkar/"}}, "image": {"item_id": "3938544845", "src": "https://www.marktechpost.com/wp-content/uploads/2023/09/Screenshot-2023-09-20-at-10.40.15-PM.png", "width": "696", "height": "370"}, "images": {"1": {"item_id": "3938544845", "image_id": "1", "src": "https://www.marktechpost.com/wp-content/uploads/2023/09/Screenshot-2023-09-20-at-10.40.15-PM.png", "width": "696", "height": "370", "credit": "", "caption": "https://openai.com/dall-e-3?ref=maginative.com"}}, "listen_duration_estimate": 184}, "3946908625": {"item_id": "3946908625", "resolved_id": "3946908625", "given_url": "https://www.marktechpost.com/2023/10/07/meta-ai-researchers-propose-advanced-long-context-llms-a-deep-dive-into-upsampling-training-techniques-and-surpassing-gpt-3-5-turbo-16ks-performance/", "given_title": "Meta AI Researchers Propose Advanced Long-Context LLMs: A Deep Dive into Up", "favorite": "0", "status": "1", "time_added": "1696780399", "time_updated": "1697764690", "time_read": "1697764690", "time_favorited": "0", "sort_id": 120, "resolved_title": "Meta AI Researchers Propose Advanced Long-Context LLMs: A Deep Dive into Upsampling,...", "resolved_url": "https://www.marktechpost.com/2023/10/07/meta-ai-researchers-propose-advanced-long-context-llms-a-deep-dive-into-upsampling-training-techniques-and-surpassing-gpt-3-5-turbo-16ks-performance/", "excerpt": "The emergence of Large Language Models (LLMs) in natural language processing represents a groundbreaking development. These models, trained on vast amounts of data and leveraging immense computational resources, promise to transform human interactions with the digital world.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "590", "lang": "en", "time_to_read": 3, "amp_url": "https://www.marktechpost.com/2023/10/07/meta-ai-researchers-propose-advanced-long-context-llms-a-deep-dive-into-upsampling-training-techniques-and-surpassing-gpt-3-5-turbo-16ks-performance/?amp", "top_image_url": "https://www.marktechpost.com/wp-content/uploads/2023/10/Screenshot-2023-10-08-at-8.08.38-AM.png", "tags": {"llms": {"item_id": "3946908625", "tag": "llms"}}, "authors": {"174215351": {"item_id": "3946908625", "author_id": "174215351", "name": "Dhanshree Shripad Shenwai", "url": "https://www.marktechpost.com/author/dhanshree0078/"}}, "image": {"item_id": "3946908625", "src": "https://www.marktechpost.com/wp-content/uploads/2023/10/Screenshot-2023-10-08-at-8.08.38-AM.png", "width": "696", "height": "427"}, "images": {"1": {"item_id": "3946908625", "image_id": "1", "src": "https://www.marktechpost.com/wp-content/uploads/2023/10/Screenshot-2023-10-08-at-8.08.38-AM.png", "width": "696", "height": "427", "credit": "", "caption": "https://ai.meta.com/research/publications/effective-long-context-scaling-of-foundation-models/"}}, "listen_duration_estimate": 228}, "3947930866": {"item_id": "3947930866", "resolved_id": "3947930866", "given_url": "https://www.marktechpost.com/2023/10/09/meet-waymos-motionlm-the-state-of-the-art-multi-agent-motion-prediction-approach-that-can-make-it-possible-for-large-language-models-llms-to-help-drive-cars/", "given_title": "Meet Waymo’s MotionLM: The State-of-the-Art Multi-Agent Motion Prediction A", "favorite": "0", "status": "1", "time_added": "1696935499", "time_updated": "1706199875", "time_read": "1704665774", "time_favorited": "0", "sort_id": 121, "resolved_title": "Meet Waymo's MotionLM : The State-of-the-Art Multi-Agent Motion Prediction Approach that can Make it Possible for Large Language Models (LLMs) to Help Drive Cars ", "resolved_url": "https://www.marktechpost.com/2023/10/09/meet-waymos-motionlm-the-state-of-the-art-multi-agent-motion-prediction-approach-that-can-make-it-possible-for-large-language-models-llms-to-help-drive-cars/", "excerpt": "Autoregressive language models have excelled at predicting the subsequent subword in a sentence without the need for any predefined grammar or parsing concepts.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "540", "lang": "en", "amp_url": "https://www.marktechpost.com/2023/10/09/meet-waymos-motionlm-the-state-of-the-art-multi-agent-motion-prediction-approach-that-can-make-it-possible-for-large-language-models-llms-to-help-drive-cars/?amp", "top_image_url": "https://www.marktechpost.com/wp-content/uploads/2023/10/ezgif-4-5e9741ba41.gif", "tags": {"llms": {"item_id": "3947930866", "tag": "llms"}}, "authors": {"175902762": {"item_id": "3947930866", "author_id": "175902762", "name": "Tanya Malhotra", "url": "https://www.marktechpost.com/author/tanyamalhotra/"}}, "image": {"item_id": "3947930866", "src": "https://www.marktechpost.com/wp-content/uploads/2023/10/ezgif-4-5e9741ba41.gif", "width": "600", "height": "593"}, "images": {"1": {"item_id": "3947930866", "image_id": "1", "src": "https://www.marktechpost.com/wp-content/uploads/2023/10/ezgif-4-5e9741ba41.gif", "width": "600", "height": "593", "credit": "", "caption": ""}}, "listen_duration_estimate": 209}, "3948066239": {"item_id": "3948066239", "resolved_id": "3948066239", "given_url": "https://www.marktechpost.com/2023/10/10/this-ai-paper-from-nvidia-explores-the-power-of-retrieval-augmentation-vs-long-context-in-language-models-which-reigns-supreme-and-can-they-coexist/", "given_title": "This AI Paper from NVIDIA Explores the Power of Retrieval-Augmentation vs. ", "favorite": "0", "status": "1", "time_added": "1696952672", "time_updated": "1706647408", "time_read": "1697764687", "time_favorited": "0", "sort_id": 122, "resolved_title": "This AI Paper from NVIDIA Explores the Power of Retrieval-Augmentation vs. Long Context in Language Models: Which Reigns Supreme and Can They Coexist?", "resolved_url": "https://www.marktechpost.com/2023/10/10/this-ai-paper-from-nvidia-explores-the-power-of-retrieval-augmentation-vs-long-context-in-language-models-which-reigns-supreme-and-can-they-coexist/", "excerpt": "In a comparative study, Researchers from Nvidia investigated the impact of retrieval augmentation and context window size on the performance of large language models (LLMs) in downstream tasks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "538", "lang": "en", "amp_url": "https://www.marktechpost.com/2023/10/10/this-ai-paper-from-nvidia-explores-the-power-of-retrieval-augmentation-vs-long-context-in-language-models-which-reigns-supreme-and-can-they-coexist/?amp", "top_image_url": "https://www.marktechpost.com/wp-content/uploads/2023/10/Screenshot-2023-10-10-at-5.55.31-PM.png", "tags": {"llms": {"item_id": "3948066239", "tag": "llms"}}, "authors": {"185440471": {"item_id": "3948066239", "author_id": "185440471", "name": "Adnan Hassan", "url": "https://www.marktechpost.com/author/adnanhassan_01/"}}, "image": {"item_id": "3948066239", "src": "https://www.marktechpost.com/wp-content/uploads/2023/10/Screenshot-2023-10-10-at-5.55.31-PM.png", "width": "696", "height": "290"}, "images": {"1": {"item_id": "3948066239", "image_id": "1", "src": "https://www.marktechpost.com/wp-content/uploads/2023/10/Screenshot-2023-10-10-at-5.55.31-PM.png", "width": "696", "height": "290", "credit": "", "caption": "https://arxiv.org/abs/2310.03025"}}, "listen_duration_estimate": 208}, "3999352205": {"item_id": "3999352205", "resolved_id": "3999352205", "given_url": "https://www.marktechpost.com/2024/01/25/meet-ragxplorer-an-interactive-ai-tool-to-support-the-building-of-retrieval-augmented-generation-rag-applications-by-visualizing-document-chunks-and-the-queries-in-the-embedding-space/", "given_title": "Meet RAGxplorer: An interactive AI Tool to Support the Building of Retrieva", "favorite": "0", "status": "1", "time_added": "1706236634", "time_updated": "1709250456", "time_read": "1709250456", "time_favorited": "0", "sort_id": 123, "resolved_title": "Meet RAGxplorer : An interactive AI Tool to Support the Building of Retrieval Augmented Generation (RAG) Applications by Visualizing Document Chunks and the Queries in the Embedding Space", "resolved_url": "https://www.marktechpost.com/2024/01/25/meet-ragxplorer-an-interactive-ai-tool-to-support-the-building-of-retrieval-augmented-generation-rag-applications-by-visualizing-document-chunks-and-the-queries-in-the-embedding-space/", "excerpt": "Understanding how well they comprehend and organize information is crucial in advanced language models. A common challenge arises in visualizing the intricate relationships between different document parts, especially when using complex models like the Retriever-Answer Generator (RAG).", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "432", "lang": "en", "amp_url": "https://www.marktechpost.com/2024/01/25/meet-ragxplorer-an-interactive-ai-tool-to-support-the-building-of-retrieval-augmented-generation-rag-applications-by-visualizing-document-chunks-and-the-queries-in-the-embedding-space/?amp", "top_image_url": "https://www.marktechpost.com/wp-content/uploads/2024/01/Screenshot-2024-01-25-at-3.55.05-PM.png", "tags": {"llms": {"item_id": "3999352205", "tag": "llms"}}, "authors": {"177644645": {"item_id": "3999352205", "author_id": "177644645", "name": "Niharika Singh", "url": "https://www.marktechpost.com/author/niharika98678/"}}, "image": {"item_id": "3999352205", "src": "https://www.marktechpost.com/wp-content/uploads/2024/01/Screenshot-2024-01-25-at-3.55.05-PM.png", "width": "696", "height": "397"}, "images": {"1": {"item_id": "3999352205", "image_id": "1", "src": "https://www.marktechpost.com/wp-content/uploads/2024/01/Screenshot-2024-01-25-at-3.55.05-PM.png", "width": "696", "height": "397", "credit": "", "caption": "https://github.com/gabrielchua/RAGxplorer"}}, "listen_duration_estimate": 167}, "4010563082": {"item_id": "4010563082", "resolved_id": "4010563082", "given_url": "https://www.marktechpost.com/2024/02/20/how-well-can-llms-negotiate-stanford-researchers-developed-negotiationarena-a-flexible-ai-framework-for-evaluating-and-probing-the-negotiation-abilities-of-llm-agents/", "given_title": "How Well Can LLMs Negotiate? Stanford Researchers Developed ‘NegotiationAre", "favorite": "0", "status": "1", "time_added": "1708443731", "time_updated": "1708443757", "time_read": "1708443757", "time_favorited": "0", "sort_id": 124, "resolved_title": "How Well Can LLMs Negotiate? Stanford Researchers Developed 'NegotiationArena' : A Flexible AI Framework for Evaluating and Probing the Negotiation Abilities of LLM Agents", "resolved_url": "https://www.marktechpost.com/2024/02/20/how-well-can-llms-negotiate-stanford-researchers-developed-negotiationarena-a-flexible-ai-framework-for-evaluating-and-probing-the-negotiation-abilities-of-llm-agents/", "excerpt": "In artificial intelligence, the capacity of Large Language Models (LLMs) to negotiate mirrors a leap toward achieving human-like interactions in digital negotiations.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "526", "lang": "en", "amp_url": "https://www.marktechpost.com/2024/02/20/how-well-can-llms-negotiate-stanford-researchers-developed-negotiationarena-a-flexible-ai-framework-for-evaluating-and-probing-the-negotiation-abilities-of-llm-agents/?amp", "top_image_url": "https://www.marktechpost.com/wp-content/uploads/2024/02/Screenshot-2024-02-20-at-6.06.54-AM.png", "tags": {"llms": {"item_id": "4010563082", "tag": "llms"}, "negotiation": {"item_id": "4010563082", "tag": "negotiation"}}, "authors": {"186984820": {"item_id": "4010563082", "author_id": "186984820", "name": "Muhammad Athar Ganaie", "url": "https://www.marktechpost.com/author/muhammad-athar-ganaie/"}}, "image": {"item_id": "4010563082", "src": "https://www.marktechpost.com/wp-content/uploads/2024/02/Screenshot-2024-02-20-at-6.06.54-AM.png", "width": "696", "height": "636"}, "images": {"1": {"item_id": "4010563082", "image_id": "1", "src": "https://www.marktechpost.com/wp-content/uploads/2024/02/Screenshot-2024-02-20-at-6.06.54-AM.png", "width": "696", "height": "636", "credit": "", "caption": "https://arxiv.org/abs/2402.05863"}}, "listen_duration_estimate": 204}, "3896213170": {"item_id": "3896213170", "resolved_id": "3896213170", "given_url": "https://www.mosaicml.com/blog/amd-mi250", "given_title": "Training LLMs with AMD MI250 GPUs and MosaicML", "favorite": "0", "status": "1", "time_added": "1688164042", "time_updated": "1690156787", "time_read": "1690156787", "time_favorited": "0", "sort_id": 125, "resolved_title": "Training LLMs with AMD MI250 GPUs and MosaicML", "resolved_url": "https://www.mosaicml.com/blog/amd-mi250", "excerpt": "At MosaicML, we’ve searched high and low for new ML training hardware on behalf of our customers. We do this to increase compute availability (as the world is in an NVIDIA supply crunch!), expand and educate the market, and ultimately reduce times and costs to train models.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2462", "lang": "", "top_image_url": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/649ed766a36f2026a15cfbad_Screenshot%202023-06-30%20at%209.23.45%20AM.png", "tags": {"llms": {"item_id": "3896213170", "tag": "llms"}}, "authors": {"183277770": {"item_id": "3896213170", "author_id": "183277770", "name": "Abhi Venigalla", "url": ""}}, "image": {"item_id": "3896213170", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/649ee9671fe7eb8177e302f3_Screenshot%202023-06-30%20at%2010.40.08%20AM.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3896213170", "image_id": "1", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/649ee9671fe7eb8177e302f3_Screenshot%202023-06-30%20at%2010.40.08%20AM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3896213170", "image_id": "2", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/649ed87c56977b29f1fcca5d_Screenshot%202023-06-30%20at%209.28.19%20AM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3896213170", "image_id": "3", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/649ed8caaf634d6f09c33bce_Screenshot%202023-06-30%20at%209.29.38%20AM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3896213170", "image_id": "4", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/649f22efda90a745c8606d48_Screenshot%202023-06-30%20at%202.45.46%20PM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3896213170", "image_id": "5", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/649f18c88715e3113695640f_Screenshot%202023-06-30%20at%202.02.26%20PM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3896213170", "image_id": "6", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/649ed9d18c6e79defe23523d_Screenshot%202023-06-30%20at%209.33.40%20AM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3896213170", "image_id": "7", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/649edb991698a5fffa6bc235_Screenshot%202023-06-30%20at%209.41.13%20AM.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 953}, "3891767351": {"item_id": "3891767351", "resolved_id": "3891767351", "given_url": "https://www.mosaicml.com/blog/mpt-30b", "given_title": "MPT-30B: Raising the bar for open-source foundation models", "favorite": "0", "status": "1", "time_added": "1687457249", "time_updated": "1690571810", "time_read": "1690571810", "time_favorited": "0", "sort_id": 126, "resolved_title": "MPT-30B: Raising the bar for open-source foundation models", "resolved_url": "https://www.mosaicml.com/blog/mpt-30b", "excerpt": "Since the launch of MPT-7B in May, the ML community has eagerly embraced open-source MosaicML Foundation Series models. The MPT-7B base, -Instruct, -Chat, and -StoryWriter models have collectively been downloaded over 3M times! We’ve been overwhelmed by what the community has built with  MPT-7B.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3149", "lang": "", "top_image_url": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/649299a07abed2b0fdeb591f_IMG_1587.jpg", "tags": {"llms": {"item_id": "3891767351", "tag": "llms"}}, "authors": {"181302851": {"item_id": "3891767351", "author_id": "181302851", "name": "The MosaicML NLP", "url": ""}}, "image": {"item_id": "3891767351", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/64944ad290de50c2de85c923_MPT-30B%20Tables%20-%20Data%20-%20Pretraining%20(2).png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3891767351", "image_id": "1", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/64944ad290de50c2de85c923_MPT-30B%20Tables%20-%20Data%20-%20Pretraining%20(2).png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3891767351", "image_id": "2", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/64944b05231136658cca0388_Screenshot%202023-06-22%20at%206.22.01%20AM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3891767351", "image_id": "3", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/649461607eb7256eea19cada_Screenshot%202023-06-22%20at%207.57.26%20AM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3891767351", "image_id": "4", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/649461a9d0716030570bac4d_Screenshot%202023-06-22%20at%207.58.37%20AM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3891767351", "image_id": "5", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/649467443579065495cc37d7_Screenshot%202023-06-22%20at%208.19.32%20AM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3891767351", "image_id": "6", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/64944d59e9581b2ac6410058_Screenshot%202023-06-22%20at%206.29.09%20AM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3891767351", "image_id": "7", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/64944db3811523a349608392_Frame%201%20(18).png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3891767351", "image_id": "8", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/64944e7692065baf735538b8_image.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3891767351", "image_id": "9", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/64944eee92065baf7355c98d_MPT%20Starter%20Edition%20Vertical%20Bars%20(1).png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3891767351", "image_id": "10", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/64945e92d7842ad7ce8d07f6_Enterprise%20Edition%20Inference.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3891767351", "image_id": "11", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/64944f8417dced4d628dd293_Screenshot%202023-06-22%20at%206.40.38%20AM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3891767351", "image_id": "12", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/649450cbceb618f0fa6438bb_Screenshot%202023-06-22%20at%206.45.46%20AM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3891767351", "image_id": "13", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/64945f85d708f2bf63cfb58c_MPT-30B%20Tables%20-%20Data%20-%208k%20Finetuning.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "3891767351", "image_id": "14", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/64945f2b27d3e9f8fb99191f_Screenshot%202023-06-22%20at%207.47.43%20AM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "3891767351", "image_id": "15", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/6494685d7ceeac7c32751803_Screenshot%202023-06-22%20at%208.27.12%20AM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "3891767351", "image_id": "16", "src": "https://assets-global.website-files.com/61fd4eb76a8d78bc0676b47d/649462391eee5b238cb04029_Screenshot%202023-06-22%20at%207.54.49%20AM.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1219}, "3943762213": {"item_id": "3943762213", "resolved_id": "3943762213", "given_url": "https://www.nngroup.com/articles/ai-bot-comparison/", "given_title": "ChatGPT, Bard, or Bing Chat? Differences Among 3 Generative-AI Bots", "favorite": "1", "status": "1", "time_added": "1696189277", "time_updated": "1706456139", "time_read": "1696362360", "time_favorited": "1696280386", "sort_id": 127, "resolved_title": "ChatGPT, Bard, or Bing Chat? Differences Among 3 Generative-AI Bots", "resolved_url": "https://www.nngroup.com/articles/ai-bot-comparison/", "excerpt": "Summary: Participants rated Bing Chat as less helpful and trustworthy than ChatGPT or Bard. These results can be attributed to Bing’s richer yet imperfect UI and to its poorer information aggregation.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "4507", "lang": "en", "time_to_read": 20, "top_image_url": "https://media.nngroup.com/media/articles/opengraph_images/AI-Bots_social-33.png", "tags": {"chatbots": {"item_id": "3943762213", "tag": "chatbots"}, "generative": {"item_id": "3943762213", "tag": "generative"}, "llms": {"item_id": "3943762213", "tag": "llms"}}, "authors": {"123726195": {"item_id": "3943762213", "author_id": "123726195", "name": "Feifei Liu", "url": ""}}, "image": {"item_id": "3943762213", "src": "https://media.nngroup.com/media/editor/2023/09/28/chatgpt_interface.jpg", "width": "700", "height": "719"}, "images": {"1": {"item_id": "3943762213", "image_id": "1", "src": "https://media.nngroup.com/media/editor/2023/09/28/chatgpt_interface.jpg", "width": "700", "height": "719", "credit": "thumbs up or down", "caption": "ChatGPT: The interface available at the time of the diary study included buttons for regenerating responses, a quick binary-rating system"}, "2": {"item_id": "3943762213", "image_id": "2", "src": "https://media.nngroup.com/media/editor/2023/09/28/bard_interface.jpg", "width": "700", "height": "355", "credit": "", "caption": "Bard: The interface was fairly similar to ChatGPT's. However, Bard did not allow access to the complete text of the past conversations."}, "3": {"item_id": "3943762213", "image_id": "3", "src": "https://media.nngroup.com/media/editor/2023/09/28/bardimage-cropped.jpg", "width": "346", "height": "443", "credit": "", "caption": "Bard: Some Bard answers included images and links. The links were placed at the top right of the images in a tag format and usually pointed to product or site recommendations mentioned in the answer."}, "4": {"item_id": "3943762213", "image_id": "4", "src": "https://media.nngroup.com/media/editor/2023/09/28/bingchat_interface.jpg", "width": "1384", "height": "879", "credit": "in-text, as links, and also as footnotes, listed in the Learn more section", "caption": "Bing Chat: Bing Chat’s interface elements at the time of the study included references"}, "5": {"item_id": "3943762213", "image_id": "5", "src": "https://media.nngroup.com/media/editor/2023/09/28/bing-ads.png", "width": "700", "height": "608", "credit": "", "caption": "Bing Chat: Bing Chat’s responses could contain images and videos, as well as ads."}, "6": {"item_id": "3943762213", "image_id": "6", "src": "https://media.nngroup.com/media/editor/2023/09/28/chatbot-comparison_graph2.jpg", "width": "700", "height": "578", "credit": "", "caption": "Bing Chat had significantly lower helpfulness and trustworthiness scores than Bard and ChatGPT. "}, "7": {"item_id": "3943762213", "image_id": "7", "src": "https://media.nngroup.com/media/editor/2023/09/28/bingchat_chainsaw.jpg", "width": "700", "height": "467", "credit": "", "caption": "One participant complained about the too little detail provided by Bing Chat in response to the prompt I want to buy a chainsaw."}, "8": {"item_id": "3943762213", "image_id": "8", "src": "https://media.nngroup.com/media/editor/2023/09/28/bing_steak_littleaggregation-combined.jpg", "width": "700", "height": "707", "credit": "top", "caption": "One participant was unsatisfied with the information provided by Bing Chat in response to the question what is the best way to cook a steak"}, "9": {"item_id": "3943762213", "image_id": "9", "src": "https://media.nngroup.com/media/editor/2023/09/28/bard_treadingwater.jpg", "width": "700", "height": "1319", "credit": "The screenshot was taken from the extension MyChatGPT, which study participants used to share the conversations with us; the interface might look different from the actual Bard interface.", "caption": "Bard provided a detailed answer to the question the best ways to tread water, with detailed instructions and illustrations on each technique."}, "10": {"item_id": "3943762213", "image_id": "10", "src": "https://media.nngroup.com/media/editor/2023/09/28/chatbot-comparison_graph.jpg", "width": "700", "height": "578", "credit": "", "caption": "Bing Chat’s UI was used significantly more than the UI of the other chatbots."}, "11": {"item_id": "3943762213", "image_id": "11", "src": "https://media.nngroup.com/media/editor/2023/09/28/bingchat_irrevelantsources.jpg", "width": "700", "height": "428", "credit": "", "caption": "A US participant did not like that the first source listed by Bing Chat was Canadian, since healthcare standards or policies may differ across countries."}, "12": {"item_id": "3943762213", "image_id": "12", "src": "https://media.nngroup.com/media/editor/2023/09/28/bingchat_linkswithanswers_both.png", "width": "700", "height": "397", "credit": "marked in purple", "caption": "Aside from references, Bing Chat’s answers could include links"}, "13": {"item_id": "3943762213", "image_id": "13", "src": "https://media.nngroup.com/media/editor/2023/09/28/bingchat_inaccurateresults.jpg", "width": "692", "height": "618", "credit": "left", "caption": "One participant was looking for events in Nashville on a Friday night. The bot failed to provide any helpful information other than a few links at first"}, "14": {"item_id": "3943762213", "image_id": "14", "src": "https://media.nngroup.com/media/editor/2023/09/28/bingchat_followup.jpg", "width": "350", "height": "631", "credit": "", "caption": "A particularly helpful followup question involves shortening an already provided answer."}, "15": {"item_id": "3943762213", "image_id": "15", "src": "https://media.nngroup.com/media/editor/2023/09/28/bingchat_servevolleyball.jpg", "width": "700", "height": "470", "credit": "", "caption": "When short videos were present to help visualize instructions about a specific process, people generally found them helpful."}, "16": {"item_id": "3943762213", "image_id": "16", "src": "https://media.nngroup.com/media/editor/2023/09/28/bingchat_multiplevideos.jpg", "width": "700", "height": "399", "credit": "", "caption": "Bing Chat sometimes displayed a video panel below its answer but failed to provide any information about these videos other than their names."}, "17": {"item_id": "3943762213", "image_id": "17", "src": "https://media.nngroup.com/media/editor/2023/09/28/google-camtasia.png", "width": "700", "height": "594", "credit": "", "caption": "A Google search-results page includes video featured snippet, showing an excerpt of the video transcript to help users decide if that video is relevant."}, "18": {"item_id": "3943762213", "image_id": "18", "src": "https://media.nngroup.com/media/editor/2023/09/28/bingchat-wrongsizemobile.jpg", "width": "350", "height": "717", "credit": "", "caption": "A flight detail and price widget didn’t size proportionally to the mobile screen when a participant searched for the cheapest flight from Nashville to Flagstaff."}, "19": {"item_id": "3943762213", "image_id": "19", "src": "https://media.nngroup.com/media/editor/2023/09/28/bingchat-losecontext.jpg", "width": "359", "height": "639", "credit": "Note also that the broom button for a new conversation was very close to the input box and easy to touch by mistake.", "caption": "A Bing participant meant to copy and paste some text in the prompt box but accidentally submitted the query too soon and had to resubmit the query. In this case, Bing remembered the bigger conversation contexts, but in other situations it would assume a new conversation was started."}, "20": {"item_id": "3943762213", "image_id": "20", "src": "https://media.nngroup.com/media/editor/2023/09/28/bingchat_bullettraintickets.jpg", "width": "700", "height": "591", "credit": "", "caption": "Participants were fine with ads if they were highly relevant to their queries."}, "21": {"item_id": "3943762213", "image_id": "21", "src": "https://media.nngroup.com/media/editor/2023/09/28/bingchat_irrelevantads.jpg", "width": "700", "height": "450", "credit": "", "caption": "An irrelevant ad panel about clutch kits was placed below the answer to the participant’s question about the website Clutch, a service for finding web-related agencies."}}, "videos": {"1": {"item_id": "3943762213", "video_id": "1", "src": "https://media.nngroup.com/media/editor/2023/09/28/bingchat_multiplefollowups_compressed.mp4", "width": "692", "height": "0", "type": "5", "vid": "", "length": "0"}}, "listen_duration_estimate": 1745}, "3840267465": {"item_id": "3840267465", "resolved_id": "3840267465", "given_url": "https://www.nvidia.com/en-us/lp/ai-data-science/large-language-models-ebook/", "given_title": "New Ebook: A Beginner’s Guide to Large Language Models", "favorite": "0", "status": "1", "time_added": "1680721352", "time_updated": "1681439189", "time_read": "1681439189", "time_favorited": "0", "sort_id": 128, "resolved_title": "An Enterprise Guide to Large Language Models", "resolved_url": "https://www.nvidia.com/en-us/lp/ai-data-science/large-language-models-ebook/", "excerpt": "What Are Large Language Models and How Do They Work? Learn about the evolution of LLMs, the role of foundation models, and how the underlying technologies have come together to unlock the power of LLMs for the enterprise.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "38", "lang": "en", "top_image_url": "https://www.nvidia.com/content/dam/en-zz/Solutions/lp/large-language-models-ebook/nvidia-llm-ebook-og.jpg", "tags": {"deep-learning": {"item_id": "3840267465", "tag": "deep-learning"}, "llms": {"item_id": "3840267465", "tag": "llms"}}, "listen_duration_estimate": 15}, "3843863413": {"item_id": "3843863413", "resolved_id": "3843863413", "given_url": "https://www.ruxu.dev/articles/ai/maximizing-the-potential-of-llms/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1681222742", "time_updated": "1681426305", "time_read": "1681426305", "time_favorited": "0", "sort_id": 129, "resolved_title": "Maximizing the Potential of LLMs: A Guide to Prompt Engineering", "resolved_url": "https://ruxu.dev/articles/ai/maximizing-the-potential-of-llms/", "excerpt": "Language models have rapidly improved in recent years, with large language models (LLMs) such as GPT-3 and GPT-4 taking center stage. These models have become popular due to their ability to perform a great variety of tasks with incredible skill.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2541", "lang": "en", "time_to_read": 12, "top_image_url": "https://ruxu.devassets/images/openai.png", "tags": {"llms": {"item_id": "3843863413", "tag": "llms"}, "prompt-engineering": {"item_id": "3843863413", "tag": "prompt-engineering"}}, "image": {"item_id": "3843863413", "src": "https://www.ruxu.dev/articles/ai/maximizing-the-potential-of-llms/assets/images/openai.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3843863413", "image_id": "1", "src": "https://www.ruxu.dev/articles/ai/maximizing-the-potential-of-llms/assets/images/openai.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 984}, "3944181268": {"item_id": "3944181268", "resolved_id": "3944181268", "given_url": "https://www.scientificamerican.com/podcast/episode/the-state-of-large-language-models/", "given_title": "The State of Large Language Models", "favorite": "0", "status": "1", "time_added": "1696275379", "time_updated": "1696294145", "time_read": "1696294145", "time_favorited": "0", "sort_id": 130, "resolved_title": "The State of Large Language Models", "resolved_url": "https://www.scientificamerican.com/podcast/episode/the-state-of-large-language-models/", "excerpt": "We present the latest updates on ChatGPT, Bard and other competitors in the artificial intelligence arms race. Sophie Bushwick is an associate editor covering technology at Scientific American. Follow her on Twitter @sophiebushwick", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "64", "lang": "en", "top_image_url": "https://static.scientificamerican.com/sciam/cache/file/48E0C0D2-E023-4F16-BE1A7D26DC05AF36.gif", "tags": {"llms": {"item_id": "3944181268", "tag": "llms"}}, "authors": {"63956191": {"item_id": "3944181268", "author_id": "63956191", "name": "Sophie Bushwick", "url": "https://www.scientificamerican.com/author/sophie-bushwick/"}}, "image": {"item_id": "3944181268", "src": "https://static.scientificamerican.com/sciam/cache/file/D74DE7B2-FEEB-4EF8-AC8594150C942597_small.jpg?h=65&w=65", "width": "65", "height": "65"}, "images": {"1": {"item_id": "3944181268", "image_id": "1", "src": "https://static.scientificamerican.com/sciam/cache/file/D74DE7B2-FEEB-4EF8-AC8594150C942597_small.jpg?h=65&w=65", "width": "65", "height": "65", "credit": "Nick Higgins", "caption": ""}}, "domain_metadata": {"name": "Scientific American", "logo": "https://logo.clearbit.com/scientificamerican.com?size=800", "greyscale_logo": "https://logo.clearbit.com/scientificamerican.com?size=800&greyscale=true"}, "listen_duration_estimate": 25}, "4011090301": {"item_id": "4011090301", "resolved_id": "4011090301", "given_url": "https://www.semianalysis.com/p/groq-inference-tokenomics-speed-but", "given_title": "Groq Inference Tokenomics: Speed, But At What Cost?", "favorite": "0", "status": "1", "time_added": "1708532322", "time_updated": "1708566367", "time_read": "1708566367", "time_favorited": "0", "sort_id": 131, "resolved_title": "Groq Inference Tokenomics: Speed, But At What Cost?", "resolved_url": "https://www.semianalysis.com/p/groq-inference-tokenomics-speed-but", "excerpt": "Groq, an AI hardware startup, has been making the rounds recently because of their extremely impressive demos showcasing the leading open-source model, Mistral Mixtral 8x7b on their inference API.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1647", "lang": "en", "time_to_read": 7, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4aad86a5-7fda-444f-9179-7912e9196547_2156x1100.png", "tags": {"inference": {"item_id": "4011090301", "tag": "inference"}, "llms": {"item_id": "4011090301", "tag": "llms"}, "semiconductors": {"item_id": "4011090301", "tag": "semiconductors"}}, "authors": {"185369951": {"item_id": "4011090301", "author_id": "185369951", "name": "Daniel Nishball", "url": "https://substack.com/profile/160965795-daniel-nishball"}}, "image": {"item_id": "4011090301", "src": "https://substackcdn.com/image/fetch/w_474,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffea52d37-f371-4feb-b6e4-16897425def7_2072x1040.png", "width": "474", "height": "0"}, "images": {"1": {"item_id": "4011090301", "image_id": "1", "src": "https://substackcdn.com/image/fetch/w_474,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffea52d37-f371-4feb-b6e4-16897425def7_2072x1040.png", "width": "474", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "4011090301", "image_id": "2", "src": "https://substackcdn.com/image/fetch/w_474,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe784c52f-6ea5-4832-a718-93b8643cc5f1_2116x1020.png", "width": "474", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "4011090301", "image_id": "3", "src": "https://substackcdn.com/image/fetch/w_474,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2aca79a1-1f57-47b1-83a2-44425b3165b2_2156x1100.png", "width": "474", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 638}, "3610149901": {"item_id": "3610149901", "resolved_id": "3610149901", "given_url": "https://www.technologyreview.com/2022/05/03/1051691/meta-ai-large-language-model-gpt3-ethics-huggingface-transparency/", "given_title": "Meta has built a massive new language AI—and it’s giving it away for free", "favorite": "0", "status": "1", "time_added": "1681069729", "time_updated": "1682120651", "time_read": "1682120651", "time_favorited": "0", "sort_id": 132, "resolved_title": "Meta has built a massive new language AI—and it’s giving it away for free", "resolved_url": "https://www.technologyreview.com/2022/05/03/1051691/meta-ai-large-language-model-gpt3-ethics-huggingface-transparency/", "excerpt": "Meta’s AI lab has created a massive new language model that shares both the remarkable abilities and the harmful flaws of OpenAI’s pioneering neural network GPT-3.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1198", "lang": "en", "time_to_read": 5, "amp_url": "https://www.technologyreview.com/2022/05/03/1051691/meta-ai-large-language-model-gpt3-ethics-huggingface-transparency/amp/", "top_image_url": "https://wp.technologyreview.com/wp-content/uploads/2022/05/tiles2-1.jpeg?resize=1200,600", "tags": {"llms": {"item_id": "3610149901", "tag": "llms"}, "transformers": {"item_id": "3610149901", "tag": "transformers"}}, "authors": {"25561932": {"item_id": "3610149901", "author_id": "25561932", "name": "Will Douglas Heaven", "url": ""}}, "image": {"item_id": "3610149901", "src": "https://wp.technologyreview.com/wp-content/uploads/2022/05/tiles2-1.jpeg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3610149901", "image_id": "1", "src": "https://wp.technologyreview.com/wp-content/uploads/2022/05/tiles2-1.jpeg", "width": "0", "height": "0", "credit": "Ms Tech | Unsplash", "caption": ""}, "2": {"item_id": "3610149901", "image_id": "2", "src": "https://wp.technologyreview.com/wp-content/uploads/2020/11/newsletter-preferences-sm.png", "width": "0", "height": "0", "credit": "Illustration  Rose Wong", "caption": "Illustration by Rose Wong"}}, "domain_metadata": {"name": "MIT Technology Review", "logo": "https://logo.clearbit.com/technologyreview.com?size=800", "greyscale_logo": "https://logo.clearbit.com/technologyreview.com?size=800&greyscale=true"}, "listen_duration_estimate": 464}, "3907678011": {"item_id": "3907678011", "resolved_id": "3904767388", "given_url": "https://www.thediff.co/r/a2af7311?m=5ba63d9b-6620-4051-8686-515cd8a8f374", "given_title": "The $1 billion gamble to ensure AI doesn’t destroy humanity", "favorite": "1", "status": "1", "time_added": "1690056269", "time_updated": "1690067590", "time_read": "1690067590", "time_favorited": "1690067590", "sort_id": 133, "resolved_title": "The $1 billion gamble to ensure AI doesn’t destroy humanity", "resolved_url": "https://www.vox.com/future-perfect/23794855/anthropic-ai-openai-claude-2", "excerpt": "The founders of Anthropic quit OpenAI to make a safe AI company. It’s easier said than done. The scientists want the AI to lie to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "6104", "lang": "en", "time_to_read": 28, "top_image_url": "https://cdn.vox-cdn.com/thumbor/PMO5NtFcDVf9JdEllg9NGtnDS5o=/0x47:2400x1304/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/24788204/Vox_Anthropic_final.jpg", "tags": {"llms": {"item_id": "3907678011", "tag": "llms"}}, "authors": {"173555598": {"item_id": "3907678011", "author_id": "173555598", "name": "Dylan Matthews", "url": "https://www.vox.com/authors/dylan-matthews"}}, "image": {"item_id": "3907678011", "src": "https://cdn.vox-cdn.com/thumbor/Luxhui1JYC1tkllnHEs1EDT_XTs=/0x0:2400x1350/1200x675/filters:focal(1008x483:1392x867)/cdn.vox-cdn.com/uploads/chorus_image/image/72457793/Vox_Anthropic_final.0.jpg", "width": "2400", "height": "1350"}, "images": {"1": {"item_id": "3907678011", "image_id": "1", "src": "https://cdn.vox-cdn.com/thumbor/Luxhui1JYC1tkllnHEs1EDT_XTs=/0x0:2400x1350/1200x675/filters:focal(1008x483:1392x867)/cdn.vox-cdn.com/uploads/chorus_image/image/72457793/Vox_Anthropic_final.0.jpg", "width": "2400", "height": "1350", "credit": "Ariel Davis for Vox", "caption": ""}, "2": {"item_id": "3907678011", "image_id": "2", "src": "https://cdn.vox-cdn.com/thumbor/w5URkJ6-NEIFROoJVU3mffnaYQU=/0x0:1280x720/1200x0/filters:focal(0x0:1280x720):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/24788213/maxresdefault.jpg", "width": "1280", "height": "720", "credit": "", "caption": ""}, "3": {"item_id": "3907678011", "image_id": "3", "src": "https://cdn.vox-cdn.com/thumbor/MIgprZMO42rEAfeWcXevIPa1IUc=/0x0:3350x2234/1200x0/filters:focal(0x0:3350x2234):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/24788261/AP23124575277305.jpg", "width": "3350", "height": "2234", "credit": "", "caption": ""}, "4": {"item_id": "3907678011", "image_id": "4", "src": "https://cdn.vox-cdn.com/uploads/chorus_asset/file/22734206/paypal_logo.png", "width": "136", "height": "42", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Vox", "logo": "https://logo.clearbit.com/vox.com?size=800", "greyscale_logo": "https://logo.clearbit.com/vox.com?size=800&greyscale=true"}, "listen_duration_estimate": 2363}, "3944747073": {"item_id": "3944747073", "resolved_id": "3944747073", "given_url": "https://www.tomtunguz.com/easy-feedback-ml-bard/", "given_title": "SaaS Competitive Advantage Through Elegant LLM Feedback Mechanisms", "favorite": "0", "status": "1", "time_added": "1696359975", "time_updated": "1696381987", "time_read": "1696381987", "time_favorited": "0", "sort_id": 134, "resolved_title": "SaaS Competitive Advantage Through Elegant LLM Feedback Mechanisms", "resolved_url": "https://www.tomtunguz.com/easy-feedback-ml-bard/", "excerpt": "Eliciting product feedback elegantly is a competitive advantage for LLM-software. Over the weekend, I queried Google’s Bard, & noticed the elegant feedback loop the product team has incorporated into their product.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "192", "lang": "en", "tags": {"ideas": {"item_id": "3944747073", "tag": "ideas"}, "llms": {"item_id": "3944747073", "tag": "llms"}, "prodmgmt": {"item_id": "3944747073", "tag": "prodmgmt"}}, "image": {"item_id": "3944747073", "src": "https://res.cloudinary.com/dzawgnnlr/image/upload/smao9huamftyh3abtoao.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3944747073", "image_id": "1", "src": "https://res.cloudinary.com/dzawgnnlr/image/upload/smao9huamftyh3abtoao.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3944747073", "image_id": "2", "src": "https://res.cloudinary.com/dzawgnnlr/image/upload/jsmaz1feupmctopagvuq.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3944747073", "image_id": "3", "src": "https://res.cloudinary.com/dzawgnnlr/image/upload/ilzrwhpupayocaors5en.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3944747073", "image_id": "4", "src": "https://res.cloudinary.com/dzawgnnlr/image/upload/vza4mdor0wtneswxqb2r.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 74}, "3914330578": {"item_id": "3914330578", "resolved_id": "3914330578", "given_url": "https://www.turingpost.com/p/practicalllms", "given_title": "How to Leverage Open-Source LLMs in Your Project", "favorite": "0", "status": "1", "time_added": "1691151831", "time_updated": "1691365622", "time_read": "1691365622", "time_favorited": "0", "sort_id": 135, "resolved_title": "How to Leverage Open-Source LLMs in Your Project", "resolved_url": "https://www.turingpost.com/p/practicalllms", "excerpt": "In the previous deep dive, we explored the leading open-source LLM models: LLaMA, Falcon, Llama 2, and their chatbot counterparts: Falcon-40B-Instruct, Llama 2-Chat, and FreeWilly 2. Now, the question is: how can you integrate these impressive models into your projects?", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "294", "lang": "en", "top_image_url": "https://beehiiv-images-production.s3.amazonaws.com/uploads/asset/file/dcdb6688-78cb-4270-9260-f56572e5c41f/kseniase_computer_scientist_working_on_a_modern_computer_real_l_d3921681-e75d-4b0b-a469-1d2f250afb70.png", "tags": {"llms": {"item_id": "3914330578", "tag": "llms"}}, "authors": {"183638027": {"item_id": "3914330578", "author_id": "183638027", "name": "Valeriia Kuka", "url": "https://www.turingpost.com/authors/f8f27bbe-6e7e-47fe-8a77-dce74efc6f5f"}}, "image": {"item_id": "3914330578", "src": "https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/dcdb6688-78cb-4270-9260-f56572e5c41f/kseniase_computer_scientist_working_on_a_modern_computer_real_l_d3921681-e75d-4b0b-a469-1d2f250afb70.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3914330578", "image_id": "1", "src": "https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/dcdb6688-78cb-4270-9260-f56572e5c41f/kseniase_computer_scientist_working_on_a_modern_computer_real_l_d3921681-e75d-4b0b-a469-1d2f250afb70.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 114}, "3910654438": {"item_id": "3910654438", "resolved_id": "3910654438", "given_url": "https://www.turingpost.com/p/top3llmsope", "given_title": "A Deep Dive Into LLaMA, Falcon, Llama 2 and Their Remarkable Fine-Tuned Ver", "favorite": "0", "status": "1", "time_added": "1690544264", "time_updated": "1690571807", "time_read": "1690571807", "time_favorited": "0", "sort_id": 136, "resolved_title": "A Deep Dive Into LLaMA, Falcon, Llama 2 and Their Remarkable Fine-Tuned Versions", "resolved_url": "https://www.turingpost.com/p/top3llmsope", "excerpt": "In February 2023, Meta AI introduced the LLaMA (Large Language Model Meta AI) series of models, but access was restricted to a select group of researchers from academia, government, civil society, and industry laboratories.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1366", "lang": "en", "time_to_read": 6, "top_image_url": "https://beehiiv-images-production.s3.amazonaws.com/uploads/asset/file/620e77de-767c-48eb-9495-27e4446fcf3f/kseniase_modern_computer_with_code_window_opened_volumetric_lig_a22de1de-afaf-41b3-a4c9-75d454834e5f.png", "tags": {"benchmarks": {"item_id": "3910654438", "tag": "benchmarks"}, "chatbots": {"item_id": "3910654438", "tag": "chatbots"}, "llms": {"item_id": "3910654438", "tag": "llms"}}, "authors": {"183638027": {"item_id": "3910654438", "author_id": "183638027", "name": "Valeriia Kuka", "url": "https://www.turingpost.com/authors/f8f27bbe-6e7e-47fe-8a77-dce74efc6f5f"}}, "image": {"item_id": "3910654438", "src": "https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/4d650a2e-0276-4df7-a7c0-f56c1dcaf50c/Screen_Shot_2023-07-26_at_16.37.52.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3910654438", "image_id": "1", "src": "https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/4d650a2e-0276-4df7-a7c0-f56c1dcaf50c/Screen_Shot_2023-07-26_at_16.37.52.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 529}, "3933511500": {"item_id": "3933511500", "resolved_id": "3930473807", "given_url": "https://www.wired.com/story/what-openai-really-wants/?utm_source=pocket_reader", "given_title": "What OpenAI Really Wants", "favorite": "0", "status": "1", "time_added": "1694432734", "time_updated": "1706652652", "time_read": "1694988827", "time_favorited": "0", "sort_id": 137, "resolved_title": "What OpenAI Really Wants", "resolved_url": "https://www.wired.com/story/what-openai-really-wants/", "excerpt": "The air crackles with an almost Beatlemaniac energy as the star and his entourage tumble into a waiting Mercedes van. They’ve just ducked out of one event and are headed to another, then another, where a frenzied mob awaits.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "9451", "lang": "en", "time_to_read": 43, "top_image_url": "https://media.wired.com/photos/64ed0bc52da6c6d86e70e575/191:100/w_1280,c_limit/WI100123_FF_OpenAI_01.jpg", "tags": {"llms": {"item_id": "3933511500", "tag": "llms"}}, "authors": {"69592376": {"item_id": "3933511500", "author_id": "69592376", "name": "Steven Levy", "url": "https://www.wired.com/author/steven-levy"}}, "image": {"item_id": "3933511500", "src": "https://media.wired.com/photos/64ed0bc52da6c6d86e70e575/master/w_2560%2Cc_limit/WI100123_FF_OpenAI_01.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3933511500", "image_id": "1", "src": "https://media.wired.com/photos/64ed0bc52da6c6d86e70e575/master/w_2560%2Cc_limit/WI100123_FF_OpenAI_01.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3933511500", "image_id": "2", "src": "https://media.wired.com/photos/64f75d8219dd7a7b51b87e00/master/w_1600%2Cc_limit/WIRED_3110_white%2520shadow.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3933511500", "image_id": "3", "src": "https://media.wired.com/photos/64f78076c3986cb07d5a6b34/master/w_1600%2Cc_limit/WI100123_FF_OpenAI_03-web.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3933511500", "image_id": "4", "src": "https://media.wired.com/photos/64ed0ee6459738d8def33415/master/w_1600%2Cc_limit/WI100123_FF_OpenAI_04.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3933511500", "image_id": "5", "src": "https://media.wired.com/photos/64ed0fb11abb6e03bbf80cd4/master/w_1600%2Cc_limit/WI100123_FF_OpenAI_05.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3933511500", "image_id": "6", "src": "https://media.wired.com/photos/64ed109729c860a2e660cbb3/master/w_1600%2Cc_limit/WI100123_FF_OpenAI_06.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3933511500", "image_id": "7", "src": "https://media.wired.com/photos/64ed10adef79238a96952a01/master/w_1600%2Cc_limit/WI100123_FF_OpenAI_07.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "WIRED", "logo": "https://logo.clearbit.com/wired.com?size=800", "greyscale_logo": "https://logo.clearbit.com/wired.com?size=800&greyscale=true"}, "listen_duration_estimate": 3658}}, "error": nil, "search_meta": {"search_type": "normal"}, "since": 1709419445}