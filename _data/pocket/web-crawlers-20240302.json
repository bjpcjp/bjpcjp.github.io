{"status": 1, "complete": 1, "list": {"1667511506": {"item_id": "1667511506", "resolved_id": "1667511506", "given_url": "http://www.practicalecommerce.com/articles/135667-SEO-How-to-Part-9-Diagnosing-Crawler-Issues", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638225234", "time_updated": "1691368623", "time_read": "1656444470", "time_favorited": "0", "sort_id": 0, "resolved_title": "SEO How-to, Part 9: Diagnosing Crawler Issues", "resolved_url": "http://www.practicalecommerce.com/articles/135667-SEO-How-to-Part-9-Diagnosing-Crawler-Issues", "excerpt": "Editor’s note: This post continues our weekly primer in SEO, touching on all the foundational aspects. In the end, you’ll be able to practice SEO more confidently and converse about its challenges and opportunities.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1151", "lang": "en", "time_to_read": 5, "top_image_url": "http://www.practicalecommerce.com/wp-content/uploads/2017/03/SEO-How-to-Part-9-Diagnosing-Crawler-Issues-100x100.jpg", "tags": {"keywords-ppc-seo": {"item_id": "1667511506", "tag": "keywords-ppc-seo"}, "web-crawlers": {"item_id": "1667511506", "tag": "web-crawlers"}}, "authors": {"11018722": {"item_id": "1667511506", "author_id": "11018722", "name": "Bio", "url": "http://www.practicalecommerce.com/author/jill-kocher/"}, "11018723": {"item_id": "1667511506", "author_id": "11018723", "name": "RSS Feed", "url": "http://www.practicalecommerce.com/author/jill-kocher/feed/"}}, "listen_duration_estimate": 446}, "4004207241": {"item_id": "4004207241", "resolved_id": "4004207241", "given_url": "https://foundation.mozilla.org/en/research/library/generative-ai-training-data/common-crawl/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1707335673", "time_updated": "1707528938", "time_read": "1707528938", "time_favorited": "0", "sort_id": 1, "resolved_title": "", "resolved_url": "https://foundation.mozilla.org/en/research/library/generative-ai-training-data/common-crawl/", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"web-crawlers": {"item_id": "4004207241", "tag": "web-crawlers"}}, "listen_duration_estimate": 0}, "3194426382": {"item_id": "3194426382", "resolved_id": "3194426382", "given_url": "https://github.com/ArchiveBox/ArchiveBox/wiki/Usage#Import-list-of-links-from-browser-history", "given_title": "Usage · ArchiveBox/ArchiveBox Wiki · GitHub", "favorite": "0", "status": "1", "time_added": "1656020226", "time_updated": "1706833159", "time_read": "1656026013", "time_favorited": "0", "sort_id": 2, "resolved_title": "Usage", "resolved_url": "https://github.com/ArchiveBox/ArchiveBox/wiki/Usage#Import-a-list-of-URLs-from-a-text-file", "excerpt": "Usage Usage CLI Usage: Docs and examples for the ArchiveBox command line interface. UI Usage: Docs and screenshots for the outputted HTML archive interface. Disk Layout: Description of the archive folder structure and contents.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "146", "lang": "en", "top_image_url": "https://repository-images.githubusercontent.com/90356372/6ce4d400-6129-11e9-9898-707bd6d5df76", "tags": {"browsers": {"item_id": "3194426382", "tag": "browsers"}, "programming": {"item_id": "3194426382", "tag": "programming"}, "python": {"item_id": "3194426382", "tag": "python"}, "web-crawlers": {"item_id": "3194426382", "tag": "web-crawlers"}}, "image": {"item_id": "3194426382", "src": "https://camo.githubusercontent.com/5a26c1ed205bb3ad02a0c179d9f8e193d38cc39bcacffc34ac84b6966562ef23/68747470733a2f2f692e696d6775722e636f6d2f50564f3838415a2e706e67", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3194426382", "image_id": "1", "src": "https://camo.githubusercontent.com/5a26c1ed205bb3ad02a0c179d9f8e193d38cc39bcacffc34ac84b6966562ef23/68747470733a2f2f692e696d6775722e636f6d2f50564f3838415a2e706e67", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3194426382", "image_id": "2", "src": "https://camo.githubusercontent.com/b00cf1d8c2d3f8737c941b342f86a1b08963ab8701e16856812993dc6a8f6417/68747470733a2f2f692e696d6775722e636f6d2f346e6b466a64762e706e67", "width": "0", "height": "30", "credit": "", "caption": ""}, "3": {"item_id": "3194426382", "image_id": "3", "src": "https://camo.githubusercontent.com/90bc908826728c0e4261acfff5619fd732c7be2b2a00624fce6363c9a3623c90/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f75726c2f687474702f736869656c64732e696f2e7376673f7374796c653d736f6369616c", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3194426382", "image_id": "4", "src": "https://camo.githubusercontent.com/2207dd0a5bc5bd9c5c5da2227eb5ebbb1cc78c06ac9d80c986f38fb0a068da51/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f537570706f7274253230646576656c6f706d656e742d50617472656f6e2d2532334444354437362e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3194426382", "image_id": "5", "src": "https://camo.githubusercontent.com/f96ddf989704970baff9f608dd5be65295cfaf70f010820deac91568d3612938/68747470733a2f2f692e696d6775722e636f6d2f38793668765a612e706e67", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 57}, "3739671437": {"item_id": "3739671437", "resolved_id": "3739671437", "given_url": "https://jvns.ca/blog/2022/11/06/making-a-dns-query-in-ruby-from-scratch/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1667825815", "time_updated": "1691368623", "time_read": "1667862877", "time_favorited": "0", "sort_id": 3, "resolved_title": "Making a DNS query in Ruby from scratch", "resolved_url": "https://jvns.ca/blog/2022/11/06/making-a-dns-query-in-ruby-from-scratch/", "excerpt": "Hello! A while back I wrote a post about how to write a toy DNS resolver in Go.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "2808", "lang": "en", "time_to_read": 13, "tags": {"dns": {"item_id": "3739671437", "tag": "dns"}, "ruby": {"item_id": "3739671437", "tag": "ruby"}, "web-crawlers": {"item_id": "3739671437", "tag": "web-crawlers"}, "webdev": {"item_id": "3739671437", "tag": "webdev"}}, "authors": {"5751812": {"item_id": "3739671437", "author_id": "5751812", "name": "Julia Evans", "url": ""}}, "listen_duration_estimate": 1087}, "205374511": {"item_id": "205374511", "resolved_id": "205374511", "given_url": "https://michaelnielsen.org/ddi/how-to-crawl-a-quarter-billion-webpages-in-40-hours/", "given_title": "How to crawl a quarter billion webpages in 40 hours", "favorite": "0", "status": "1", "time_added": "1686826154", "time_updated": "1690158941", "time_read": "1690158941", "time_favorited": "0", "sort_id": 4, "resolved_title": "How to crawl a quarter billion webpages in 40 hours", "resolved_url": "https://michaelnielsen.org/ddi/how-to-crawl-a-quarter-billion-webpages-in-40-hours/", "excerpt": "More precisely, I crawled 250,113,669 pages for just under 580 dollars in 39 hours and 25 minutes, using 20 Amazon EC2 machine instances.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4231", "lang": "en", "time_to_read": 19, "tags": {"web-crawlers": {"item_id": "205374511", "tag": "web-crawlers"}, "webdev": {"item_id": "205374511", "tag": "webdev"}}, "authors": {"155124": {"item_id": "205374511", "author_id": "155124", "name": "Michael Nielsen", "url": ""}}, "image": {"item_id": "205374511", "src": "https://michaelnielsen.org/ddi/wp-content/uploads/2012/08/quarter_billion_page_crawl_big_picture.png", "width": "440", "height": "0"}, "images": {"1": {"item_id": "205374511", "image_id": "1", "src": "https://michaelnielsen.org/ddi/wp-content/uploads/2012/08/quarter_billion_page_crawl_big_picture.png", "width": "440", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "205374511", "image_id": "2", "src": "https://s0.wp.com/latex.php?latex=0%2C+1%2C+2%2C+%5Cldots%2C+19&bg=ffffff&fg=000000&s=0", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "205374511", "image_id": "3", "src": "https://michaelnielsen.org/ddi/wp-content/uploads/2012/08/quarter_billion_page_crawl_single_instance.png", "width": "440", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "205374511", "image_id": "4", "src": "https://s0.wp.com/latex.php?latex=0%2C+1%2C+%5Cldots%2C+140&bg=ffffff&fg=000000&s=0", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1638}, "4009634870": {"item_id": "4009634870", "resolved_id": "4009622140", "given_url": "https://tech.slashdot.org/story/24/02/17/2029202/can-robotstxt-files-really-stop-ai-crawlers?utm_source=rss1.0mainlinkanon&utm_medium=feed", "given_title": "Can Robots.txt Files Really Stop AI Crawlers?", "favorite": "0", "status": "1", "time_added": "1708283918", "time_updated": "1708320427", "time_read": "1708320427", "time_favorited": "0", "sort_id": 5, "resolved_title": "Can Robots.txt Files Really Stop AI Crawlers?", "resolved_url": "https://tech.slashdot.org/story/24/02/17/2029202/can-robotstxt-files-really-stop-ai-crawlers", "excerpt": "In the high-stakes world of AI, \"The fundamental agreement behind robots.txt [files], and the web as a whole — which for so long amounted to 'everybody just be cool' — may not be able to keep up...", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "493", "lang": "en", "top_image_url": "https://a.fsdn.com/sd/topics/ai_64.png", "tags": {"web-crawlers": {"item_id": "4009634870", "tag": "web-crawlers"}}, "authors": {"47789051": {"item_id": "4009634870", "author_id": "47789051", "name": "EditorDavid", "url": ""}}, "domain_metadata": {"name": "Slashdot", "logo": "https://logo.clearbit.com/slashdot.org?size=800", "greyscale_logo": "https://logo.clearbit.com/slashdot.org?size=800&greyscale=true"}, "listen_duration_estimate": 191}, "3771360729": {"item_id": "3771360729", "resolved_id": "3771360729", "given_url": "https://www.practicalecommerce.com/how-to-use-web-crawlers-for-seo", "given_title": "How to Use Web Crawlers for SEO", "favorite": "0", "status": "1", "time_added": "1671711385", "time_updated": "1706833159", "time_read": "1671725286", "time_favorited": "0", "sort_id": 6, "resolved_title": "How to Use Web Crawlers for SEO", "resolved_url": "https://www.practicalecommerce.com/how-to-use-web-crawlers-for-seo", "excerpt": "A web crawler tool emulates search engine bots. Web crawlers are indispensable for search engine optimization. But leading crawlers are so comprehensive that their findings — lists of URLs and the various statuses and metrics of each — can be overwhelming.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "521", "lang": "en", "top_image_url": "https://www.practicalecommerce.com/wp-content/uploads/2022/12/How-to-Use-Web-Crawlers-for-SEO.jpg", "tags": {"keywords-ppc-seo": {"item_id": "3771360729", "tag": "keywords-ppc-seo"}, "programming": {"item_id": "3771360729", "tag": "programming"}, "web-crawlers": {"item_id": "3771360729", "tag": "web-crawlers"}}, "authors": {"89778274": {"item_id": "3771360729", "author_id": "89778274", "name": "Editorial Policy", "url": "https://www.practicalecommerce.com/editorial-policy"}}, "listen_duration_estimate": 202}, "4007645954": {"item_id": "4007645954", "resolved_id": "4007645954", "given_url": "https://www.theverge.com/24067997/robots-txt-ai-text-file-web-crawlers-spiders", "given_title": "The text file that runs the internet", "favorite": "0", "status": "1", "time_added": "1707935112", "time_updated": "1707970976", "time_read": "1707970976", "time_favorited": "0", "sort_id": 7, "resolved_title": "The text file that runs the internet", "resolved_url": "https://www.theverge.com/24067997/robots-txt-ai-text-file-web-crawlers-spiders", "excerpt": "For three decades, a tiny text file has kept the internet from chaos. This text file has no particular legal or technical authority, and it’s not even particularly complicated.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "2991", "lang": "en", "time_to_read": 14, "top_image_url": "https://cdn.vox-cdn.com/thumbor/WFqBb11u9zi1lsts2WBWjivX0rg=/0x0:2040x1360/1200x628/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/25282612/246992_AI_at_Work_TXT_FILE_ECarter.png", "tags": {"web-crawlers": {"item_id": "4007645954", "tag": "web-crawlers"}, "webdev": {"item_id": "4007645954", "tag": "webdev"}}, "authors": {"166565063": {"item_id": "4007645954", "author_id": "166565063", "name": "David Pierce", "url": "https://www.theverge.com/authors/david-pierce"}}, "domain_metadata": {"name": "The Verge", "logo": "https://logo.clearbit.com/theverge.com?size=800", "greyscale_logo": "https://logo.clearbit.com/theverge.com?size=800&greyscale=true"}, "listen_duration_estimate": 1158}, "1467487": {"item_id": "1467487", "resolved_id": "1467487", "given_url": "https://yacy.net/", "given_title": "Home - YaCy", "favorite": "0", "status": "1", "time_added": "1661466848", "time_updated": "1706833159", "time_read": "1661613975", "time_favorited": "0", "sort_id": 8, "resolved_title": "Home", "resolved_url": "https://yacy.net/", "excerpt": "Join a community of search engines or make your own search portal! Web Search by the people, for the people: decentralized, all users are equal, no central, no search request storage, shared index.", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "195", "lang": "en", "tags": {"programming": {"item_id": "1467487", "tag": "programming"}, "web-crawlers": {"item_id": "1467487", "tag": "web-crawlers"}}, "authors": {"60146580": {"item_id": "1467487", "author_id": "60146580", "name": "Michael Christen", "url": ""}}, "image": {"item_id": "1467487", "src": "https://yacy.net/img/YaCyLogo2011_240.png", "width": "240", "height": "0"}, "images": {"1": {"item_id": "1467487", "image_id": "1", "src": "https://yacy.net/img/YaCyLogo2011_240.png", "width": "240", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1467487", "image_id": "2", "src": "https://yacy.net/img/usecase_freeworld.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "1467487", "image_id": "3", "src": "https://yacy.net/img/usecase_webportal.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "1467487", "image_id": "4", "src": "https://yacy.net/img/usecase_intranet.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "1467487", "image_id": "5", "src": "https://yacy.searchlab.eu/NetworkPicture.png?width=960&height=720&bgcolor=2C3E4F&pal=10080&pol=10080", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 75}}, "error": nil, "search_meta": {"search_type": "normal"}, "since": 1709419730}