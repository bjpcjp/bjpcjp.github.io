{"status": 1, "complete": 1, "list": {"310987269": {"item_id": "310987269", "resolved_id": "310987269", "given_url": "http://tomtunguz.com/crawling-the-most-under-rated-hack", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638240363", "time_updated": "1675106776", "time_read": "1640553102", "time_favorited": "0", "sort_id": 0, "resolved_title": "Crawling - The Most Underrated Hack", "resolved_url": "https://www.tomtunguz.com/crawling-the-most-under-rated-hack/", "excerpt": "It’s been a little while since I traded code with anyone. But a few weeks ago, one of our entrepreneurs-in-residence, Javier, who joined Redpoint from VMWare, told me about a Ruby gem called Mechanize that makes it really easy to crawl websites, particularly those with username/password logins.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "228", "lang": "en", "tags": {"web-scraping": {"item_id": "310987269", "tag": "web-scraping"}, "webdev": {"item_id": "310987269", "tag": "webdev"}}, "listen_duration_estimate": 88}, "3685230913": {"item_id": "3685230913", "resolved_id": "3685230913", "given_url": "https://observablehq.com/@asg017/scrape-json-html-zip-with-sqlite", "given_title": "", "favorite": "0", "status": "1", "time_added": "1661343419", "time_updated": "1675106776", "time_read": "1664912669", "time_favorited": "0", "sort_id": 1, "resolved_title": "Scraping JSON, HTML, and ZIP Files with Pure SQLite", "resolved_url": "https://observablehq.com/@asg017/scrape-json-html-zip-with-sqlite", "excerpt": "<i><small>a.k.a. leave BeautifulSoup in the past and embrace SQL <small>I used DALL·E to generate thumbnails for this post: “cute cartoon|claymation abominable snowman scraping ice off his frozen car windshield” is nightmare fuel Some of the most common web-scraping tasks can be done in pure SQLite - meaning no Python, Node, Ruby, or other programming languages necessary, only the SQLite CLI and some extensions. The main extension that enables this: sqlite-http, which allows you to make HTTP requests and sa", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "top_image_url": "https://static.observableusercontent.com/thumbnail/c2de010b717366cf7cefe0d56aabb89fbfec2fba680a0e695c7ce21625f9f706.jpg", "tags": {"sqlite": {"item_id": "3685230913", "tag": "sqlite"}, "web-scraping": {"item_id": "3685230913", "tag": "web-scraping"}}, "authors": {"169037092": {"item_id": "3685230913", "author_id": "169037092", "name": "Alex Garcia", "url": "https://observablehq.com/@asg017"}}, "listen_duration_estimate": 0}, "3617565775": {"item_id": "3617565775", "resolved_id": "3617565780", "given_url": "https://www.reddit.com/r/ruby/comments/uom86y/ruby_web_scraping/?utm_source=share&utm_medium=ios_app&utm_name=iossmf", "given_title": "", "favorite": "0", "status": "1", "time_added": "1652489705", "time_updated": "1675106776", "time_read": "1653699531", "time_favorited": "0", "sort_id": 2, "resolved_title": "Ruby Web Scraping", "resolved_url": "https://www.reddit.com/r/ruby/comments/uom86y/ruby_web_scraping/", "excerpt": "15Posted by18 hours ago scraperapi.com/blog/r...", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "9", "lang": "en", "top_image_url": "https://external-preview.redd.it/-FJ8DcMs6IW5NanWWrmFnLxpEBqnvhnPMLGxDnkV9iA.jpg?auto=webp&s=6c034d66398a53f6ca34aa94dede9963af82ab86", "tags": {"ruby": {"item_id": "3617565775", "tag": "ruby"}, "web-scraping": {"item_id": "3617565775", "tag": "web-scraping"}}, "domain_metadata": {"name": "Reddit", "logo": "https://logo.clearbit.com/reddit.com?size=800", "greyscale_logo": "https://logo.clearbit.com/reddit.com?size=800&greyscale=true"}, "listen_duration_estimate": 3}, "3505857132": {"item_id": "3505857132", "resolved_id": "3505857132", "given_url": "https://www.troyhunt.com/when-is-a-scrape-a-breach/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1640220843", "time_updated": "1675106776", "time_read": "1640258338", "time_favorited": "0", "sort_id": 3, "resolved_title": "When is a Scrape a Breach?", "resolved_url": "https://www.troyhunt.com/when-is-a-scrape-a-breach/", "excerpt": "A decade and a bit ago during my tenure at Pfizer, a colleague's laptop containing information about customers, healthcare providers and other vendors was stolen from their car. The machine had full disk encryption and it's not known whether the thief was ever actually able to access the data.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1541", "lang": "en", "time_to_read": 7, "top_image_url": "https://www.troyhunt.com/content/images/2021/12/image-3-1.png", "tags": {"web-scraping": {"item_id": "3505857132", "tag": "web-scraping"}}, "image": {"item_id": "3505857132", "src": "https://www.troyhunt.com/content/images/2021/12/image-3.png", "width": "917", "height": "619"}, "images": {"1": {"item_id": "3505857132", "image_id": "1", "src": "https://www.troyhunt.com/content/images/2021/12/image-3.png", "width": "917", "height": "619", "credit": "", "caption": ""}, "2": {"item_id": "3505857132", "image_id": "2", "src": "https://www.troyhunt.com/content/images/2021/12/image-4.png", "width": "731", "height": "218", "credit": "", "caption": ""}}, "listen_duration_estimate": 597}, "3381528060": {"item_id": "3381528060", "resolved_id": "3381528060", "given_url": "https://towardsdatascience.com/scrape-data-from-pdf-files-using-python-fe2dc96b1e68", "given_title": "", "favorite": "0", "status": "1", "time_added": "1645455323", "time_updated": "1691367674", "time_read": "1645464932", "time_favorited": "0", "sort_id": 4, "resolved_title": "Scrape Data from PDF Files Using Python", "resolved_url": "https://towardsdatascience.com/scrape-data-from-pdf-files-using-python-fe2dc96b1e68", "excerpt": "Data science professionals are dealing with data in all shapes and forms. Data could be stored in popular SQL databases, such as PostgreSQL, MySQL, or am old-fashioned excel spreadsheet. Sometimes, data might also be saved in an unconventional format, such as PDF.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1014", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/1*piLISDEa1nMIWGKzf3VL4A.png", "tags": {"pdfs": {"item_id": "3381528060", "tag": "pdfs"}, "python": {"item_id": "3381528060", "tag": "python"}, "web-scraping": {"item_id": "3381528060", "tag": "web-scraping"}}, "authors": {"151777053": {"item_id": "3381528060", "author_id": "151777053", "name": "Aaron Zhu", "url": "https://aaron-zhu.medium.com"}}, "image": {"item_id": "3381528060", "src": "https://miro.medium.com/fit/c/56/56/1*ryphLEGrwr8XmJWhjBx7vg.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3381528060", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*ryphLEGrwr8XmJWhjBx7vg.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3381528060", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*piLISDEa1nMIWGKzf3VL4A.png", "width": "700", "height": "500", "credit": "", "caption": "Sample Structured Data"}, "3": {"item_id": "3381528060", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*jEOtTU1DWH8aAL1YPmMpAw.png", "width": "700", "height": "509", "credit": "", "caption": ""}, "4": {"item_id": "3381528060", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*r5VUzr6iSRl4oqzgIn1pBA.png", "width": "700", "height": "454", "credit": "", "caption": ""}, "5": {"item_id": "3381528060", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*Lnk7XfDYxJmgpXQZ8z_fPQ.png", "width": "700", "height": "397", "credit": "", "caption": ""}, "6": {"item_id": "3381528060", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*ykVECK8YSCM791qnbmFHng.png", "width": "700", "height": "166", "credit": "", "caption": ""}, "7": {"item_id": "3381528060", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*V17v9SbEzdwoTKooObB4mA.png", "width": "700", "height": "159", "credit": "", "caption": ""}, "8": {"item_id": "3381528060", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*dPDum4zH4aVkC4zx-qrLTw.png", "width": "700", "height": "118", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 393}, "735206485": {"item_id": "735206485", "resolved_id": "735206485", "given_url": "https://github.com/ericchiang/pup", "given_title": "", "favorite": "0", "status": "1", "time_added": "1669858435", "time_updated": "1706833159", "time_read": "1670683507", "time_favorited": "0", "sort_id": 5, "resolved_title": "ericchiang/pup", "resolved_url": "https://github.com/ericchiang/pup", "excerpt": "pup is a command line tool for processing HTML. It reads from stdin, prints to stdout, and allows the user to filter parts of the page using CSS selectors. Inspired by jq, pup aims to be a fast and flexible way of exploring HTML from the terminal.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "962", "lang": "en", "time_to_read": 4, "top_image_url": "https://opengraph.githubassets.com/8cccff06ff0c16faecd2a9f0307a343f8259efddeeba75a1f79633ab2befa2dc/ericchiang/pup", "tags": {"command-line": {"item_id": "735206485", "tag": "command-line"}, "html": {"item_id": "735206485", "tag": "html"}, "programming": {"item_id": "735206485", "tag": "programming"}, "web-scraping": {"item_id": "735206485", "tag": "web-scraping"}}, "authors": {"170794182": {"item_id": "735206485", "author_id": "170794182", "name": "ericchiang", "url": "https://github.com/ericchiang/pup/commits?author=ericchiang"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 372}, "3639685212": {"item_id": "3639685212", "resolved_id": "3639685212", "given_url": "https://dev.to/oxylabs-io/13-tips-on-how-to-crawl-a-website-without-getting-blocked-35l9", "given_title": "13 Tips on How to Crawl a Website Without Getting Blocked", "favorite": "0", "status": "1", "time_added": "1655205255", "time_updated": "1675106776", "time_read": "1655205270", "time_favorited": "0", "sort_id": 6, "resolved_title": "13 Tips on How to Crawl a Website Without Getting Blocked", "resolved_url": "https://dev.to/oxylabs-io/13-tips-on-how-to-crawl-a-website-without-getting-blocked-35l9", "excerpt": "It’s not a secret that businesses and individuals use web scrapers to collect public data from various websites. However, getting blacklisted while scraping data is a common issue for those who don’t know how to avoid getting your IP blocked.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "1339", "lang": "en", "time_to_read": 6, "top_image_url": "https://res.cloudinary.com/practicaldev/image/fetch/s--Q0-J7JDA--/c_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/di4tbko1nl72iw5gsmdy.jpg", "tags": {"web-scraping": {"item_id": "3639685212", "tag": "web-scraping"}, "webdev": {"item_id": "3639685212", "tag": "webdev"}}, "image": {"item_id": "3639685212", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--IktLX8eB--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/di4tbko1nl72iw5gsmdy.jpg", "width": "1000", "height": "420"}, "images": {"1": {"item_id": "3639685212", "image_id": "1", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--IktLX8eB--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/di4tbko1nl72iw5gsmdy.jpg", "width": "1000", "height": "420", "credit": "", "caption": ""}, "2": {"item_id": "3639685212", "image_id": "2", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--0ZMr2EEv--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/czhirs6138vf1hswxnki.jpg", "width": "880", "height": "406", "credit": "", "caption": ""}, "3": {"item_id": "3639685212", "image_id": "3", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--mAkpsNOy--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8drfeynmozfpujw5ts3o.jpg", "width": "880", "height": "406", "credit": "", "caption": ""}, "4": {"item_id": "3639685212", "image_id": "4", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--aW5gYNex--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/dkbttzm1m8mbdq6gljlp.jpg", "width": "880", "height": "441", "credit": "", "caption": ""}, "5": {"item_id": "3639685212", "image_id": "5", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--6kvhgQyY--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/g12mojcg9rie8tv9lhja.jpg", "width": "880", "height": "406", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "3639685212", "video_id": "1", "src": "https://www.youtube.com/embed/_5dhS4r0g2A", "width": "710", "height": "399", "type": "1", "vid": "_5dhS4r0g2A", "length": "0"}}, "domain_metadata": {"name": "The Practical Dev", "logo": "https://logo.clearbit.com/dev.to?size=800", "greyscale_logo": "https://logo.clearbit.com/dev.to?size=800&greyscale=true"}, "listen_duration_estimate": 518}, "3243181577": {"item_id": "3243181577", "resolved_id": "3243181577", "given_url": "https://towardsdatascience.com/6-web-scraping-tools-that-make-collecting-data-a-breeze-457c44e4411d", "given_title": "6 Web Scraping Tools That Make Collecting Data A Breeze | by Sara A. Metwal", "favorite": "0", "status": "1", "time_added": "1611962406", "time_updated": "1706833159", "time_read": "1611962520", "time_favorited": "0", "sort_id": 7, "resolved_title": "6 Web Scraping Tools That Make Collecting Data A Breeze", "resolved_url": "https://towardsdatascience.com/6-web-scraping-tools-that-make-collecting-data-a-breeze-457c44e4411d", "excerpt": "Sara A. Metwalli No data science project is completed without data; I can even argue that you can’t say “data science” without data. Often, in most data science projects, the data you need to analyze and use to build machine learning models are stored in a database somewhere.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1346", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/0*EEr11JdomL2XlYnb", "tags": {"programming": {"item_id": "3243181577", "tag": "programming"}, "web-scraping": {"item_id": "3243181577", "tag": "web-scraping"}, "webdev": {"item_id": "3243181577", "tag": "webdev"}}, "authors": {"141607202": {"item_id": "3243181577", "author_id": "141607202", "name": "Sara A. Metwalli", "url": "https://saraametwalli.medium.com"}}, "image": {"item_id": "3243181577", "src": "https://miro.medium.com/fit/c/56/56/1*BY6sCRisdVuk5GyPL_q7rw.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3243181577", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*BY6sCRisdVuk5GyPL_q7rw.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3243181577", "image_id": "2", "src": "https://miro.medium.com/max/2000/0*EEr11JdomL2XlYnb", "width": "1000", "height": "667", "credit": "Markus Spiske on Unsplash", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 521}, "138637740": {"item_id": "138637740", "resolved_id": "138637740", "given_url": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/", "given_title": "Beautiful Soup Documentation — Beautiful Soup 4.9.0 documentation", "favorite": "0", "status": "1", "time_added": "1631123172", "time_updated": "1706833159", "time_read": "1631137991", "time_favorited": "0", "sort_id": 8, "resolved_title": "Beautiful Soup Documentation — Beautiful Soup 4.12.0 documentation", "resolved_url": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/", "excerpt": "Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "10693", "lang": "en", "time_to_read": 49, "tags": {"programming": {"item_id": "138637740", "tag": "programming"}, "python": {"item_id": "138637740", "tag": "python"}, "regexes": {"item_id": "138637740", "tag": "regexes"}, "web-scraping": {"item_id": "138637740", "tag": "web-scraping"}}, "image": {"item_id": "138637740", "src": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/_images/6.1.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "138637740", "image_id": "1", "src": "https://www.crummy.com/software/BeautifulSoup/bs4/doc/_images/6.1.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 4139}, "1303901953": {"item_id": "1303901953", "resolved_id": "1303901953", "given_url": "https://www.parsehub.com/quickstart", "given_title": "Download ParseHub | Our Quickstart Guide", "favorite": "0", "status": "1", "time_added": "1661826446", "time_updated": "1675106776", "time_read": "1661826645", "time_favorited": "0", "sort_id": 9, "resolved_title": "Download ParseHub | Our Quickstart Guide", "resolved_url": "https://www.parsehub.com/quickstart", "excerpt": "", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"web-scraping": {"item_id": "1303901953", "tag": "web-scraping"}}, "listen_duration_estimate": 0}, "2932599929": {"item_id": "2932599929", "resolved_id": "2932357628", "given_url": "http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:939888", "given_title": "Extract Data from Website to Excel Automatically", "favorite": "0", "status": "1", "time_added": "1585605790", "time_updated": "1675106776", "time_read": "1585711926", "time_favorited": "0", "sort_id": 10, "resolved_title": "Extract Data from Website to Excel Automatically", "resolved_url": "https://www.datasciencecentral.com/profiles/blogs/extract-data-from-website-to-excel-automatically", "excerpt": "To extract data from websites, you can take advantage of data extraction tools like Octoparse. These tools can pull data from websites automatically and save them into many formats such as Excel, JSON, CSV, HTML, or to your own database via APIs.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "765", "lang": "en", "time_to_read": 3, "top_image_url": "https://storage.ning.com/topology/rest/1.0/file/get/2751248758?profile=UPSCALE_150x150", "tags": {"web-scraping": {"item_id": "2932599929", "tag": "web-scraping"}, "webdev": {"item_id": "2932599929", "tag": "webdev"}}, "authors": {"123251560": {"item_id": "2932599929", "author_id": "123251560", "name": "Erika Foo", "url": "https://www.datasciencecentral.com/profile/ErikaFoo"}}, "image": {"item_id": "2932599929", "src": "http://img.youtube.com/vi/-A-A7HVYz5k/0.jpg", "width": "480", "height": "360"}, "images": {"1": {"item_id": "2932599929", "image_id": "1", "src": "http://img.youtube.com/vi/-A-A7HVYz5k/0.jpg", "width": "480", "height": "360", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "2932599929", "video_id": "1", "src": "https://www.youtube.com/embed/-A-A7HVYz5k?feature=oembed&wmode=opaque", "width": "683", "height": "384", "type": "1", "vid": "-A-A7HVYz5k", "length": "0"}}, "domain_metadata": {"name": "Data Science Central", "logo": "https://logo.clearbit.com/datasciencecentral.com?size=800", "greyscale_logo": "https://logo.clearbit.com/datasciencecentral.com?size=800&greyscale=true"}, "listen_duration_estimate": 296}, "3706726773": {"item_id": "3706726773", "resolved_id": "3706726773", "given_url": "https://support.smartbear.com/testcomplete/docs/app-testing/web/general/examples/finding-an-image.html", "given_title": "Finding an Image on a Web Page | TestComplete Documentation", "favorite": "0", "status": "1", "time_added": "1663635685", "time_updated": "1675106776", "time_read": "1663713037", "time_favorited": "0", "sort_id": 11, "resolved_title": "Finding an Image on a Web Page", "resolved_url": "https://support.smartbear.com/testcomplete/docs/app-testing/web/general/examples/finding-an-image.html", "excerpt": "When testing web pages, you may need to check whether a web page displays certain images. This may be necessary, for example, to check if the previous operation was completed successfully, or you may need to search for an image and simulate a mouse click or key press over it.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "352", "lang": "en", "tags": {"images": {"item_id": "3706726773", "tag": "images"}, "web-scraping": {"item_id": "3706726773", "tag": "web-scraping"}, "webdev": {"item_id": "3706726773", "tag": "webdev"}}, "listen_duration_estimate": 136}, "3480637938": {"item_id": "3480637938", "resolved_id": "3480637938", "given_url": "https://github.com/sibprogrammer/xq", "given_title": "Hacker News", "favorite": "0", "status": "1", "time_added": "1668342915", "time_updated": "1706833159", "time_read": "1668380612", "time_favorited": "0", "sort_id": 12, "resolved_title": "xq", "resolved_url": "https://github.com/sibprogrammer/xq", "excerpt": "Command line XML beautifier and content extractor. Similar to jq. It is possible to extract the content using XPath query language. -x parameter accepts XPath expression.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "172", "lang": "en", "top_image_url": "https://opengraph.githubassets.com/36ae2a7fb6f4534c99c2422e9976b0c14f2e5a63919ce1b710c108eb51a58d60/sibprogrammer/xq", "tags": {"html": {"item_id": "3480637938", "tag": "html"}, "programming": {"item_id": "3480637938", "tag": "programming"}, "web-scraping": {"item_id": "3480637938", "tag": "web-scraping"}}, "image": {"item_id": "3480637938", "src": "https://github.com/sibprogrammer/xq/blob/master/assets/images/screenshot.png?raw=true", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3480637938", "image_id": "1", "src": "https://github.com/sibprogrammer/xq/blob/master/assets/images/screenshot.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 67}, "2934061676": {"item_id": "2934061676", "resolved_id": "2934061676", "given_url": "https://thenextweb.com/basics/2020/03/31/holy-sheet-heres-how-to-grab-a-web-pages-data-with-google-sheets/", "given_title": "Holy sheet: Here’s how to grab a web page’s data with Google Sheets", "favorite": "0", "status": "1", "time_added": "1585666872", "time_updated": "1675106776", "time_read": "1585677824", "time_favorited": "0", "sort_id": 13, "resolved_title": "Holy sheet: Here’s how to grab a web page’s data with Google Sheets", "resolved_url": "https://thenextweb.com/basics/2020/03/31/holy-sheet-heres-how-to-grab-a-web-pages-data-with-google-sheets/", "excerpt": "Welcome to TNW Basics, a collection of tips, guides, and advice on how to easily get the most out of your gadgets, apps, and other stuff. Scraping data is all the rage nowadays. But what many don’t know is that you don’t need to be a fancy hacker to be able to collect data from websites.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "367", "lang": "en", "top_image_url": "https://img-cdn.tnwcdn.com/image/tnw?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2020%2F03%2Fsheets_formula.png&signature=0a93b4a008c02bd156fb2e231ee6efc1", "tags": {"web-scraping": {"item_id": "2934061676", "tag": "web-scraping"}, "webdev": {"item_id": "2934061676", "tag": "webdev"}}, "authors": {"111886556": {"item_id": "2934061676", "author_id": "111886556", "name": "Yaron Yitzhak", "url": "https://thenextweb.com/author/yaron-yitzhak/"}}, "image": {"item_id": "2934061676", "src": "https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2020/03/sheets_formula-796x417.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2934061676", "image_id": "1", "src": "https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2020/03/sheets_formula-796x417.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2934061676", "image_id": "2", "src": "https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2020/03/Screenshot-2020-03-31-at-15.58.18.png", "width": "1710", "height": "816", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The Next Web", "logo": "https://logo.clearbit.com/thenextweb.com?size=800", "greyscale_logo": "https://logo.clearbit.com/thenextweb.com?size=800&greyscale=true"}, "listen_duration_estimate": 142}, "3431031201": {"item_id": "3431031201", "resolved_id": "3431031201", "given_url": "https://www.babbling.fish/scraping-for-a-job/", "given_title": "How to Crawl the Web with Scrapy", "favorite": "0", "status": "1", "time_added": "1631559865", "time_updated": "1675106776", "time_read": "1633111088", "time_favorited": "0", "sort_id": 14, "resolved_title": "How to Crawl the Web with Scrapy", "resolved_url": "https://www.babbling.fish/scraping-for-a-job/", "excerpt": "Web scraping is the process of downloading data from a public website. For example, you could scrape ESPN for stats of baseball players and build a model to predict a team’s odds of winning based on their players stats and win rates. Below are a few use-cases for web scraping.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "3031", "lang": "en", "time_to_read": 14, "tags": {"web-scraping": {"item_id": "3431031201", "tag": "web-scraping"}}, "authors": {"34036688": {"item_id": "3431031201", "author_id": "34036688", "name": "Matt Bass", "url": ""}}, "listen_duration_estimate": 1173}, "3831590357": {"item_id": "3831590357", "resolved_id": "3831590357", "given_url": "https://towardsdatascience.com/how-to-parse-html-with-regex-6b9c0980382f", "given_title": "How To Parse HTML With Regex", "favorite": "0", "status": "1", "time_added": "1679599248", "time_updated": "1682421867", "time_read": "1679752412", "time_favorited": "0", "sort_id": 15, "resolved_title": "How To Parse HTML With Regex", "resolved_url": "https://towardsdatascience.com/how-to-parse-html-with-regex-6b9c0980382f", "excerpt": "Python allows you to natively parse HTML and extract the data you need from it. Whether you are an experienced Python developer or just getting started, this step-by-step tutorial will teach you how to parse HTML with regex like a pro. Let’s dig into HTML parsing in Python!", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "2776", "lang": "en", "time_to_read": 13, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/0*PZSgzhnMpultg8mV", "tags": {"python": {"item_id": "3831590357", "tag": "python"}, "regexes": {"item_id": "3831590357", "tag": "regexes"}, "web-scraping": {"item_id": "3831590357", "tag": "web-scraping"}}, "authors": {"146854547": {"item_id": "3831590357", "author_id": "146854547", "name": "Antonello Zanini", "url": "https://antozanini.medium.com"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1075}, "2023805531": {"item_id": "2023805531", "resolved_id": "2023805531", "given_url": "https://www.pythoncentral.io/html-parser/", "given_title": "HTML Parser: How to scrap HTML content | Python Central", "favorite": "0", "status": "1", "time_added": "1572628937", "time_updated": "1675106776", "time_read": "1577120310", "time_favorited": "0", "sort_id": 16, "resolved_title": "HTML Parser: How to scrape HTML content", "resolved_url": "https://www.pythoncentral.io/html-parser/", "excerpt": "Prerequisites Knowledge of the following is required: Python 3 Basic HTML Urllib2 (not mandatory but recommended) Basic OOP concepts Python data structures - Lists, Tuples Why parse HTML? Python is one of the languages that is extensively used to scrape data from web pages.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1058", "lang": "en", "time_to_read": 5, "top_image_url": "https://www.pythoncentral.io/wp-content/uploads/2017/07/wordpress-hints-html-pexel.jpeg", "tags": {"html": {"item_id": "2023805531", "tag": "html"}, "python": {"item_id": "2023805531", "tag": "python"}, "web-scraping": {"item_id": "2023805531", "tag": "web-scraping"}}, "listen_duration_estimate": 410}, "2346531750": {"item_id": "2346531750", "resolved_id": "2346531750", "given_url": "https://www.mixnode.com/blog/posts/turn-the-web-into-a-database-an-alternative-to-web-crawling-scraping", "given_title": "https://www.mixnode.com/blog/posts/turn-the-web-into-a-database-an-alternat", "favorite": "0", "status": "1", "time_added": "1538946801", "time_updated": "1675106776", "time_read": "1539009319", "time_favorited": "0", "sort_id": 17, "resolved_title": "Turn the web into a database: An alternative to web crawling/scraping", "resolved_url": "https://www.mixnode.com/blog/posts/turn-the-web-into-a-database-an-alternative-to-web-crawling-scraping", "excerpt": "After months of development we are incredibly excited to announce that starting today Mixnode will enter private beta and we will start sending invitations to the awesome, patient people on the waiting list. Once you receive your invitation you can create an account and take Mixnode for a spin.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "957", "lang": "en", "time_to_read": 4, "top_image_url": "https://www.mixnode.com/img/og_image.png", "tags": {"search": {"item_id": "2346531750", "tag": "search"}, "web-scraping": {"item_id": "2346531750", "tag": "web-scraping"}}, "image": {"item_id": "2346531750", "src": "https://s3.amazonaws.com/assets.mixnode.com/particles.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2346531750", "image_id": "1", "src": "https://s3.amazonaws.com/assets.mixnode.com/particles.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2346531750", "image_id": "2", "src": "https://s3.amazonaws.com/assets.mixnode.com/arrow-bent.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2346531750", "image_id": "3", "src": "https://s3.amazonaws.com/assets.mixnode.com/arrow-down.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 370}, "3557680425": {"item_id": "3557680425", "resolved_id": "3557680425", "given_url": "https://towardsdatascience.com/scrape-data-from-pdf-files-using-python-and-pdfquery-d033721c3b28", "given_title": "Scrape Data from PDF Files Using Python and PDFQuery", "favorite": "0", "status": "1", "time_added": "1645450861", "time_updated": "1691367674", "time_read": "1645464879", "time_favorited": "0", "sort_id": 18, "resolved_title": "Scrape Data from PDF Files Using Python and PDFQuery", "resolved_url": "https://towardsdatascience.com/scrape-data-from-pdf-files-using-python-and-pdfquery-d033721c3b28", "excerpt": "In the previous article, I talked about how to use tabula-py and Pandas in Python to scrape data from both structured and unstructured data from PDF files. In this article, I’m going to introduce an alternative way to scrape data from PDF files: PDFQuery.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "934", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/max/1200/1*SLwrjTpeOD4MpwrYqJUBmg.png", "tags": {"pdfs": {"item_id": "3557680425", "tag": "pdfs"}, "python": {"item_id": "3557680425", "tag": "python"}, "web-scraping": {"item_id": "3557680425", "tag": "web-scraping"}}, "authors": {"151777053": {"item_id": "3557680425", "author_id": "151777053", "name": "Aaron Zhu", "url": "https://aaron-zhu.medium.com"}}, "image": {"item_id": "3557680425", "src": "https://miro.medium.com/max/1400/1*SLwrjTpeOD4MpwrYqJUBmg.png", "width": "700", "height": "343"}, "images": {"1": {"item_id": "3557680425", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*SLwrjTpeOD4MpwrYqJUBmg.png", "width": "700", "height": "343", "credit": "", "caption": "Image by Author"}, "2": {"item_id": "3557680425", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*Ls8U-PQQkSm8ZlhDFhKo8Q.png", "width": "700", "height": "464", "credit": "", "caption": "Image by Author"}, "3": {"item_id": "3557680425", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*5zBFkBu9N_fXQS2cBYBknQ.png", "width": "700", "height": "292", "credit": "", "caption": "Image by Author"}, "4": {"item_id": "3557680425", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*F6V22QapyXPo5DuHSFiivQ.png", "width": "700", "height": "92", "credit": "", "caption": "Image by Author"}, "5": {"item_id": "3557680425", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*ckul1Wxb3bl3P_G__ip4wA.png", "width": "700", "height": "537", "credit": "", "caption": "Image by Author"}, "6": {"item_id": "3557680425", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*xxCTmQ5YgNtwn4lzHEh__A.png", "width": "700", "height": "294", "credit": "", "caption": "Image by Author"}, "7": {"item_id": "3557680425", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*xc1c6_kjUlgGuLeBAcYdow.png", "width": "700", "height": "387", "credit": "", "caption": "Image by Author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 362}, "3240649417": {"item_id": "3240649417", "resolved_id": "3240649417", "given_url": "https://code.tutsplus.com/articles/scrape-the-web-at-scale-with-the-scrapestack-api--cms-36366", "given_title": "Scrape the Web at Scale With the scrapestack API", "favorite": "0", "status": "1", "time_added": "1611744601", "time_updated": "1706833159", "time_read": "1611746358", "time_favorited": "0", "sort_id": 19, "resolved_title": "Scrape the Web at Scale With the scrapestack API", "resolved_url": "https://code.tutsplus.com/articles/scrape-the-web-at-scale-with-the-scrapestack-api--cms-36366", "excerpt": "Businesses need better information to target and reach wider audiences. They get this information by scraping the web for content from social media platforms, eCommerce platforms, video platforms, travel platforms, review and ratings, and more.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1407", "lang": "en", "time_to_read": 6, "top_image_url": "https://cms-assets.tutsplus.com/uploads/users/769/posts/36366/preview_image/scrapestack.jpg", "tags": {"programming": {"item_id": "3240649417", "tag": "programming"}, "web-scraping": {"item_id": "3240649417", "tag": "web-scraping"}, "webdev": {"item_id": "3240649417", "tag": "webdev"}}, "authors": {"126357110": {"item_id": "3240649417", "author_id": "126357110", "name": "Franc Lucas", "url": "https://tutsplus.com/authors/franc-lucas"}}, "image": {"item_id": "3240649417", "src": "https://cms-assets.tutsplus.com/uploads/users/1997/posts/36366/image-upload/10421109-F3A6-4E6B-9257-F7B520D04B9D.jpeg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3240649417", "image_id": "1", "src": "https://cms-assets.tutsplus.com/uploads/users/1997/posts/36366/image-upload/10421109-F3A6-4E6B-9257-F7B520D04B9D.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3240649417", "image_id": "2", "src": "https://cms-assets.tutsplus.com/uploads/users/1997/posts/36366/image-upload/2B935E80-AC10-43A4-8B06-F140DF7AF4C9.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3240649417", "image_id": "3", "src": "https://cms-assets.tutsplus.com/uploads/users/1997/posts/36366/image-upload/734E0787-0200-41D8-B01D-BA798663D428.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3240649417", "image_id": "4", "src": "https://cms-assets.tutsplus.com/uploads/users/1997/posts/36366/image-upload/845CA033-6771-4933-8392-25D6A144059C.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3240649417", "image_id": "5", "src": "https://cms-assets.tutsplus.com/uploads/users/1997/posts/36366/image-upload/23A76A48-7639-49B8-8169-0DEF4F250CF7.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3240649417", "image_id": "6", "src": "https://cms-assets.tutsplus.com/uploads/users/1997/posts/36366/image-upload/7E08C541-390A-4F90-9FC2-E76696A42196.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3240649417", "image_id": "7", "src": "https://cms-assets.tutsplus.com/uploads/users/1997/posts/36366/image-upload/87126326-BA16-4F92-B671-9B94D4D55096.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3240649417", "image_id": "8", "src": "https://cms-assets.tutsplus.com/uploads/users/1997/posts/36366/image-upload/36BED83A-3765-4F74-A6B5-3188EC14671D.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Envato Tuts+", "logo": "https://logo.clearbit.com/tutsplus.com?size=800", "greyscale_logo": "https://logo.clearbit.com/tutsplus.com?size=800&greyscale=true"}, "listen_duration_estimate": 545}, "3345406690": {"item_id": "3345406690", "resolved_id": "3345406722", "given_url": "https://www.kdnuggets.com/2021/05/top-4-data-extraction-tools.html", "given_title": "Top 4 Data Extraction Tools", "favorite": "0", "status": "1", "time_added": "1622480674", "time_updated": "1706833159", "time_read": "1622499087", "time_favorited": "0", "sort_id": 20, "resolved_title": "Top 4 Data Extraction Tools", "resolved_url": "https://www.kdnuggets.com/top-4-data-extraction-tools.html/", "excerpt": "By Zoltan Bettenbuk, CTO, Scraper API. Data extraction can be a daunting task, and the right tools can improve productivity while providing valuable insights.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "697", "lang": "en", "time_to_read": 3, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/data-scraping-500.jpg", "tags": {"programming": {"item_id": "3345406690", "tag": "programming"}, "web-scraping": {"item_id": "3345406690", "tag": "web-scraping"}}, "image": {"item_id": "3345406690", "src": "https://www.kdnuggets.com/wp-content/uploads/data-scraping-500.jpg", "width": "90", "height": "0"}, "images": {"1": {"item_id": "3345406690", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/uploads/data-scraping-500.jpg", "width": "90", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 270}, "2301754911": {"item_id": "2301754911", "resolved_id": "2301754911", "given_url": "https://github.com/vifreefly/kimuraframework", "given_title": "vifreefly/kimuraframework: Kimurai is a modern web scraping framework writt", "favorite": "0", "status": "1", "time_added": "1675106729", "time_updated": "1706833159", "time_read": "1675128953", "time_favorited": "0", "sort_id": 21, "resolved_title": "Kimurai", "resolved_url": "https://github.com/vifreefly/kimuraframework", "excerpt": "UPD. I will soon have a time to work on issues for current 1.4 version and also plan to release new 2.0 version with https://github.com/twalpole/apparition engine.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "10580", "lang": "en", "time_to_read": 48, "top_image_url": "https://opengraph.githubassets.com/46c8ecda0ef8b1addb742bb583577d7ee301408c3bc60adb51ac45cc836fa39c/vifreefly/kimuraframework", "tags": {"programming": {"item_id": "2301754911", "tag": "programming"}, "ruby": {"item_id": "2301754911", "tag": "ruby"}, "web-scraping": {"item_id": "2301754911", "tag": "web-scraping"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 4095}, "3791574992": {"item_id": "3791574992", "resolved_id": "3791574992", "given_url": "https://dev.to/serpdogapi/web-scraping-a-complete-guide-1lk2", "given_title": "Web Scraping - A Complete Guide", "favorite": "0", "status": "1", "time_added": "1674351392", "time_updated": "1675106776", "time_read": "1674389864", "time_favorited": "0", "sort_id": 22, "resolved_title": "Web Scraping - A Complete Guide", "resolved_url": "https://dev.to/serpdogapi/web-scraping-a-complete-guide-1lk2", "excerpt": "Web Scraping, also known as data extraction or data scraping, is the process of extracting or collecting data from websites or other sources in the form of text, images, videos, links, etc.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2574", "lang": "en", "time_to_read": 12, "top_image_url": "https://res.cloudinary.com/practicaldev/image/fetch/s--viMJ8cFE--/c_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/jkauywnklpa9t9usey9n.png", "tags": {"web-scraping": {"item_id": "3791574992", "tag": "web-scraping"}}, "image": {"item_id": "3791574992", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--0FF1ipn3--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/jkauywnklpa9t9usey9n.png", "width": "1000", "height": "420"}, "images": {"1": {"item_id": "3791574992", "image_id": "1", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--0FF1ipn3--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/jkauywnklpa9t9usey9n.png", "width": "1000", "height": "420", "credit": "", "caption": ""}, "2": {"item_id": "3791574992", "image_id": "2", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--a8pYaytG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/08hts0mb1sj0869s6o0q.png", "width": "880", "height": "495", "credit": "", "caption": ""}, "3": {"item_id": "3791574992", "image_id": "3", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--Bw2jYcT5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/6dnraexvkj7t2ziar4iq.png", "width": "880", "height": "495", "credit": "", "caption": ""}, "4": {"item_id": "3791574992", "image_id": "4", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--NhVkblFD--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vh4fa4yo4c4w8tlfjfvv.png", "width": "880", "height": "495", "credit": "", "caption": ""}, "5": {"item_id": "3791574992", "image_id": "5", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--_rQFwTOV--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/3zi7u4dpwbgqc5um1nhb.png", "width": "880", "height": "495", "credit": "", "caption": ""}, "6": {"item_id": "3791574992", "image_id": "6", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--7sKscnmo--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ywp8xs5dt567ou3jp1xw.png", "width": "880", "height": "495", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The Practical Dev", "logo": "https://logo.clearbit.com/dev.to?size=800", "greyscale_logo": "https://logo.clearbit.com/dev.to?size=800&greyscale=true"}, "listen_duration_estimate": 996}, "3418362433": {"item_id": "3418362433", "resolved_id": "3418362433", "given_url": "https://www.zenrows.com/blog", "given_title": "Web Scraping Blog - ZenRows", "favorite": "0", "status": "1", "time_added": "1678654998", "time_updated": "1679094815", "time_read": "1679094815", "time_favorited": "0", "sort_id": 23, "resolved_title": "The ZenRows Blog", "resolved_url": "https://www.zenrows.com/blog", "excerpt": "We share everything we know about data automation and visualization to help you stand out.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "15", "lang": "en", "top_image_url": "https://cdn.zenrows.com/images/logo.png", "tags": {"web-scraping": {"item_id": "3418362433", "tag": "web-scraping"}, "webdev": {"item_id": "3418362433", "tag": "webdev"}}, "listen_duration_estimate": 6}, "3839960714": {"item_id": "3839960714", "resolved_id": "3839960714", "given_url": "https://dev.to/zenrowshq/web-scraping-in-python-avoid-detection-like-a-ninja-2op1", "given_title": "Web Scraping in Python: Avoid Detection Like a Ninja", "favorite": "0", "status": "1", "time_added": "1680693375", "time_updated": "1680823234", "time_read": "1680823234", "time_favorited": "0", "sort_id": 24, "resolved_title": "Web Scraping in Python: Avoid Detection Like a Ninja", "resolved_url": "https://dev.to/zenrowshq/web-scraping-in-python-avoid-detection-like-a-ninja-2op1", "excerpt": "Scraping should be about extracting content from HTML. It sounds simple but has many obstacles. The first one is to obtain the said HTML. For that, we'll use Python to avoid detection. That might require bypassing anti-bot systems.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3080", "lang": "en", "time_to_read": 14, "top_image_url": "https://res.cloudinary.com/practicaldev/image/fetch/s--6Z6OObLI--/c_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/b2y3fz2o365hcfcpish7.jpg", "tags": {"python": {"item_id": "3839960714", "tag": "python"}, "web-scraping": {"item_id": "3839960714", "tag": "web-scraping"}}, "image": {"item_id": "3839960714", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--KBbotFYL--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/b2y3fz2o365hcfcpish7.jpg", "width": "1000", "height": "420"}, "images": {"1": {"item_id": "3839960714", "image_id": "1", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--KBbotFYL--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/b2y3fz2o365hcfcpish7.jpg", "width": "1000", "height": "420", "credit": "", "caption": ""}, "2": {"item_id": "3839960714", "image_id": "2", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--TVEI2vxl--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/sftv56a1irpzuemk0xb4.jpg", "width": "880", "height": "1029", "credit": "", "caption": ""}, "3": {"item_id": "3839960714", "image_id": "3", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--KNOLsU97--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/tglqnbe8o26najeybvyx.jpg", "width": "700", "height": "400", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The Practical Dev", "logo": "https://logo.clearbit.com/dev.to?size=800", "greyscale_logo": "https://logo.clearbit.com/dev.to?size=800&greyscale=true"}, "listen_duration_estimate": 1192}, "3824256663": {"item_id": "3824256663", "resolved_id": "3824256672", "given_url": "https://www.zenrows.com/blog/web-scraping-ruby#web-crawling-in-ruby", "given_title": "Web Scraping in Ruby: Complete Guide 2023 - ZenRows", "favorite": "1", "status": "1", "time_added": "1678654859", "time_updated": "1679096299", "time_read": "1679096299", "time_favorited": "1679095988", "sort_id": 25, "resolved_title": "Web Scraping in Ruby: Complete Guide 2023", "resolved_url": "https://www.zenrows.com/blog/web-scraping-ruby", "excerpt": "The need to scrape data by companies and individuals has increased in recent years, and Ruby is one of the best programming languages for this purpose.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3620", "lang": "en", "time_to_read": 16, "top_image_url": "https://cdn.zenrows.com/images/blog/web-scraping-ruby.jpg", "tags": {"ruby": {"item_id": "3824256663", "tag": "ruby"}, "web-scraping": {"item_id": "3824256663", "tag": "web-scraping"}, "webdev": {"item_id": "3824256663", "tag": "webdev"}}, "image": {"item_id": "3824256663", "src": "https://cdn.zenrows.com/images/blog/r-web-scraping/scrapeme-product-dev-tools.png", "width": "768", "height": "351"}, "images": {"1": {"item_id": "3824256663", "image_id": "1", "src": "https://cdn.zenrows.com/images/blog/r-web-scraping/scrapeme-product-dev-tools.png", "width": "768", "height": "351", "credit": "", "caption": ""}, "2": {"item_id": "3824256663", "image_id": "2", "src": "https://cdn.zenrows.com/images/blog/r-web-scraping/scrapeme-output.png", "width": "1037", "height": "420", "credit": "", "caption": ""}, "3": {"item_id": "3824256663", "image_id": "3", "src": "https://cdn.zenrows.com/images/blog/devtools-inspect-scrapeme-live.png", "width": "768", "height": "416", "credit": "", "caption": ""}, "4": {"item_id": "3824256663", "image_id": "4", "src": "https://cdn.zenrows.com/images/blog/devtools-open-scrapeme-live.png", "width": "768", "height": "335", "credit": "", "caption": ""}}, "listen_duration_estimate": 1401}, "3331618395": {"item_id": "3331618395", "resolved_id": "3331618395", "given_url": "https://thecleverprogrammer.com/2021/05/14/web-scraping-to-create-a-dataset-using-python/", "given_title": "Web Scraping to Create a Dataset using Python", "favorite": "0", "status": "1", "time_added": "1620993394", "time_updated": "1675106776", "time_read": "1621357076", "time_favorited": "0", "sort_id": 26, "resolved_title": "Web Scraping to Create a Dataset using Python", "resolved_url": "https://thecleverprogrammer.com/2021/05/14/web-scraping-to-create-a-dataset-using-python/", "excerpt": "The datasets that you find on the internet from various data sources are either created by companies and organizations or are collected from websites. You must have scraped data from web pages by using the Python libraries, but may have stuck while preparing the scraped data to create a dataset.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "336", "lang": "en", "top_image_url": "https://thecleverprogrammer.com/wp-content/uploads/2021/05/Web-Scraping-to-Create-a-Dataset-using-python.png", "tags": {"datasets": {"item_id": "3331618395", "tag": "datasets"}, "python": {"item_id": "3331618395", "tag": "python"}, "web-scraping": {"item_id": "3331618395", "tag": "web-scraping"}}, "authors": {"142033929": {"item_id": "3331618395", "author_id": "142033929", "name": "Facebook", "url": "https://www.facebook.com/thecleverprogrammer"}}, "image": {"item_id": "3331618395", "src": "https://i1.wp.com/thecleverprogrammer.com/wp-content/uploads/2021/05/dataset-1.png?resize=1024%2C335&ssl=1", "width": "1024", "height": "335"}, "images": {"1": {"item_id": "3331618395", "image_id": "1", "src": "https://i1.wp.com/thecleverprogrammer.com/wp-content/uploads/2021/05/dataset-1.png?resize=1024%2C335&ssl=1", "width": "1024", "height": "335", "credit": "", "caption": ""}}, "listen_duration_estimate": 130}, "3797402397": {"item_id": "3797402397", "resolved_id": "3797402397", "given_url": "https://dev.to/juniordevforlife/web-scraping-with-puppeteer-for-total-noobs-38j4", "given_title": "Web Scraping With Puppeteer for Total Noobs", "favorite": "0", "status": "1", "time_added": "1675152796", "time_updated": "1706833159", "time_read": "1675160011", "time_favorited": "0", "sort_id": 27, "resolved_title": "Web Scraping With Puppeteer for Total Noobs", "resolved_url": "https://dev.to/juniordevforlife/web-scraping-with-puppeteer-for-total-noobs-38j4", "excerpt": "Web scraping is something I never thought I'd do. I'm primarily a UI developer, although my career started as a backend developer. I've never been asked at a job to perform any scraping tasks, and I'd never had a personal project that required me to scrape some data until recently.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1096", "lang": "en", "time_to_read": 5, "top_image_url": "https://dev.to/social_previews/article/1347488.png", "tags": {"programming": {"item_id": "3797402397", "tag": "programming"}, "web-scraping": {"item_id": "3797402397", "tag": "web-scraping"}}, "image": {"item_id": "3797402397", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--O6M-mrIB--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1e49twnxojmux4sitysh.png", "width": "338", "height": "252"}, "images": {"1": {"item_id": "3797402397", "image_id": "1", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--O6M-mrIB--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1e49twnxojmux4sitysh.png", "width": "338", "height": "252", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The Practical Dev", "logo": "https://logo.clearbit.com/dev.to?size=800", "greyscale_logo": "https://logo.clearbit.com/dev.to?size=800&greyscale=true"}, "listen_duration_estimate": 424}, "3021978290": {"item_id": "3021978290", "resolved_id": "3021978290", "given_url": "https://www.scrapingbee.com/blog/web-scraping-ruby/", "given_title": "Web Scraping with Ruby | ScrapingBee", "favorite": "0", "status": "1", "time_added": "1675082486", "time_updated": "1679780678", "time_read": "1675097510", "time_favorited": "0", "sort_id": 28, "resolved_title": "Web Scraping with Ruby", "resolved_url": "https://www.scrapingbee.com/blog/web-scraping-ruby/", "excerpt": "This post will cover main tools and techniques for web scraping in Ruby. We start with an introduction to building a web scraper using common Ruby HTTP clients and parsing the response. This approach to web scraping has, however, its limitations and can come with a fair dose of frustration.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "0", "word_count": "3883", "lang": "en", "time_to_read": 18, "top_image_url": "https://www.scrapingbee.com/images/post/webscraping-ruby/header.jpg", "tags": {"ruby": {"item_id": "3021978290", "tag": "ruby"}, "web-scraping": {"item_id": "3021978290", "tag": "web-scraping"}}, "authors": {"7487352": {"item_id": "3021978290", "author_id": "7487352", "name": "Sylwia", "url": ""}}, "videos": {"1": {"item_id": "3021978290", "video_id": "1", "src": "https://www.scrapingbee.com/blog/web-scraping-ruby/kimurai-1.mp4", "width": "0", "height": "0", "type": "5", "vid": "", "length": "0"}, "2": {"item_id": "3021978290", "video_id": "2", "src": "https://www.scrapingbee.com/blog/web-scraping-ruby/kimurai-2.mp4", "width": "0", "height": "0", "type": "5", "vid": "", "length": "0"}, "3": {"item_id": "3021978290", "video_id": "3", "src": "https://www.scrapingbee.com/blog/web-scraping-ruby/kimurai-3.mp4", "width": "0", "height": "0", "type": "5", "vid": "", "length": "0"}}, "listen_duration_estimate": 1503}}, "error": nil, "search_meta": {"search_type": "normal"}, "since": 1709934988}