{"status": 1, "complete": 1, "list": {"2848510220": {"item_id": "2848510220", "resolved_id": "2848510220", "given_url": "http://ieeexplore.ieee.org/document/8621059", "given_title": "Feature Boosting Network For 3D Pose Estimation", "favorite": "0", "status": "1", "time_added": "1578658294", "time_updated": "1638708525", "time_read": "1582142817", "time_favorited": "0", "sort_id": 0, "resolved_title": "Feature Boosting Network For 3D Pose Estimation", "resolved_url": "https://ieeexplore.ieee.org/document/8621059", "excerpt": "In this paper, a feature boosting network is proposed for estimating 3D hand pose and 3D body pose from a single RGB image. In this method, the features learned by the convolutional layers are boosted with a new long short-term dependence-aware (LSTD) module, which enables the intermediate convolutional feature maps to perceive the graphical long short-term dependency among different hand (or body) parts using the designed Graphical ConvLSTM. Learning a set of features that are reliable and discriminatively representative of the pose of a hand (or body) part is difficult due to the ambiguities, texture and illumination variation, and self-occlusion in the real application of 3D pose estimation. To improve the reliability of the features for representing each body part and enhance the LSTD module, we further introduce a context consistency gate (CCG) in this paper, with which the convolutional feature maps are modulated according to their consistency with the context representations. We evaluate the proposed method on challenging benchmark datasets for 3D hand pose estimation and 3D full body pose estimation. Experimental results show the effectiveness of our method that achieves state-of-the-art performance on both of the tasks.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "top_image_url": "https://ieeexplore.ieee.org/assets/img/ieee_logo_smedia_200X200.png", "tags": {"boosting": {"item_id": "2848510220", "tag": "boosting"}, "deep-learning": {"item_id": "2848510220", "tag": "deep-learning"}, "pose-estimation": {"item_id": "2848510220", "tag": "pose-estimation"}}, "authors": {"1133402": {"item_id": "2848510220", "author_id": "1133402", "name": "Jun Liu", "url": ""}, "183370692": {"item_id": "2848510220", "author_id": "183370692", "name": "Henghui Ding", "url": ""}}, "listen_duration_estimate": 0}, "2604575224": {"item_id": "2604575224", "resolved_id": "2604533332", "given_url": "https://github.com/benedekrozemberczki/awesome-gradient-boosting-papers?utm_source=share&utm_medium=ios_app", "given_title": "", "favorite": "0", "status": "1", "time_added": "1558797365", "time_updated": "1612385105", "time_read": "1567124390", "time_favorited": "0", "sort_id": 1, "resolved_title": "Awesome Gradient Boosting Research Papers.", "resolved_url": "https://github.com/benedekrozemberczki/awesome-gradient-boosting-papers", "excerpt": "Awesome Gradient Boosting Research Papers.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "7099", "lang": "en", "time_to_read": 32, "top_image_url": "https://repository-images.githubusercontent.com/186163475/acd05400-7d84-11e9-8f05-84fedee77748", "tags": {"boosting": {"item_id": "2604575224", "tag": "boosting"}, "machine-learning": {"item_id": "2604575224", "tag": "machine-learning"}}, "image": {"item_id": "2604575224", "src": "https://camo.githubusercontent.com/abb97269de2982c379cbc128bba93ba724d8822bfbe082737772bd4feb59cb54/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2604575224", "image_id": "1", "src": "https://camo.githubusercontent.com/abb97269de2982c379cbc128bba93ba724d8822bfbe082737772bd4feb59cb54/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2604575224", "image_id": "2", "src": "https://camo.githubusercontent.com/0ff11ed110cfa69f703ef0dcca3cee6141c0a8ef465e8237221ae245de3deb3d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d77656c636f6d652d627269676874677265656e2e7376673f7374796c653d666c61742d737175617265", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2604575224", "image_id": "3", "src": "https://camo.githubusercontent.com/7c1a269ce6c08c29fedacb1db64619f13b2d320d4101ed4bb791688561d608b8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f62656e6564656b726f7a656d626572637a6b692f617765736f6d652d6772616469656e742d626f6f7374696e672d7061706572732e7376673f636f6c6f723d626c7565", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2604575224", "image_id": "4", "src": "https://camo.githubusercontent.com/ac83d747922f999d4d44c8d0742bfb938117e063b8017dbe9285fe397cfca2ce/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f7265706f2d73697a652f62656e6564656b726f7a656d626572637a6b692f617765736f6d652d6772616469656e742d626f6f7374696e672d7061706572732e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2604575224", "image_id": "5", "src": "https://camo.githubusercontent.com/ebe5384d312bf1a1ee8a51a6e5a8804099f8f24d28799b59c99bc348d015379f/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f62656e726f7a656d626572637a6b693f7374796c653d736f6369616c266c6f676f3d74776974746572", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2604575224", "image_id": "6", "src": "https://github.com/benedekrozemberczki/awesome-gradient-boosting-papers/raw/master/boosting.gif", "width": "450", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 2748}, "3079019519": {"item_id": "3079019519", "resolved_id": "3079019519", "given_url": "https://github.com/fabsig/GPBoost", "given_title": "GPBoost: Combining Tree-Boosting with Gaussian Process and Mixed Effects Mo", "favorite": "0", "status": "1", "time_added": "1624616840", "time_updated": "1624618013", "time_read": "1624618013", "time_favorited": "0", "sort_id": 2, "resolved_title": "GPBoost: Combining Tree-Boosting with Gaussian Process and Mixed Effects Models", "resolved_url": "https://github.com/fabsig/GPBoost", "excerpt": "GPBoost is a software library for combining tree-boosting with Gaussian process and mixed effects models. It also allows for independently doing tree-boosting as well as inference and prediction for Gaussian process and mixed effects models.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "616", "lang": "en", "time_to_read": 3, "top_image_url": "https://opengraph.githubassets.com/b65d4c0a752e467b7aeec980fe9a74ab7b3e6f0a9de3bf82b45c229ab76b4c2b/fabsig/GPBoost", "tags": {"boosting": {"item_id": "3079019519", "tag": "boosting"}, "gaussian": {"item_id": "3079019519", "tag": "gaussian"}, "machine-learning": {"item_id": "3079019519", "tag": "machine-learning"}, "python": {"item_id": "3079019519", "tag": "python"}}, "image": {"item_id": "3079019519", "src": "https://github.com/fabsig/GPBoost/blob/master/gpboost_sticker.jpg?raw=true", "width": "40", "height": "0"}, "images": {"1": {"item_id": "3079019519", "image_id": "1", "src": "https://github.com/fabsig/GPBoost/blob/master/gpboost_sticker.jpg?raw=true", "width": "40", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 238}, "2755893816": {"item_id": "2755893816", "resolved_id": "2755893816", "given_url": "https://github.com/stanfordmlgroup/ngboost", "given_title": "", "favorite": "0", "status": "1", "time_added": "1615293400", "time_updated": "1615318291", "time_read": "1615318290", "time_favorited": "0", "sort_id": 3, "resolved_title": "NGBoost: Natural Gradient Boosting for Probabilistic Prediction", "resolved_url": "https://github.com/stanfordmlgroup/ngboost", "excerpt": "ngboost is a Python library that implements Natural Gradient Boosting, as described in \"NGBoost: Natural Gradient Boosting for Probabilistic Prediction\".", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "253", "lang": "en", "top_image_url": "https://opengraph.githubassets.com/665cfdecc16f16035368bf48a66b3667043eb98fa33f796d0e3bf2fd817d6067/stanfordmlgroup/ngboost", "tags": {"boosting": {"item_id": "2755893816", "tag": "boosting"}, "machine-learning": {"item_id": "2755893816", "tag": "machine-learning"}}, "image": {"item_id": "2755893816", "src": "https://github.com/stanfordmlgroup/ngboost/workflows/Python%20package/badge.svg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2755893816", "image_id": "1", "src": "https://github.com/stanfordmlgroup/ngboost/workflows/Python%20package/badge.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2755893816", "image_id": "2", "src": "https://camo.githubusercontent.com/2a2157c971b7ae1deb8eb095799440551c33dcf61ea3d965d86b496a5a65df55/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d626c75652e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2755893816", "image_id": "3", "src": "https://camo.githubusercontent.com/d91ed7ac7abbd5a6102cbe988dd8e9ac21bde0a73d97be7603b891ad08ce3479/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 98}, "3458585818": {"item_id": "3458585818", "resolved_id": "3457406069", "given_url": "https://link.medium.com/IJAjhlTIqkb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1634479778", "time_updated": "1634504923", "time_read": "1634504923", "time_favorited": "0", "sort_id": 4, "resolved_title": "Benefits of the CatBoost Machine Learning Algorithm", "resolved_url": "https://towardsdatascience.com/benefits-of-the-catboost-machine-learning-algorithm-fcd8c1ff2a8", "excerpt": "Out with the old, and in with the new. More specifically, CatBoost [2] may be replacing XGBoost for many data scientists and ML engineers moving forward.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1270", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/1*rq3u687BjNwXKLa7ssum2w.jpeg", "tags": {"boosting": {"item_id": "3458585818", "tag": "boosting"}, "machine-learning": {"item_id": "3458585818", "tag": "machine-learning"}}, "authors": {"146315031": {"item_id": "3458585818", "author_id": "146315031", "name": "Matt Przybyla", "url": "https://datascience2.medium.com"}}, "image": {"item_id": "3458585818", "src": "https://miro.medium.com/fit/c/56/56/1*gNyyt6lkWJQOA_feKfvghQ@2x.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3458585818", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*gNyyt6lkWJQOA_feKfvghQ@2x.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3458585818", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*rq3u687BjNwXKLa7ssum2w.jpeg", "width": "700", "height": "467", "credit": "Ludemeula Fernandes on Unsplash [1]", "caption": ""}, "3": {"item_id": "3458585818", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*7fGZoZOiLb4XKyvSL0Dg0Q.jpeg", "width": "700", "height": "438", "credit": "Mikhail Vasilyev on Unsplash [3]", "caption": ""}, "4": {"item_id": "3458585818", "image_id": "4", "src": "https://miro.medium.com/max/1330/0*2iYYmcIeMMByK0US.png", "width": "665", "height": "568", "credit": "4", "caption": "Summary plot of CatBoost implementation of SHAP"}, "5": {"item_id": "3458585818", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*y1v_J1u-QzM0guOG4eejiQ.jpeg", "width": "700", "height": "466", "credit": "Kurt Cotoaga on Unsplash [6]", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 492}, "3261066739": {"item_id": "3261066739", "resolved_id": "777143948", "given_url": "https://scikit-learn.org/dev/auto_examples/ensemble/plot_gradient_boosting_quantile.html#prediction-intervals-for-gradient-boosting-regression", "given_title": "", "favorite": "0", "status": "1", "time_added": "1617028923", "time_updated": "1617138552", "time_read": "1617138552", "time_favorited": "0", "sort_id": 5, "resolved_title": "Prediction Intervals for Gradient Boosting Regression — scikit-learn 0.24.2 documentation", "resolved_url": "https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_quantile.html", "excerpt": "This example shows how quantile regression can be used to create prediction intervals.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "287", "lang": "en", "tags": {"boosting": {"item_id": "3261066739", "tag": "boosting"}, "machine-learning": {"item_id": "3261066739", "tag": "machine-learning"}}, "image": {"item_id": "3261066739", "src": "https://scikit-learn.org/stable/_images/sphx_glr_plot_gradient_boosting_quantile_001.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3261066739", "image_id": "1", "src": "https://scikit-learn.org/stable/_images/sphx_glr_plot_gradient_boosting_quantile_001.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 111}, "3285912319": {"item_id": "3285912319", "resolved_id": "3285912376", "given_url": "https://towardsdatascience.com/4-easy-steps-for-implementing-catboost-c196fd82274b?source=rss----7f60cf5620c9---4", "given_title": "4 Easy Steps for Implementing CatBoost", "favorite": "0", "status": "1", "time_added": "1616268926", "time_updated": "1616335732", "time_read": "1616335731", "time_favorited": "0", "sort_id": 6, "resolved_title": "", "resolved_url": "https://towardsdatascience.com/4-easy-steps-for-implementing-catboost-c196fd82274b", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"boosting": {"item_id": "3285912319", "tag": "boosting"}, "machine-learning": {"item_id": "3285912319", "tag": "machine-learning"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3278346944": {"item_id": "3278346944", "resolved_id": "3278346965", "given_url": "https://towardsdatascience.com/a-comprehensive-mathematical-approach-to-understand-adaboost-f185104edced?source=rss----7f60cf5620c9---4", "given_title": "A Comprehensive Mathematical Approach to Understand AdaBoost", "favorite": "0", "status": "1", "time_added": "1615501547", "time_updated": "1615503728", "time_read": "1615503727", "time_favorited": "0", "sort_id": 7, "resolved_title": "A Comprehensive Mathematical Approach to Understand AdaBoost", "resolved_url": "https://towardsdatascience.com/a-comprehensive-mathematical-approach-to-understand-adaboost-f185104edced", "excerpt": "Learn how AdaBoost works from a Math perspective, in a comprehensive and straight-to-the-point manner.Andrew WilliamFeb 28·12 min readIn this tutorial, I’ll be explaining how AdaBoost works through the math involved in it.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2535", "lang": "en", "time_to_read": 12, "top_image_url": "https://miro.medium.com/max/1200/1*iXE5khfhaitDWnVvwKCKTg.jpeg", "tags": {"boosting": {"item_id": "3278346944", "tag": "boosting"}, "machine-learning": {"item_id": "3278346944", "tag": "machine-learning"}}, "authors": {"147952243": {"item_id": "3278346944", "author_id": "147952243", "name": "Andrew William", "url": "https://andrew-william.medium.com"}}, "image": {"item_id": "3278346944", "src": "https://miro.medium.com/fit/c/56/56/1*-q6W3Vnj4Jb8k8UZ1KsqPQ.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3278346944", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*-q6W3Vnj4Jb8k8UZ1KsqPQ.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3278346944", "image_id": "2", "src": "https://miro.medium.com/max/6528/1*iXE5khfhaitDWnVvwKCKTg.jpeg", "width": "3264", "height": "2448", "credit": "Roman Mager on Unsplash", "caption": ""}, "3": {"item_id": "3278346944", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*9NjSsLHRSXUwl0cyvKbWGQ.png", "width": "700", "height": "638", "credit": "2009", "caption": "Modified from : Hastie, T., Tibshirani, R., & Friedman, J."}, "4": {"item_id": "3278346944", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*DVdys8z6Qobvmb0tFvm2XQ.png", "width": "700", "height": "360", "credit": "", "caption": "Visualization of how AdaBoost’s final predictions are made"}, "5": {"item_id": "3278346944", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*U16jWJJfhWa5QiQQhoa92g.png", "width": "700", "height": "226", "credit": "", "caption": "Steps 1–2a) of AdaBoost"}, "6": {"item_id": "3278346944", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*2DFPtONH1UpcX1tNAPaPCQ.png", "width": "700", "height": "325", "credit": "", "caption": "Subset of Iris Dataset as our actual dataset"}, "7": {"item_id": "3278346944", "image_id": "7", "src": "https://miro.medium.com/max/1000/1*JMm1dNDD6BwkktZXOvYeSQ.png", "width": "500", "height": "232", "credit": "", "caption": "Training Dataset sampled from the original dataset"}, "8": {"item_id": "3278346944", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*US8fXwA7fRgcbdO0zOIbXA.png", "width": "700", "height": "61", "credit": "", "caption": "Step 2b) of AdaBoost"}, "9": {"item_id": "3278346944", "image_id": "9", "src": "https://miro.medium.com/max/732/1*WdnVQz9fm9qqdkQXVCQJyA.png", "width": "366", "height": "501", "credit": "", "caption": "Performance of first stump on training set"}, "10": {"item_id": "3278346944", "image_id": "10", "src": "https://miro.medium.com/max/2214/1*lJKXXIj9_yBOpB8bDb4NWA.png", "width": "1107", "height": "511", "credit": "", "caption": ""}, "11": {"item_id": "3278346944", "image_id": "11", "src": "https://miro.medium.com/max/300/1*6hrsGiNIJQJ8hNjFS-x_pQ.png", "width": "150", "height": "508", "credit": "", "caption": "Left Table : The new weights for the data based on first stump’s performance on train set || Right Table: Result of sampling dataset from new weights"}, "12": {"item_id": "3278346944", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*S9Ohe2OcOpDZKWrAelTFLQ.png", "width": "700", "height": "300", "credit": "", "caption": "Steps 2c-2e of AdaBoost Algorithm"}, "13": {"item_id": "3278346944", "image_id": "13", "src": "https://miro.medium.com/max/782/1*eCFwnJcHfqwDuYw9xAawig.png", "width": "391", "height": "141", "credit": "x", "caption": "Equation 1a . Overall prediction of AdaBoost at iteration m, denoted by C_m"}, "14": {"item_id": "3278346944", "image_id": "14", "src": "https://miro.medium.com/max/750/1*k8UJKtexnFzZALEZENGIHA.png", "width": "375", "height": "73", "credit": "", "caption": "Equation 2a. Exponential loss for AdaBoost"}, "15": {"item_id": "3278346944", "image_id": "15", "src": "https://miro.medium.com/max/1044/1*JbnHZai75pIZDUciaUwVGg.png", "width": "522", "height": "78", "credit": "", "caption": ""}, "16": {"item_id": "3278346944", "image_id": "16", "src": "https://miro.medium.com/max/1166/1*sM282aby-n_5PifaAaSjIw.png", "width": "583", "height": "70", "credit": "", "caption": "Left : Eq 1b. Reformulation of C_m || Right : Eq 2b. Plugging the new formula for C_m into the error function"}, "17": {"item_id": "3278346944", "image_id": "17", "src": "https://miro.medium.com/max/660/1*n9HyKokCC6k5Wia0zGvOTw.png", "width": "330", "height": "78", "credit": "w_i ^m", "caption": "Equation 3. Weight of training sample i at iteration m"}, "18": {"item_id": "3278346944", "image_id": "18", "src": "https://miro.medium.com/max/1026/1*X8B6WqMs2W8-C-TR0sox1A.png", "width": "513", "height": "84", "credit": "weights of samples", "caption": "Equation 2c. Error function using Equation 3"}, "19": {"item_id": "3278346944", "image_id": "19", "src": "https://miro.medium.com/max/1400/1*QBAGTYIBY9FIyk0F5eb3bA.png", "width": "700", "height": "206", "credit": "", "caption": "Equation 2d. Error function as having a component made from incorrect classifications, and correct classifications respectively"}, "20": {"item_id": "3278346944", "image_id": "20", "src": "https://miro.medium.com/max/1238/1*Zu3vWEPCpyG8hiIEwklvLA.png", "width": "619", "height": "79", "credit": "", "caption": "Equation 4a. Derivative of Error function w.r.t alpha_m"}, "21": {"item_id": "3278346944", "image_id": "21", "src": "https://miro.medium.com/max/626/1*1Ow4YihgtB83q4OQtwhUcw.png", "width": "313", "height": "132", "credit": "", "caption": "Representation of summation components from equation 2d"}, "22": {"item_id": "3278346944", "image_id": "22", "src": "https://miro.medium.com/max/704/1*ga9Cs8QOqpE5DkONadCRpQ.png", "width": "352", "height": "66", "credit": "", "caption": "Representation of sum of weights of correctly classified samples"}, "23": {"item_id": "3278346944", "image_id": "23", "src": "https://miro.medium.com/max/1370/1*2lT1lRxS-IMd9vOupWqv8A.png", "width": "685", "height": "63", "credit": "", "caption": "Equation 4b. Derivative of E w.r.t to alpha_m, using T and W"}, "24": {"item_id": "3278346944", "image_id": "24", "src": "https://miro.medium.com/max/414/1*ZxbaCGDIPvWPwrWyzmXA6A.png", "width": "207", "height": "67", "credit": "", "caption": "Equation 4c. Manipulation of Equation 4b, making alpha_m on one side."}, "25": {"item_id": "3278346944", "image_id": "25", "src": "https://miro.medium.com/max/786/1*WxWT0Ul8kvmL3dBbIimWmw.png", "width": "393", "height": "178", "credit": "", "caption": "Equation 4d. Solving for alpha_m that minimizes error function"}, "26": {"item_id": "3278346944", "image_id": "26", "src": "https://miro.medium.com/max/398/1*aduT3nZTff3Id50FlinZJQ.png", "width": "199", "height": "612", "credit": "", "caption": "Graph of alpha_m against epsilon"}, "27": {"item_id": "3278346944", "image_id": "27", "src": "https://miro.medium.com/max/1400/1*lnQ-KvTdG6VFGiP9Ax_yZw.png", "width": "700", "height": "56", "credit": "", "caption": "Step 3) of AdaBoost"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 981}, "3824165484": {"item_id": "3824165484", "resolved_id": "3820758926", "given_url": "https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702?source=social.tw", "given_title": "", "favorite": "0", "status": "1", "time_added": "1681050400", "time_updated": "1681136494", "time_read": "1681136493", "time_favorited": "0", "sort_id": 8, "resolved_title": "Beginner’s Guide to the Must-Know LightGBM Hyperparameters", "resolved_url": "https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702", "excerpt": "LightGBM is a popular gradient-boosting framework. Usually, you will begin specifying the following core parameters: But where do you go from here? LightGBM has over 100 parameters [2] that can be tuned.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "937", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*gDW1lYGGBn1fIF-kscw06g@2x.jpeg", "tags": {"boosting": {"item_id": "3824165484", "tag": "boosting"}, "machine-learning": {"item_id": "3824165484", "tag": "machine-learning"}}, "authors": {"169303828": {"item_id": "3824165484", "author_id": "169303828", "name": "Leonie Monigatti", "url": "https://medium.com/@iamleonie"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 363}, "3300550986": {"item_id": "3300550986", "resolved_id": "3300550986", "given_url": "https://towardsdatascience.com/beginners-guide-to-xgboost-for-classification-problems-50f75aac5390", "given_title": "Beginner’s Guide to XGBoost for Classification Problems", "favorite": "0", "status": "1", "time_added": "1617804031", "time_updated": "1617830929", "time_read": "1617830929", "time_favorited": "0", "sort_id": 9, "resolved_title": "Beginner’s Guide to XGBoost for Classification Problems", "resolved_url": "https://towardsdatascience.com/beginners-guide-to-xgboost-for-classification-problems-50f75aac5390", "excerpt": "Bex T. Let me introduce you to the hottest Machine Learning library in the ML community — XGBoost. In recent years, it has been the main driving force behind the algorithms that win massive ML competitions.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1879", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/1200/1*QROfVQn2bKxrgKf9-VAVrQ.jpeg", "tags": {"boosting": {"item_id": "3300550986", "tag": "boosting"}, "machine-learning": {"item_id": "3300550986", "tag": "machine-learning"}}, "authors": {"144328593": {"item_id": "3300550986", "author_id": "144328593", "name": "Bex T.", "url": "https://ibexorigin.medium.com"}}, "image": {"item_id": "3300550986", "src": "https://miro.medium.com/fit/c/56/56/1*nr_fnJnhzIKrtzdvWOLlMg.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3300550986", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*nr_fnJnhzIKrtzdvWOLlMg.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3300550986", "image_id": "2", "src": "https://miro.medium.com/max/2000/1*QROfVQn2bKxrgKf9-VAVrQ.jpeg", "width": "1000", "height": "667", "credit": "Dom Gould on Pexels", "caption": ""}, "3": {"item_id": "3300550986", "image_id": "3", "src": "https://miro.medium.com/proxy/1*-0TO2LFfYl7EgmuDEsAMkA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3300550986", "image_id": "4", "src": "https://miro.medium.com/max/0/1*0e-3tgPVUJOhTfe2vRNjqg.png", "width": "0", "height": "0", "credit": "", "caption": "Image by the author. Decision tree to predict rain"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 727}, "3989984963": {"item_id": "3989984963", "resolved_id": "3989984975", "given_url": "https://towardsdatascience.com/boosting-algorithms-in-machine-learning-part-i-adaboost-b9d86041a521?source=rss----7f60cf5620c9---4", "given_title": "Boosting Algorithms in Machine Learning, Part I: AdaBoost", "favorite": "0", "status": "1", "time_added": "1704488348", "time_updated": "1704488853", "time_read": "1704488856", "time_favorited": "0", "sort_id": 10, "resolved_title": "Boosting Algorithms in Machine Learning, Part I: AdaBoost", "resolved_url": "https://towardsdatascience.com/boosting-algorithms-in-machine-learning-part-i-adaboost-b9d86041a521", "excerpt": "In machine learning, boosting is a kind of ensemble learning method that combines several weak learners into a single strong learner.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "297", "lang": "en", "top_image_url": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*O3fXJXD1GTlRCVVH", "tags": {"boosting": {"item_id": "3989984963", "tag": "boosting"}, "machine-learning": {"item_id": "3989984963", "tag": "machine-learning"}}, "authors": {"170728470": {"item_id": "3989984963", "author_id": "170728470", "name": "Gurjinder Kaur", "url": "https://medium.com/@gurjinderkaur95"}}, "image": {"item_id": "3989984963", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*sHLuc7ZZ3x1oihePC62aSQ.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3989984963", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*sHLuc7ZZ3x1oihePC62aSQ.png", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3989984963", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 115}, "3304741255": {"item_id": "3304741255", "resolved_id": "3304741285", "given_url": "https://towardsdatascience.com/diy-xgboost-library-in-less-than-200-lines-of-python-69b6bf25e7d9?source=rss----7f60cf5620c9---4", "given_title": "DIY XGBoost library in less than 200 lines of python", "favorite": "0", "status": "1", "time_added": "1618241741", "time_updated": "1618314195", "time_read": "1618314196", "time_favorited": "0", "sort_id": 11, "resolved_title": "XGBoost explained: DIY XGBoost library in less than 200 lines of python", "resolved_url": "https://towardsdatascience.com/diy-xgboost-library-in-less-than-200-lines-of-python-69b6bf25e7d9", "excerpt": "XGBoost is probably one of the most widely used libraries in data science. Many data scientists around the world are using it. It’s a very versatile algorithm that can be use to perform classification, regression as well as confidence intervals as shown in this article.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1623", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/1200/0*v7uP108oJifBZXrj", "tags": {"boosting": {"item_id": "3304741255", "tag": "boosting"}, "machine-learning": {"item_id": "3304741255", "tag": "machine-learning"}, "python": {"item_id": "3304741255", "tag": "python"}}, "authors": {"142005448": {"item_id": "3304741255", "author_id": "142005448", "name": "Saupin Guillaume", "url": "https://medium.com/@guillaume.saupin"}}, "image": {"item_id": "3304741255", "src": "https://miro.medium.com/max/1400/0*v7uP108oJifBZXrj", "width": "700", "height": "469"}, "images": {"1": {"item_id": "3304741255", "image_id": "1", "src": "https://miro.medium.com/max/1400/0*v7uP108oJifBZXrj", "width": "700", "height": "469", "credit": "Jens Lelie on Unsplash", "caption": ""}, "2": {"item_id": "3304741255", "image_id": "2", "src": "https://miro.medium.com/max/940/1*6JiNRLLaZiVmCIDwI7b0cQ.png", "width": "470", "height": "351", "credit": "", "caption": "A three-level decision tree. Image by the author."}, "3": {"item_id": "3304741255", "image_id": "3", "src": "https://miro.medium.com/max/846/1*4RuWqoeljq7jY525oWwVGw.png", "width": "423", "height": "111", "credit": "", "caption": "Objective formula. Formula by the author."}, "4": {"item_id": "3304741255", "image_id": "4", "src": "https://miro.medium.com/max/800/1*HIUjyaintVq7KoS8bEV2fA.png", "width": "400", "height": "158", "credit": "", "caption": "Regularization term. Formula by the author."}, "5": {"item_id": "3304741255", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*wKpQ-hXdrizZze9_1Lc3wQ.png", "width": "700", "height": "101", "credit": "", "caption": "Second-order expansion of the loss. Formula by the author."}, "6": {"item_id": "3304741255", "image_id": "6", "src": "https://miro.medium.com/max/832/1*YXfXo5EH5Dy7n4sEgGKdxg.png", "width": "416", "height": "240", "credit": "", "caption": "Gaussian and hessian formulas. Formula by the author."}, "7": {"item_id": "3304741255", "image_id": "7", "src": "https://miro.medium.com/max/594/1*Q7Nbq-3Giw53XfEZEUiQbA.png", "width": "297", "height": "145", "credit": "", "caption": "Optimal leaf value with respect to objective. Formula by the author."}, "8": {"item_id": "3304741255", "image_id": "8", "src": "https://miro.medium.com/max/972/1*3YNIy3auM6LYuainjezZMA.png", "width": "486", "height": "165", "credit": "", "caption": "Objective improvement when using optimal weight. Formula by the author."}, "9": {"item_id": "3304741255", "image_id": "9", "src": "https://miro.medium.com/max/348/1*UEPmfAakqbVsnZn7xJpljA.png", "width": "174", "height": "54", "credit": "", "caption": "Squared error loss function. Formula by the author"}, "10": {"item_id": "3304741255", "image_id": "10", "src": "https://miro.medium.com/max/236/1*GBVRp186tIT4uuWIRI3e6Q.png", "width": "118", "height": "64", "credit": "", "caption": "The gradient of the loss function. Formula by the author."}, "11": {"item_id": "3304741255", "image_id": "11", "src": "https://miro.medium.com/max/96/1*OI4DnqeHNX6P2nLTijYQ1Q.png", "width": "48", "height": "37", "credit": "", "caption": "Hessian of the loss function. Formula by the author."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 628}, "2907036500": {"item_id": "2907036500", "resolved_id": "2906974546", "given_url": "https://towardsdatascience.com/implementing-xgboost-from-scratch-6b7f2eb593c?source=rss----7f60cf5620c9---4", "given_title": "Implementing XGBoost from scratch", "favorite": "0", "status": "1", "time_added": "1583525188", "time_updated": "1612385105", "time_read": "1583785007", "time_favorited": "0", "sort_id": 12, "resolved_title": "Implementing XGBoost from scratch", "resolved_url": "https://towardsdatascience.com/implementing-xgboost-from-scratch-6b7f2eb593c", "excerpt": "XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It has been used in almost every machine learning hackathon and is usually the first preference while choosing a model.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "733", "lang": "en", "time_to_read": 3, "top_image_url": "https://miro.medium.com/max/1200/0*FUXQVipq3qlSd5uI", "tags": {"boosting": {"item_id": "2907036500", "tag": "boosting"}, "machine-learning": {"item_id": "2907036500", "tag": "machine-learning"}}, "authors": {"130299171": {"item_id": "2907036500", "author_id": "130299171", "name": "Siddhesh Jadhav", "url": "https://medium.com/@siddhesh_jadhav"}}, "image": {"item_id": "2907036500", "src": "https://miro.medium.com/fit/c/56/56/2*9GcAcgprmO_35y8NEX36Mw.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2907036500", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*9GcAcgprmO_35y8NEX36Mw.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2907036500", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*FUXQVipq3qlSd5uI", "width": "700", "height": "467", "credit": "Annie Spratt on Unsplash", "caption": ""}, "3": {"item_id": "2907036500", "image_id": "3", "src": "https://miro.medium.com/max/1400/0*1TdX-mAM9jVrauD9", "width": "700", "height": "467", "credit": "bruce mars on Unsplash", "caption": ""}, "4": {"item_id": "2907036500", "image_id": "4", "src": "https://miro.medium.com/max/492/1*Vc1E0iWtefXMjGZobKiDTQ.png", "width": "246", "height": "364", "credit": "", "caption": "Output for above code snippet"}, "5": {"item_id": "2907036500", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*4IKqcLNG7pyfwEmxBlIxuw.png", "width": "700", "height": "342", "credit": "", "caption": "Output after 2 iterations"}, "6": {"item_id": "2907036500", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*2nZPnWi-hnHzcRhKhwk_lA.png", "width": "700", "height": "291", "credit": "", "caption": "Output after 100 iterations"}, "7": {"item_id": "2907036500", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*RnNqyTycCZoRq98Uk6zajg.png", "width": "700", "height": "394", "credit": "", "caption": "Plot for above code snippet"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 284}, "3678312661": {"item_id": "3678312661", "resolved_id": "3678312661", "given_url": "https://towardsdatascience.com/shap-for-categorical-features-with-catboost-8315e14dac1", "given_title": "", "favorite": "0", "status": "1", "time_added": "1660308549", "time_updated": "1660353586", "time_read": "1660353586", "time_favorited": "0", "sort_id": 13, "resolved_title": "SHAP for Categorical Features with CatBoost", "resolved_url": "https://towardsdatascience.com/shap-for-categorical-features-with-catboost-8315e14dac1", "excerpt": "Typically, to model a categorical feature it first needs to be transformed using one-hot encodings. We end up with a binary variable for each category. The problem with this is that each variable will have its own SHAP value.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1328", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/0*hL5vA5El5XQ8BU96", "tags": {"boosting": {"item_id": "3678312661", "tag": "boosting"}, "machine-learning": {"item_id": "3678312661", "tag": "machine-learning"}}, "authors": {"150959613": {"item_id": "3678312661", "author_id": "150959613", "name": "Conor O'Sullivan", "url": "https://conorosullyds.medium.com"}}, "image": {"item_id": "3678312661", "src": "https://miro.medium.com/max/1400/0*hL5vA5El5XQ8BU96", "width": "700", "height": "525"}, "images": {"1": {"item_id": "3678312661", "image_id": "1", "src": "https://miro.medium.com/max/1400/0*hL5vA5El5XQ8BU96", "width": "700", "height": "525", "credit": "Andrew Ridley on Unsplash", "caption": ""}, "2": {"item_id": "3678312661", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*1XNCRcVli497OzBi.png", "width": "700", "height": "257", "credit": "source: author", "caption": "Figure 1: Mushroom dataset snapshot"}, "3": {"item_id": "3678312661", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*d5pz9f1nCXSWkNyD23rcoA.png", "width": "700", "height": "487", "credit": "source: author", "caption": "Figure 2: SHAP waterfall for CatBoost"}, "4": {"item_id": "3678312661", "image_id": "4", "src": "https://miro.medium.com/max/1400/0*xk7Vt3uiaMppYXoq.png", "width": "700", "height": "430", "credit": "source: author", "caption": "Figure 3: SHAP waterfall for one-hot encodings"}, "5": {"item_id": "3678312661", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*A4P3XSGN1XNV73HLxfUY3w.png", "width": "700", "height": "447", "credit": "source: author", "caption": "Figure 4: mean SHAP plot"}, "6": {"item_id": "3678312661", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*YWTbSa3aX_CvbyRERHE8zg.png", "width": "700", "height": "396", "credit": "source: author", "caption": "Figure 5: beeswarm plot"}, "7": {"item_id": "3678312661", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*N2bRNOjSgcPMTUrdD2hVyg.png", "width": "700", "height": "407", "credit": "source: author", "caption": "Figure 6: beeswarm for odor"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 514}, "3632030848": {"item_id": "3632030848", "resolved_id": "3632030873", "given_url": "https://towardsdatascience.com/xgboost-alternative-base-learners-a2dc72d97e64?source=rss----7f60cf5620c9---4", "given_title": "XGBoost Alternative Base Learners", "favorite": "0", "status": "1", "time_added": "1654257955", "time_updated": "1654258552", "time_read": "1654258552", "time_favorited": "0", "sort_id": 14, "resolved_title": "XGBoost Alternative Base Learners", "resolved_url": "https://towardsdatascience.com/xgboost-alternative-base-learners-a2dc72d97e64", "excerpt": "XGBoost, short for “Extreme Gradient Boosting,” is one of the strongest machine learning algorithms for handling tabular data, a well-deserved reputation due to its success in winning numerous Kaggle competitions.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2086", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/1200/1*_5zQeNoGrjoYUTbApfj-rw.png", "tags": {"boosting": {"item_id": "3632030848", "tag": "boosting"}, "machine-learning": {"item_id": "3632030848", "tag": "machine-learning"}}, "authors": {"142597389": {"item_id": "3632030848", "author_id": "142597389", "name": "Corey Wade", "url": "https://medium.com/@coreywade"}}, "image": {"item_id": "3632030848", "src": "https://miro.medium.com/max/1400/1*P-FY-BYIsTAZYPlQoiaPFw.jpeg", "width": "700", "height": "525"}, "images": {"1": {"item_id": "3632030848", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*P-FY-BYIsTAZYPlQoiaPFw.jpeg", "width": "700", "height": "525", "credit": "Duncan C, Flickr https://www.flickr.com/photos/duncan/99863704", "caption": ""}, "2": {"item_id": "3632030848", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*QdvY2S1wMh5g71E_9HZ50g.png", "width": "700", "height": "123", "credit": "", "caption": "California Housing DataFrame. Photo submitted by author."}, "3": {"item_id": "3632030848", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*hFdJRRJh0oig0ZIs7wXc8A.png", "width": "700", "height": "723", "credit": "", "caption": "GYassineMrabetTalk✉, CC BY 3.0 <https://creativecommons.org/licenses/by/3.0>, via Wikimedia Commons. https://commons.wikimedia.org/wiki/File:Linear_programming_graphical_solution.png"}, "4": {"item_id": "3632030848", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*lZiWZDvXzXV9Mlp9sr6OcQ.png", "width": "700", "height": "414", "credit": "", "caption": "Excerpt from Jupyter Notebook published in Hands-on Gradient Boosting with XGBoost and Scikit-learn. Photo submitted by author."}, "5": {"item_id": "3632030848", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*_5zQeNoGrjoYUTbApfj-rw.png", "width": "700", "height": "450", "credit": "", "caption": "Photo submitted by author."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 807}, "3286568053": {"item_id": "3286568053", "resolved_id": "3286568074", "given_url": "https://towardsdatascience.com/xgboost-extreme-gradient-boosting-how-to-improve-on-regular-gradient-boosting-5c6acf66c70a?source=rss----7f60cf5620c9---4", "given_title": "", "favorite": "0", "status": "1", "time_added": "1616352543", "time_updated": "1616353899", "time_read": "1616353899", "time_favorited": "0", "sort_id": 15, "resolved_title": "XGBoost optimizations", "resolved_url": "https://towardsdatascience.com/xgboost-extreme-gradient-boosting-how-to-improve-on-regular-gradient-boosting-5c6acf66c70a", "excerpt": "If you want to be a successful Data Scientist, you need to understand the differences between various Machine Learning Algorithms. This story is part of the series that looks at how different algorithms work and provides you with examples and Python code to help you along your Data Science journey.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1074", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/focal/1200/632/50/48/1*66fzuTlxboYEgTox3r9ZvA.png", "tags": {"boosting": {"item_id": "3286568053", "tag": "boosting"}, "machine-learning": {"item_id": "3286568053", "tag": "machine-learning"}}, "authors": {"148379686": {"item_id": "3286568053", "author_id": "148379686", "name": "Saul Dobilas", "url": "https://solclover.com"}}, "image": {"item_id": "3286568053", "src": "https://miro.medium.com/max/1400/1*66fzuTlxboYEgTox3r9ZvA.png", "width": "700", "height": "395"}, "images": {"1": {"item_id": "3286568053", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*66fzuTlxboYEgTox3r9ZvA.png", "width": "700", "height": "395", "credit": "", "caption": "XGBoost. Image by author."}, "2": {"item_id": "3286568053", "image_id": "2", "src": "https://miro.medium.com/max/2000/1*OiGbqPYF7QFASYlCQLOUBA.png", "width": "1000", "height": "296", "credit": "", "caption": "The process map for Gradient Boosting and XGBoost algorithms. Image by author."}, "3": {"item_id": "3286568053", "image_id": "3", "src": "https://miro.medium.com/max/916/1*0o1rvHRlign-mhkL-5SBCg.png", "width": "458", "height": "78", "credit": "", "caption": ""}, "4": {"item_id": "3286568053", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*FNxbJl7KNAQb0W2irktpmw.png", "width": "700", "height": "64", "credit": "", "caption": ""}, "5": {"item_id": "3286568053", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*WsK8DbhOqBhjMmymHsBV4g.png", "width": "700", "height": "34", "credit": "", "caption": ""}, "6": {"item_id": "3286568053", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*ce_kQzIGaNxgl3dpn4rJ5g.png", "width": "700", "height": "78", "credit": "", "caption": ""}, "7": {"item_id": "3286568053", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*ERRAjbQooIf9-FqR8ZcfxA.png", "width": "700", "height": "72", "credit": "", "caption": ""}, "8": {"item_id": "3286568053", "image_id": "8", "src": "https://miro.medium.com/max/2000/1*_uGLQadAwuS1FpVbLluUlw.png", "width": "1000", "height": "358", "credit": "", "caption": "Gradient Boosting Example. Image by author."}, "9": {"item_id": "3286568053", "image_id": "9", "src": "https://miro.medium.com/max/2000/1*W00bdW-ppVtxlQ9KPd9OZQ.png", "width": "1000", "height": "356", "credit": "", "caption": "Extreme Gradient Boosting example. Image by author."}, "10": {"item_id": "3286568053", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*UirJ8_pVPZ5K6XOqABWFaQ.png", "width": "700", "height": "345", "credit": "", "caption": "A snippet of Kaggle’s Australian weather data with some modifications. Image by author."}, "11": {"item_id": "3286568053", "image_id": "11", "src": "https://miro.medium.com/max/1400/1*F6sVyO7kzovoenjM5BNlHQ.png", "width": "700", "height": "761", "credit": "", "caption": "XGBoost model results. Image by author."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 416}, "3938932293": {"item_id": "3938932293", "resolved_id": "3938932293", "given_url": "https://towardsdatascience.com/xgboost-how-deep-learning-can-replace-gradient-boosting-and-decision-trees-part-2-training-b432620750f8", "given_title": "XGBoost: How Deep Learning Can Replace Gradient Boosting and Decision Trees", "favorite": "0", "status": "1", "time_added": "1695339605", "time_updated": "1695566856", "time_read": "1695566856", "time_favorited": "0", "sort_id": 16, "resolved_title": "XGBoost: How Deep Learning Can Replace Gradient Boosting and Decision Trees", "resolved_url": "https://towardsdatascience.com/xgboost-how-deep-learning-can-replace-gradient-boosting-and-decision-trees-part-2-training-b432620750f8", "excerpt": "you have learned about rewriting decision trees using a Differentiable Programming approach, as suggested by the NODE paper. The idea of this paper is to replace XGBoost by a Neural Network. The NODE paper shows that both can be handled using the entmax function.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "294", "lang": "en", "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/0*-JOVxdRTNEOODFEf", "tags": {"boosting": {"item_id": "3938932293", "tag": "boosting"}, "machine-learning": {"item_id": "3938932293", "tag": "machine-learning"}}, "authors": {"142005448": {"item_id": "3938932293", "author_id": "142005448", "name": "Saupin Guillaume", "url": "https://medium.com/@guillaume.saupin"}}, "image": {"item_id": "3938932293", "src": "https://miro.medium.com/v2/resize:fill:88:88/2*6JGfgbkxIy0-JVbQIinQnw.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3938932293", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/2*6JGfgbkxIy0-JVbQIinQnw.png", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3938932293", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 114}, "3287824623": {"item_id": "3287824623", "resolved_id": "3287824668", "given_url": "https://towardsdatascience.com/xgboost-regression-training-on-cpu-and-gpu-in-python-5a8187a43395?source=rss----7f60cf5620c9---4", "given_title": "Xgboost regression training on CPU and GPU in python", "favorite": "0", "status": "1", "time_added": "1616494099", "time_updated": "1616495165", "time_read": "1616495165", "time_favorited": "0", "sort_id": 17, "resolved_title": "Xgboost Regression Training on CPU and GPU in Python", "resolved_url": "https://towardsdatascience.com/xgboost-regression-training-on-cpu-and-gpu-in-python-5a8187a43395", "excerpt": "In this article, I want to go along with the steps that are needed to train xgboost models using a GPU and not the default CPU. Additionally, an analysis of how the training speeds are influenced by the sizes of the matrices and certain hyperparameters is presented as well.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "942", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/max/1200/1*Q6IdeF35djYrU177L_PoKA.jpeg", "tags": {"boosting": {"item_id": "3287824623", "tag": "boosting"}, "machine-learning": {"item_id": "3287824623", "tag": "machine-learning"}, "python": {"item_id": "3287824623", "tag": "python"}}, "authors": {"143628803": {"item_id": "3287824623", "author_id": "143628803", "name": "Eligijus Bujokas", "url": "https://eligijus-bujokas.medium.com"}}, "image": {"item_id": "3287824623", "src": "https://miro.medium.com/fit/c/56/56/1*Ld9l66RspBH-o7_35O_9-Q.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3287824623", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*Ld9l66RspBH-o7_35O_9-Q.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3287824623", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*Q6IdeF35djYrU177L_PoKA.jpeg", "width": "700", "height": "525", "credit": "", "caption": "GPU vs CPU; Drawing by the author"}, "3": {"item_id": "3287824623", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*7ND6tFTj0AjY76UzB972yA.png", "width": "700", "height": "657", "credit": "", "caption": "Inside of my desktop; photo owned by the author"}, "4": {"item_id": "3287824623", "image_id": "4", "src": "https://miro.medium.com/max/2000/1*tkc85ZZ9OnPTMNgGIAUQiQ.png", "width": "1000", "height": "398", "credit": "", "caption": "List of commands; Image by author"}, "5": {"item_id": "3287824623", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*g2rlxTTwcROj4ZiF2CFMUQ.png", "width": "700", "height": "274", "credit": "", "caption": "Snippet of data; Image by author"}, "6": {"item_id": "3287824623", "image_id": "6", "src": "https://miro.medium.com/max/368/1*zi3UmgSstEyxIjE5rrzSqw.png", "width": "184", "height": "177", "credit": "", "caption": "Unique categorical levels; Image by author"}, "7": {"item_id": "3287824623", "image_id": "7", "src": "https://miro.medium.com/max/808/1*3wg6zjt5b-il_6Kqi4cALA.png", "width": "404", "height": "262", "credit": "", "caption": "Y variable histogram; Image by author"}, "8": {"item_id": "3287824623", "image_id": "8", "src": "https://miro.medium.com/max/622/1*P-yzrcfDO33nLeKPn_83QA.png", "width": "311", "height": "157", "credit": "", "caption": "Dimensions; Image by author"}, "9": {"item_id": "3287824623", "image_id": "9", "src": "https://miro.medium.com/max/608/1*h8XcNSnBl93730cbkvVVOA.png", "width": "304", "height": "149", "credit": "", "caption": "CPU and GPU kwargs; Image by author"}, "10": {"item_id": "3287824623", "image_id": "10", "src": "https://miro.medium.com/max/1316/1*v2aBJ0ab63iqrOI9W64SAQ.png", "width": "658", "height": "606", "credit": "", "caption": "Training rows vs training time; Image by author"}, "11": {"item_id": "3287824623", "image_id": "11", "src": "https://miro.medium.com/max/592/1*ZMSy5_wMN_vF_o33tethQw.png", "width": "296", "height": "288", "credit": "", "caption": "Table of speeds I; Image by author"}, "12": {"item_id": "3287824623", "image_id": "12", "src": "https://miro.medium.com/max/792/1*_dG5nbOh0XGiVsG5K_o2kA.png", "width": "396", "height": "287", "credit": "", "caption": "Table of speeds II; Image by author"}, "13": {"item_id": "3287824623", "image_id": "13", "src": "https://miro.medium.com/max/1400/1*PoOhf4YZiGzia2Xt8OLnTw.png", "width": "700", "height": "596", "credit": "", "caption": "3D plane for the speed difference; Image by author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 365}, "2124354831": {"item_id": "2124354831", "resolved_id": "2124354831", "given_url": "https://www.kdnuggets.com/2018/03/catboost-vs-light-gbm-vs-xgboost.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1521802031", "time_updated": "1612385105", "time_read": "1522005457", "time_favorited": "0", "sort_id": 18, "resolved_title": "CatBoost vs. Light GBM vs. XGBoost", "resolved_url": "https://www.kdnuggets.com/2018/03/catboost-vs-light-gbm-vs-xgboost.html", "excerpt": "I recently participated in this Kaggle competition (WIDS Datathon by Stanford) where I was able to land up in Top 10 using various boosting algorithms.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1532", "lang": "en", "time_to_read": 7, "tags": {"boosting": {"item_id": "2124354831", "tag": "boosting"}, "machine-learning": {"item_id": "2124354831", "tag": "machine-learning"}}, "image": {"item_id": "2124354831", "src": "https://cdn-images-1.medium.com/max/1000/1*B9wDla365AI9HjZEcUFq6A.jpeg", "width": "99", "height": "0"}, "images": {"1": {"item_id": "2124354831", "image_id": "1", "src": "https://cdn-images-1.medium.com/max/1000/1*B9wDla365AI9HjZEcUFq6A.jpeg", "width": "99", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2124354831", "image_id": "2", "src": "https://cdn-images-1.medium.com/max/800/1*i0CA9ho0WArOj-0UdpuKGQ.png", "width": "99", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2124354831", "image_id": "3", "src": "https://cdn-images-1.medium.com/max/800/1*Zo9K6RiHvBdjYxJKLpsyaA.png", "width": "99", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2124354831", "image_id": "4", "src": "https://cdn-images-1.medium.com/max/800/1*09uNKZvIG2rhSpjTTnrDvw.png", "width": "99", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2124354831", "image_id": "5", "src": "https://cdn-images-1.medium.com/max/600/1*gw_AZFeu-Q0C95W6QWFJ2g.png", "width": "600", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2124354831", "image_id": "6", "src": "https://cdn-images-1.medium.com/max/800/1*pDN6jzHnCYBqlW4_RoT0Gg.png", "width": "500", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2124354831", "image_id": "7", "src": "https://cdn-images-1.medium.com/max/800/1*fR5nLi61SkS031Spb3qgLg.png", "width": "99", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2124354831", "image_id": "8", "src": "https://cdn-images-1.medium.com/max/1000/1*A0b_ahXOrrijazzJengwYw.png", "width": "99", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2124354831", "image_id": "9", "src": "https://cdn-images-1.medium.com/max/1000/1*w05Hg2QZ5ioDi2OXdCCMiw.png", "width": "99", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 593}, "3535825557": {"item_id": "3535825557", "resolved_id": "3535825567", "given_url": "https://www.kdnuggets.com/2022/01/data-scientists-reasons-lightgbm.html", "given_title": "3 Reasons Why Data Scientists Should Use LightGBM", "favorite": "0", "status": "1", "time_added": "1643030612", "time_updated": "1706233547", "time_read": "1643055053", "time_favorited": "0", "sort_id": 19, "resolved_title": "3 Reasons Why Data Scientists Should Use LightGBM", "resolved_url": "https://www.kdnuggets.com/3-reasons-why-data-scientists-should-use-lightgbm.html/", "excerpt": "There are many great boosting Python libraries for data scientists to reap the benefits of. In this article, the author discusses LightGBM benefits and how they are specific to your data science job. There are many great boosting Python libraries for data scientists to reap the benefits of.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "868", "lang": "en", "time_to_read": 4, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/przybyla-lightgbm-4.jpg", "tags": {"algorithms-math": {"item_id": "3535825557", "tag": "algorithms-math"}, "boosting": {"item_id": "3535825557", "tag": "boosting"}, "machine-learning": {"item_id": "3535825557", "tag": "machine-learning"}}, "authors": {"162202485": {"item_id": "3535825557", "author_id": "162202485", "name": "Matthew Przybyla", "url": "https://www.kdnuggets.com/author/matthew-przybyla"}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 336}, "3911204408": {"item_id": "3911204408", "resolved_id": "3911204410", "given_url": "https://www.kdnuggets.com/2023/07/lgbmclassifier-gettingstarted-guide.html", "given_title": "LGBMClassifier: A Getting Started Guide", "favorite": "0", "status": "1", "time_added": "1690640601", "time_updated": "1690664744", "time_read": "1690664744", "time_favorited": "0", "sort_id": 20, "resolved_title": "LGBMClassifier: A Getting Started Guide", "resolved_url": "https://www.kdnuggets.com/lgbmclassifier-a-getting-started-guide.html", "excerpt": "There are a vast number of machine learning algorithms that are apt to model specific phenomena.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1016", "lang": "en", "time_to_read": 5, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/chugh_lgbmclassifier_gettingstarted_guide_1.png", "tags": {"boosting": {"item_id": "3911204408", "tag": "boosting"}, "machine-learning": {"item_id": "3911204408", "tag": "machine-learning"}}, "authors": {"164770597": {"item_id": "3911204408", "author_id": "164770597", "name": "Vidhi Chugh", "url": "https://www.kdnuggets.com/author/vidhi-chugh"}}, "image": {"item_id": "3911204408", "src": "https://www.kdnuggets.com/wp-content/uploads/chugh_lgbmclassifier_gettingstarted_guide_1.png", "width": "100", "height": "0"}, "images": {"1": {"item_id": "3911204408", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/uploads/chugh_lgbmclassifier_gettingstarted_guide_1.png", "width": "100", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 393}}, "error": nil, "search_meta": {"search_type": "normal"}, "since": 1709169806}