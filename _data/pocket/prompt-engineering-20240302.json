{"status": 1, "complete": 1, "list": {"3813135366": {"item_id": "3813135366", "resolved_id": "3813135366", "given_url": "https://arxiv.org/pdf/2302.11382.pdf", "given_title": "2302.11382.pdf", "favorite": "0", "status": "1", "time_added": "1696174927", "time_updated": "1696362362", "time_read": "1696362362", "time_favorited": "0", "sort_id": 0, "resolved_title": "", "resolved_url": "https://arxiv.org/pdf/2302.11382.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"llms": {"item_id": "3813135366", "tag": "llms"}, "prompt-engineering": {"item_id": "3813135366", "tag": "prompt-engineering"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3898228147": {"item_id": "3898228147", "resolved_id": "3898228147", "given_url": "https://dev.to/kanani_nirav/chatgpt-prompts-a-guide-for-developers-p6m", "given_title": "ChatGPT Prompts: A Guide for Developers ?‚Äç?", "favorite": "0", "status": "1", "time_added": "1688496038", "time_updated": "1688999938", "time_read": "1688999938", "time_favorited": "0", "sort_id": 1, "resolved_title": "ChatGPT Prompts: A Guide for Developers üßë‚Äçüíª", "resolved_url": "https://dev.to/kanani_nirav/chatgpt-prompts-a-guide-for-developers-p6m", "excerpt": "In this article, we will demonstrate how to use different prompts to ask ChatGPT for help and make coding easier and more fun ü§© Sometimes as a developer, when we write code, we get stuck or need help.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "806", "lang": "en", "time_to_read": 4, "top_image_url": "https://dev.to/social_previews/article/1526014.png", "tags": {"chatgpt": {"item_id": "3898228147", "tag": "chatgpt"}, "prompt-engineering": {"item_id": "3898228147", "tag": "prompt-engineering"}}, "domain_metadata": {"name": "The Practical Dev", "logo": "https://logo.clearbit.com/dev.to?size=800", "greyscale_logo": "https://logo.clearbit.com/dev.to?size=800&greyscale=true"}, "listen_duration_estimate": 312}, "3935874788": {"item_id": "3935874788", "resolved_id": "3935874788", "given_url": "https://devblogs.microsoft.com/ise/2023/06/27/gpt-summary-prompt-engineering/", "given_title": "Large Language Model Prompt Engineering for Complex Summarization - ISE Dev", "favorite": "0", "status": "1", "time_added": "1694808519", "time_updated": "1706802574", "time_read": "1695684336", "time_favorited": "0", "sort_id": 2, "resolved_title": "Large Language Model Prompt Engineering for Complex Summarization", "resolved_url": "https://devblogs.microsoft.com/ise/2023/06/27/gpt-summary-prompt-engineering/", "excerpt": "In this post we‚Äôll demonstrate some prompt engineering techniques to create summaries of medical research publications.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "2132", "lang": "en", "time_to_read": 10, "top_image_url": "https://devblogs.microsoft.com/ise/wp-content/uploads/sites/55/2023/06/prompt-engineering-may23.png", "tags": {"llms": {"item_id": "3935874788", "tag": "llms"}, "prompt-engineering": {"item_id": "3935874788", "tag": "prompt-engineering"}}, "authors": {"152347": {"item_id": "3935874788", "author_id": "152347", "name": "John Stewart", "url": ""}}, "listen_duration_estimate": 825}, "3868425280": {"item_id": "3868425280", "resolved_id": "3868425282", "given_url": "https://digiday.com/media/how-this-conversational-ai-bot-helps-provide-mental-health-needs-for-workers/?utm_campaign=digidaydis&utm_medium=rss&utm_source=general-rss", "given_title": "WTF is prompt engineering?", "favorite": "0", "status": "1", "time_added": "1684493850", "time_updated": "1685213100", "time_read": "1685213100", "time_favorited": "0", "sort_id": 3, "resolved_title": "WTF is prompt engineering?", "resolved_url": "https://digiday.com/media/how-this-conversational-ai-bot-helps-provide-mental-health-needs-for-workers/", "excerpt": "Language models like ChatGPT ‚Äî which uses algorithms to process large amounts of data before spitting out an answer to prompted questions ‚Äî is prone to hallucinating, or giving irrelevant and incorrect responses.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "155", "lang": "en", "top_image_url": "https://digiday.com/wp-content/uploads/sites/3/2021/02/robot_nurture-02-02-02-02.jpg", "tags": {"prompt-engineering": {"item_id": "3868425280", "tag": "prompt-engineering"}}, "authors": {"181577935": {"item_id": "3868425280", "author_id": "181577935", "name": "Hailey Mensik", "url": "https://digiday.com/author/haileymensik/"}}, "domain_metadata": {"name": "Digiday", "logo": "https://logo.clearbit.com/digiday.com?size=800", "greyscale_logo": "https://logo.clearbit.com/digiday.com?size=800&greyscale=true"}, "listen_duration_estimate": 60}, "3918079040": {"item_id": "3918079040", "resolved_id": "3918079040", "given_url": "https://docs.cohere.com/docs/chaining-prompts", "given_title": "Chaining Prompts", "favorite": "0", "status": "1", "time_added": "1691771060", "time_updated": "1692018440", "time_read": "1692018440", "time_favorited": "0", "sort_id": 4, "resolved_title": "Chaining Prompts", "resolved_url": "https://docs.cohere.com/docs/chaining-prompts", "excerpt": "In the previous chapters, we have explored all things generative AI with the Cohere Platform. We looked at prompting models, generating use case ideas, working with the Generate endpoint, and creating custom models.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1777", "lang": "en", "time_to_read": 8, "tags": {"prompt-engineering": {"item_id": "3918079040", "tag": "prompt-engineering"}}, "image": {"item_id": "3918079040", "src": "https://files.readme.io/0986b67-image.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3918079040", "image_id": "1", "src": "https://files.readme.io/0986b67-image.png", "width": "0", "height": "0", "credit": "", "caption": "An overview of the story generation approach, consisting of multiple text generation prompts"}, "2": {"item_id": "3918079040", "image_id": "2", "src": "https://files.readme.io/6423bff-image.png", "width": "0", "height": "0", "credit": "", "caption": "The log line expands as we progress through the steps"}, "3": {"item_id": "3918079040", "image_id": "3", "src": "https://files.readme.io/65f25af-image.png", "width": "0", "height": "0", "credit": "", "caption": "Entering a story summary"}, "4": {"item_id": "3918079040", "image_id": "4", "src": "https://files.readme.io/6739f11-image.png", "width": "0", "height": "0", "credit": "", "caption": "Generating title suggestions"}, "5": {"item_id": "3918079040", "image_id": "5", "src": "https://files.readme.io/d616e45-image.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3918079040", "image_id": "6", "src": "https://files.readme.io/cd5d934-image.png", "width": "0", "height": "0", "credit": "", "caption": "Generating characters and their descriptions"}, "7": {"item_id": "3918079040", "image_id": "7", "src": "https://files.readme.io/a30e8b8-image.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3918079040", "image_id": "8", "src": "https://files.readme.io/68bb692-image.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3918079040", "image_id": "9", "src": "https://files.readme.io/d1deba6-image.png", "width": "0", "height": "0", "credit": "", "caption": "Generating story beats"}, "10": {"item_id": "3918079040", "image_id": "10", "src": "https://files.readme.io/95927fc-image.png", "width": "0", "height": "0", "credit": "", "caption": "Two types of narrative structures used by the paper. We‚Äôll use a simplified version of the second one."}, "11": {"item_id": "3918079040", "image_id": "11", "src": "https://files.readme.io/0c1d0dc-image.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3918079040", "image_id": "12", "src": "https://files.readme.io/b026a90-image.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3918079040", "image_id": "13", "src": "https://files.readme.io/ca1ef35-image.png", "width": "0", "height": "0", "credit": "", "caption": "Generating location descriptions"}, "14": {"item_id": "3918079040", "image_id": "14", "src": "https://files.readme.io/d2a8163-image.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "3918079040", "image_id": "15", "src": "https://files.readme.io/e339dc0-image.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "3918079040", "image_id": "16", "src": "https://files.readme.io/7dcaf4c-image.png", "width": "0", "height": "0", "credit": "", "caption": "Generating dialog"}, "17": {"item_id": "3918079040", "image_id": "17", "src": "https://files.readme.io/22e923e-image.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "3918079040", "image_id": "18", "src": "https://files.readme.io/f560aec-image.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 688}, "3828369493": {"item_id": "3828369493", "resolved_id": "3828369493", "given_url": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1680180511", "time_updated": "1681439271", "time_read": "1681439270", "time_favorited": "0", "sort_id": 5, "resolved_title": "Prompt Engineering", "resolved_url": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/", "excerpt": "Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4053", "lang": "en", "time_to_read": 18, "tags": {"llms": {"item_id": "3828369493", "tag": "llms"}, "prompt-engineering": {"item_id": "3828369493", "tag": "prompt-engineering"}}, "authors": {"76470090": {"item_id": "3828369493", "author_id": "76470090", "name": "Lilian Weng", "url": ""}}, "image": {"item_id": "3828369493", "src": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/SelfAsk-search.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3828369493", "image_id": "1", "src": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/SelfAsk-search.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3828369493", "image_id": "2", "src": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/tree-of-thoughts.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3828369493", "image_id": "3", "src": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/PoT.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3828369493", "image_id": "4", "src": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/TALM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3828369493", "image_id": "5", "src": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/TALM-iteration.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3828369493", "image_id": "6", "src": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/toolformer.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3828369493", "image_id": "7", "src": "https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/toolformer-annotation.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1569}, "3859154948": {"item_id": "3859154948", "resolved_id": "3858108170", "given_url": "https://medium.com/towards-data-science/the-art-of-prompt-design-use-clear-syntax-4fc846c1ebd5", "given_title": "", "favorite": "0", "status": "1", "time_added": "1684602033", "time_updated": "1685291139", "time_read": "1685291139", "time_favorited": "0", "sort_id": 6, "resolved_title": "The Art of Prompt Design: Use Clear Syntax", "resolved_url": "https://towardsdatascience.com/the-art-of-prompt-design-use-clear-syntax-4fc846c1ebd5", "excerpt": "This is the first installment of a series on how to use guidance to control large language models (LLMs), written jointly with Marco Tulio Ribeiro. We‚Äôll start from the basics and work our way up to more advanced topics.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "2286", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*4q-D4si5XBmcPph7jhOcdA.png", "tags": {"prompt-engineering": {"item_id": "3859154948", "tag": "prompt-engineering"}}, "authors": {"92213802": {"item_id": "3859154948", "author_id": "92213802", "name": "Scott Lundberg", "url": "https://medium.com/@scottmlundberg"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 885}, "3905331816": {"item_id": "3905331816", "resolved_id": "3905331816", "given_url": "https://thesequence.substack.com/p/edge-309-what-is-active-prompting", "given_title": "Edge 309: What is Active Prompting?", "favorite": "0", "status": "1", "time_added": "1689685386", "time_updated": "1690067596", "time_read": "1690067596", "time_favorited": "0", "sort_id": 7, "resolved_title": "Edge 309: What is Active Prompting?", "resolved_url": "https://thesequence.substack.com/p/edge-309-what-is-active-prompting", "excerpt": "An overview of active prompting. Active prompting is one of the most novel techniques used to determine the effectiness of certain prompts in order to accomplish specific tasks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "133", "lang": "en", "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3d72fea3-99be-4fbe-942d-f0531b8b24b3_1024x1024.png", "tags": {"prompt-engineering": {"item_id": "3905331816", "tag": "prompt-engineering"}}, "authors": {"86252": {"item_id": "3905331816", "author_id": "86252", "name": "Jesus Rodriguez", "url": ""}}, "listen_duration_estimate": 51}, "3925060327": {"item_id": "3925060327", "resolved_id": "3903060640", "given_url": "https://towardsdatascience.com/a-practical-introduction-to-llms-65194dda1148?utm_source=pocket_reader", "given_title": "A Practical Introduction to LLMs", "favorite": "0", "status": "1", "time_added": "1692962196", "time_updated": "1693003963", "time_read": "1693003963", "time_favorited": "0", "sort_id": 8, "resolved_title": "A Practical Introduction to LLMs", "resolved_url": "https://towardsdatascience.com/a-practical-introduction-to-llms-65194dda1148", "excerpt": "This is the first article in a series on using Large Language Models (LLMs) in practice. Here I will give an introduction to LLMs and present 3 levels of working with them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1544", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/0*Nl-5C1WBW4XdGkNI", "tags": {"llms": {"item_id": "3925060327", "tag": "llms"}, "prompt-engineering": {"item_id": "3925060327", "tag": "prompt-engineering"}}, "authors": {"143628755": {"item_id": "3925060327", "author_id": "143628755", "name": "Shawhin Talebi", "url": "https://shawhin.medium.com"}}, "image": {"item_id": "3925060327", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*mhVX2L2LGQM4XZNwvU7H5A.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3925060327", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*mhVX2L2LGQM4XZNwvU7H5A.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3925060327", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 598}, "4013436730": {"item_id": "4013436730", "resolved_id": "4013436748", "given_url": "https://towardsdatascience.com/an-introduction-to-prompting-for-llms-61d36aec2048?source=rss----7f60cf5620c9---4", "given_title": "An Introduction to Prompting for LLMs", "favorite": "0", "status": "1", "time_added": "1708901334", "time_updated": "1709183632", "time_read": "1709183632", "time_favorited": "0", "sort_id": 9, "resolved_title": "An Introduction to Prompting for LLMs", "resolved_url": "https://towardsdatascience.com/an-introduction-to-prompting-for-llms-61d36aec2048", "excerpt": "Unless you‚Äôve been completely disconnected from the buzz on social media and in the news, it‚Äôs unlikely that you‚Äôd have missed the excitement around Large Language Models (LLMs). LLMs have become ubiquitous, with new models being released almost daily.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "7380", "lang": "en", "time_to_read": 34, "top_image_url": "https://miro.medium.com/v2/resize:fit:795/1*q75Lv523Rr13bLRnQVSiXQ.png", "tags": {"prompt-engineering": {"item_id": "4013436730", "tag": "prompt-engineering"}}, "authors": {"188306971": {"item_id": "4013436730", "author_id": "188306971", "name": "Anand Subramanian", "url": "https://medium.com/@anand.subu10"}}, "image": {"item_id": "4013436730", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*IfxBBsal-XaXfAXh_c9g1A.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "4013436730", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*IfxBBsal-XaXfAXh_c9g1A.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "4013436730", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 2857}, "3908493553": {"item_id": "3908493553", "resolved_id": "3908493573", "given_url": "https://towardsdatascience.com/chain-of-thought-prompting-for-llms-33c963eead38?source=rss----7f60cf5620c9---4", "given_title": "Chain of Thought Prompting for LLMs", "favorite": "0", "status": "1", "time_added": "1690211392", "time_updated": "1690550594", "time_read": "1690550594", "time_favorited": "0", "sort_id": 10, "resolved_title": "Chain of Thought Prompting for LLMs", "resolved_url": "https://towardsdatascience.com/chain-of-thought-prompting-for-llms-33c963eead38", "excerpt": "The success of large language models (LLMs) stems from our ability to pre-train (using a language modeling objective) decoder-only transformer models across massive textual corpora. Given that we pre-train sufficiently large models, LLMs are incredibly capable few-shot learners.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "308", "lang": "en", "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*g5Q-4lGt9UySnOK0JRQiPg.jpeg", "tags": {"llms": {"item_id": "3908493553", "tag": "llms"}, "prompt-engineering": {"item_id": "3908493553", "tag": "prompt-engineering"}}, "authors": {"125209980": {"item_id": "3908493553", "author_id": "125209980", "name": "Cameron R. Wolfe", "url": ""}}, "image": {"item_id": "3908493553", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*wv4savxpgdp3RXjMrCYrXQ.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3908493553", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*wv4savxpgdp3RXjMrCYrXQ.png", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3908493553", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 119}, "3924954789": {"item_id": "3924954789", "resolved_id": "3924954789", "given_url": "https://towardsdatascience.com/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f", "given_title": "Prompt Engineering‚Ää‚Äî‚ÄäHow to trick AI into solving your problems", "favorite": "0", "status": "1", "time_added": "1692960717", "time_updated": "1693512231", "time_read": "1693512231", "time_favorited": "0", "sort_id": 11, "resolved_title": "Prompt Engineering‚Ää‚Äî‚ÄäHow to trick AI into solving your problems", "resolved_url": "https://towardsdatascience.com/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f", "excerpt": "This is the fourth article in a series on using large language models (LLMs) in practice. Here, I will discuss prompt engineering (PE) and how to use it to build LLM-enabled applications.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3441", "lang": "en", "time_to_read": 16, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/0*ZcfH-qxXT4AYAqwr", "tags": {"llms": {"item_id": "3924954789", "tag": "llms"}, "prompt-engineering": {"item_id": "3924954789", "tag": "prompt-engineering"}}, "authors": {"143628755": {"item_id": "3924954789", "author_id": "143628755", "name": "Shawhin Talebi", "url": "https://shawhin.medium.com"}}, "image": {"item_id": "3924954789", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*mhVX2L2LGQM4XZNwvU7H5A.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3924954789", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*mhVX2L2LGQM4XZNwvU7H5A.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3924954789", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1332}, "3861597253": {"item_id": "3861597253", "resolved_id": "3861597253", "given_url": "https://towardsdatascience.com/the-art-of-prompt-design-prompt-boundaries-and-token-healing-3b2448b0be38", "given_title": "The Art of Prompt Design: Prompt Boundaries and Token Healing", "favorite": "0", "status": "1", "time_added": "1683561803", "time_updated": "1685270299", "time_read": "1685270298", "time_favorited": "0", "sort_id": 12, "resolved_title": "The Art of Prompt Design: Prompt Boundaries and Token Healing", "resolved_url": "https://towardsdatascience.com/the-art-of-prompt-design-prompt-boundaries-and-token-healing-3b2448b0be38", "excerpt": "This (written jointly with Marco Tulio Ribeiro) is part 2 of a series on the art of prompt design (part 1 here), where we talk about controlling large language models (LLMs) with guidance.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1402", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*PPLOArQM0wXZ5V55VbTNYA.png", "tags": {"gpt": {"item_id": "3861597253", "tag": "gpt"}, "llms": {"item_id": "3861597253", "tag": "llms"}, "prompt-engineering": {"item_id": "3861597253", "tag": "prompt-engineering"}}, "authors": {"92213802": {"item_id": "3861597253", "author_id": "92213802", "name": "Scott Lundberg", "url": "https://medium.com/@scottmlundberg"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 543}, "3867987038": {"item_id": "3867987038", "resolved_id": "3867987038", "given_url": "https://towardsdatascience.com/the-emerging-art-of-prompt-engineering-b86fa70de6ca", "given_title": "The Emerging Art of Prompt Engineering", "favorite": "0", "status": "1", "time_added": "1684431956", "time_updated": "1685213114", "time_read": "1685213114", "time_favorited": "0", "sort_id": 13, "resolved_title": "The Emerging Art of Prompt Engineering", "resolved_url": "https://towardsdatascience.com/the-emerging-art-of-prompt-engineering-b86fa70de6ca", "excerpt": "By now, even the most casual generative-AI tinkerer knows that the specificity of one‚Äôs prompt determines, to a large extent, the quality of a model‚Äôs output‚Äîwhether that‚Äôs a realistic image, an on-topic paragraph, or a code block that actually works.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "477", "lang": "en", "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/0*fehyeb7ieER7qFym", "tags": {"prompt-engineering": {"item_id": "3867987038", "tag": "prompt-engineering"}}, "authors": {"181672459": {"item_id": "3867987038", "author_id": "181672459", "name": "Follow", "url": "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7e12c71dfa81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-emerging-art-of-prompt-engineering-b86fa70de6ca&user=TDS+Editors&userId=7e12c71dfa81&source=post_page-7e12c71dfa81----b86fa70de6ca---------------------post_header-----------"}}, "image": {"item_id": "3867987038", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*W8dhinLQHGYmwipTuH0k3A.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3867987038", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*W8dhinLQHGYmwipTuH0k3A.png", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3867987038", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 185}, "3845251749": {"item_id": "3845251749", "resolved_id": "3845251760", "given_url": "https://towardsdatascience.com/the-magic-of-llms-prompt-engineering-9c3e46130131?source=rss----7f60cf5620c9---4", "given_title": "The Magic of LLMs‚Ää‚Äî‚ÄäPrompt Engineering", "favorite": "0", "status": "1", "time_added": "1681384846", "time_updated": "1681426047", "time_read": "1681426047", "time_favorited": "0", "sort_id": 14, "resolved_title": "The Magic of LLMs‚Ää‚Äî‚ÄäPrompt Engineering", "resolved_url": "https://towardsdatascience.com/the-magic-of-llms-prompt-engineering-9c3e46130131", "excerpt": "Large language models (LLMs) are able to conversationally provide an unprecedented level of ML-generated information when asked the right question.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1263", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/0*ri0kB_t9WfNZtpLe", "tags": {"llms": {"item_id": "3845251749", "tag": "llms"}, "prompt-engineering": {"item_id": "3845251749", "tag": "prompt-engineering"}}, "authors": {"146668156": {"item_id": "3845251749", "author_id": "146668156", "name": "Frank Neugebauer", "url": "https://franklyai.medium.com"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 489}, "3936472349": {"item_id": "3936472349", "resolved_id": "3932222104", "given_url": "https://www.exponentialview.co/p/promptpack-using-code-interpreter?utm_medium=email", "given_title": "? Promptpack: Using Code Interpreter to crack your marketing funnel", "favorite": "0", "status": "1", "time_added": "1694960164", "time_updated": "1706802574", "time_read": "1695684321", "time_favorited": "0", "sort_id": 15, "resolved_title": "üêô Promptpack: Using Code Interpreter to crack your marketing funnel", "resolved_url": "https://www.exponentialview.co/p/promptpack-using-code-interpreter", "excerpt": "Recently, I introduced you to Code Interpreter1 ‚Äî a powerful feature that allows ChatGPT to write, run and iterate Python code within the browser. In today‚Äôs Promptpack, I will showcase high-level examples of how it can be applied to some marketing activities.¬†", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "513", "lang": "en", "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09361104-059f-437d-9ebc-f9569678a76e_1456x816.png", "tags": {"prompt-engineering": {"item_id": "3936472349", "tag": "prompt-engineering"}}, "authors": {"7154254": {"item_id": "3936472349", "author_id": "7154254", "name": "Azeem Azhar", "url": ""}}, "image": {"item_id": "3936472349", "src": "https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcaef3f0-5860-4035-b4c5-9a612858f1f0_1398x788.png", "width": "140", "height": "140"}, "images": {"1": {"item_id": "3936472349", "image_id": "1", "src": "https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcaef3f0-5860-4035-b4c5-9a612858f1f0_1398x788.png", "width": "140", "height": "140", "credit": "", "caption": "? Promptpack: Getting started with Code Interpreter"}}, "listen_duration_estimate": 199}, "3899421887": {"item_id": "3899421887", "resolved_id": "3899414414", "given_url": "https://www.kdnuggets.com/2023/07/power-chain-thought-prompting-large-language-models.html", "given_title": "Unraveling the Power of Chain-of-Thought Prompting in Large Language Models", "favorite": "0", "status": "1", "time_added": "1688670475", "time_updated": "1689188727", "time_read": "1689188727", "time_favorited": "0", "sort_id": 16, "resolved_title": "Unraveling the Power of Chain-of-Thought Prompting in Large Language Models", "resolved_url": "https://www.kdnuggets.com/unraveling-the-power-of-chain-of-thought-prompting-in-large-language-models.html", "excerpt": "Large Language Models (LLMs) have revolutionized the field of artificial intelligence, offering unprecedented capabilities in natural language understanding and generation. However, their ability to perform complex reasoning tasks has been a subject of intense research.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "854", "lang": "en", "time_to_read": 4, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/cot-brain-model-chains.jpg", "tags": {"llms": {"item_id": "3899421887", "tag": "llms"}, "prompt-engineering": {"item_id": "3899421887", "tag": "prompt-engineering"}}, "authors": {"77311567": {"item_id": "3899421887", "author_id": "77311567", "name": "Matthew Mayo", "url": "https://www.kdnuggets.com/author/matt-mayo"}}, "image": {"item_id": "3899421887", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500"}, "images": {"1": {"item_id": "3899421887", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 331}, "3944068200": {"item_id": "3944068200", "resolved_id": "3944035126", "given_url": "https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique", "given_title": "Parallel Processing in Prompt Engineering: The Skeleton-of-Thought Techniqu", "favorite": "0", "status": "1", "time_added": "1696294456", "time_updated": "1706802574", "time_read": "1696699742", "time_favorited": "0", "sort_id": 17, "resolved_title": "Parallel Processing in Prompt Engineering: The Skeleton-of-Thought Technique", "resolved_url": "https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique.html", "excerpt": "Skeleton-of-Thought (SoT) is an innovative prompt engineering technique that minimizes generation latency in Large Language Models (LLMs), enhancing their efficiency By creating a skeleton of the answer and then parallelly elaborating on each point, SoT emulates human thinking, promoting more reliab", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "631", "lang": "en", "time_to_read": 3, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/skeleton-of-thought-header.png", "tags": {"llms": {"item_id": "3944068200", "tag": "llms"}, "prompt-engineering": {"item_id": "3944068200", "tag": "prompt-engineering"}}, "authors": {"77311567": {"item_id": "3944068200", "author_id": "77311567", "name": "Matthew Mayo", "url": "https://www.kdnuggets.com/author/matt-mayo"}}, "image": {"item_id": "3944068200", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500"}, "images": {"1": {"item_id": "3944068200", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 244}, "3947488893": {"item_id": "3947488893", "resolved_id": "3947488897", "given_url": "https://www.kdnuggets.com/unlocking-gpt-4-summarization-with-chain-of-density-prompting", "given_title": "Unlocking GPT-4 Summarization with Chain of Density Prompting", "favorite": "0", "status": "1", "time_added": "1696852013", "time_updated": "1706802574", "time_read": "1697764404", "time_favorited": "0", "sort_id": 18, "resolved_title": "Unlocking GPT-4 Summarization with Chain of Density Prompting", "resolved_url": "https://www.kdnuggets.com/unlocking-gpt-4-summarization-with-chain-of-density-prompting.html", "excerpt": "Chain of Density (CoD) is a novel prompt engineering technique designed for optimizing summarization tasks in Large Language Models like GPT-4 The technique deals with controlling the information density in the generated summary, providing a balanced output that is neither too sparse nor too dense C", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "835", "lang": "en", "time_to_read": 4, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/chain-of-density-header-3.png", "tags": {"llms": {"item_id": "3947488893", "tag": "llms"}, "prompt-engineering": {"item_id": "3947488893", "tag": "prompt-engineering"}}, "authors": {"77311567": {"item_id": "3947488893", "author_id": "77311567", "name": "Matthew Mayo", "url": "https://www.kdnuggets.com/author/matt-mayo"}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 323}, "4010809329": {"item_id": "4010809329", "resolved_id": "4010809329", "given_url": "https://www.marktechpost.com/2024/02/20/unlocking-ais-potential-a-comprehensive-survey-of-prompt-engineering-techniques/", "given_title": "Unlocking AI‚Äôs Potential: A Comprehensive Survey of Prompt Engineering Tech", "favorite": "0", "status": "1", "time_added": "1708473464", "time_updated": "1709246629", "time_read": "1709246629", "time_favorited": "0", "sort_id": 19, "resolved_title": "Unlocking AI‚Äôs Potential: A Comprehensive Survey of Prompt Engineering Techniques", "resolved_url": "https://www.marktechpost.com/2024/02/20/unlocking-ais-potential-a-comprehensive-survey-of-prompt-engineering-techniques/", "excerpt": "Prompt engineering has burgeoned into a pivotal technique for augmenting the capabilities of large language models (LLMs) and vision-language models (VLMs), utilizing task-specific instructions or prompts to amplify model efficacy without altering core model parameters.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "454", "lang": "en", "amp_url": "https://www.marktechpost.com/2024/02/20/unlocking-ais-potential-a-comprehensive-survey-of-prompt-engineering-techniques/?amp", "top_image_url": "https://www.marktechpost.com/wp-content/uploads/2024/02/Screenshot-2024-02-20-at-3.44.55-PM.png", "tags": {"prompt-engineering": {"item_id": "4010809329", "tag": "prompt-engineering"}}, "authors": {"185440471": {"item_id": "4010809329", "author_id": "185440471", "name": "Adnan Hassan", "url": "https://www.marktechpost.com/author/adnanhassan_01/"}}, "image": {"item_id": "4010809329", "src": "https://www.marktechpost.com/wp-content/uploads/2024/02/Screenshot-2024-02-20-at-3.44.55-PM.png", "width": "696", "height": "389"}, "images": {"1": {"item_id": "4010809329", "image_id": "1", "src": "https://www.marktechpost.com/wp-content/uploads/2024/02/Screenshot-2024-02-20-at-3.44.55-PM.png", "width": "696", "height": "389", "credit": "", "caption": "https://arxiv.org/abs/2402.07927"}}, "listen_duration_estimate": 176}, "3875551992": {"item_id": "3875551992", "resolved_id": "3875551992", "given_url": "https://www.practicalecommerce.com/chatgpt-prompts-for-text-analysis", "given_title": "", "favorite": "0", "status": "1", "time_added": "1685286067", "time_updated": "1685289706", "time_read": "1685289705", "time_favorited": "0", "sort_id": 20, "resolved_title": "6 ChatGPT Prompts for Text Analysis", "resolved_url": "https://www.practicalecommerce.com/chatgpt-prompts-for-text-analysis", "excerpt": "ChatGPT can analyze content, not just produce it. What follows are six ChatGPT prompts to improve text for search engine optimization and social media. But don‚Äôt stop there. Ask:", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "532", "lang": "en", "top_image_url": "https://www.practicalecommerce.com/wp-content/uploads/2023/05/6-ChatGPT-Prompts-for-Text-Analysis.jpg", "tags": {"chatgpt": {"item_id": "3875551992", "tag": "chatgpt"}, "ecommerce": {"item_id": "3875551992", "tag": "ecommerce"}, "keywords-ppc-seo": {"item_id": "3875551992", "tag": "keywords-ppc-seo"}, "prompt-engineering": {"item_id": "3875551992", "tag": "prompt-engineering"}}, "authors": {"89778274": {"item_id": "3875551992", "author_id": "89778274", "name": "Editorial Policy", "url": "https://www.practicalecommerce.com/editorial-policy"}}, "listen_duration_estimate": 206}, "3894470351": {"item_id": "3894470351", "resolved_id": "3894470351", "given_url": "https://www.practicalecommerce.com/tools-and-communities-for-ai-prompt-inspiration", "given_title": "10 Tools for ChatGPT Prompt Ideas - Practical Ecommerce", "favorite": "0", "status": "1", "time_added": "1688942292", "time_updated": "1689188497", "time_read": "1689188497", "time_favorited": "0", "sort_id": 21, "resolved_title": "10 Tools for ChatGPT Prompt Ideas", "resolved_url": "https://www.practicalecommerce.com/tools-and-communities-for-ai-prompt-inspiration", "excerpt": "ChatGPT is only as good as the prompt. In my experience, it is not so much about creating a detailed prompt as knowing what to ask. It‚Äôs not as easy as it would seem. I tend to use the same prompts repeatedly instead of brainstorming something new.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "526", "lang": "en", "top_image_url": "https://www.practicalecommerce.com/wp-content/uploads/2023/06/10-Tools-and-Communities-for-ChatGPT-Prompt-Ideas.jpg", "tags": {"chatgpt": {"item_id": "3894470351", "tag": "chatgpt"}, "prompt-engineering": {"item_id": "3894470351", "tag": "prompt-engineering"}}, "authors": {"89778274": {"item_id": "3894470351", "author_id": "89778274", "name": "Editorial Policy", "url": "https://www.practicalecommerce.com/editorial-policy"}}, "listen_duration_estimate": 204}, "3827312262": {"item_id": "3827312262", "resolved_id": "3827312262", "given_url": "https://www.promptingguide.ai/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1684851343", "time_updated": "1685213022", "time_read": "1685213022", "time_favorited": "0", "sort_id": 22, "resolved_title": "Prompt Engineering Guide", "resolved_url": "https://www.promptingguide.ai/", "excerpt": "Prompt engineering is a relatively new discipline for developing and optimizing prompts to efficiently use language models (LMs) for a wide variety of applications and research topics.", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "228", "lang": "en", "tags": {"prompt-engineering": {"item_id": "3827312262", "tag": "prompt-engineering"}}, "listen_duration_estimate": 88}, "3843863413": {"item_id": "3843863413", "resolved_id": "3843863413", "given_url": "https://www.ruxu.dev/articles/ai/maximizing-the-potential-of-llms/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1681222742", "time_updated": "1681426305", "time_read": "1681426305", "time_favorited": "0", "sort_id": 23, "resolved_title": "Maximizing the Potential of LLMs: A Guide to Prompt Engineering", "resolved_url": "https://ruxu.dev/articles/ai/maximizing-the-potential-of-llms/", "excerpt": "Language models have rapidly improved in recent years, with large language models (LLMs) such as GPT-3 and GPT-4 taking center stage. These models have become popular due to their ability to perform a great variety of tasks with incredible skill.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2541", "lang": "en", "time_to_read": 12, "top_image_url": "https://ruxu.devassets/images/openai.png", "tags": {"llms": {"item_id": "3843863413", "tag": "llms"}, "prompt-engineering": {"item_id": "3843863413", "tag": "prompt-engineering"}}, "image": {"item_id": "3843863413", "src": "https://www.ruxu.dev/articles/ai/maximizing-the-potential-of-llms/assets/images/openai.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3843863413", "image_id": "1", "src": "https://www.ruxu.dev/articles/ai/maximizing-the-potential-of-llms/assets/images/openai.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 984}, "4002192749": {"item_id": "4002192749", "resolved_id": "4002192749", "given_url": "https://www.webdesignerdepot.com/ai-prompts/", "given_title": "The Art of Engineering AI Prompts", "favorite": "0", "status": "1", "time_added": "1707067579", "time_updated": "1708582802", "time_read": "1708582802", "time_favorited": "0", "sort_id": 24, "resolved_title": "The Art of Engineering AI Prompts", "resolved_url": "https://www.webdesignerdepot.com/ai-prompts/", "excerpt": "In the rapidly evolving world of artificial intelligence, the ability to communicate effectively with AI tools has become an indispensable skill.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1208", "lang": "en", "time_to_read": 5, "top_image_url": "https://www.webdesignerdepot.com/assets/posts/featured/_1200x630_crop_center-center_82_none/ai_prompts.jpg?mtime=1706815050", "tags": {"prompt-engineering": {"item_id": "4002192749", "tag": "prompt-engineering"}}, "authors": {"148296711": {"item_id": "4002192749", "author_id": "148296711", "name": "Louise North", "url": "https://www.webdesignerdepot.com/author/Louise-North"}}, "image": {"item_id": "4002192749", "src": "https://www.webdesignerdepot.com/imager/assets/posts/featured/ai_prompts_fdc69fe0c71b74e8bae1eed2ab8cd73c.jpg", "width": "160", "height": "104"}, "images": {"1": {"item_id": "4002192749", "image_id": "1", "src": "https://www.webdesignerdepot.com/imager/assets/posts/featured/ai_prompts_fdc69fe0c71b74e8bae1eed2ab8cd73c.jpg", "width": "160", "height": "104", "credit": "", "caption": ""}}, "listen_duration_estimate": 468}, "4011832952": {"item_id": "4011832952", "resolved_id": "4011832952", "given_url": "https://www.wired.com/story/17-tips-better-chatgpt-prompts/", "given_title": "17 Tips to Take Your ChatGPT Prompts to the Next Level", "favorite": "0", "status": "1", "time_added": "1709082689", "time_updated": "1709142181", "time_read": "1709142181", "time_favorited": "0", "sort_id": 25, "resolved_title": "17 Tips to Take Your ChatGPT Prompts to the Next Level", "resolved_url": "https://www.wired.com/story/17-tips-better-chatgpt-prompts/", "excerpt": "ChatGPT, Google Gemini, and other tools like them are making artificial intelligence available to the masses. We can now get all sorts of responses back on almost any topic imaginable. These chatbots can compose sonnets, write code, get philosophical, and automate tasks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1804", "lang": "en", "time_to_read": 8, "top_image_url": "https://media.wired.com/photos/641df3ef11b9b75446f8f278/191:100/w_1280,c_limit/11-Creative-ChatGPT-Prompts-Gear-GettyImages-1433912783.jpg", "tags": {"chatgpt": {"item_id": "4011832952", "tag": "chatgpt"}, "prompt-engineering": {"item_id": "4011832952", "tag": "prompt-engineering"}}, "authors": {"93431661": {"item_id": "4011832952", "author_id": "93431661", "name": "David Nield", "url": "https://www.wired.com/author/david-nield/"}}, "image": {"item_id": "4011832952", "src": "https://media.wired.com/photos/641df3ef11b9b75446f8f278/master/w_2560%2Cc_limit/11-Creative-ChatGPT-Prompts-Gear-GettyImages-1433912783.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "4011832952", "image_id": "1", "src": "https://media.wired.com/photos/641df3ef11b9b75446f8f278/master/w_2560%2Cc_limit/11-Creative-ChatGPT-Prompts-Gear-GettyImages-1433912783.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "4011832952", "image_id": "2", "src": "https://media.wired.com/photos/65d645a71c295636581d2ab0/master/w_1600%2Cc_limit/02-quantum.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "4011832952", "image_id": "3", "src": "https://media.wired.com/photos/65d645a6f328fa0af3b6d97e/master/w_1600%2Cc_limit/03-columbo.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "4011832952", "image_id": "4", "src": "https://media.wired.com/photos/65d645a7f6368219c1c30666/master/w_1600%2Cc_limit/04-choose.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "4011832952", "image_id": "5", "src": "https://media.wired.com/photos/65d645a8700214e853b15595/master/w_1600%2Cc_limit/05-headline.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "WIRED", "logo": "https://logo.clearbit.com/wired.com?size=800", "greyscale_logo": "https://logo.clearbit.com/wired.com?size=800&greyscale=true"}, "listen_duration_estimate": 698}}, "error": nil, "search_meta": {"search_type": "normal"}, "since": 1709419568}