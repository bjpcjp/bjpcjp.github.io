{"status": 1, "complete": 1, "list": {"3916798910": {"item_id": "3916798910", "resolved_id": "3916798910", "given_url": "https://blog.briankitano.com/llama-from-scratch/", "given_title": "Llama from scratch", "favorite": "0", "status": "1", "time_added": "1691588426", "time_updated": "1695684191", "time_read": "1695684191", "time_favorited": "0", "sort_id": 0, "resolved_title": "Llama from scratch (or how to implement a paper without crying)", "resolved_url": "https://blog.briankitano.com/llama-from-scratch/", "excerpt": "I want to provide some tips from my experience implementing a paper. I'm going to cover my tips so far from implementing a dramatically scaled-down version of Llama for training TinyShakespeare. This post is heavily inspired by Karpathy's Makemore series, which I highly recommend.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "5689", "lang": "en", "time_to_read": 26, "tags": {"llama": {"item_id": "3916798910", "tag": "llama"}, "llms": {"item_id": "3916798910", "tag": "llms"}}, "image": {"item_id": "3916798910", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_23_2.png?raw=true", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3916798910", "image_id": "1", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_23_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3916798910", "image_id": "2", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_25_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3916798910", "image_id": "3", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_35_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3916798910", "image_id": "4", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_39_0.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3916798910", "image_id": "5", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_50_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3916798910", "image_id": "6", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_54_1.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3916798910", "image_id": "7", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_57_1.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3916798910", "image_id": "8", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_60_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3916798910", "image_id": "9", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_62_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3916798910", "image_id": "10", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_65_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3916798910", "image_id": "11", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_69_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3916798910", "image_id": "12", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_71_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3916798910", "image_id": "13", "src": "https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_73_2.png?raw=true", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 2202}, "3824289621": {"item_id": "3824289621", "resolved_id": "3824289627", "given_url": "https://cocktailpeanut.github.io/dalai/#/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1678707382", "time_updated": "1678882332", "time_read": "1678882332", "time_favorited": "0", "sort_id": 1, "resolved_title": "cocktailpeanut/dalai", "resolved_url": "https://github.com/cocktailpeanut/dalai", "excerpt": "Run LLaMA and Alpaca on your computer. Both alpaca and llama working on your computer!", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "1794", "lang": "en", "time_to_read": 8, "top_image_url": "https://opengraph.githubassets.com/17560ced9fe722110f4c540433743ce56a26b8052fe2525fcde957d9d0d2bd59/cocktailpeanut/dalai", "tags": {"deep-learning": {"item_id": "3824289621", "tag": "deep-learning"}, "llama": {"item_id": "3824289621", "tag": "llama"}, "nlp": {"item_id": "3824289621", "tag": "nlp"}}, "authors": {"179263246": {"item_id": "3824289621", "author_id": "179263246", "name": "cocktailpeanut", "url": "https://github.com/cocktailpeanut/dalai/commits?author=cocktailpeanut"}}, "image": {"item_id": "3824289621", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/npx2.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3824289621", "image_id": "1", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/npx2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3824289621", "image_id": "2", "src": "https://github.com/cocktailpeanut/dalai/raw/main/docs/alpaca.gif", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3824289621", "image_id": "3", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/alpaca_7b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3824289621", "image_id": "4", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/alpaca_13b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3824289621", "image_id": "5", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/7b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3824289621", "image_id": "6", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/13b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3824289621", "image_id": "7", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/30b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3824289621", "image_id": "8", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/65b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3824289621", "image_id": "9", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/vs.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 694}, "3909837477": {"item_id": "3909837477", "resolved_id": "3909837477", "given_url": "https://github.com/weaviate/recipes/blob/main/integrations/llama2-demo/notebook.ipynb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1691255618", "time_updated": "1692744555", "time_read": "1692744555", "time_favorited": "0", "sort_id": 2, "resolved_title": "", "resolved_url": "https://github.com/weaviate/recipes/blob/main/integrations/llama2-demo/notebook.ipynb", "excerpt": "{\"payload\":{\"allShortcutsEnabled\":false,\"fileTree\":{\"integrations/llama2-demo\":{\"items\":[{\"name\":\"data\",\"path\":\"integrations/llama2-demo/data\",\"contentType\":\"directory\"},{\"name\":\"notebook.ipynb\",\"path\":\"integrations/llama2-demo/notebook.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1355", "lang": "", "tags": {"llama": {"item_id": "3909837477", "tag": "llama"}, "llms": {"item_id": "3909837477", "tag": "llms"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 525}, "3842651311": {"item_id": "3842651311", "resolved_id": "3842651311", "given_url": "https://thesequence.substack.com/p/the-llama-effect-how-an-accidental", "given_title": "The LLama Effect: How an Accidental Leak Sparked a Series of Impressive Ope", "favorite": "1", "status": "1", "time_added": "1681068939", "time_updated": "1682120660", "time_read": "1682120660", "time_favorited": "1681069741", "sort_id": 3, "resolved_title": "The LLama Effect: How an Accidental Leak Sparked a Series of Impressive Open Source Alternatives to ChatGPT", "resolved_url": "https://thesequence.substack.com/p/the-llama-effect-how-an-accidental", "excerpt": "Edge 281: Our series about federated learning(FL) continues with an overview of cross-device FL, Googleâ€™s research about FL and differential privacy and the FedLab framework for FL simulation. Edge 282: We deep dive into LangChain, the uber popular framework for LLM-based development.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "705", "lang": "en", "time_to_read": 3, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fef03b36c-e5da-49d6-af96-e1ad9a078c0d_1024x1024.png", "tags": {"chatgpt": {"item_id": "3842651311", "tag": "chatgpt"}, "llama": {"item_id": "3842651311", "tag": "llama"}, "llms": {"item_id": "3842651311", "tag": "llms"}}, "authors": {"86252": {"item_id": "3842651311", "author_id": "86252", "name": "Jesus Rodriguez", "url": ""}}, "listen_duration_estimate": 273}, "3923244601": {"item_id": "3923244601", "resolved_id": "3923244601", "given_url": "https://www.marktechpost.com/2023/08/21/together-ai-unveils-llama-2-7b-32k-instruct-a-breakthrough-in-extended-context-language-processing/", "given_title": "Together AI Unveils Llama-2-7B-32K-Instruct: A Breakthrough in Extended-Con", "favorite": "0", "status": "1", "time_added": "1692671099", "time_updated": "1693167730", "time_read": "1693167730", "time_favorited": "0", "sort_id": 4, "resolved_title": "Together AI Unveils Llama-2-7B-32K-Instruct: A Breakthrough in Extended-Context Language Processing", "resolved_url": "https://www.marktechpost.com/2023/08/21/together-ai-unveils-llama-2-7b-32k-instruct-a-breakthrough-in-extended-context-language-processing/", "excerpt": "A multifaceted challenge has arisen in the expansive realm of natural language processing: the ability to adeptly comprehend and respond to intricate and lengthy instructions.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "505", "lang": "en", "top_image_url": "https://www.marktechpost.com/wp-content/uploads/2023/08/F301xvJW0AARkdL.jpeg", "tags": {"llama": {"item_id": "3923244601", "tag": "llama"}, "llms": {"item_id": "3923244601", "tag": "llms"}}, "authors": {"184016858": {"item_id": "3923244601", "author_id": "184016858", "name": "Madhur Garg", "url": "https://www.marktechpost.com/author/madhurgarg/"}}, "image": {"item_id": "3923244601", "src": "https://www.marktechpost.com/wp-content/uploads/2023/08/F301xvJW0AARkdL.jpeg", "width": "696", "height": "464"}, "images": {"1": {"item_id": "3923244601", "image_id": "1", "src": "https://www.marktechpost.com/wp-content/uploads/2023/08/F301xvJW0AARkdL.jpeg", "width": "696", "height": "464", "credit": "", "caption": "https://together.ai/blog/llama-2-7b-32k-instruct"}, "2": {"item_id": "3923244601", "image_id": "2", "src": "https://lh4.googleusercontent.com/DKa1MESYqnclDlwUrdWVLmhulWHA7N3HSshXSbnz1fcRWJocnh3kvPuwZI-lu7p0ZS7dAsvh6KXkffV8C9_M64tvlR1X9zg5pFkxJq1Fvj37GY9Ecm30p2vi7FIe0xLP9rHM62a3pCToVXRVp1ZmNws", "width": "413", "height": "263", "credit": "", "caption": "https://together.ai/blog/llama-2-7b-32k-instruct"}}, "listen_duration_estimate": 195}}, "error": nil, "search_meta": {"search_type": "normal"}, "since": 1709419444}