{"status": 1, "complete": 1, "list": {"3366151857": {"item_id": "3366151857", "resolved_id": "3366104113", "given_url": "http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1054932", "given_title": "Face Detection Explained: State-of-the-Art Methods and Best Tools", "favorite": "0", "status": "1", "time_added": "1624661812", "time_updated": "1638708525", "time_read": "1624744701", "time_favorited": "0", "sort_id": 0, "resolved_title": "Face Detection Explained: State-of-the-Art Methods and Best Tools", "resolved_url": "https://www.datasciencecentral.com/profiles/blogs/face-detection-explained-state-of-the-art-methods-and-best-tools", "excerpt": "So many of us have used different Facebook applications to see us aging, turned into rock stars, or applied festive make-up. Such waves of facial transformations are usually accompanied by warnings not to share images of your faces – otherwise, they will be processed and misused.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1710", "lang": "en", "time_to_read": 8, "top_image_url": "https://storage.ning.com/topology/rest/1.0/file/get/9136999481?profile=RESIZE_710x", "tags": {"deep-learning": {"item_id": "3366151857", "tag": "deep-learning"}, "face-recognition": {"item_id": "3366151857", "tag": "face-recognition"}, "machine-learning": {"item_id": "3366151857", "tag": "machine-learning"}, "machine-vision": {"item_id": "3366151857", "tag": "machine-vision"}}, "authors": {"149633473": {"item_id": "3366151857", "author_id": "149633473", "name": "Oleksandr Tyron", "url": "https://www.datasciencecentral.com/profile/OleksandrTyron"}}, "image": {"item_id": "3366151857", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9136999481?profile=RESIZE_710x", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3366151857", "image_id": "1", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9136999481?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3366151857", "image_id": "2", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9137038095?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3366151857", "image_id": "3", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9137045853?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3366151857", "image_id": "4", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9137055692?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3366151857", "image_id": "5", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9137061890?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3366151857", "image_id": "6", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9137073095?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3366151857", "image_id": "7", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9137084477?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Data Science Central", "logo": "https://logo.clearbit.com/datasciencecentral.com?size=800", "greyscale_logo": "https://logo.clearbit.com/datasciencecentral.com?size=800&greyscale=true"}, "listen_duration_estimate": 662}, "3840186225": {"item_id": "3840186225", "resolved_id": "3840055593", "given_url": "https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/?utm_source=twitter&utm_medium=organic_social&utm_campaign=segmentanything&utm_content=gif", "given_title": "Introducing Segment Anything: Working toward the first foundation model for", "favorite": "0", "status": "1", "time_added": "1680793754", "time_updated": "1680908481", "time_read": "1680908481", "time_favorited": "0", "sort_id": 1, "resolved_title": "Introducing Segment Anything: Working toward the first foundation model for image segmentation", "resolved_url": "https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/", "excerpt": "Segmentation — identifying which image pixels belong to an object — is a core task in computer vision and is used in a broad array of applications, from analyzing scientific imagery to editing photos.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1930", "lang": "en", "time_to_read": 9, "top_image_url": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/338318848_238475658638014_6444534044370711549_n.gif?_nc_cat=108&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=feCOAaD69isAX_QcqPX&_nc_ht=scontent-iad3-1.xx&oh=00_AfAEqqYcSdMMZgrdRhmFJSVeT_OV0zfbb06bX_GMnspk-w&oe=64332CE9", "tags": {"deep-learning": {"item_id": "3840186225", "tag": "deep-learning"}, "image-segmentation": {"item_id": "3840186225", "tag": "image-segmentation"}, "machine-vision": {"item_id": "3840186225", "tag": "machine-vision"}}, "image": {"item_id": "3840186225", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/338558258_1349701259095991_4358060436604292355_n.png?_nc_cat=104&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=BFL6nEDeLysAX9MbPLA&_nc_ht=scontent-iad3-1.xx&oh=00_AfBuZzxOJZfjyBhosGDZtIBnHcjsH82FjhU2K3HWnlBmDw&oe=64323D49", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3840186225", "image_id": "1", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/338558258_1349701259095991_4358060436604292355_n.png?_nc_cat=104&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=BFL6nEDeLysAX9MbPLA&_nc_ht=scontent-iad3-1.xx&oh=00_AfBuZzxOJZfjyBhosGDZtIBnHcjsH82FjhU2K3HWnlBmDw&oe=64323D49", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3840186225", "image_id": "2", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/338490494_577019134187999_95483266747832988_n.png?_nc_cat=104&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=mCgg7vGPoR4AX_c8WIw&_nc_ht=scontent-iad3-1.xx&oh=00_AfC3WeDFerrnu4DzNUjurSLTPt_wZ3M_XDULNYO1JC-zPQ&oe=6432C1BC", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3840186225", "image_id": "3", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/338713754_989652268682274_1644116157216484057_n.png?_nc_cat=108&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=r4P02ca0zPQAX-eC-Oo&_nc_ht=scontent-iad3-1.xx&oh=00_AfDOWhS0MHEhyzRpyAfH_Vy3CqPZgCmnE9ViBH-DBVeuAQ&oe=6432097F", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 747}, "3272198783": {"item_id": "3272198783", "resolved_id": "3272198783", "given_url": "https://arankomatsuzaki.wordpress.com/2021/03/04/state-of-the-art-image-generative-models/", "given_title": "State-of-the-Art Image Generation Models", "favorite": "0", "status": "1", "time_added": "1614941707", "time_updated": "1614946406", "time_read": "1614946406", "time_favorited": "0", "sort_id": 2, "resolved_title": "State-of-the-Art Image Generative Models", "resolved_url": "https://arankomatsuzaki.wordpress.com/2021/03/04/state-of-the-art-image-generative-models/", "excerpt": "I have aggregated some of the SotA image generative models released recently, with short summaries, visualizations and comments. The overall development is summarized, and the future trends are speculated.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1665", "lang": "en", "time_to_read": 8, "amp_url": "https://arankomatsuzaki.wordpress.com/2021/03/04/state-of-the-art-image-generative-models/amp/", "top_image_url": "https://arankomatsuzaki.files.wordpress.com/2021/03/fig1.jpg?w=1200", "tags": {"image-generation": {"item_id": "3272198783", "tag": "image-generation"}, "machine-learning": {"item_id": "3272198783", "tag": "machine-learning"}, "machine-vision": {"item_id": "3272198783", "tag": "machine-vision"}}, "authors": {"93456081": {"item_id": "3272198783", "author_id": "93456081", "name": "Aran Komatsuzaki", "url": ""}}, "image": {"item_id": "3272198783", "src": "https://arankomatsuzaki.files.wordpress.com/2021/03/fig1-11.png", "width": "419", "height": "112"}, "images": {"1": {"item_id": "3272198783", "image_id": "1", "src": "https://arankomatsuzaki.files.wordpress.com/2021/03/fig1-11.png", "width": "419", "height": "112", "credit": "", "caption": ""}, "2": {"item_id": "3272198783", "image_id": "2", "src": "https://arankomatsuzaki.files.wordpress.com/2021/03/fig1.png", "width": "866", "height": "588", "credit": "", "caption": ""}, "3": {"item_id": "3272198783", "image_id": "3", "src": "https://arankomatsuzaki.files.wordpress.com/2021/03/fig1-1.png", "width": "730", "height": "147", "credit": "", "caption": ""}, "4": {"item_id": "3272198783", "image_id": "4", "src": "https://arankomatsuzaki.files.wordpress.com/2021/03/fig1-7.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3272198783", "image_id": "5", "src": "https://arankomatsuzaki.files.wordpress.com/2021/03/fig2-2.png", "width": "577", "height": "290", "credit": "", "caption": ""}, "6": {"item_id": "3272198783", "image_id": "6", "src": "https://arankomatsuzaki.files.wordpress.com/2021/03/fig1-6.png", "width": "569", "height": "270", "credit": "", "caption": ""}, "7": {"item_id": "3272198783", "image_id": "7", "src": "https://arankomatsuzaki.files.wordpress.com/2021/03/fig1-10.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3272198783", "image_id": "8", "src": "https://arankomatsuzaki.files.wordpress.com/2021/03/fig1-12.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3272198783", "image_id": "9", "src": "https://arankomatsuzaki.files.wordpress.com/2021/03/fig1-14.png", "width": "618", "height": "312", "credit": "", "caption": ""}, "10": {"item_id": "3272198783", "image_id": "10", "src": "https://arankomatsuzaki.files.wordpress.com/2021/03/fig1-8.png", "width": "334", "height": "335", "credit": "", "caption": ""}, "11": {"item_id": "3272198783", "image_id": "11", "src": "https://arankomatsuzaki.files.wordpress.com/2021/03/fig1-9.png", "width": "662", "height": "190", "credit": "", "caption": ""}, "12": {"item_id": "3272198783", "image_id": "12", "src": "https://arankomatsuzaki.files.wordpress.com/2021/03/fig1-2.png", "width": "475", "height": "473", "credit": "", "caption": ""}, "13": {"item_id": "3272198783", "image_id": "13", "src": "https://arankomatsuzaki.files.wordpress.com/2021/03/fig2.png", "width": "479", "height": "162", "credit": "", "caption": ""}, "14": {"item_id": "3272198783", "image_id": "14", "src": "https://arankomatsuzaki.files.wordpress.com/2021/03/fig3.png", "width": "416", "height": "237", "credit": "", "caption": ""}, "15": {"item_id": "3272198783", "image_id": "15", "src": "https://arankomatsuzaki.files.wordpress.com/2021/03/fig1-1.jpg", "width": "674", "height": "293", "credit": "", "caption": ""}}, "listen_duration_estimate": 645}, "3526769589": {"item_id": "3526769589", "resolved_id": "3526769589", "given_url": "https://arxiv.org/abs/2201.02605v2", "given_title": "", "favorite": "0", "status": "1", "time_added": "1642022243", "time_updated": "1642028814", "time_read": "1642028813", "time_favorited": "0", "sort_id": 3, "resolved_title": "Title:Detecting Twenty-thousand Classes using Image-level Supervision", "resolved_url": "https://arxiv.org/abs/2201.02605v2", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"arxiv": {"item_id": "3526769589", "tag": "arxiv"}, "deep-learning": {"item_id": "3526769589", "tag": "deep-learning"}, "machine-vision": {"item_id": "3526769589", "tag": "machine-vision"}}, "authors": {"162218028": {"item_id": "3526769589", "author_id": "162218028", "name": "cs", "url": "https://arxiv.org/abs/2201.02605?context=cs"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3655631329": {"item_id": "3655631329", "resolved_id": "3655523951", "given_url": "https://arxiv.org/abs/2207.02696", "given_title": "", "favorite": "0", "status": "1", "time_added": "1658149840", "time_updated": "1658187784", "time_read": "1658187784", "time_favorited": "0", "sort_id": 4, "resolved_title": "Title:YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors", "resolved_url": "https://arxiv.org/abs/2207.02696v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"arxiv": {"item_id": "3655631329", "tag": "arxiv"}, "machine-learning": {"item_id": "3655631329", "tag": "machine-learning"}, "machine-vision": {"item_id": "3655631329", "tag": "machine-vision"}}, "authors": {"169614829": {"item_id": "3655631329", "author_id": "169614829", "name": "cs", "url": "https://arxiv.org/abs/2207.02696?context=cs"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3662527004": {"item_id": "3662527004", "resolved_id": "3662527004", "given_url": "https://blog.roboflow.com/yolov7-breakdown/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1658149353", "time_updated": "1658187786", "time_read": "1658187786", "time_favorited": "0", "sort_id": 5, "resolved_title": "YOLOv7 Breakdown", "resolved_url": "https://blog.roboflow.com/yolov7-breakdown/", "excerpt": "Realtime object detection advances with the release of YOLOv7, the latest iteration in the life cycle of YOLO models. YOLOv7 infers faster and with greater accuracy than its cohorts, pushing the state of the art in object detection to new heights.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "1144", "lang": "en", "time_to_read": 5, "amp_url": "https://blog.roboflow.com/yolov7-breakdown/amp/", "top_image_url": "https://blog.roboflow.com/content/images/2022/07/YOLOv7_explained.webp", "tags": {"machine-learning": {"item_id": "3662527004", "tag": "machine-learning"}, "machine-vision": {"item_id": "3662527004", "tag": "machine-vision"}}, "authors": {"138861352": {"item_id": "3662527004", "author_id": "138861352", "name": "Jacob Solawetz", "url": "https://blog.roboflow.com/author/jacob/"}}, "image": {"item_id": "3662527004", "src": "https://blog.roboflow.com/content/images/2022/07/yolov7_sota.webp", "width": "322", "height": "244"}, "images": {"1": {"item_id": "3662527004", "image_id": "1", "src": "https://blog.roboflow.com/content/images/2022/07/yolov7_sota.webp", "width": "322", "height": "244", "credit": "x-axis", "caption": "The evaluation of YOLOv7 models show that they infer faster"}, "2": {"item_id": "3662527004", "image_id": "2", "src": "https://blog.roboflow.com/content/images/2022/07/yolov7_inference.webp", "width": "536", "height": "354", "credit": "", "caption": ""}, "3": {"item_id": "3662527004", "image_id": "3", "src": "https://blog.roboflow.com/content/images/2022/07/yolov7_eval.webp", "width": "673", "height": "405", "credit": "", "caption": ""}, "4": {"item_id": "3662527004", "image_id": "4", "src": "https://blog.roboflow.com/content/images/2022/07/image-38.png", "width": "415", "height": "325", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "3662527004", "video_id": "1", "src": "https://www.youtube.com/embed/OFggvqHy_5Y?feature=oembed", "width": "200", "height": "113", "type": "1", "vid": "OFggvqHy_5Y", "length": "0"}}, "listen_duration_estimate": 443}, "108148073": {"item_id": "108148073", "resolved_id": "108148073", "given_url": "https://blogs.mathworks.com/steve/2011/10/04/binary-image-convex-hull-algorithm-notes/", "given_title": "Binary image convex hull – algorithm notes » Steve on Image Processing with", "favorite": "0", "status": "1", "time_added": "1706568885", "time_updated": "1707015395", "time_read": "1707015395", "time_favorited": "0", "sort_id": 6, "resolved_title": "Binary image convex hull – algorithm notes", "resolved_url": "https://blogs.mathworks.com/steve/2011/10/04/binary-image-convex-hull-algorithm-notes/", "excerpt": "Today I want to tell a little image processing algorithm story related to my post last week about the new bwconvhull function in the Image Processing Toolbox.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "722", "lang": "en", "time_to_read": 3, "top_image_url": "https://blogs.mathworks.com/images/steve/2011/convex_hull_calculation_01.png", "tags": {"convex-hulls": {"item_id": "108148073", "tag": "convex-hulls"}, "machine-vision": {"item_id": "108148073", "tag": "machine-vision"}}, "authors": {"137274372": {"item_id": "108148073", "author_id": "137274372", "name": "Steve Eddins", "url": "https://www.mathworks.com/matlabcentral/profile/authors/476476?s_tid=blg_to_profile"}}, "image": {"item_id": "108148073", "src": "https://blogs.mathworks.com/images/steve/2011/convex_hull_calculation_01.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "108148073", "image_id": "1", "src": "https://blogs.mathworks.com/images/steve/2011/convex_hull_calculation_01.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "108148073", "image_id": "2", "src": "https://blogs.mathworks.com/images/steve/2011/convex_hull_calculation_02.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "108148073", "image_id": "3", "src": "https://blogs.mathworks.com/images/steve/2011/convex_hull_calculation_03.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "108148073", "image_id": "4", "src": "https://blogs.mathworks.com/images/steve/2011/convex_hull_calculation_04.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "108148073", "image_id": "5", "src": "https://blogs.mathworks.com/images/steve/2011/convex_hull_calculation_05.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "108148073", "image_id": "6", "src": "https://blogs.mathworks.com/images/steve/2011/convex_hull_calculation_06.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "108148073", "image_id": "7", "src": "https://blogs.mathworks.com/images/steve/2011/convex_hull_calculation_07.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 279}, "3945139867": {"item_id": "3945139867", "resolved_id": "3945139867", "given_url": "https://dataconomy.com/2023/10/04/chatgpt-vision-is-insanely-good-here-is-what-it-can-and-cant-do/", "given_title": "ChatGPT Vision is insanely good, here is what it can and can’t do", "favorite": "0", "status": "1", "time_added": "1696426744", "time_updated": "1696545906", "time_read": "1696545906", "time_favorited": "0", "sort_id": 7, "resolved_title": "ChatGPT Vision is insanely good, here is what it can and can’t do", "resolved_url": "https://dataconomy.com/2023/10/04/chatgpt-vision-is-insanely-good-here-is-what-it-can-and-cant-do/", "excerpt": "OpenAI’s ChatGPT Vision is making waves in the world of artificial intelligence, but what exactly is it, and how can you harness its capabilities? In this article, we’ll break down ChatGPT Vision in simple terms, explore what it can and can’t do, and offer practical insights into its effective", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "983", "lang": "en", "time_to_read": 4, "top_image_url": "https://dataconomy.com/wp-content/uploads/2023/10/jonathan-kemper-UF3vfhV04SA-unsplash.jpg", "tags": {"chatgpt": {"item_id": "3945139867", "tag": "chatgpt"}, "machine-vision": {"item_id": "3945139867", "tag": "machine-vision"}}, "authors": {"182152479": {"item_id": "3945139867", "author_id": "182152479", "name": "Onur Demirkol", "url": "https://dataconomy.com/author/onurdemirkol/"}}, "listen_duration_estimate": 381}, "3509864981": {"item_id": "3509864981", "resolved_id": "3509864981", "given_url": "https://dev.to/imagescv/python-computer-vision-libraries-every-developer-should-know-1i00", "given_title": "Python Computer Vision Libraries Every Developer Should Know", "favorite": "0", "status": "1", "time_added": "1640091599", "time_updated": "1640290928", "time_read": "1640290927", "time_favorited": "0", "sort_id": 8, "resolved_title": "Python Computer Vision Libraries Every Developer Should Know", "resolved_url": "https://dev.to/imagescv/python-computer-vision-libraries-every-developer-should-know-1i00", "excerpt": "Python is one of the most popular languages of the current age. It has gained more popularity with the rise of Artificial Intelligence and Machine Learning. Developers of these domains prefer python for coding and developing applications.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "817", "lang": "en", "time_to_read": 4, "top_image_url": "https://res.cloudinary.com/practicaldev/image/fetch/s--j0LY8pAE--/c_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/swzpqzsxfchytdn0nrna.jpg", "tags": {"machine-learning": {"item_id": "3509864981", "tag": "machine-learning"}, "machine-vision": {"item_id": "3509864981", "tag": "machine-vision"}, "python": {"item_id": "3509864981", "tag": "python"}}, "image": {"item_id": "3509864981", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--VejUwAdA--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/swzpqzsxfchytdn0nrna.jpg", "width": "1000", "height": "420"}, "images": {"1": {"item_id": "3509864981", "image_id": "1", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--VejUwAdA--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/swzpqzsxfchytdn0nrna.jpg", "width": "1000", "height": "420", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The Practical Dev", "logo": "https://logo.clearbit.com/dev.to?size=800", "greyscale_logo": "https://logo.clearbit.com/dev.to?size=800&greyscale=true"}, "listen_duration_estimate": 316}, "3324767457": {"item_id": "3324767457", "resolved_id": "3324767457", "given_url": "https://dev.to/stokry/top-5-python-libraries-for-computer-vision-47ga", "given_title": "Top 5 Python libraries for Computer vision", "favorite": "0", "status": "1", "time_added": "1620315321", "time_updated": "1706833159", "time_read": "1620401401", "time_favorited": "0", "sort_id": 9, "resolved_title": "Top 5 Python libraries for Computer vision", "resolved_url": "https://dev.to/stokry/top-5-python-libraries-for-computer-vision-47ga", "excerpt": "Computer vision is the field of computer science that focuses on replicating parts of the complexity of the human visual system and enabling computers to identify and process objects in images and videos in the same way that humans do.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "424", "lang": "en", "top_image_url": "https://res.cloudinary.com/practicaldev/image/fetch/s--HSLkb7Yo--/c_imagga_scale,f_auto,fl_progressive,h_500,q_66,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/0qrkw79dpm95yxooymed.gif", "tags": {"deep-learning": {"item_id": "3324767457", "tag": "deep-learning"}, "machine-vision": {"item_id": "3324767457", "tag": "machine-vision"}, "programming": {"item_id": "3324767457", "tag": "programming"}, "python": {"item_id": "3324767457", "tag": "python"}}, "authors": {"19165162": {"item_id": "3324767457", "author_id": "19165162", "name": "may 6", "url": ""}, "65419642": {"item_id": "3324767457", "author_id": "65419642", "name": "stokry", "url": ""}, "149123214": {"item_id": "3324767457", "author_id": "149123214", "name": "・2 min read", "url": ""}}, "image": {"item_id": "3324767457", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--92Zm0Q6B--/c_imagga_scale,f_auto,fl_progressive,h_420,q_66,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/0qrkw79dpm95yxooymed.gif", "width": "1000", "height": "420"}, "images": {"1": {"item_id": "3324767457", "image_id": "1", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--92Zm0Q6B--/c_imagga_scale,f_auto,fl_progressive,h_420,q_66,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/0qrkw79dpm95yxooymed.gif", "width": "1000", "height": "420", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The Practical Dev", "logo": "https://logo.clearbit.com/dev.to?size=800", "greyscale_logo": "https://logo.clearbit.com/dev.to?size=800&greyscale=true"}, "listen_duration_estimate": 164}, "3329310377": {"item_id": "3329310377", "resolved_id": "3329310377", "given_url": "https://dropbox.tech/machine-learning/how-image-search-works-at-dropbox", "given_title": "How image search works at Dropbox - Dropbox", "favorite": "0", "status": "1", "time_added": "1620825082", "time_updated": "1620841121", "time_read": "1620841121", "time_favorited": "0", "sort_id": 10, "resolved_title": "How image search works at Dropbox", "resolved_url": "https://dropbox.tech/machine-learning/how-image-search-works-at-dropbox", "excerpt": "Photos are among the most common types of files in Dropbox, but searching for them by filename is even less productive than it is for text-based files.  When you're looking for that photo from a picnic a few years ago, you surely don't remember that the filename set by your camera was .  ", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2310", "lang": "en", "time_to_read": 11, "top_image_url": "https://aem.dropbox.com/cms/content/dam/dropbox/tech-blog/en-us/2021/05/image-search/Techblog-ImageSearch-Social2.png", "tags": {"machine-learning": {"item_id": "3329310377", "tag": "machine-learning"}, "machine-vision": {"item_id": "3329310377", "tag": "machine-vision"}, "search": {"item_id": "3329310377", "tag": "search"}}, "authors": {"368922": {"item_id": "3329310377", "author_id": "368922", "name": "Thomas Berg", "url": ""}}, "image": {"item_id": "3329310377", "src": "https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/05/image-search/xx_yrSW-.png/_jcr_content/renditions/xx_yrSW-.webp", "width": "720", "height": "473"}, "images": {"1": {"item_id": "3329310377", "image_id": "1", "src": "https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/05/image-search/xx_yrSW-.png/_jcr_content/renditions/xx_yrSW-.webp", "width": "720", "height": "473", "credit": "", "caption": ""}, "2": {"item_id": "3329310377", "image_id": "2", "src": "https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/05/image-search/NZT1drfj.png/_jcr_content/renditions/NZT1drfj.webp", "width": "720", "height": "318", "credit": "", "caption": ""}, "3": {"item_id": "3329310377", "image_id": "3", "src": "https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/05/image-search/veZNQZbt.png/_jcr_content/renditions/veZNQZbt.webp", "width": "720", "height": "289", "credit": "", "caption": ""}, "4": {"item_id": "3329310377", "image_id": "4", "src": "https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/05/image-search/w7RFa4Y_.png/_jcr_content/renditions/w7RFa4Y_.webp", "width": "720", "height": "248", "credit": "", "caption": ""}, "5": {"item_id": "3329310377", "image_id": "5", "src": "https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/05/image-search/MEda8mit.png/_jcr_content/renditions/MEda8mit.webp", "width": "720", "height": "265", "credit": "", "caption": ""}}, "listen_duration_estimate": 894}, "3493082108": {"item_id": "3493082108", "resolved_id": "3493082108", "given_url": "https://github.com/bjpcjp/scikit-image-tutorial/blob/master/gallery/edges-lines.ipynb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638239964", "time_updated": "1642439877", "time_read": "1642439877", "time_favorited": "0", "sort_id": 11, "resolved_title": "", "resolved_url": "https://github.com/bjpcjp/scikit-image-tutorial/blob/master/gallery/edges-lines.ipynb", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"machine-vision": {"item_id": "3493082108", "tag": "machine-vision"}, "scikit-image": {"item_id": "3493082108", "tag": "scikit-image"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3493082109": {"item_id": "3493082109", "resolved_id": "3493082221", "given_url": "https://github.com/bjpcjp/scikit-image-tutorial/blob/master/gallery/exposure-colors.ipynb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638239964", "time_updated": "1642941296", "time_read": "1642941296", "time_favorited": "0", "sort_id": 12, "resolved_title": "scikit-image notes", "resolved_url": "https://github.com/bjpcjp/scikit-image-tutorial", "excerpt": "scikit-image notes contents: README.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "187", "lang": "en", "top_image_url": "https://repository-images.githubusercontent.com/242269326/d53f0100-683a-11eb-9e41-33ec71a1f8b6", "tags": {"machine-vision": {"item_id": "3493082109", "tag": "machine-vision"}, "scikit-image": {"item_id": "3493082109", "tag": "scikit-image"}}, "image": {"item_id": "3493082109", "src": "https://github.com/bjpcjp/scikit-image-tutorial/blob/master/scikit-image-logo.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3493082109", "image_id": "1", "src": "https://github.com/bjpcjp/scikit-image-tutorial/blob/master/scikit-image-logo.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 72}, "3493082113": {"item_id": "3493082113", "resolved_id": "3493082113", "given_url": "https://github.com/bjpcjp/scikit-image-tutorial/blob/master/gallery/filtering-restoration.ipynb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638239964", "time_updated": "1642439897", "time_read": "1642439897", "time_favorited": "0", "sort_id": 13, "resolved_title": "", "resolved_url": "https://github.com/bjpcjp/scikit-image-tutorial/blob/master/gallery/filtering-restoration.ipynb", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"machine-vision": {"item_id": "3493082113", "tag": "machine-vision"}, "scikit-image": {"item_id": "3493082113", "tag": "scikit-image"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3493082114": {"item_id": "3493082114", "resolved_id": "3493082114", "given_url": "https://github.com/bjpcjp/scikit-image-tutorial/blob/master/gallery/image-data.ipynb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638239964", "time_updated": "1642941329", "time_read": "1642941329", "time_favorited": "0", "sort_id": 14, "resolved_title": "", "resolved_url": "https://github.com/bjpcjp/scikit-image-tutorial/blob/master/gallery/image-data.ipynb", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"machine-learning": {"item_id": "3493082114", "tag": "machine-learning"}, "machine-vision": {"item_id": "3493082114", "tag": "machine-vision"}, "scikit-image": {"item_id": "3493082114", "tag": "scikit-image"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "2361292242": {"item_id": "2361292242", "resolved_id": "2361292242", "given_url": "https://github.com/jsbroks/coco-annotator", "given_title": "", "favorite": "0", "status": "1", "time_added": "1619946297", "time_updated": "1638708525", "time_read": "1619975157", "time_favorited": "0", "sort_id": 15, "resolved_title": "Features", "resolved_url": "https://github.com/jsbroks/coco-annotator", "excerpt": "COCO Annotator is a web-based image annotation tool designed for versatility and efficiently label images to create training data for image localization and object detection.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "360", "lang": "en", "top_image_url": "https://opengraph.githubassets.com/7b8d5e5054445da9a446c0875b1aefecd6051bb7e6e58c5396f80f96a40ac8b5/jsbroks/coco-annotator", "tags": {"deep-learning": {"item_id": "2361292242", "tag": "deep-learning"}, "machine-vision": {"item_id": "2361292242", "tag": "machine-vision"}}, "image": {"item_id": "2361292242", "src": "https://camo.githubusercontent.com/69ce7a40db8bdee3e2a292950b5d84cd3f60cc8ac32bdce3316e40ca4130a71d/68747470733a2f2f692e696d6775722e636f6d2f414137496462512e706e67", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2361292242", "image_id": "1", "src": "https://camo.githubusercontent.com/69ce7a40db8bdee3e2a292950b5d84cd3f60cc8ac32bdce3316e40ca4130a71d/68747470733a2f2f692e696d6775722e636f6d2f414137496462512e706e67", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2361292242", "image_id": "2", "src": "https://camo.githubusercontent.com/27beb08a24fa9cdcaa34922076d06036b413c919d0e05950909f03a943e49de0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a7362726f6b732f636f636f2d616e6e6f7461746f722e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2361292242", "image_id": "3", "src": "https://camo.githubusercontent.com/30926cd756b4cbb535f573c9eef48cbd9c99c03cd1fb45bcf0c17e5baa4a9234/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f6a7362726f6b732f636f636f2d616e6e6f7461746f722e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2361292242", "image_id": "4", "src": "https://camo.githubusercontent.com/2ff6a06f2f6e08b17783133ca7ebc23ce1f8ac4415eee8e835647b57048a8f0d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d6173686170652f6170697374617475732e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2361292242", "image_id": "5", "src": "https://camo.githubusercontent.com/467c76f1dba5284c5b3498c5c050546b6372d029f4e295e323f8e24abe474ae7/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f6a6176617363726970742f672f6a7362726f6b732f636f636f2d616e6e6f7461746f722e7376673f6c6162656c3d636f64652532307175616c697479", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2361292242", "image_id": "6", "src": "https://camo.githubusercontent.com/4a28be9123410257788f557f35fa0952906e882eee2289501b163226e6f82422/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64656d6f2d6f6e6c696e652d677265656e2e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2361292242", "image_id": "7", "src": "https://camo.githubusercontent.com/2c664b37ca079051d4393da800f4c0d4676ed6eea0d069e3381a9b92a49c196d/68747470733a2f2f7472617669732d63692e6f72672f6a7362726f6b732f636f636f2d616e6e6f7461746f722e7376673f6272616e63683d6d6173746572", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2361292242", "image_id": "8", "src": "https://camo.githubusercontent.com/5bfb3d72aba7e089bc55547611e0eb7b0793b7954498bb443c10728842afdb46/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f70756c6c732f6a7362726f6b732f636f636f2d616e6e6f7461746f722e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2361292242", "image_id": "9", "src": "https://camo.githubusercontent.com/93247a2ccf90df2b8077980a18025a0c361c7351fe1cef6d69fa0b8c5bec20a5/68747470733a2f2f646973636f72642e636f6d2f6173736574732f65343932333539346536393461323135343261343839343731656366666135302e737667", "width": "120", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2361292242", "image_id": "10", "src": "https://camo.githubusercontent.com/7fe796df96bd5b9036ac5934f390c8d46f68bd1c8e6c5ab1811da5426da843ad/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f4f4d4a52636a6e4d4d6f6b2f6d617872657364656661756c742e6a7067", "width": "600", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2361292242", "image_id": "11", "src": "https://camo.githubusercontent.com/5f495baf75cafc48aff2d39594a44e5d47a983b33c7b275aa608410a12f898cf/68747470733a2f2f692e696d6775722e636f6d2f6d34526d6a43702e676966", "width": "600", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2361292242", "image_id": "12", "src": "https://camo.githubusercontent.com/ca317983c1ee436cd8c1157c5d2769c641372ee441af705dc0a32e3654fcbc9f/68747470733a2f2f63352e70617472656f6e2e636f6d2f65787465726e616c2f6c6f676f2f6265636f6d655f615f706174726f6e5f627574746f6e4032782e706e67", "width": "120", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "2361292242", "image_id": "13", "src": "https://camo.githubusercontent.com/fe25c35204cc9a688bfd1113a85f4c40a1b825fcf8ea461bbb2e7e487ad90452/68747470733a2f2f692e696d6775722e636f6d2f734f51317335462e706e67", "width": "250", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 139}, "3131820715": {"item_id": "3131820715", "resolved_id": "3131820715", "given_url": "https://github.com/lucidrains/vit-pytorch", "given_title": "", "favorite": "0", "status": "1", "time_added": "1671369674", "time_updated": "1671403223", "time_read": "1671403222", "time_favorited": "0", "sort_id": 16, "resolved_title": "lucidrains/vit-pytorch", "resolved_url": "https://github.com/lucidrains/vit-pytorch", "excerpt": "Implementation of Vision Transformer, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch. Significance is further explained in Yannic Kilcher's video.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2899", "lang": "en", "time_to_read": 13, "top_image_url": "https://opengraph.githubassets.com/e225c022a1f8272134515bd1488ec8fb876695df81a4b08ea2057d7bc9cc877e/lucidrains/vit-pytorch", "tags": {"deep-learning": {"item_id": "3131820715", "tag": "deep-learning"}, "machine-vision": {"item_id": "3131820715", "tag": "machine-vision"}, "pytorch": {"item_id": "3131820715", "tag": "pytorch"}, "transformers": {"item_id": "3131820715", "tag": "transformers"}}, "image": {"item_id": "3131820715", "src": "https://github.com/lucidrains/vit-pytorch/raw/main/images/vit.gif", "width": "500", "height": "0"}, "images": {"1": {"item_id": "3131820715", "image_id": "1", "src": "https://github.com/lucidrains/vit-pytorch/raw/main/images/vit.gif", "width": "500", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3131820715", "image_id": "2", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/distill.png", "width": "300", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3131820715", "image_id": "3", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/t2t.png", "width": "400", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3131820715", "image_id": "4", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/cross_vit.png", "width": "400", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3131820715", "image_id": "5", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/pit.png", "width": "400", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3131820715", "image_id": "6", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/levit.png", "width": "300", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3131820715", "image_id": "7", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/cvt.png", "width": "400", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3131820715", "image_id": "8", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/twins_svt.png", "width": "400", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3131820715", "image_id": "9", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/nest.png", "width": "400", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3131820715", "image_id": "10", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/dino.png", "width": "350", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 1122}, "3689137102": {"item_id": "3689137102", "resolved_id": "3689137102", "given_url": "https://grandy.substack.com/p/the-new-normal-the-coming-tsunami", "given_title": "", "favorite": "0", "status": "1", "time_added": "1661469821", "time_updated": "1661613933", "time_read": "1661613933", "time_favorited": "0", "sort_id": 17, "resolved_title": "The New Normal: The Coming Tsunami of Fakery", "resolved_url": "https://grandy.substack.com/p/the-new-normal-the-coming-tsunami", "excerpt": "The word robot derives from the Slavonic word robota, roughly translating to servitude, forced labor, or drudgery. It came into vogue during the Central European system of serfdom, whereby a tenant’s rent was paid for in forced labor.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2143", "lang": "en", "time_to_read": 10, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2c9ecb5-eb24-449c-974a-014606a87d9a_680x383.jpeg", "tags": {"deepfakes": {"item_id": "3689137102", "tag": "deepfakes"}, "machine-vision": {"item_id": "3689137102", "tag": "machine-vision"}}, "authors": {"171477005": {"item_id": "3689137102", "author_id": "171477005", "name": "Monsieur Grandy", "url": "https://substack.com/profile/101911528-monsieur-grandy"}}, "image": {"item_id": "3689137102", "src": "https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4be01d7e-4253-4378-9343-9a6e924b7084_664x227.webp", "width": "664", "height": "227"}, "images": {"1": {"item_id": "3689137102", "image_id": "1", "src": "https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4be01d7e-4253-4378-9343-9a6e924b7084_664x227.webp", "width": "664", "height": "227", "credit": "", "caption": "The irony"}, "2": {"item_id": "3689137102", "image_id": "2", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2c9ecb5-eb24-449c-974a-014606a87d9a_680x383.jpeg", "width": "472", "height": "266", "credit": "", "caption": ""}, "3": {"item_id": "3689137102", "image_id": "3", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff793159d-ef5c-4e6d-8be8-1813c71869d6_994x994.png", "width": "428", "height": "428", "credit": "", "caption": "This is actually a random midjourney image, much more impressive than the colab notebook"}, "4": {"item_id": "3689137102", "image_id": "4", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2ae2e06-9db0-481d-bf03-791423950030_1125x877.jpeg", "width": "292", "height": "228", "credit": "", "caption": ""}, "5": {"item_id": "3689137102", "image_id": "5", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F485b5d5e-dc20-4edb-b634-0d44deef2d81_1024x1024.png", "width": "426", "height": "426", "credit": "", "caption": "Another midjourney image. Mindblowing."}}, "listen_duration_estimate": 830}, "3581824922": {"item_id": "3581824922", "resolved_id": "3581824922", "given_url": "https://hothardware.com/news/nvidia-nerf-ai-renders-3d-scenes-2d-photos-milliseconds", "given_title": "NVIDIA NeRF AI Renders Amazingly Realistic 3D Scenes From 2D Photos In Just", "favorite": "0", "status": "1", "time_added": "1648233694", "time_updated": "1654559376", "time_read": "1648303175", "time_favorited": "0", "sort_id": 18, "resolved_title": "NVIDIA NeRF AI Renders Amazingly Realistic 3D Scenes From 2D Photos In Just Milliseconds", "resolved_url": "https://hothardware.com/news/nvidia-nerf-ai-renders-3d-scenes-2d-photos-milliseconds", "excerpt": "It takes a human being around 0.1 to 0.4 seconds to blink. In even less time, an AI-based inverse rendering process developed by NVIDIA can generate a realistic three-dimensional scene from a series of two-dimensional photographs taken from different angles.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "453", "lang": "en", "amp_url": "https://amp.hothardware.com/news/nvidia-nerf-ai-renders-3d-scenes-2d-photos-milliseconds", "top_image_url": "https://images.hothardware.com/contentimages/newsitem/58082/content/small_nvidia_nerf_thumbnail.jpg", "tags": {"deep-learning": {"item_id": "3581824922", "tag": "deep-learning"}, "image-generation": {"item_id": "3581824922", "tag": "image-generation"}, "machine-vision": {"item_id": "3581824922", "tag": "machine-vision"}}, "authors": {"68870047": {"item_id": "3581824922", "author_id": "68870047", "name": "Paul Lilly", "url": "https://hothardware.com/author/Paul-Lilly"}}, "listen_duration_estimate": 175}, "3266401672": {"item_id": "3266401672", "resolved_id": "3265116344", "given_url": "https://link.medium.com/MBOlUwEWaeb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1614293473", "time_updated": "1638708525", "time_read": "1614780587", "time_favorited": "0", "sort_id": 19, "resolved_title": "How to Use Roboflow and Streamlit to Visualize Object Detection Output", "resolved_url": "https://towardsdatascience.com/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output-672ba11b2f7c", "excerpt": "Most technology is designed to make your life, or your work, easier. If your work involves building computer vision into your applications, using the Roboflow platform gives you everything you need.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1889", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/freeze/max/1200/0*asY-S_5_Nf5x__Mc.gif", "tags": {"deep-learning": {"item_id": "3266401672", "tag": "deep-learning"}, "machine-vision": {"item_id": "3266401672", "tag": "machine-vision"}, "object-detection": {"item_id": "3266401672", "tag": "object-detection"}}, "authors": {"142575116": {"item_id": "3266401672", "author_id": "142575116", "name": "Matt Brems", "url": "https://matthew-brems.medium.com"}}, "image": {"item_id": "3266401672", "src": "https://miro.medium.com/max/1400/0*asY-S_5_Nf5x__Mc.gif", "width": "700", "height": "389"}, "images": {"1": {"item_id": "3266401672", "image_id": "1", "src": "https://miro.medium.com/max/1400/0*asY-S_5_Nf5x__Mc.gif", "width": "700", "height": "389", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "The app in action."}, "2": {"item_id": "3266401672", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*xCjlACpcSRVnrrOA.png", "width": "700", "height": "700", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "Red blood cells, white blood cells, and platelets."}, "3": {"item_id": "3266401672", "image_id": "3", "src": "https://miro.medium.com/max/1400/0*_n5TdunZkKtFYjK9", "width": "700", "height": "258", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "The computer vision workflow."}, "4": {"item_id": "3266401672", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*S5mhEGuLm86pDvK_kQBCJw.gif", "width": "700", "height": "467", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "Forking a public dataset."}, "5": {"item_id": "3266401672", "image_id": "5", "src": "https://miro.medium.com/max/1400/0*tX8Xm3C5w0s4QzrK.png", "width": "700", "height": "546", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "Image preprocessing and image augmentation techniques."}, "6": {"item_id": "3266401672", "image_id": "6", "src": "https://miro.medium.com/max/1400/0*0FWS3P6jwF_9aEOm.png", "width": "700", "height": "199", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "Training, validation, and testing splits."}, "7": {"item_id": "3266401672", "image_id": "7", "src": "https://miro.medium.com/max/1400/0*rAF8tqbEi6-mcR55.png", "width": "700", "height": "444", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "Two clicks to train a computer vision model."}, "8": {"item_id": "3266401672", "image_id": "8", "src": "https://miro.medium.com/max/1400/0*hk-VHM2HWbOoxIx6.png", "width": "700", "height": "438", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "Build a model from scratch or use transfer learning."}, "9": {"item_id": "3266401672", "image_id": "9", "src": "https://miro.medium.com/max/1400/0*rTFWrwX3kqcLwYIS.png", "width": "700", "height": "409", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "Overall results for our model’s performance, including mean average precision."}, "10": {"item_id": "3266401672", "image_id": "10", "src": "https://miro.medium.com/max/1400/0*c1FZLjbEuBZiBY1N.png", "width": "700", "height": "386", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "Looking at model performance by class."}, "11": {"item_id": "3266401672", "image_id": "11", "src": "https://miro.medium.com/max/1400/0*oUbz9kf8asy4h42a.png", "width": "700", "height": "628", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "The app sidebar, enabling you to quickly change the parameters of your predictions."}, "12": {"item_id": "3266401672", "image_id": "12", "src": "https://miro.medium.com/max/1400/0*uXP3jt3pkyCswWrs.png", "width": "700", "height": "486", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "The main app area, visualizing predicted output, summary statistics, and bounding box confidence levels."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 731}, "3524055507": {"item_id": "3524055507", "resolved_id": "3521963967", "given_url": "https://link.medium.com/PdMh44o0Fmb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1641730313", "time_updated": "1642360402", "time_read": "1642360402", "time_favorited": "0", "sort_id": 20, "resolved_title": "Curating a Dataset from Raw Images and Videos", "resolved_url": "https://towardsdatascience.com/curating-a-dataset-from-raw-images-and-videos-c8b962eca9ba", "excerpt": "Data is hoarded in large quantities by almost every organization. People coining phrases like “data is the new oil” further incentivizes this. Visual data is no different. Logs and video snippets are constantly packaged and stored in robot fleets.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2258", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/max/1200/0*xNDajhqQHMydCUrB", "tags": {"datasets": {"item_id": "3524055507", "tag": "datasets"}, "deep-learning": {"item_id": "3524055507", "tag": "deep-learning"}, "machine-vision": {"item_id": "3524055507", "tag": "machine-vision"}}, "authors": {"161621023": {"item_id": "3524055507", "author_id": "161621023", "name": "Mokshith Voodarla", "url": "https://medium.com/@mvoodarla"}}, "image": {"item_id": "3524055507", "src": "https://miro.medium.com/fit/c/56/56/1*FSuXj-pnj4UxvG7kL80f1A.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3524055507", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*FSuXj-pnj4UxvG7kL80f1A.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3524055507", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*xNDajhqQHMydCUrB", "width": "700", "height": "203", "credit": "", "caption": "Image by Author"}, "3": {"item_id": "3524055507", "image_id": "3", "src": "https://miro.medium.com/max/1400/0*ggpimVHI1bEiZbTM", "width": "700", "height": "478", "credit": "", "caption": "Sample Image from CamNet dataset, provided by UC Riverside. Link to raw data."}, "4": {"item_id": "3524055507", "image_id": "4", "src": "https://miro.medium.com/max/2000/0*5zIXu4q5apwNRjxX", "width": "1000", "height": "215", "credit": "", "caption": "Image by Author"}, "5": {"item_id": "3524055507", "image_id": "5", "src": "https://miro.medium.com/max/1400/0*WZ2SFf2mxnv9CAZe", "width": "700", "height": "392", "credit": "", "caption": "Tagged Image from CamNet Dataset by Sieve — Image by Author"}, "6": {"item_id": "3524055507", "image_id": "6", "src": "https://miro.medium.com/max/1400/0*VdGvK3LH6PMMxY2y", "width": "700", "height": "629", "credit": "", "caption": "Example Video Filtering Setup, courtesy of Sieve — Image by Author"}, "7": {"item_id": "3524055507", "image_id": "7", "src": "https://miro.medium.com/max/1400/0*W4pe5llFy9KvHE0x", "width": "700", "height": "265", "credit": "", "caption": "Example for percentage-based sampling query from Sieve website — Image by Author"}, "8": {"item_id": "3524055507", "image_id": "8", "src": "https://miro.medium.com/max/1400/0*C20JQ_9lyrHOxgdQ", "width": "700", "height": "228", "credit": "", "caption": "Create different subset scenarios to test models on, photo from Sieve — Image by Author"}, "9": {"item_id": "3524055507", "image_id": "9", "src": "https://miro.medium.com/max/1400/0*4XVJipZFPPDbAtlR", "width": "700", "height": "223", "credit": "", "caption": "Image by Author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 874}, "3899261396": {"item_id": "3899261396", "resolved_id": "3899261396", "given_url": "https://magazine.sebastianraschka.com/p/ahead-of-ai-10-state-of-computer", "given_title": "Ahead of AI #10: State of Computer Vision 2023", "favorite": "0", "status": "1", "time_added": "1688679559", "time_updated": "1689241678", "time_read": "1689241678", "time_favorited": "0", "sort_id": 21, "resolved_title": "Ahead of AI #10: State of Computer Vision 2023", "resolved_url": "https://magazine.sebastianraschka.com/p/ahead-of-ai-10-state-of-computer", "excerpt": "Large language model development (LLM) development is still happening at a rapid pace. At the same time, leaving AI regulation debates aside, LLM news seem to be arriving at a just slightly slower rate than usual.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3016", "lang": "en", "time_to_read": 14, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6090e66d-32e4-45e4-b1c3-d739135aa94c_1074x1108.png", "tags": {"machine-vision": {"item_id": "3899261396", "tag": "machine-vision"}}, "authors": {"177301683": {"item_id": "3899261396", "author_id": "177301683", "name": "Sebastian Raschka, PhD", "url": ""}}, "image": {"item_id": "3899261396", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd086bca6-847b-45ac-9e12-3cd17874a68c_1918x2505.png", "width": "206", "height": "269"}, "images": {"1": {"item_id": "3899261396", "image_id": "1", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd086bca6-847b-45ac-9e12-3cd17874a68c_1918x2505.png", "width": "206", "height": "269", "credit": "or rather gem-packed", "caption": "The jam-packed"}, "2": {"item_id": "3899261396", "image_id": "2", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2673d04-118a-458c-8706-7880a24ac900_852x516.png", "width": "326", "height": "197", "credit": "ViTs", "caption": "Main idea behind vision transformers"}, "3": {"item_id": "3899261396", "image_id": "3", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa0a9e167-b60a-402a-b98b-5324989e3b1e_1542x556.png", "width": "610", "height": "220", "credit": "", "caption": "Training a ViT from scratch versus finetuning a pretrained ViT"}, "4": {"item_id": "3899261396", "image_id": "4", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa208d7a-75c4-4f32-98e1-4a7bacc2507b_1072x862.png", "width": "410", "height": "330", "credit": "", "caption": "Annotated figure from https://arxiv.org/abs/2305.07027"}, "5": {"item_id": "3899261396", "image_id": "5", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5384ffd-36c9-414e-99e3-d988e837a64d_1508x912.png", "width": "488", "height": "295", "credit": "annoated figure from https://arxiv.org/abs/2305.07027", "caption": "Key architecture changes in EfficientViT"}, "6": {"item_id": "3899261396", "image_id": "6", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39356910-f7ee-4ba7-a5ae-d440566dfe1f_1084x730.png", "width": "454", "height": "306", "credit": "known as Stable Diffusion", "caption": "Latent diffusion model"}, "7": {"item_id": "3899261396", "image_id": "7", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d5b1297-2ff2-4b01-b953-7a466da5c1ca_1074x1108.png", "width": "398", "height": "411", "credit": "", "caption": "The new U-ViT architecture introduced in https://arxiv.org/abs/2209.12152"}, "8": {"item_id": "3899261396", "image_id": "8", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa62691f6-762f-4bef-8be9-c1865a79867c_900x1138.png", "width": "304", "height": "384", "credit": "pictures from https://arxiv.org/abs/2303.13817", "caption": "Improved realism via ABLE-NeRF"}, "9": {"item_id": "3899261396", "image_id": "9", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbf450ab5-8334-46ab-a4c4-f31b8145c05c_870x1026.png", "width": "392", "height": "462", "credit": "top", "caption": "Object detection"}, "10": {"item_id": "3899261396", "image_id": "10", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F20a7d8d7-454a-41b4-a9ca-b7d6bf6a5ef4_1434x1000.png", "width": "522", "height": "364", "credit": "", "caption": "Figure from https://arxiv.org/abs/1801.00868"}, "11": {"item_id": "3899261396", "image_id": "11", "src": "https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58367bfb-306b-4b23-8d55-f88b371f52fd_1934x690.png", "width": "140", "height": "140", "credit": "May-June 2023", "caption": "AI Research Highlights In 3 Sentences Or Less"}}, "listen_duration_estimate": 1167}, "3342464232": {"item_id": "3342464232", "resolved_id": "3342464232", "given_url": "https://mars.nasa.gov/technology/helicopter/status/305/surviving-an-in-flight-anomaly-what-happened-on-ingenuitys-sixth-flight/", "given_title": "Surviving an In-Flight Anomaly: What Happened on Ingenuity’s Sixth Flight -", "favorite": "0", "status": "1", "time_added": "1622216391", "time_updated": "1655853208", "time_read": "1622227344", "time_favorited": "0", "sort_id": 22, "resolved_title": "Surviving an In-Flight Anomaly: What Happened on Ingenuity’s Sixth Flight", "resolved_url": "https://mars.nasa.gov/technology/helicopter/status/305/surviving-an-in-flight-anomaly-what-happened-on-ingenuitys-sixth-flight/", "excerpt": "On the 91st Martian day, or sol, of NASA’s Mars 2020 Perseverance rover mission, the Ingenuity Mars Helicopter performed its sixth flight. The flight was designed to expand the flight envelope and demonstrate aerial-imaging capabilities by taking stereo images of a region of interest to the west.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "922", "lang": "en", "time_to_read": 4, "top_image_url": "https://mars.nasa.gov/images/mepjpl/PIA24600-16x9.jpg", "tags": {"astronomy-space": {"item_id": "3342464232", "tag": "astronomy-space"}, "autonomous-driving": {"item_id": "3342464232", "tag": "autonomous-driving"}, "machine-vision": {"item_id": "3342464232", "tag": "machine-vision"}}, "authors": {"149791404": {"item_id": "3342464232", "author_id": "149791404", "name": "Håvard Grip", "url": ""}}, "image": {"item_id": "3342464232", "src": "https://mars.nasa.gov/images/mepjpl/PIA24600-16x9.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3342464232", "image_id": "1", "src": "https://mars.nasa.gov/images/mepjpl/PIA24600-16x9.jpg", "width": "0", "height": "0", "credit": "10 meters", "caption": "This image of Mars was taken from the height of 33 feet"}, "2": {"item_id": "3342464232", "image_id": "2", "src": "https://mars.nasa.gov/system/resources/list_images/25942_PIA24599-web.jpg", "width": "100", "height": "0", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "3342464232", "video_id": "1", "src": "https://mars.nasa.gov/files/mepjpl/PIA24598-IngenuityFlightSix.m4v", "width": "0", "height": "0", "type": "5", "vid": "", "length": "0"}}, "listen_duration_estimate": 357}, "3409982141": {"item_id": "3409982141", "resolved_id": "3409982141", "given_url": "https://neptune.ai/blog/object-detection-algorithms-and-libraries", "given_title": "Object Detection Algorithms and Libraries - neptune.ai", "favorite": "0", "status": "1", "time_added": "1629666972", "time_updated": "1638708525", "time_read": "1629796875", "time_favorited": "0", "sort_id": 23, "resolved_title": "Object Detection Algorithms and Libraries", "resolved_url": "https://neptune.ai/blog/object-detection-algorithms-and-libraries", "excerpt": "Object detection finds and identifies things in images, and it’s one of the biggest accomplishments of deep learning and image processing. One of the common approaches to creating localizations for objects is with the help of bounding boxes.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3892", "lang": "en", "time_to_read": 18, "amp_url": "https://neptune.ai/blog/object-detection-algorithms-and-libraries/amp", "top_image_url": "https://neptune.ai/wp-content/uploads/Object-detection-algorithms-libraries.jpg", "tags": {"deep-learning": {"item_id": "3409982141", "tag": "deep-learning"}, "machine-vision": {"item_id": "3409982141", "tag": "machine-vision"}, "object-detection": {"item_id": "3409982141", "tag": "object-detection"}}, "image": {"item_id": "3409982141", "src": "https://i2.wp.com/neptune.ai/wp-content/uploads/HOG-object-detection-algorithm.png?resize=1024%2C354&ssl=1", "width": "1024", "height": "354"}, "images": {"1": {"item_id": "3409982141", "image_id": "1", "src": "https://i2.wp.com/neptune.ai/wp-content/uploads/HOG-object-detection-algorithm.png?resize=1024%2C354&ssl=1", "width": "1024", "height": "354", "credit": "", "caption": ""}, "2": {"item_id": "3409982141", "image_id": "2", "src": "https://i0.wp.com/neptune.ai/wp-content/uploads/RCNN-object-detection-algorithm.png?resize=1024%2C303&ssl=1", "width": "1024", "height": "303", "credit": "", "caption": ""}, "3": {"item_id": "3409982141", "image_id": "3", "src": "https://i0.wp.com/neptune.ai/wp-content/uploads/Faster-RCNN-object-detection-algorithm.png?resize=1024%2C570&ssl=1", "width": "1024", "height": "570", "credit": "", "caption": ""}, "4": {"item_id": "3409982141", "image_id": "4", "src": "https://i2.wp.com/neptune.ai/wp-content/uploads/SSD-object-detection-algorithm.png?resize=1024%2C345&ssl=1", "width": "1024", "height": "345", "credit": "", "caption": ""}, "5": {"item_id": "3409982141", "image_id": "5", "src": "https://i2.wp.com/neptune.ai/wp-content/uploads/YOLO-object-detection-algorithm.png?resize=1024%2C402&ssl=1", "width": "1024", "height": "402", "credit": "", "caption": ""}, "6": {"item_id": "3409982141", "image_id": "6", "src": "https://i2.wp.com/neptune.ai/wp-content/uploads/RetinaNet-object-detection-algorithm.png?resize=1024%2C278&ssl=1", "width": "1024", "height": "278", "credit": "", "caption": ""}}, "listen_duration_estimate": 1507}, "3874700681": {"item_id": "3874700681", "resolved_id": "3874700681", "given_url": "https://omriavrahami.com/break-a-scene/", "given_title": "Break-A-Scene", "favorite": "0", "status": "1", "time_added": "1696263078", "time_updated": "1696294167", "time_read": "1696294167", "time_favorited": "0", "sort_id": 24, "resolved_title": "Break-A-Scene: Extracting Multiple Concepts from a Single Image", "resolved_url": "https://omriavrahami.com/break-a-scene", "excerpt": "Humans have a natural ability to decompose complex scenes into their constituent parts and envision them in diverse contexts.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "297", "lang": "en", "top_image_url": "https://omriavrahami.com/break-a-scene/static/images/teaser_1200_630.jpg", "tags": {"machine-vision": {"item_id": "3874700681", "tag": "machine-vision"}}, "image": {"item_id": "3874700681", "src": "https://omriavrahami.com/break-a-scene/static/images/method.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3874700681", "image_id": "1", "src": "https://omriavrahami.com/break-a-scene/static/images/method.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 115}, "3778170333": {"item_id": "3778170333", "resolved_id": "3778170333", "given_url": "https://softwarescalability.com/editorial/real-time-object-detection-with-webrtc-and-yolo", "given_title": "Multi-camera real-time object detection with WebRTC and YOLO", "favorite": "0", "status": "1", "time_added": "1672795162", "time_updated": "1672925147", "time_read": "1672925146", "time_favorited": "0", "sort_id": 25, "resolved_title": "Multi-camera real-time object detection with WebRTC and YOLO", "resolved_url": "https://softwarescalability.com/editorial/real-time-object-detection-with-webrtc-and-yolo", "excerpt": "Ever seen Jason Bourne trilogy? In the Jason Bourne trilogy, cameras play a crucial role in the hunt for the titular character, a former CIA assassin suffering from dissociative amnesia who is on the run and trying to uncover the truth about his past.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3766", "lang": "en", "time_to_read": 17, "top_image_url": "https://softwarescalability.com/assets/blog/real-time-object-detection-with-webrtc-and-yolo/cover.jpg", "tags": {"machine-vision": {"item_id": "3778170333", "tag": "machine-vision"}, "object-detection": {"item_id": "3778170333", "tag": "object-detection"}}, "authors": {"176523776": {"item_id": "3778170333", "author_id": "176523776", "name": "Genert Org", "url": "https://twitter.com/_genert"}}, "image": {"item_id": "3778170333", "src": "https://softwarescalability.com/_next/image?url=%2Fassets%2Fblog%2Freal-time-object-detection-with-webrtc-and-yolo%2Fmovie_bourne_scene_001.gif&w=828&q=75", "width": "400", "height": "169"}, "images": {"1": {"item_id": "3778170333", "image_id": "1", "src": "https://softwarescalability.com/_next/image?url=%2Fassets%2Fblog%2Freal-time-object-detection-with-webrtc-and-yolo%2Fmovie_bourne_scene_001.gif&w=828&q=75", "width": "400", "height": "169", "credit": "", "caption": ""}, "2": {"item_id": "3778170333", "image_id": "2", "src": "https://softwarescalability.com/_next/image?url=%2Fassets%2Fblog%2Freal-time-object-detection-with-webrtc-and-yolo%2Fpattern_classification_example.png&w=2048&q=75", "width": "1000", "height": "657", "credit": "", "caption": ""}, "3": {"item_id": "3778170333", "image_id": "3", "src": "https://softwarescalability.com/_next/image?url=%2Fassets%2Fblog%2Freal-time-object-detection-with-webrtc-and-yolo%2Fpoc_result.jpeg&w=3840&q=75", "width": "1280", "height": "698", "credit": "", "caption": ""}}, "listen_duration_estimate": 1458}, "3931711811": {"item_id": "3931711811", "resolved_id": "3931711811", "given_url": "https://techcrunch.com/2023/09/07/ebay-rolls-out-a-tool-that-generates-product-listings-from-photos/", "given_title": "eBay rolls out a tool that generates product listings from photos", "favorite": "0", "status": "1", "time_added": "1694103989", "time_updated": "1694105463", "time_read": "1694105463", "time_favorited": "0", "sort_id": 26, "resolved_title": "eBay rolls out a tool that generates product listings from photos", "resolved_url": "https://techcrunch.com/2023/09/07/ebay-rolls-out-a-tool-that-generates-product-listings-from-photos/", "excerpt": "Available in the eBay app for iOS to start, with the Android app to follow in the coming weeks, the tool can automatically write a title and description based on a photo, as well as information including a product release date, and suggest a category, subcategory, list price and shipping cost.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "803", "lang": "en", "time_to_read": 4, "amp_url": "https://techcrunch.com/2023/09/07/ebay-rolls-out-a-tool-that-generates-product-listings-from-photos/amp/", "top_image_url": "https://techcrunch.com/wp-content/uploads/2019/09/GettyImages-632621434.jpg?w=1024", "tags": {"ecommerce": {"item_id": "3931711811", "tag": "ecommerce"}, "machine-vision": {"item_id": "3931711811", "tag": "machine-vision"}, "object-detection": {"item_id": "3931711811", "tag": "object-detection"}, "prodmgmt": {"item_id": "3931711811", "tag": "prodmgmt"}}, "authors": {"165625342": {"item_id": "3931711811", "author_id": "165625342", "name": "Kyle Wiggers", "url": "https://techcrunch.com/author/kyle-wiggers/"}}, "image": {"item_id": "3931711811", "src": "https://techcrunch.com/wp-content/uploads/2019/09/GettyImages-632621434.jpg?w=600", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3931711811", "image_id": "1", "src": "https://techcrunch.com/wp-content/uploads/2019/09/GettyImages-632621434.jpg?w=600", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3931711811", "image_id": "2", "src": "https://techcrunch.com/wp-content/uploads/2023/09/magical-listing-still-alt-2.png", "width": "1024", "height": "576", "credit": "", "caption": "eBay’s tool converts photos to listings."}}, "domain_metadata": {"name": "TechCrunch", "logo": "https://logo.clearbit.com/techcrunch.com?size=800", "greyscale_logo": "https://logo.clearbit.com/techcrunch.com?size=800&greyscale=true"}, "listen_duration_estimate": 311}, "3911851965": {"item_id": "3911851965", "resolved_id": "3911851965", "given_url": "https://thehustle.co/how-to-make-photos-confusing-to-ai/", "given_title": "How to make photos confusing to AI", "favorite": "0", "status": "1", "time_added": "1690764371", "time_updated": "1691365713", "time_read": "1691365713", "time_favorited": "0", "sort_id": 27, "resolved_title": "How to make photos confusing to AI", "resolved_url": "https://thehustle.co/how-to-make-photos-confusing-to-ai/", "excerpt": "AI image generators are fun to play with, but the problem with generative AI is, well, it’s generative. It absorbs information from the internet and spits out content influenced by that info.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "255", "lang": "en", "amp_url": "https://thehustle.co/how-to-make-photos-confusing-to-ai/amp/", "top_image_url": "https://thehustle.co/wp-content/uploads/2022/04/hustle-og-image.jpg", "tags": {"machine-vision": {"item_id": "3911851965", "tag": "machine-vision"}}, "authors": {"23905043": {"item_id": "3911851965", "author_id": "23905043", "name": "Juliet Bennett Rylah", "url": ""}}, "listen_duration_estimate": 99}, "3287162741": {"item_id": "3287162741", "resolved_id": "3287162741", "given_url": "https://theness.com/neurologicablog/index.php/breaking-through-the-uncanny-valley/", "given_title": "Breaking Through the Uncanny Valley", "favorite": "0", "status": "1", "time_added": "1616415006", "time_updated": "1616442435", "time_read": "1616442435", "time_favorited": "0", "sort_id": 28, "resolved_title": "Breaking Through the Uncanny Valley", "resolved_url": "https://theness.com/neurologicablog/index.php/breaking-through-the-uncanny-valley/", "excerpt": "In 1970 robotics professor Masahiro Mori observed, “Bbukimi no tani genshō,” which was later translated into “uncanny valley”.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1053", "lang": "en", "time_to_read": 5, "top_image_url": "https://theness.com/neurologicablog/wp-content/uploads/sites/3/2021/03/creepy-girl-uncanny-valley.jpg", "tags": {"behaviors": {"item_id": "3287162741", "tag": "behaviors"}, "machine-vision": {"item_id": "3287162741", "tag": "machine-vision"}, "robotics": {"item_id": "3287162741", "tag": "robotics"}}, "authors": {"79851630": {"item_id": "3287162741", "author_id": "79851630", "name": "Steven Novella", "url": "https://theness.com/neurologicablog/index.php/author/snovella/"}}, "image": {"item_id": "3287162741", "src": "https://theness.com/neurologicablog/wp-content/uploads/sites/3/2021/03/creepy-girl-uncanny-valley-700x412.jpg", "width": "340", "height": "200"}, "images": {"1": {"item_id": "3287162741", "image_id": "1", "src": "https://theness.com/neurologicablog/wp-content/uploads/sites/3/2021/03/creepy-girl-uncanny-valley-700x412.jpg", "width": "340", "height": "200", "credit": "", "caption": ""}}, "listen_duration_estimate": 408}, "3278175081": {"item_id": "3278175081", "resolved_id": "3278175081", "given_url": "https://thenextweb.com/neural/2021/03/11/ai-detects-deepfakes-analyzing-light-reflections-in-the-cornea-eyes-gans-thispersondoesnotexist/", "given_title": "New AI tool detects Deepfakes by analyzing light reflections in the eyes", "favorite": "0", "status": "1", "time_added": "1615720596", "time_updated": "1638708525", "time_read": "1615720629", "time_favorited": "0", "sort_id": 29, "resolved_title": "AI tool detects Deepfakes by analyzing light reflections in the eyes", "resolved_url": "https://thenextweb.com/neural/2021/03/11/ai-detects-deepfakes-analyzing-light-reflections-in-the-cornea-eyes-gans-thispersondoesnotexist/", "excerpt": "Writer at Neural by TNW — Thomas covers AI in all its iterations. Likes Werner Herzog films and Arsenal FC.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "437", "lang": "en", "amp_url": "https://thenextweb.com/news/ai-detects-deepfakes-analyzing-light-reflections-in-the-cornea-eyes-gans-thispersondoesnotexist/amp", "top_image_url": "https://img-cdn.tnwcdn.com/image/neural?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2021%2F03%2Fimage-2-1.jpg&signature=dda76292883900c4239ddfdb05eb5045", "tags": {"deep-learning": {"item_id": "3278175081", "tag": "deep-learning"}, "deepfakes": {"item_id": "3278175081", "tag": "deepfakes"}, "gans": {"item_id": "3278175081", "tag": "gans"}, "machine-vision": {"item_id": "3278175081", "tag": "machine-vision"}}, "authors": {"28642972": {"item_id": "3278175081", "author_id": "28642972", "name": "Thomas Macaulay", "url": ""}}, "image": {"item_id": "3278175081", "src": "https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2021/03/Screenshot-2021-03-11-at-16.15.55.png", "width": "982", "height": "634"}, "images": {"1": {"item_id": "3278175081", "image_id": "1", "src": "https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2021/03/Screenshot-2021-03-11-at-16.15.55.png", "width": "982", "height": "634", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The Next Web", "logo": "https://logo.clearbit.com/thenextweb.com?size=800", "greyscale_logo": "https://logo.clearbit.com/thenextweb.com?size=800&greyscale=true"}, "listen_duration_estimate": 169}, "3411518543": {"item_id": "3411518543", "resolved_id": "3411518561", "given_url": "https://towardsdatascience.com/10-computer-vision-terms-everyone-must-know-about-687a98845fc8?source=rss----7f60cf5620c9---4", "given_title": "10 Computer Vision Terms Everyone Must Know About!", "favorite": "0", "status": "1", "time_added": "1629481209", "time_updated": "1706233547", "time_read": "1629666990", "time_favorited": "0", "sort_id": 30, "resolved_title": "10 Computer Vision Terms Everyone Must Know About!", "resolved_url": "https://towardsdatascience.com/10-computer-vision-terms-everyone-must-know-about-687a98845fc8", "excerpt": "The notion that machines or computers could perceive images in the real world and interpret them accordingly was once deemed impossible.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2386", "lang": "en", "time_to_read": 11, "top_image_url": "https://miro.medium.com/max/1200/0*LFhMuFB1_hyYnoE2", "tags": {"algorithms-math": {"item_id": "3411518543", "tag": "algorithms-math"}, "deep-learning": {"item_id": "3411518543", "tag": "deep-learning"}, "machine-vision": {"item_id": "3411518543", "tag": "machine-vision"}}, "authors": {"144409854": {"item_id": "3411518543", "author_id": "144409854", "name": "Bharath K", "url": "https://bharath-k1297.medium.com"}}, "image": {"item_id": "3411518543", "src": "https://miro.medium.com/max/2000/0*LFhMuFB1_hyYnoE2", "width": "1000", "height": "667"}, "images": {"1": {"item_id": "3411518543", "image_id": "1", "src": "https://miro.medium.com/max/2000/0*LFhMuFB1_hyYnoE2", "width": "1000", "height": "667", "credit": "Brooke Cagle on Unsplash", "caption": ""}, "2": {"item_id": "3411518543", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*9U8ZGWvLj1sEtmjD.png", "width": "700", "height": "417", "credit": "", "caption": ""}, "3": {"item_id": "3411518543", "image_id": "3", "src": "https://miro.medium.com/max/680/1*hDustSl11Py-vFlrBDqffA.png", "width": "340", "height": "94", "credit": "", "caption": "Dice Similarity Coefficient"}, "4": {"item_id": "3411518543", "image_id": "4", "src": "https://miro.medium.com/max/1400/0*IxXXM1M-PuXmp8u0", "width": "700", "height": "467", "credit": "Jackie Zhao on Unsplash", "caption": ""}, "5": {"item_id": "3411518543", "image_id": "5", "src": "https://miro.medium.com/max/1400/0*TcbseoIR_tvGnOEY", "width": "700", "height": "467", "credit": "C D-X on Unsplash", "caption": ""}, "6": {"item_id": "3411518543", "image_id": "6", "src": "https://miro.medium.com/max/670/1*q4eWelNCz1Yu2RbxusVyHQ.png", "width": "335", "height": "362", "credit": "", "caption": "Image By Author"}, "7": {"item_id": "3411518543", "image_id": "7", "src": "https://miro.medium.com/max/1400/0*o7TfTqm7qN_JGiCA", "width": "700", "height": "433", "credit": "Mike Dorner on Unsplash", "caption": ""}, "8": {"item_id": "3411518543", "image_id": "8", "src": "https://miro.medium.com/max/1400/0*oCFochYai3A2h5ez", "width": "700", "height": "466", "credit": "Eric Prouzet on Unsplash", "caption": ""}, "9": {"item_id": "3411518543", "image_id": "9", "src": "https://miro.medium.com/max/1400/0*RPUGZ9ySmAGVcIWE", "width": "700", "height": "394", "credit": "Austin Distel on Unsplash", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 924}, "3393063573": {"item_id": "3393063573", "resolved_id": "3393063587", "given_url": "https://towardsdatascience.com/5-ultimate-python-libraries-for-image-processing-13f89d32769e?source=rss----7f60cf5620c9---4", "given_title": "5 Ultimate Python Libraries for Image Processing", "favorite": "0", "status": "1", "time_added": "1627573932", "time_updated": "1627647590", "time_read": "1627647590", "time_favorited": "0", "sort_id": 31, "resolved_title": "5 Ultimate Python Libraries for Image Processing", "resolved_url": "https://towardsdatascience.com/5-ultimate-python-libraries-for-image-processing-13f89d32769e", "excerpt": "Image processing is the phenomenon of manipulating an image to extract features from it. In today’s world of computer vision and deep learning, different algorithms for image processing are heavily used to carry out edge detection, recognition, classification from a dataset of images.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "721", "lang": "en", "time_to_read": 3, "top_image_url": "https://miro.medium.com/max/1200/1*7SF7Ai0xkGVZ5i-Xi5ABxg.jpeg", "tags": {"machine-learning": {"item_id": "3393063573", "tag": "machine-learning"}, "machine-vision": {"item_id": "3393063573", "tag": "machine-vision"}, "python": {"item_id": "3393063573", "tag": "python"}}, "authors": {"141786504": {"item_id": "3393063573", "author_id": "141786504", "name": "Pranjal Saxena", "url": "https://pranjalai.medium.com"}}, "image": {"item_id": "3393063573", "src": "https://miro.medium.com/fit/c/56/56/1*iLih1inv6JGE7xopBXYu9A.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3393063573", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*iLih1inv6JGE7xopBXYu9A.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3393063573", "image_id": "2", "src": "https://miro.medium.com/max/2000/1*7SF7Ai0xkGVZ5i-Xi5ABxg.jpeg", "width": "1000", "height": "751", "credit": "Mike from Pexels", "caption": ""}, "3": {"item_id": "3393063573", "image_id": "3", "src": "https://miro.medium.com/max/2000/1*1_1RvV3ngtsMqgVN6MwINA.png", "width": "1000", "height": "641", "credit": "", "caption": "Blurred Image after applying filter — Screenshot by Author"}, "4": {"item_id": "3393063573", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*Rz7b9DlrAG5UsRDhcLuQOg.png", "width": "700", "height": "405", "credit": "", "caption": "Screenshot added by Author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 279}, "3292048312": {"item_id": "3292048312", "resolved_id": "3292048336", "given_url": "https://towardsdatascience.com/a-beginners-guide-to-image-augmentations-in-machine-learning-22c48a2fbd99?source=rss----7f60cf5620c9---4", "given_title": "A Beginner’s Guide to Image Augmentations in Machine Learning", "favorite": "0", "status": "1", "time_added": "1616936859", "time_updated": "1616952292", "time_read": "1616952293", "time_favorited": "0", "sort_id": 32, "resolved_title": "A Beginner’s Guide to Image Augmentations in Machine Learning", "resolved_url": "https://towardsdatascience.com/a-beginners-guide-to-image-augmentations-in-machine-learning-22c48a2fbd99", "excerpt": "Data Augmentation is one of the most important yet underrated aspects of a machine learning system and has a significant impact on the model's performance. In this article, we will go over some prevalent image augmentation techniques and also discuss why such methods are required in the first place.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1542", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/1200/0*9A-t8pz7YSCMwJRo", "tags": {"image-augmentation": {"item_id": "3292048312", "tag": "image-augmentation"}, "machine-learning": {"item_id": "3292048312", "tag": "machine-learning"}, "machine-vision": {"item_id": "3292048312", "tag": "machine-vision"}}, "authors": {"144893955": {"item_id": "3292048312", "author_id": "144893955", "name": "Aryansh Omray", "url": "https://aryanshomray.medium.com"}}, "image": {"item_id": "3292048312", "src": "https://miro.medium.com/fit/c/56/56/0*k6ANrJ2re23C9u-q", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3292048312", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/0*k6ANrJ2re23C9u-q", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3292048312", "image_id": "2", "src": "https://miro.medium.com/max/2000/0*9A-t8pz7YSCMwJRo", "width": "1000", "height": "667", "credit": "Markus Spiske on Unsplash", "caption": ""}, "3": {"item_id": "3292048312", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*qGDoWtQcFr4S1LAsIVjJ6w.png", "width": "700", "height": "232", "credit": "Unsplash", "caption": "Image and blurred Image."}, "4": {"item_id": "3292048312", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*vXuuRgK2c5xfazHitD94YA.png", "width": "700", "height": "894", "credit": "Real image is at bottom right", "caption": "The resulting image after noise addition"}, "5": {"item_id": "3292048312", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*VLXq7_5LJMKWTTh2e8DmEA.png", "width": "700", "height": "271", "credit": "Unsplash", "caption": ""}, "6": {"item_id": "3292048312", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*lCE4_5-8bDApQoBfEhYTAg.png", "width": "700", "height": "348", "credit": "Unsplash", "caption": ""}, "7": {"item_id": "3292048312", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*GH2ppnmD7DQLawSSxhbJZA.png", "width": "700", "height": "350", "credit": "Unsplash", "caption": ""}, "8": {"item_id": "3292048312", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*W-o88TuE7aKvTwP3ljU-2Q.png", "width": "700", "height": "344", "credit": "Unsplash", "caption": ""}, "9": {"item_id": "3292048312", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*LmRmfcoqjgixR1DRiiPPWA.png", "width": "700", "height": "346", "credit": "Unsplash", "caption": ""}, "10": {"item_id": "3292048312", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*UWPb6rrKiDocYkYE-sORZQ.png", "width": "700", "height": "230", "credit": "Unsplash", "caption": ""}, "11": {"item_id": "3292048312", "image_id": "11", "src": "https://miro.medium.com/max/1400/1*xQVgcG3rXiRdFEW-RlVPsA.png", "width": "700", "height": "156", "credit": "Unsplash", "caption": ""}, "12": {"item_id": "3292048312", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*1Akn_-ihRFPNUSPU_InuLg.png", "width": "700", "height": "155", "credit": "Unsplash", "caption": ""}, "13": {"item_id": "3292048312", "image_id": "13", "src": "https://miro.medium.com/max/1400/1*S7Dm9V6iVFUSMdv7U0eURQ.png", "width": "700", "height": "336", "credit": "Unsplash", "caption": ""}, "14": {"item_id": "3292048312", "image_id": "14", "src": "https://miro.medium.com/max/1400/1*GxIO_BexvTd5_0sj0U_gpQ.png", "width": "700", "height": "354", "credit": "Unsplash", "caption": ""}, "15": {"item_id": "3292048312", "image_id": "15", "src": "https://miro.medium.com/max/1400/1*QnIPws9GK7u0rHmLkNPWmA.png", "width": "700", "height": "393", "credit": "Unsplash", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 597}, "3698888204": {"item_id": "3698888204", "resolved_id": "3698888204", "given_url": "https://towardsdatascience.com/a-comprehensive-tutorial-on-stereo-geometry-and-stereo-rectification-with-python-7f368b09924a", "given_title": "A Comprehensive Tutorial on Stereo Geometry and Stereo Rectification with P", "favorite": "0", "status": "1", "time_added": "1662677551", "time_updated": "1706650991", "time_read": "1663289638", "time_favorited": "0", "sort_id": 33, "resolved_title": "A Comprehensive Tutorial on Stereo Geometry and Stereo Rectification with Python", "resolved_url": "https://towardsdatascience.com/a-comprehensive-tutorial-on-stereo-geometry-and-stereo-rectification-with-python-7f368b09924a", "excerpt": "In the pin-hole model of a camera, light rays reflect off of an object and hit the film to form an image. So all the points that lie along the same ray will correspond to a single point in the image. Hence given a point in the image, it’s impossible to pin-point its exact location in the world i.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4294", "lang": "en", "time_to_read": 20, "top_image_url": "https://miro.medium.com/max/1200/1*bq7TY8eW7Q6dlwHh2LwQVA.jpeg", "tags": {"cameras": {"item_id": "3698888204", "tag": "cameras"}, "machine-vision": {"item_id": "3698888204", "tag": "machine-vision"}, "movies-television": {"item_id": "3698888204", "tag": "movies-television"}, "python": {"item_id": "3698888204", "tag": "python"}}, "authors": {"154402863": {"item_id": "3698888204", "author_id": "154402863", "name": "Neeraj Krishna", "url": "https://ms-neerajkrishna.medium.com"}}, "image": {"item_id": "3698888204", "src": "https://miro.medium.com/max/1400/1*bq7TY8eW7Q6dlwHh2LwQVA.jpeg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3698888204", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*bq7TY8eW7Q6dlwHh2LwQVA.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3698888204", "image_id": "2", "src": "https://miro.medium.com/max/460/1*67CKM6bzPjK7TlgHserjDQ.png", "width": "0", "height": "0", "credit": "", "caption": "homogeneous <-> euclidean representation"}, "3": {"item_id": "3698888204", "image_id": "3", "src": "https://miro.medium.com/max/838/1*NJer-jNhHnOufnyuDFFEyQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3698888204", "image_id": "4", "src": "https://miro.medium.com/max/1356/1*p2kpVcgwiw8_-ZJrhvZM6Q.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3698888204", "image_id": "5", "src": "https://miro.medium.com/max/722/1*I-8TlIk3xcoUy1djNU7KsQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3698888204", "image_id": "6", "src": "https://miro.medium.com/max/1122/1*spdnHO0V6fmnVGXbgUU4ag.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3698888204", "image_id": "7", "src": "https://miro.medium.com/max/1082/1*EpIdoa44CcWjqAdbya4-Sw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3698888204", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*6LKxt7iT6p2-eAPmmBpciw.png", "width": "0", "height": "0", "credit": "", "caption": "A calibrated system of two cameras where the relative position and orientation are known"}, "9": {"item_id": "3698888204", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*bzvUdmx1tRl132snTlsvsg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3698888204", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*h7D3MXZxsqfSqAQsZPiK-g.png", "width": "0", "height": "0", "credit": "", "caption": "cross product as matrix representation"}, "11": {"item_id": "3698888204", "image_id": "11", "src": "https://miro.medium.com/max/1400/1*d4BE7WrT_BQoQCC3R51u3A.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3698888204", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*288oXxTRIV54m7oWcWHseQ.png", "width": "0", "height": "0", "credit": "", "caption": "the cross product matrix"}, "13": {"item_id": "3698888204", "image_id": "13", "src": "https://miro.medium.com/max/1400/1*lXZWnTTQvNghq0jdIZ_-pw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "3698888204", "image_id": "14", "src": "https://miro.medium.com/max/1400/1*Doja2jGsTVtKXvzplPTWSg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "3698888204", "image_id": "15", "src": "https://miro.medium.com/max/1400/1*gNKITvr6TQLVCdrmXPOTWg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "3698888204", "image_id": "16", "src": "https://miro.medium.com/max/1400/1*JNWKOoVr1d0TNQ6tGNK4uA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "3698888204", "image_id": "17", "src": "https://miro.medium.com/max/1400/1*0AYd4VPetD-6swbl4SjoSg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "3698888204", "image_id": "18", "src": "https://miro.medium.com/max/1400/1*GDT2E7FyYEhZJRhRpzwdkA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "3698888204", "image_id": "19", "src": "https://miro.medium.com/max/1400/1*ENRGL1eNVKkEbSgEWH56AA.png", "width": "0", "height": "0", "credit": "", "caption": "The essential matrix equation"}, "20": {"item_id": "3698888204", "image_id": "20", "src": "https://miro.medium.com/max/1400/1*EtBD23NjENQ_69Xr0shryQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "3698888204", "image_id": "21", "src": "https://miro.medium.com/max/1400/1*oNBGIiSY7KkeZj344ECO1Q.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "3698888204", "image_id": "22", "src": "https://miro.medium.com/max/1400/1*YpMKcdNatVl0eY80kgtKPA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "23": {"item_id": "3698888204", "image_id": "23", "src": "https://miro.medium.com/max/1400/1*0lYevnkv38QdKRH66YOrRA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "3698888204", "image_id": "24", "src": "https://miro.medium.com/max/1400/1*IqZ80qZ470sA9FywcPNm1A.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "3698888204", "image_id": "25", "src": "https://miro.medium.com/max/1400/1*ivThyA81RzAWoRSASO6PmA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "26": {"item_id": "3698888204", "image_id": "26", "src": "https://miro.medium.com/max/1400/1*0cE6ycpLsftjb4m0PXIA8Q.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "27": {"item_id": "3698888204", "image_id": "27", "src": "https://miro.medium.com/max/1400/1*OWlXeI3NUqGd-6RdMXQg9A.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "28": {"item_id": "3698888204", "image_id": "28", "src": "https://miro.medium.com/max/1400/1*kk-Ln4DiqLgX4xCYAM_2dg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "29": {"item_id": "3698888204", "image_id": "29", "src": "https://miro.medium.com/max/1400/1*I6uc8FCNRRYg-IePQBkVRw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "30": {"item_id": "3698888204", "image_id": "30", "src": "https://miro.medium.com/max/1400/1*wQwgIgYO4KP6t7jrJWPK4A.png", "width": "0", "height": "0", "credit": "", "caption": "epipolar lines in the image"}, "31": {"item_id": "3698888204", "image_id": "31", "src": "https://miro.medium.com/max/1400/1*sE2mgSQIFPRIqYTRU6UqHg.png", "width": "0", "height": "0", "credit": "", "caption": "Top down view of two parallel cameras"}, "32": {"item_id": "3698888204", "image_id": "32", "src": "https://miro.medium.com/max/1400/1*a0MxanszxqTf7r3tVfxnoQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "33": {"item_id": "3698888204", "image_id": "33", "src": "https://miro.medium.com/max/1400/1*qqvoPNuf414DHFtGKVtwZA.png", "width": "0", "height": "0", "credit": "", "caption": "Essential Matrix in Parallel Image Planes"}, "34": {"item_id": "3698888204", "image_id": "34", "src": "https://miro.medium.com/max/1400/1*TI4zZXh6_XAFwCiwc-nJYA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "35": {"item_id": "3698888204", "image_id": "35", "src": "https://miro.medium.com/max/1400/1*Yjpnz4Jbl9kA0FFcBqo1OA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "36": {"item_id": "3698888204", "image_id": "36", "src": "https://miro.medium.com/max/1400/1*CkmDiKjkWMPB9OweJDBpDA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "37": {"item_id": "3698888204", "image_id": "37", "src": "https://miro.medium.com/max/1400/1*ikuBo1bmcgD3eSShoSa6PQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "38": {"item_id": "3698888204", "image_id": "38", "src": "https://miro.medium.com/max/1400/1*qnFlNS0SANKY71loXkOExg.png", "width": "0", "height": "0", "credit": "", "caption": "Epipolar Line Equation for Parallel Image Planes"}, "39": {"item_id": "3698888204", "image_id": "39", "src": "https://miro.medium.com/max/1400/1*CVim_18eii_whFjSMZjTTA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "40": {"item_id": "3698888204", "image_id": "40", "src": "https://miro.medium.com/max/1400/1*hTCNvsf0HrIwy_3MNQPpHQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "41": {"item_id": "3698888204", "image_id": "41", "src": "https://miro.medium.com/max/1400/1*gibFJz3VltAYZDx6tmypzQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "42": {"item_id": "3698888204", "image_id": "42", "src": "https://miro.medium.com/max/1400/1*jxn6_tF402z6vF-5hX8T_g.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "43": {"item_id": "3698888204", "image_id": "43", "src": "https://miro.medium.com/max/1400/1*DFRWNhYeyO5Qi_pyOeMm4w.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "44": {"item_id": "3698888204", "image_id": "44", "src": "https://miro.medium.com/max/1400/1*P2wkQfpuFRk1F7y8L-nn1w.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "45": {"item_id": "3698888204", "image_id": "45", "src": "https://miro.medium.com/max/1400/1*v7TISEwijDXurZrNPWrkxw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "46": {"item_id": "3698888204", "image_id": "46", "src": "https://miro.medium.com/max/1400/1*XCuSXveYbRo0Bh_gWUnteQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "47": {"item_id": "3698888204", "image_id": "47", "src": "https://miro.medium.com/max/1400/1*d6MweO9ubLLnXj34ISF8FQ.png", "width": "0", "height": "0", "credit": "", "caption": "The Fundamental Matrix Equation"}, "48": {"item_id": "3698888204", "image_id": "48", "src": "https://miro.medium.com/max/1400/1*c6UPKBR6PrGZlDA4vq4Hlw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "49": {"item_id": "3698888204", "image_id": "49", "src": "https://miro.medium.com/max/1400/1*XeuD63jjVRVYMa_JV5aZ6w.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "50": {"item_id": "3698888204", "image_id": "50", "src": "https://miro.medium.com/max/1400/1*cPwd5Qym8oTNo3bES5NsbQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "51": {"item_id": "3698888204", "image_id": "51", "src": "https://miro.medium.com/max/1400/1*O-9PnM9FXF_0tNJIfrjccQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "52": {"item_id": "3698888204", "image_id": "52", "src": "https://miro.medium.com/max/1400/1*aWWNaDzjx7pWrTG3yf4rPQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "53": {"item_id": "3698888204", "image_id": "53", "src": "https://miro.medium.com/max/1400/1*eUwCvaNRkOKvt04k5TAAJQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "54": {"item_id": "3698888204", "image_id": "54", "src": "https://miro.medium.com/max/1400/1*p9bhZib94eB8W7XYawJgSQ.png", "width": "0", "height": "0", "credit": "", "caption": "Normalizing point correspondences"}, "55": {"item_id": "3698888204", "image_id": "55", "src": "https://miro.medium.com/max/1400/1*gArByQV7VkhS3bKJnDIgUw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "56": {"item_id": "3698888204", "image_id": "56", "src": "https://miro.medium.com/max/1400/1*nWjvnUdTpFMebMSPofEHZA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "57": {"item_id": "3698888204", "image_id": "57", "src": "https://miro.medium.com/max/1400/1*rD5DBoXvi2ei3IQrbV8gkw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "58": {"item_id": "3698888204", "image_id": "58", "src": "https://miro.medium.com/max/1400/1*m1ajvQEF5IggJHUzxauMfA.png", "width": "0", "height": "0", "credit": "", "caption": "Image from left camera"}, "59": {"item_id": "3698888204", "image_id": "59", "src": "https://miro.medium.com/max/1400/1*65x5oakfuAM82rPHWCeMyg.png", "width": "0", "height": "0", "credit": "", "caption": "Image from right camera"}, "60": {"item_id": "3698888204", "image_id": "60", "src": "https://miro.medium.com/max/1400/1*405iAA1TwpGh0WTapbeBNQ.png", "width": "0", "height": "0", "credit": "", "caption": "Point Correspondences"}, "61": {"item_id": "3698888204", "image_id": "61", "src": "https://miro.medium.com/max/1400/1*5KhFS5tNiwRUloJN0zLk3A.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "62": {"item_id": "3698888204", "image_id": "62", "src": "https://miro.medium.com/max/1400/1*SSgHBgBxlGXHb7kh6iAEfw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "63": {"item_id": "3698888204", "image_id": "63", "src": "https://miro.medium.com/max/1400/1*ijsomgzTEBJyUwmOnWESNA.png", "width": "0", "height": "0", "credit": "", "caption": "Epipolar Lines"}, "64": {"item_id": "3698888204", "image_id": "64", "src": "https://miro.medium.com/max/1400/1*WlardvBPWt4qUTq9CP101A.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "65": {"item_id": "3698888204", "image_id": "65", "src": "https://miro.medium.com/max/1400/1*VZtYdFarK62yoCLUs9rNUw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "66": {"item_id": "3698888204", "image_id": "66", "src": "https://miro.medium.com/max/1400/1*33gEuxORACV0qkjxN-WQ-Q.png", "width": "0", "height": "0", "credit": "", "caption": "Epipoles"}, "67": {"item_id": "3698888204", "image_id": "67", "src": "https://miro.medium.com/max/1400/1*thxzTmqS8crtGmr4HDaprQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "68": {"item_id": "3698888204", "image_id": "68", "src": "https://miro.medium.com/max/1400/1*mnYzapFe2MwvjvwmxcYBPw.png", "width": "0", "height": "0", "credit": "", "caption": "Rotation matrix to rotate the point back to X~axis"}, "69": {"item_id": "3698888204", "image_id": "69", "src": "https://miro.medium.com/max/1400/1*ul6zeJPnX_URx2c5uGjV-w.png", "width": "0", "height": "0", "credit": "", "caption": "The homography matrix"}, "70": {"item_id": "3698888204", "image_id": "70", "src": "https://miro.medium.com/max/1400/1*-qv2TzVZHgpXz-9Bl6v2mQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "71": {"item_id": "3698888204", "image_id": "71", "src": "https://miro.medium.com/max/1400/1*uQDJAuCmSE2lVWzccEkPbQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "72": {"item_id": "3698888204", "image_id": "72", "src": "https://miro.medium.com/max/1400/1*IV91o6wz9hQoPvq4SsLptg.png", "width": "0", "height": "0", "credit": "", "caption": "Y coordinate is zero here because we’ve rotated the point back to X-axis"}, "73": {"item_id": "3698888204", "image_id": "73", "src": "https://miro.medium.com/max/1400/1*CiF-YGf8BJnzy8JqKIDyag.png", "width": "0", "height": "0", "credit": "", "caption": "Translation matrix to shift to center"}, "74": {"item_id": "3698888204", "image_id": "74", "src": "https://miro.medium.com/max/1400/1*HR93Pqv6FMjGVfMq5YpVGw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "75": {"item_id": "3698888204", "image_id": "75", "src": "https://miro.medium.com/max/1400/1*gvwujN1KdtSq4X0AzYaebw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "76": {"item_id": "3698888204", "image_id": "76", "src": "https://miro.medium.com/max/1400/1*7oB3d6p8EzgJ_h5yz5YC4Q.png", "width": "0", "height": "0", "credit": "", "caption": "Warp images using homography matrices"}, "77": {"item_id": "3698888204", "image_id": "77", "src": "https://miro.medium.com/max/1400/1*_zg0iSJdJnthEuJWaL3Y7A.png", "width": "0", "height": "0", "credit": "", "caption": "Parallel epipolar lines for warped images"}, "78": {"item_id": "3698888204", "image_id": "78", "src": "https://miro.medium.com/max/1400/1*gdkBm-ngtTgKDBSTVzqOUQ.png", "width": "0", "height": "0", "credit": "", "caption": "Inaccurate epipolar lines"}, "79": {"item_id": "3698888204", "image_id": "79", "src": "https://miro.medium.com/max/1102/1*7TR5f8_96aftp_6KTFfRbw.png", "width": "0", "height": "0", "credit": "", "caption": "Disparity map computed using rectified images"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1662}, "3480858287": {"item_id": "3480858287", "resolved_id": "3480858287", "given_url": "https://towardsdatascience.com/asset2vec-turning-3d-objects-into-vectors-and-back-8335496b756d", "given_title": "", "favorite": "0", "status": "1", "time_added": "1645893627", "time_updated": "1691365171", "time_read": "1646009648", "time_favorited": "0", "sort_id": 34, "resolved_title": "Asset2Vec: Turning 3D Objects into Vectors and Back", "resolved_url": "https://towardsdatascience.com/asset2vec-turning-3d-objects-into-vectors-and-back-8335496b756d", "excerpt": "At Datagen, where I currently work as the Head of AI research, we create synthetic photorealistic images of common 3D environments, for the purpose of training computer vision algorithms.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1526", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/963/1*EKdPweq5B-8w7dnkYKXQ2g.png", "tags": {"machine-learning": {"item_id": "3480858287", "tag": "machine-learning"}, "machine-vision": {"item_id": "3480858287", "tag": "machine-vision"}}, "authors": {"155494392": {"item_id": "3480858287", "author_id": "155494392", "name": "Jonathan Laserson, PhD", "url": "https://medium.com/@jonilaserson"}}, "image": {"item_id": "3480858287", "src": "https://miro.medium.com/fit/c/56/56/1*EW7E0dD57lQ6C0oZC06BEA.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3480858287", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*EW7E0dD57lQ6C0oZC06BEA.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3480858287", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*ZwDfxAGr_yIz5oCT", "width": "700", "height": "394", "credit": "Image by author", "caption": "A synthetic image of a messy bedroom"}, "3": {"item_id": "3480858287", "image_id": "3", "src": "https://miro.medium.com/max/1024/1*MdsVvoOSQoYcpKEi4ZROUQ.png", "width": "512", "height": "288", "credit": "", "caption": ""}, "4": {"item_id": "3480858287", "image_id": "4", "src": "https://miro.medium.com/max/1024/1*fnTr2AOBU5c-dslyF77L8A.png", "width": "512", "height": "288", "credit": "", "caption": ""}, "5": {"item_id": "3480858287", "image_id": "5", "src": "https://miro.medium.com/max/1024/1*fjk8Ko9epLKN949j75DqgA.png", "width": "512", "height": "288", "credit": "", "caption": ""}, "6": {"item_id": "3480858287", "image_id": "6", "src": "https://miro.medium.com/max/1024/1*jZU93uVkF8NuPCNOMPKHdA.png", "width": "512", "height": "288", "credit": "Image by author", "caption": "From top-left going clockwise: scene rendered under different light conditions, surface normal-map, depth map, object class labels"}, "7": {"item_id": "3480858287", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*i9efJ0hLIYtHMWieL9DfhA.png", "width": "700", "height": "275", "credit": "left", "caption": "An asset"}, "8": {"item_id": "3480858287", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*EKdPweq5B-8w7dnkYKXQ2g.png", "width": "700", "height": "329", "credit": "", "caption": "Encoding all our 3D assets into vectors. Image by author."}, "9": {"item_id": "3480858287", "image_id": "9", "src": "https://miro.medium.com/max/1400/0*AfHoqXHQ0eG2McZD.png", "width": "700", "height": "183", "credit": "Image by author", "caption": "The neural network at the center of NeRF"}, "10": {"item_id": "3480858287", "image_id": "10", "src": "https://miro.medium.com/max/1676/1*KRFny8HM8mbtsOb3hkH1bg.png", "width": "838", "height": "617", "credit": "", "caption": ""}, "11": {"item_id": "3480858287", "image_id": "11", "src": "https://miro.medium.com/max/1024/1*Wrva7VPRl5K3tULXKovEvQ.gif", "width": "512", "height": "512", "credit": "each pyramid is a simulated camera", "caption": "Left: A screenshot from Blender, a graphics software, where we render 80 synthetic images of the asset from various directions"}, "12": {"item_id": "3480858287", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*M2zjufeZJXF-Y9j2yGeLVw.png", "width": "700", "height": "172", "credit": "Image by author", "caption": "The NeRF network, with the latent vector as an additional input. During training, the latent vectors of the assets are also learned together with the weights of the fully-connected layers"}, "13": {"item_id": "3480858287", "image_id": "13", "src": "https://miro.medium.com/max/1024/1*OrkU9cGlvGbCK0YRiKkxcQ.gif", "width": "512", "height": "410", "credit": "", "caption": "A sample of our chair assets rendered by querying a single NeRF network. Image by author."}, "14": {"item_id": "3480858287", "image_id": "14", "src": "https://miro.medium.com/max/1024/1*dPUqOvyj2sKUvr6Fi-r8zQ.png", "width": "512", "height": "512", "credit": "i, j", "caption": "Mixing latent vectors: The chair at location"}, "15": {"item_id": "3480858287", "image_id": "15", "src": "https://miro.medium.com/max/1400/1*SZ5BbYNyJqOGuojSsx1KCQ.png", "width": "700", "height": "565", "credit": "", "caption": "T-SNE plot of the vectors of 522 of our assets. Clear separation between object classes and subclasses. Image by Author."}, "16": {"item_id": "3480858287", "image_id": "16", "src": "https://miro.medium.com/max/1024/1*Plc1fTYTGglcJE3p8gRI4w.gif", "width": "512", "height": "410", "credit": "", "caption": "A sample of our table assets rendered by querying a single NeRF network. Image by author."}, "17": {"item_id": "3480858287", "image_id": "17", "src": "https://miro.medium.com/max/1400/1*GZZ3uQf-woSwTMFBKd7VZA.png", "width": "700", "height": "407", "credit": "Image by author", "caption": "Architecture of our revised NeRF network"}, "18": {"item_id": "3480858287", "image_id": "18", "src": "https://miro.medium.com/max/1024/1*7K5VkXpTNZo2ECPC_s-kww.gif", "width": "512", "height": "205", "credit": "", "caption": ""}, "19": {"item_id": "3480858287", "image_id": "19", "src": "https://miro.medium.com/max/1024/1*uKxP0st9e3t-kBpt2mofvA.gif", "width": "512", "height": "205", "credit": "top", "caption": "Illustration of the top 10 PCA components for the shape-space"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 591}, "3346201434": {"item_id": "3346201434", "resolved_id": "3346201461", "given_url": "https://towardsdatascience.com/complete-guide-to-data-augmentation-for-computer-vision-1abe4063ad07?source=rss----7f60cf5620c9---4", "given_title": "Complete Guide to Data Augmentation for Computer Vision", "favorite": "0", "status": "1", "time_added": "1622574598", "time_updated": "1622575671", "time_read": "1622575671", "time_favorited": "0", "sort_id": 35, "resolved_title": "Complete Guide to Data Augmentation for Computer Vision", "resolved_url": "https://towardsdatascience.com/complete-guide-to-data-augmentation-for-computer-vision-1abe4063ad07", "excerpt": "Data Augmentation is one of the most important topics in Deep Computer Vision. When you train your neural network, you should do data augmentation like… ALWAYS. Otherwise, you are not using your dataset effectively and your model does not perform as well as it could.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1713", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1200/0*I9uwq0r1x_4Gs1x9", "tags": {"machine-learning": {"item_id": "3346201434", "tag": "machine-learning"}, "machine-vision": {"item_id": "3346201434", "tag": "machine-vision"}}, "authors": {"149901236": {"item_id": "3346201434", "author_id": "149901236", "name": "Olga Chernytska", "url": "https://olga-chernytska.medium.com"}}, "image": {"item_id": "3346201434", "src": "https://miro.medium.com/fit/c/56/56/1*_-N0T_1eQ-vVlm2hyhMb4A.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3346201434", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*_-N0T_1eQ-vVlm2hyhMb4A.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3346201434", "image_id": "2", "src": "https://miro.medium.com/max/3272/0*I9uwq0r1x_4Gs1x9", "width": "1636", "height": "1092", "credit": "", "caption": "Image by Author"}, "3": {"item_id": "3346201434", "image_id": "3", "src": "https://miro.medium.com/max/3304/1*dJdNQDzNydoDlXif6Nk8xg.png", "width": "1652", "height": "762", "credit": "", "caption": "Image 1. Visualization of Data Augmentation technique. Image by Author"}, "4": {"item_id": "3346201434", "image_id": "4", "src": "https://miro.medium.com/max/3956/1*9wSxqFHWFJ-5tgYLaTanqQ.png", "width": "1978", "height": "1486", "credit": "", "caption": "Image 2. Most popular Image Augmentations. Image by Author"}, "5": {"item_id": "3346201434", "image_id": "5", "src": "https://miro.medium.com/max/2476/1*KnIOrfxloZvcLPmLHfHEQQ.png", "width": "1238", "height": "916", "credit": "", "caption": "Image 3. Basic Panel in Adobe Lightroom Classic gives a clue what other color changes may be used as data augmentations. Image by Author"}, "6": {"item_id": "3346201434", "image_id": "6", "src": "https://miro.medium.com/max/2752/1*9Kkl7l3YUFLOGJ6zMmWZ6Q.png", "width": "1376", "height": "854", "credit": "", "caption": "Image 4. Ideas on how to deal with blank borders. Image by Author"}, "7": {"item_id": "3346201434", "image_id": "7", "src": "https://miro.medium.com/max/2876/1*W8HUVYKpvYybpUXyvmWUtg.png", "width": "1438", "height": "764", "credit": "", "caption": "Image 5. Depending on the task, the same augmentation may affect image labels differently. Image by Author"}, "8": {"item_id": "3346201434", "image_id": "8", "src": "https://miro.medium.com/max/3116/1*1-Xk5c9fNrXLuGMMsmCIqg.png", "width": "1558", "height": "456", "credit": "", "caption": "Image 6. Image Augmentations used to train LeNet-5. Image by Author"}, "9": {"item_id": "3346201434", "image_id": "9", "src": "https://miro.medium.com/max/2352/1*kaU4p_BZNPL4BTSdhvxMzQ.png", "width": "1176", "height": "372", "credit": "", "caption": "Image 7. Data Augmentations used to train ImageNet. Image by Author"}, "10": {"item_id": "3346201434", "image_id": "10", "src": "https://miro.medium.com/max/2380/1*nrkQjAoV7fEzlzcEcpA0bg.png", "width": "1190", "height": "396", "credit": "Medical data is usually grayscaled", "caption": "Image 8. Data Augmentations used to train U-Net on medical data"}, "11": {"item_id": "3346201434", "image_id": "11", "src": "https://miro.medium.com/max/3456/1*I4QL84ZFsXPx0GhaYul3AA.jpeg", "width": "1728", "height": "576", "credit": "4", "caption": "Image 9. Examples of data augmentation for satellite images. Image source:"}, "12": {"item_id": "3346201434", "image_id": "12", "src": "https://miro.medium.com/max/1728/1*HDo7qjP9EsOPcdjQAlJTyg.jpeg", "width": "864", "height": "288", "credit": "4", "caption": "Image 10. Examples of data augmentation for medical images. Image source:"}, "13": {"item_id": "3346201434", "image_id": "13", "src": "https://miro.medium.com/max/2368/1*0tWFeX7EtuE3iHEE35335w.png", "width": "1184", "height": "468", "credit": "", "caption": "Image 11. Are you going to use Horizontal Flips when developing   a Computer Vision system for a self-driving car? Image by Author"}, "14": {"item_id": "3346201434", "image_id": "14", "src": "https://miro.medium.com/max/2048/1*Kd4PlhpU1I-tr1PK7WDsgQ.jpeg", "width": "1024", "height": "1024", "credit": "5", "caption": "Image 12. About half of these examples are augmented too much. Image source:"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 663}, "3450278426": {"item_id": "3450278426", "resolved_id": "3450278462", "given_url": "https://towardsdatascience.com/essential-linux-command-line-tricks-for-computer-vision-researchers-27d4f013d9a?source=rss----7f60cf5620c9---4", "given_title": "Essential Linux Command-Line Tricks for Computer Vision Researchers", "favorite": "0", "status": "1", "time_added": "1633620499", "time_updated": "1673901697", "time_read": "1633628983", "time_favorited": "0", "sort_id": 36, "resolved_title": "Essential Linux Command-Line Tricks for Computer Vision Researchers", "resolved_url": "https://towardsdatascience.com/essential-linux-command-line-tricks-for-computer-vision-researchers-27d4f013d9a", "excerpt": "Linux has huge popularity among the data science community especially deep learning engineers. because whenever it comes to training deep learning models like YOLO, RCNN, or BERT, They have to go through DevOps to make sure packages are very well integrated with the operating system and hardware.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2041", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/1200/1*Ybu9fEJ8EG4SY9JGpycwmA.jpeg", "tags": {"command-line": {"item_id": "3450278426", "tag": "command-line"}, "linux": {"item_id": "3450278426", "tag": "linux"}, "machine-learning": {"item_id": "3450278426", "tag": "machine-learning"}, "machine-vision": {"item_id": "3450278426", "tag": "machine-vision"}}, "authors": {"141823220": {"item_id": "3450278426", "author_id": "141823220", "name": "Masoud Masoumi Moghadam", "url": "https://masoud-masoumi-moghadam.medium.com"}}, "image": {"item_id": "3450278426", "src": "https://miro.medium.com/fit/c/56/56/1*QKG0RrxYfZ-JrnhD-XfvGw.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3450278426", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*QKG0RrxYfZ-JrnhD-XfvGw.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3450278426", "image_id": "2", "src": "https://miro.medium.com/max/15780/1*Ybu9fEJ8EG4SY9JGpycwmA.jpeg", "width": "7890", "height": "5263", "credit": "ThisisEngineering RAEng on Unsplash", "caption": ""}, "3": {"item_id": "3450278426", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*ridw3_Dkm2OsT63s4ZztCA.png", "width": "700", "height": "303", "credit": "Image by author", "caption": "Sample output of the tree command"}, "4": {"item_id": "3450278426", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*N8UhwDcCspOLnDa178AqpQ.png", "width": "700", "height": "457", "credit": "", "caption": "image created by the author"}, "5": {"item_id": "3450278426", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*F7rMkqZO7SW_IrmrJEaitg.png", "width": "700", "height": "372", "credit": "", "caption": "Image by Author"}, "6": {"item_id": "3450278426", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*2AlZygqBdsaPr7EaIIawSw.png", "width": "700", "height": "450", "credit": "", "caption": "Running training along with GPU memory allocation monitoring — Image by Author"}, "7": {"item_id": "3450278426", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*qXRAur1VzFf5Rc-h6NEKzw.png", "width": "700", "height": "69", "credit": "", "caption": "Image by Author"}, "8": {"item_id": "3450278426", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*g9T-KCmLFLyL72PX3qoY5A.gif", "width": "700", "height": "700", "credit": "", "caption": "GradCam output of the project image color classification. Image by the author."}, "9": {"item_id": "3450278426", "image_id": "9", "src": "https://miro.medium.com/max/960/1*3o_QswWA4-xdpHbGe1UuHQ.gif", "width": "480", "height": "270", "credit": "", "caption": ""}, "10": {"item_id": "3450278426", "image_id": "10", "src": "https://miro.medium.com/max/960/1*i0N3mPdkcnJ2ZcAkwdwpAw.gif", "width": "480", "height": "270", "credit": "Video by Pavel Danilyuk from Pexels", "caption": "a.mp4 — b.mp4 video clips"}, "11": {"item_id": "3450278426", "image_id": "11", "src": "https://miro.medium.com/max/960/1*brF8HGPxBs8vDY0Zcs1yaA.gif", "width": "480", "height": "270", "credit": "", "caption": ""}, "12": {"item_id": "3450278426", "image_id": "12", "src": "https://miro.medium.com/max/960/1*dq3MncfAf7PpELybWvx_0g.gif", "width": "480", "height": "270", "credit": "Video by Pavel Danilyuk from Pexels", "caption": "c.mp4 and d.mp4 video clips"}, "13": {"item_id": "3450278426", "image_id": "13", "src": "https://miro.medium.com/max/1400/1*kU_8yQz6F2WfNUvqhez-5Q.gif", "width": "700", "height": "197", "credit": "", "caption": "output result video of FFmpeg horizontal stacking"}, "14": {"item_id": "3450278426", "image_id": "14", "src": "https://miro.medium.com/max/960/1*Zyvbrw_mJhKh2l0VpC1BQw.gif", "width": "480", "height": "540", "credit": "", "caption": "The output result of FFmpeg vertical stacking"}, "15": {"item_id": "3450278426", "image_id": "15", "src": "https://miro.medium.com/max/1400/1*_KB5HzJOHol5Nw-vJR5x6Q.gif", "width": "700", "height": "394", "credit": "", "caption": "The output result of FFmpeg xstacking"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 790}, "3316426075": {"item_id": "3316426075", "resolved_id": "3316426107", "given_url": "https://towardsdatascience.com/gentle-introduction-to-2d-hand-pose-estimation-approach-explained-4348d6d79b11?source=rss----7f60cf5620c9---4", "given_title": "Gentle introduction to 2D Hand Pose Estimation: Approach Explained", "favorite": "0", "status": "1", "time_added": "1619441999", "time_updated": "1619455522", "time_read": "1619455522", "time_favorited": "0", "sort_id": 37, "resolved_title": "Gentle introduction to 2D Hand Pose Estimation: Approach Explained", "resolved_url": "https://towardsdatascience.com/gentle-introduction-to-2d-hand-pose-estimation-approach-explained-4348d6d79b11", "excerpt": "In 2018 I spent 6 months working on my master’s thesis on Hand Pose Estimation. That was a challenging and insightful period of my life that resulted in 40-page research.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1949", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/1200/0*CvYL8OI0js7MWUlM", "tags": {"machine-learning": {"item_id": "3316426075", "tag": "machine-learning"}, "machine-vision": {"item_id": "3316426075", "tag": "machine-vision"}, "pose-estimation": {"item_id": "3316426075", "tag": "pose-estimation"}}, "authors": {"149901236": {"item_id": "3316426075", "author_id": "149901236", "name": "Olga Chernytska", "url": "https://olga-chernytska.medium.com"}}, "image": {"item_id": "3316426075", "src": "https://miro.medium.com/fit/c/56/56/1*K36RJKHrrxD3izmCK3tZKw.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3316426075", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*K36RJKHrrxD3izmCK3tZKw.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3316426075", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*CvYL8OI0js7MWUlM", "width": "700", "height": "465", "credit": "", "caption": "Image by Author"}, "3": {"item_id": "3316426075", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*PrMoyDC0-fFt2_mnmw_aGQ.png", "width": "700", "height": "352", "credit": "", "caption": "Image 1. Hand keypoints. Order matters here. Image by Author"}, "4": {"item_id": "3316426075", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*mThXrH5ioCkZNHAOvtfYaA.png", "width": "700", "height": "399", "credit": "", "caption": "Image 2. Visualization of typical 2D Hand Pose Estimator. Image by Author"}, "5": {"item_id": "3316426075", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*ZxLvJprsRlLu8h-Hxqn1dw.png", "width": "700", "height": "350", "credit": "", "caption": "Image 3. Left: how hand pose is visualized. Right: how hand pose is estimated. Image by Author"}, "6": {"item_id": "3316426075", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*t0V4Q9Bv3X8_EuSuxPm1ZA.png", "width": "700", "height": "483", "credit": "", "caption": "Image 4. Random samples from FreiHAND dataset with 2D keypoint labels.  Colors: green for thumb, cyan for index finger, blue for middle, pink for ring and red for little finger."}, "7": {"item_id": "3316426075", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*dnATfJDH_TPnLuGJpxB22w.png", "width": "700", "height": "545", "credit": "", "caption": "Image 5. When resizing an image, keypoint locations should be also “resized”. Image by Author"}, "8": {"item_id": "3316426075", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*tcMFmcFRG7o3xiZ-9b6azg.png", "width": "700", "height": "318", "credit": "", "caption": "Image 6. How to create a heatmap for a keypoint. Image by Author"}, "9": {"item_id": "3316426075", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*ovqDOUIAhpJ4hNlMHa8gqg.png", "width": "700", "height": "378", "credit": "", "caption": "Image 7. My simple custom UNet-like model for 2D Hand Pose Estimation. Image by Author"}, "10": {"item_id": "3316426075", "image_id": "10", "src": "https://miro.medium.com/max/1104/1*78bZt9dM2FDukswdsYVopg.png", "width": "552", "height": "342", "credit": "", "caption": "Image 8. How to calculate IoU loss for heatmaps. yi — predicted values, ti — target values for a pixel in a heatmap. Loss is calculated for each heatmap separately, then averaged among all 21 heatmaps, and then averaged among the images in the batch."}, "11": {"item_id": "3316426075", "image_id": "11", "src": "https://miro.medium.com/max/1400/1*2J2RWoSlEGzq1Eg7J_QMKg.png", "width": "700", "height": "481", "credit": "", "caption": "Image 9. Model output for a random image from the test set. Image by Author"}, "12": {"item_id": "3316426075", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*1d4R7Dv-W4zyY1aWp2Vi5w.png", "width": "700", "height": "331", "credit": "", "caption": "Image 10. How to calculate keypoint location from a heatmap by averaging. Image by Author"}, "13": {"item_id": "3316426075", "image_id": "13", "src": "https://miro.medium.com/max/1400/1*MiVDWs2MTZlHO3dOnl0VCg.png", "width": "700", "height": "959", "credit": "", "caption": "Image 11. Visualizing predictions on test set."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 754}, "3834246646": {"item_id": "3834246646", "resolved_id": "3834246646", "given_url": "https://towardsdatascience.com/hands-on-generative-ai-with-gans-using-python-image-generation-9a62e591c7c6", "given_title": "Hands-on Generative AI with GANs using Python: Image Generation", "favorite": "0", "status": "1", "time_added": "1679956545", "time_updated": "1680283996", "time_read": "1680283995", "time_favorited": "0", "sort_id": 38, "resolved_title": "Hands-on Generative AI with GANs using Python: Image Generation", "resolved_url": "https://towardsdatascience.com/hands-on-generative-ai-with-gans-using-python-image-generation-9a62e591c7c6", "excerpt": "In my previous article, we learned about Autoencoders, now let’s continue to talk about Generative AI. By now everyone is talking about it and everyone is excited about the practical applications that have been developed. But we continue to see the foundations of these AIs step by step.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1541", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*h07aDSTfNQuoPk1a1WhxlQ.png", "tags": {"image-generation": {"item_id": "3834246646", "tag": "image-generation"}, "machine-vision": {"item_id": "3834246646", "tag": "machine-vision"}}, "authors": {"156659042": {"item_id": "3834246646", "author_id": "156659042", "name": "Marcello Politi", "url": "https://medium.com/@marcellopoliti"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 597}, "3382848022": {"item_id": "3382848022", "resolved_id": "3382848043", "given_url": "https://towardsdatascience.com/hog-histogram-of-oriented-gradients-67ecd887675f?source=rss----7f60cf5620c9---4", "given_title": "HOG(Histogram of Oriented Gradients)", "favorite": "0", "status": "1", "time_added": "1626437627", "time_updated": "1626486554", "time_read": "1626486554", "time_favorited": "0", "sort_id": 39, "resolved_title": "HOG(Histogram of Oriented Gradients)", "resolved_url": "https://towardsdatascience.com/hog-histogram-of-oriented-gradients-67ecd887675f", "excerpt": "Histogram of Oriented Gradients, also known as HOG, is a feature descriptor like the Canny Edge Detector, SIFT (Scale Invariant and Feature Transform) . It is used in computer vision and image processing for the purpose of object detection.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "797", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/max/1200/1*FgpFKC9mu2WR5qHk08b1IQ.jpeg", "tags": {"deep-learning": {"item_id": "3382848022", "tag": "deep-learning"}, "machine-learning": {"item_id": "3382848022", "tag": "machine-learning"}, "machine-vision": {"item_id": "3382848022", "tag": "machine-vision"}}, "authors": {"153629679": {"item_id": "3382848022", "author_id": "153629679", "name": "Mrinal Tyagi", "url": "https://mrinaltyagi24.medium.com"}}, "image": {"item_id": "3382848022", "src": "https://miro.medium.com/fit/c/56/56/1*LLHJ4VcVgXW9e6YdXkikIQ.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3382848022", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*LLHJ4VcVgXW9e6YdXkikIQ.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3382848022", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*FgpFKC9mu2WR5qHk08b1IQ.jpeg", "width": "700", "height": "326", "credit": "Image by author", "caption": "Figure 1 : The image imported to get HOG features of. Figure 2 : The imported image grayscale for the process. Figure 3 : Resized and grayscale image of the imported image."}, "3": {"item_id": "3382848022", "image_id": "3", "src": "https://miro.medium.com/max/1082/1*osjvJUze_RCPSiYcFHvMzw.gif", "width": "541", "height": "20", "credit": "Image by author", "caption": "where r, c refer to rows and columns respectively."}, "4": {"item_id": "3382848022", "image_id": "4", "src": "https://miro.medium.com/max/910/1*E0YLcI7Ui1VUc2Q_R-s88w.png", "width": "455", "height": "33", "credit": "", "caption": ""}, "5": {"item_id": "3382848022", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*nR-a0e4X-ujaVobsykcAfA.png", "width": "700", "height": "520", "credit": "Image by author", "caption": "Figure 4 : Visualization of magnitude of the image. Figure 5 : Visualization of angle of the image."}, "6": {"item_id": "3382848022", "image_id": "6", "src": "https://miro.medium.com/max/800/1*T-kh04SD0ENcL4aU_aSQkQ.png", "width": "400", "height": "42", "credit": "Image by author", "caption": ""}, "7": {"item_id": "3382848022", "image_id": "7", "src": "https://miro.medium.com/max/298/1*Wbm4NwlZ4A_woVA2s7aPKQ.png", "width": "149", "height": "19", "credit": "Image by author", "caption": ""}, "8": {"item_id": "3382848022", "image_id": "8", "src": "https://miro.medium.com/max/268/1*-DW1IlCY2GBfhVHmJ4W_dA.png", "width": "134", "height": "20", "credit": "Image by author", "caption": ""}, "9": {"item_id": "3382848022", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*VgcYfGjg_WpbrX1S-ACE0Q.png", "width": "700", "height": "621", "credit": "Image by author", "caption": "Figure 6 : 8x8 blocks on the magnitude image. Figure 7 : 8x8 blocks on an angle image."}, "10": {"item_id": "3382848022", "image_id": "10", "src": "https://miro.medium.com/max/1344/1*JZwuE5wMPDMgZ8Q9pieAug.png", "width": "672", "height": "114", "credit": "j+1", "caption": "Figure 8 : Representation of a 9 bin histogram. This one single histogram will be unique for one 8x8 block made up of 64 cells. All 64 cells will add their Vj and Vj+1 value to the jth and"}, "11": {"item_id": "3382848022", "image_id": "11", "src": "https://miro.medium.com/max/324/1*b_Z1xcvIoNAb1UURK2ASqQ.png", "width": "162", "height": "135", "credit": "Image by author", "caption": ""}, "12": {"item_id": "3382848022", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*Cf9WWyN-605RWi0ZblsdGw.png", "width": "700", "height": "398", "credit": "Image by author", "caption": "Method for calculation of 9 bin histograms is illustrated in the above image."}, "13": {"item_id": "3382848022", "image_id": "13", "src": "https://miro.medium.com/max/348/1*vsZgV-CFQQO5GIjN_XYgWg.png", "width": "174", "height": "19", "credit": "Image by author", "caption": ""}, "14": {"item_id": "3382848022", "image_id": "14", "src": "https://miro.medium.com/max/796/1*ZNLQg81ZmN6TKFyLhPqilg.gif", "width": "398", "height": "576", "credit": "Image by author", "caption": "Traversing of 2x2 grid box around the image in order to make a combined fbi from 4 blocks."}, "15": {"item_id": "3382848022", "image_id": "15", "src": "https://miro.medium.com/max/288/1*0G_dlDgfNYGDt_6k6lcYBA.png", "width": "144", "height": "57", "credit": "Image by author", "caption": "Where ε is a small value added to the square of fb in order to avoid zero division error. In code value taken of is 1e-05."}, "16": {"item_id": "3382848022", "image_id": "16", "src": "https://miro.medium.com/max/628/1*UymIQRnu42sDlLmdsuz-Dg.png", "width": "314", "height": "78", "credit": "Image by author", "caption": ""}, "17": {"item_id": "3382848022", "image_id": "17", "src": "https://miro.medium.com/max/384/1*K67G_u5HaHrAAFIjmzVPiw.png", "width": "192", "height": "384", "credit": "Image by author", "caption": "Visualization of HOG features on the same image using skimage library."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 309}, "3449750075": {"item_id": "3449750075", "resolved_id": "3449750096", "given_url": "https://towardsdatascience.com/hrnet-explained-human-pose-estimation-sematic-segmentation-and-object-detection-63f1ce79ef82?source=rss----7f60cf5620c9---4", "given_title": "HRNet explained: Human Pose Estimation, Semantic Segmentation and Object De", "favorite": "0", "status": "1", "time_added": "1633606526", "time_updated": "1633630869", "time_read": "1633630869", "time_favorited": "0", "sort_id": 40, "resolved_title": "HRNet explained: Human Pose Estimation, Sematic Segmentation and Object Detection", "resolved_url": "https://towardsdatascience.com/hrnet-explained-human-pose-estimation-sematic-segmentation-and-object-detection-63f1ce79ef82", "excerpt": "HRNet is a state-of-the-art algorithm in the field of semantic segmentation, facial landmark detection, and human pose estimation. It has shown superior results in semantic segmentation on datasets like PASCAL Context, LIP, Cityscapes, AFLW, COFW, and 300W.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1874", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/1200/1*rLhbwmHhjFF2u9NrO3iWpg.jpeg", "tags": {"deep-learning": {"item_id": "3449750075", "tag": "deep-learning"}, "machine-vision": {"item_id": "3449750075", "tag": "machine-vision"}, "pose-estimation": {"item_id": "3449750075", "tag": "pose-estimation"}, "semantic-segmentation": {"item_id": "3449750075", "tag": "semantic-segmentation"}}, "authors": {"129050273": {"item_id": "3449750075", "author_id": "129050273", "name": "Hucker Marius", "url": "https://medium.com/@hucker.marius"}}, "image": {"item_id": "3449750075", "src": "https://miro.medium.com/fit/c/56/56/2*7IaQcIIvxhB-crtlmJWGoA.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3449750075", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*7IaQcIIvxhB-crtlmJWGoA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3449750075", "image_id": "2", "src": "https://miro.medium.com/max/9036/1*rLhbwmHhjFF2u9NrO3iWpg.jpeg", "width": "4518", "height": "3011", "credit": "Christian Lue on Unsplash", "caption": ""}, "3": {"item_id": "3449750075", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*9ATXgoGvrOXukaOAgyWuCQ.png", "width": "700", "height": "317", "credit": "", "caption": "Source: http://host.robots.ox.ac.uk/pascal/VOC/voc2012/#devkit"}, "4": {"item_id": "3449750075", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*rekAeufx3gMVi3qUL3_UEw.png", "width": "700", "height": "307", "credit": "", "caption": "Source: https://learnopencv.com/face-swap-using-opencv-c-python/"}, "5": {"item_id": "3449750075", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*pcvyvpgNMuy4MCOG5ecKbw.png", "width": "700", "height": "603", "credit": "", "caption": "Source: https://arxiv.org/abs/2103.02440"}, "6": {"item_id": "3449750075", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*4U2mB9ZE46Uj2LQz989MHQ.png", "width": "700", "height": "158", "credit": "7", "caption": "Source: https://cs231n.github.io/convolutional-networks/"}, "7": {"item_id": "3449750075", "image_id": "7", "src": "https://miro.medium.com/max/1052/1*Z87z69ufkGnNolH6R_Ln_w.gif", "width": "526", "height": "384", "credit": "", "caption": "Source: https://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/"}, "8": {"item_id": "3449750075", "image_id": "8", "src": "https://miro.medium.com/max/1148/1*TCGAV3JvaWABGC34jaN4LQ.png", "width": "574", "height": "304", "credit": "7", "caption": "Source: https://cs231n.github.io/convolutional-networks/"}, "9": {"item_id": "3449750075", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*SGjMTghF8SQdD2l-DDD9vQ.png", "width": "700", "height": "115", "credit": "", "caption": "Source: https://arxiv.org/pdf/1904.04514.pdf"}, "10": {"item_id": "3449750075", "image_id": "10", "src": "https://miro.medium.com/max/928/1*BIYwJGwbm4VGQAOoazg5SQ.png", "width": "464", "height": "468", "credit": "", "caption": "Source: https://arxiv.org/pdf/1904.04514.pdf"}, "11": {"item_id": "3449750075", "image_id": "11", "src": "https://miro.medium.com/max/560/1*5lhntnXLH1YUTJKpX5-EqA.png", "width": "280", "height": "462", "credit": "", "caption": "Source: https://arxiv.org/pdf/1904.04514.pdf"}, "12": {"item_id": "3449750075", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*W2DJWlD--JgtgVLoz_03EA.png", "width": "700", "height": "65", "credit": "", "caption": "Previous CNN with serial convolution and not parallel. Source: https://arxiv.org/pdf/1904.04514.pdf"}, "13": {"item_id": "3449750075", "image_id": "13", "src": "https://miro.medium.com/max/952/1*vh1XNEWgUxn5vF0aP7BjCQ.png", "width": "476", "height": "298", "credit": "", "caption": "HRNetV1 illustration. Source: https://arxiv.org/pdf/1904.04514.pdf"}, "14": {"item_id": "3449750075", "image_id": "14", "src": "https://miro.medium.com/max/928/1*Fq-e4ExsbpZKAJxaN3sR8A.png", "width": "464", "height": "362", "credit": "", "caption": "HRNetV2 illustration. Source: https://arxiv.org/pdf/1904.04514.pdf"}, "15": {"item_id": "3449750075", "image_id": "15", "src": "https://miro.medium.com/max/960/1*keRNOE64DQXTthrITaGOOQ.png", "width": "480", "height": "360", "credit": "", "caption": "HRNetV2p illustration. Source: https://arxiv.org/pdf/1904.04514.pdf"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 725}, "3286840883": {"item_id": "3286840883", "resolved_id": "3286840900", "given_url": "https://towardsdatascience.com/image-feature-extraction-using-pytorch-e3b327c3607a?source=rss----7f60cf5620c9---4", "given_title": "Image Feature Extraction Using PyTorch", "favorite": "0", "status": "1", "time_added": "1616415334", "time_updated": "1616441523", "time_read": "1616441522", "time_favorited": "0", "sort_id": 41, "resolved_title": "Image Feature Extraction Using PyTorch", "resolved_url": "https://towardsdatascience.com/image-feature-extraction-using-pytorch-e3b327c3607a", "excerpt": "In summary, this article will show you how to implement a convolutional neural network (CNN) for feature extraction using PyTorch. Also, I will show you how to cluster images based on their features using the K-Means algorithm. Enjoy! Let’s say you see an image of a cat.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "964", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/max/1200/1*P69zpl--JsVRSIVXL0hUzw.jpeg", "tags": {"machine-vision": {"item_id": "3286840883", "tag": "machine-vision"}, "pytorch": {"item_id": "3286840883", "tag": "pytorch"}}, "authors": {"102778521": {"item_id": "3286840883", "author_id": "102778521", "name": "Irfan Alghani Khalid", "url": "https://medium.com/@irfanalghani11"}}, "image": {"item_id": "3286840883", "src": "https://miro.medium.com/fit/c/56/56/1*ygIS0pNZ95reHXZTWBcrkw.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3286840883", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*ygIS0pNZ95reHXZTWBcrkw.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3286840883", "image_id": "2", "src": "https://miro.medium.com/max/3840/1*P69zpl--JsVRSIVXL0hUzw.jpeg", "width": "1920", "height": "1278", "credit": "NASA on Unsplash", "caption": ""}, "3": {"item_id": "3286840883", "image_id": "3", "src": "https://miro.medium.com/max/548/1*n9hOsxqF9Yc0mQstKpQ6DQ.png", "width": "274", "height": "94", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 373}, "3804061676": {"item_id": "3804061676", "resolved_id": "3804027522", "given_url": "https://towardsdatascience.com/image-filters-with-python-3dc223a12624?source=rss----7f60cf5620c9---4", "given_title": "Image Filters with Python", "favorite": "0", "status": "1", "time_added": "1676055278", "time_updated": "1676072541", "time_read": "1676072541", "time_favorited": "0", "sort_id": 42, "resolved_title": "Image Filters with Python", "resolved_url": "https://towardsdatascience.com/image-filters-with-python-3dc223a12624", "excerpt": "Images exist in different scales, contrasts, bit depths, and qualities. We are filled with a variety of unique and beautiful images that encompass us all over our surroundings and across the internet.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1776", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1200/0*h0_6ad6JsubZus2v", "tags": {"machine-vision": {"item_id": "3804061676", "tag": "machine-vision"}, "python": {"item_id": "3804061676", "tag": "python"}}, "authors": {"144409854": {"item_id": "3804061676", "author_id": "144409854", "name": "Bharath K", "url": "https://bharath-k1297.medium.com"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 687}, "3244853055": {"item_id": "3244853055", "resolved_id": "3244853071", "given_url": "https://towardsdatascience.com/image-processing-with-python-using-rg-chromaticity-c585e7905818?source=rss----7f60cf5620c9---4", "given_title": "Image Processing with Python — Using RG Chromaticity", "favorite": "0", "status": "1", "time_added": "1612135462", "time_updated": "1612207276", "time_read": "1612207276", "time_favorited": "0", "sort_id": 43, "resolved_title": "Image Processing with Python", "resolved_url": "https://towardsdatascience.com/image-processing-with-python-using-rg-chromaticity-c585e7905818", "excerpt": "Segmenting images by their color is an extremely useful skill to have. I’ve previously written an article on how to do this via the RGB and HSV color spaces. However, another effective way to segment images based on their color is by making use of RG Chromaticity and the Gaussian Distribution.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1467", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/712/1*yVaiKs01yoCxSo2CfhUQ0A.png", "tags": {"image-segmentation": {"item_id": "3244853055", "tag": "image-segmentation"}, "machine-vision": {"item_id": "3244853055", "tag": "machine-vision"}, "python": {"item_id": "3244853055", "tag": "python"}, "scikit-image": {"item_id": "3244853055", "tag": "scikit-image"}}, "authors": {"144191535": {"item_id": "3244853055", "author_id": "144191535", "name": "Tonichi Edeza", "url": "https://tonichi-edeza.medium.com"}}, "image": {"item_id": "3244853055", "src": "https://miro.medium.com/fit/c/56/56/1*2C-eNDWh-BN64joo5OzLDg.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3244853055", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*2C-eNDWh-BN64joo5OzLDg.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3244853055", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*yVaiKs01yoCxSo2CfhUQ0A.png", "width": "700", "height": "700", "credit": "Image by Author", "caption": "Masked Red Tree"}, "3": {"item_id": "3244853055", "image_id": "3", "src": "https://miro.medium.com/max/1178/1*nRhOC-KSWI8WtcV6A_KxZw.png", "width": "589", "height": "591", "credit": "Image by Author", "caption": "Hungarian Parliament"}, "4": {"item_id": "3244853055", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*CH68aCD45GEoe1CwQlfuVw.png", "width": "700", "height": "249", "credit": "", "caption": "Different Color Channels"}, "5": {"item_id": "3244853055", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*WIGVgvugK85GdMNCnt9seQ.png", "width": "700", "height": "327", "credit": "", "caption": "Original vs RG Chromaticity"}, "6": {"item_id": "3244853055", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*NHembqZbZMhdSdsiLUcV0Q.png", "width": "700", "height": "475", "credit": "", "caption": "RG Chromaticity Graph"}, "7": {"item_id": "3244853055", "image_id": "7", "src": "https://miro.medium.com/max/554/1*acyJ4XY7GKEBdvFELah6ng.png", "width": "277", "height": "280", "credit": "", "caption": "Yellow Patch"}, "8": {"item_id": "3244853055", "image_id": "8", "src": "https://miro.medium.com/max/1224/1*k_UWXR1mq9BafaYH4g1_eA.png", "width": "612", "height": "406", "credit": "", "caption": "Patch RG Chromaticity"}, "9": {"item_id": "3244853055", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*edcmDOeOi2bgt2jMkOVJBA.png", "width": "700", "height": "345", "credit": "", "caption": "Original Image and Mask"}, "10": {"item_id": "3244853055", "image_id": "10", "src": "https://miro.medium.com/max/956/1*mzTifivZH9HiXz143we-Dg.png", "width": "478", "height": "471", "credit": "", "caption": "Binarized Mask"}, "11": {"item_id": "3244853055", "image_id": "11", "src": "https://miro.medium.com/max/1400/1*sLAHRD_P5fueJQipTLXU2Q.png", "width": "700", "height": "345", "credit": "", "caption": "Original vs Masked Image"}, "12": {"item_id": "3244853055", "image_id": "12", "src": "https://miro.medium.com/max/1172/1*9_yqP7jlruHkU41o1h2p_g.png", "width": "586", "height": "542", "credit": "Image by Author", "caption": "An Empty Street in Singapore"}, "13": {"item_id": "3244853055", "image_id": "13", "src": "https://miro.medium.com/max/1400/1*z9fqXPfhbNrKOg4zrh3ptg.png", "width": "700", "height": "459", "credit": "", "caption": "Singaporean RG Chromaticity"}, "14": {"item_id": "3244853055", "image_id": "14", "src": "https://miro.medium.com/max/1400/1*u57C5YiFbH1V7sgJka0_-w.png", "width": "700", "height": "337", "credit": "", "caption": "Singaporean Mask"}, "15": {"item_id": "3244853055", "image_id": "15", "src": "https://miro.medium.com/max/1400/1*yMr_0aUQ4OADsvkqmjRQkA.png", "width": "700", "height": "337", "credit": "", "caption": "Masked Singapore Image"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 568}, "3946398713": {"item_id": "3946398713", "resolved_id": "3946398713", "given_url": "https://towardsdatascience.com/image-segmentation-an-in-depth-guide-5e56512eea2e", "given_title": "Image Segmentation: An In-Depth Guide", "favorite": "0", "status": "1", "time_added": "1696686819", "time_updated": "1697723449", "time_read": "1697723449", "time_favorited": "0", "sort_id": 44, "resolved_title": "Image Segmentation: An In-Depth Guide", "resolved_url": "https://towardsdatascience.com/image-segmentation-an-in-depth-guide-5e56512eea2e", "excerpt": "Image segmentation refers to the ability of computers (or more accurately models stored on computers) to take an image and assign each pixel in the image to a corresponding category.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "5787", "lang": "en", "time_to_read": 26, "top_image_url": "https://miro.medium.com/v2/resize:fit:512/1*YZoz7tIHda8sIJYegHMO8w.png", "tags": {"image-segmentation": {"item_id": "3946398713", "tag": "image-segmentation"}, "machine-vision": {"item_id": "3946398713", "tag": "machine-vision"}}, "authors": {"185582845": {"item_id": "3946398713", "author_id": "185582845", "name": "Ed Izaguirre", "url": "https://medium.com/@ed.izaguirre"}}, "image": {"item_id": "3946398713", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*X9RggnIeuLK8p0PvTB4jNw.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3946398713", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*X9RggnIeuLK8p0PvTB4jNw.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3946398713", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 2240}, "3728088527": {"item_id": "3728088527", "resolved_id": "3728088546", "given_url": "https://towardsdatascience.com/image-super-resolution-an-overview-of-the-current-state-of-research-94294a77ed5a?source=rss----7f60cf5620c9---4", "given_title": "Image Super-Resolution: An Overview of the Current State of Research", "favorite": "0", "status": "1", "time_added": "1666264648", "time_updated": "1666270737", "time_read": "1666270736", "time_favorited": "0", "sort_id": 45, "resolved_title": "Image Super-Resolution: An Overview of the Current State of Research", "resolved_url": "https://towardsdatascience.com/image-super-resolution-an-overview-of-the-current-state-of-research-94294a77ed5a", "excerpt": "In a previous article, an overview of super-resolution (SR) and why it has become an important research topic was given. To recap, it is the process in which low-resolution (LR) images are up-sampled to recover the underlying high-quality image.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "5102", "lang": "en", "time_to_read": 23, "top_image_url": "https://miro.medium.com/max/1200/1*bSgPxqGzylm7QZGPlPuUpg.png", "tags": {"machine-learning": {"item_id": "3728088527", "tag": "machine-learning"}, "machine-vision": {"item_id": "3728088527", "tag": "machine-vision"}, "super-resolution": {"item_id": "3728088527", "tag": "super-resolution"}}, "authors": {"173644363": {"item_id": "3728088527", "author_id": "173644363", "name": "Z. Lu", "url": ""}, "173644364": {"item_id": "3728088527", "author_id": "173644364", "name": "J. Li", "url": "https://arxiv.org/search/cs?searchtype=author&query=Li%2C+J"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1975}, "3989990042": {"item_id": "3989990042", "resolved_id": "3989990042", "given_url": "https://towardsdatascience.com/low-quality-image-detection-machine-learning-fdc2c1ba86e1", "given_title": "Low Quality Image Detection—Part 1", "favorite": "0", "status": "1", "time_added": "1704488236", "time_updated": "1704488862", "time_read": "1704488862", "time_favorited": "0", "sort_id": 46, "resolved_title": "Low Quality Image Detection—Part 1", "resolved_url": "https://towardsdatascience.com/low-quality-image-detection-machine-learning-fdc2c1ba86e1", "excerpt": "Low-quality image detection is an interesting machine learning problem because it addresses real-world challenges across diverse applications (for instance, blurry image detection in surveillance systems or automatic quality check while taking photos with a smartphone).", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "322", "lang": "en", "top_image_url": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*pZemXsaM8pOj8Uc5", "tags": {"machine-vision": {"item_id": "3989990042", "tag": "machine-vision"}}, "authors": {"135562205": {"item_id": "3989990042", "author_id": "135562205", "name": "Shuyi Yang", "url": "https://medium.com/@ngshya"}}, "image": {"item_id": "3989990042", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*5kHeUby5-qGIrRdBjzmSTA@2x.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3989990042", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*5kHeUby5-qGIrRdBjzmSTA@2x.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3989990042", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 125}, "4003885423": {"item_id": "4003885423", "resolved_id": "4003885435", "given_url": "https://towardsdatascience.com/object-detection-basics-a-comprehensive-beginners-guide-part-1-f57380c89b78?source=rss----7f60cf5620c9---4", "given_title": "Object Detection Basics — A Comprehensive Beginner’s Guide (Part 1)", "favorite": "0", "status": "1", "time_added": "1707166367", "time_updated": "1707271666", "time_read": "1707271666", "time_favorited": "0", "sort_id": 47, "resolved_title": "Object Detection Basics — A Comprehensive Beginner’s Guide (Part 1)", "resolved_url": "https://towardsdatascience.com/object-detection-basics-a-comprehensive-beginners-guide-part-1-f57380c89b78", "excerpt": "Driving a car nowadays with the latest drive assist technologies for lane detection, blind-spots, traffic signals and so on is pretty common.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2202", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*4Vq2m6HJ1OMOW77g", "tags": {"machine-vision": {"item_id": "4003885423", "tag": "machine-vision"}, "object-detection": {"item_id": "4003885423", "tag": "object-detection"}}, "authors": {"152994550": {"item_id": "4003885423", "author_id": "152994550", "name": "Raghav Bali", "url": "https://medium.com/@Rghv_Bali"}}, "image": {"item_id": "4003885423", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*6nRZK0-KCmkqu5I3auzK3w.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "4003885423", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*6nRZK0-KCmkqu5I3auzK3w.png", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "4003885423", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 852}, "3722111327": {"item_id": "3722111327", "resolved_id": "3722111353", "given_url": "https://towardsdatascience.com/the-basics-of-object-detection-yolo-ssd-r-cnn-6def60f51c0b?source=rss----7f60cf5620c9---4", "given_title": "The Basics of Object Detection: YOLO, SSD, R-CNN", "favorite": "0", "status": "1", "time_added": "1665520749", "time_updated": "1665530635", "time_read": "1665530635", "time_favorited": "0", "sort_id": 48, "resolved_title": "The Basics of Object Detection: YOLO, SSD, R-CNN", "resolved_url": "https://towardsdatascience.com/the-basics-of-object-detection-yolo-ssd-r-cnn-6def60f51c0b", "excerpt": "Note: This assumes you have a general idea of what convolutional neural networks are. If you need a refresher, this IBM post is excellent. You know how convolutional neural networks (or CNNs) detect and classify images. But you can expand on that CNN to detect objects within that image.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1311", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/0*8LMlzkU35e7S31yh", "tags": {"machine-learning": {"item_id": "3722111327", "tag": "machine-learning"}, "machine-vision": {"item_id": "3722111327", "tag": "machine-vision"}, "object-detection": {"item_id": "3722111327", "tag": "object-detection"}}, "authors": {"146320287": {"item_id": "3722111327", "author_id": "146320287", "name": "Hari Devanathan", "url": "https://hd2zm.medium.com"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 507}, "3727727107": {"item_id": "3727727107", "resolved_id": "3727727107", "given_url": "https://towardsdatascience.com/what-is-image-super-resolution-and-why-do-we-need-it-9c3bd9dc233e", "given_title": "What is ‘Image Super Resolution’, and why do we need it?", "favorite": "0", "status": "1", "time_added": "1666198925", "time_updated": "1666270768", "time_read": "1666270768", "time_favorited": "0", "sort_id": 49, "resolved_title": "What is ‘Image Super Resolution’, and why do we need it?", "resolved_url": "https://towardsdatascience.com/what-is-image-super-resolution-and-why-do-we-need-it-9c3bd9dc233e", "excerpt": "An introduction to the field, its applications, and current issuesHave you ever seen old monochrome pictures (most often grayscale) which have several artefacts, that are then colorised and made to look as if they were taken only recently with a modern camera? That is an example of image restoration", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "4495", "lang": "en", "time_to_read": 20, "top_image_url": "https://miro.medium.com/max/1200/1*7SRhVaFlkEvFfO4AAxqQFw.jpeg", "tags": {"machine-learning": {"item_id": "3727727107", "tag": "machine-learning"}, "machine-vision": {"item_id": "3727727107", "tag": "machine-vision"}, "super-resolution": {"item_id": "3727727107", "tag": "super-resolution"}}, "authors": {"173621017": {"item_id": "3727727107", "author_id": "173621017", "name": "Sarcasm", "url": "https://www.facebook.com/people/Sarcasm/100047415961281/"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1740}, "3654374151": {"item_id": "3654374151", "resolved_id": "3654374175", "given_url": "https://towardsdatascience.com/yolov6-next-generation-object-detection-review-and-comparison-c02e515dc45f?source=rss----7f60cf5620c9---4", "given_title": "YOLOv6: next-generation object detection — review and comparison", "favorite": "0", "status": "1", "time_added": "1657042783", "time_updated": "1657051305", "time_read": "1657051303", "time_favorited": "0", "sort_id": 50, "resolved_title": "YOLOv6: next-generation object detection", "resolved_url": "https://towardsdatascience.com/yolov6-next-generation-object-detection-review-and-comparison-c02e515dc45f", "excerpt": "The field of computer vision has rapidly evolved in recent years and achieved results that seemed like science fiction a few years back. From analyzing X-ray images and diagnosing patients to (semi-)autonomous cars, we’re witnessing a revolution in the making.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1050", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/1*ntuxZniu-76-7ODdQmaemA.jpeg", "tags": {"machine-vision": {"item_id": "3654374151", "tag": "machine-vision"}, "object-detection": {"item_id": "3654374151", "tag": "object-detection"}}, "authors": {"160141468": {"item_id": "3654374151", "author_id": "160141468", "name": "Nir Barazida", "url": "https://nirbarazida.medium.com"}}, "image": {"item_id": "3654374151", "src": "https://miro.medium.com/max/1400/1*ntuxZniu-76-7ODdQmaemA.jpeg", "width": "700", "height": "467"}, "images": {"1": {"item_id": "3654374151", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*ntuxZniu-76-7ODdQmaemA.jpeg", "width": "700", "height": "467", "credit": "", "caption": "Image from Unsplash"}, "2": {"item_id": "3654374151", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*spAlDl0Jv11zBLMQ.png", "width": "700", "height": "285", "credit": "", "caption": "Two-stage object detection, image from paper"}, "3": {"item_id": "3654374151", "image_id": "3", "src": "https://miro.medium.com/max/1400/0*Lg8T0ghKhK9XAeW4.png", "width": "700", "height": "258", "credit": "", "caption": "YOLOv1, image from original paper"}, "4": {"item_id": "3654374151", "image_id": "4", "src": "https://miro.medium.com/max/1400/0*EuLMAXmwMpE2bvIP.png", "width": "700", "height": "494", "credit": "", "caption": "Image from YOLOv6 Repository"}, "5": {"item_id": "3654374151", "image_id": "5", "src": "https://miro.medium.com/max/1400/0*gITL6C_55cQHNpgk.png", "width": "700", "height": "485", "credit": "", "caption": "Image from YOLOv6 Repository"}, "6": {"item_id": "3654374151", "image_id": "6", "src": "https://miro.medium.com/max/1400/0*f7MwkX8WmUOz-YPe.png", "width": "700", "height": "293", "credit": "", "caption": "Image by author"}, "7": {"item_id": "3654374151", "image_id": "7", "src": "https://miro.medium.com/max/1400/0*OddcR-Ad89dBkq0i.png", "width": "700", "height": "271", "credit": "", "caption": "Image by author"}, "8": {"item_id": "3654374151", "image_id": "8", "src": "https://miro.medium.com/max/1400/0*iOyM8lhQzj7Apohi.jpeg", "width": "700", "height": "934", "credit": "", "caption": "YOLOv6 Performances, Image from YOLOv5 Repository"}, "9": {"item_id": "3654374151", "image_id": "9", "src": "https://miro.medium.com/max/1400/0*fyxmnTPGhbGHN-Wg.png", "width": "700", "height": "934", "credit": "", "caption": "YOLOv5 Performances, Image from YOLOv5 Repository"}, "10": {"item_id": "3654374151", "image_id": "10", "src": "https://miro.medium.com/max/1400/0*a5lXCtv-j0Vny_PG.jpeg", "width": "700", "height": "399", "credit": "", "caption": "YOLOv6 Performances, Image from YOLOv5 Repository"}, "11": {"item_id": "3654374151", "image_id": "11", "src": "https://miro.medium.com/max/1400/0*-xQ9gB8n-ZEdqH_G.jpeg", "width": "700", "height": "399", "credit": "", "caption": "YOLOv5 Performances, Image from YOLOv5 Repository"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 406}, "3753126157": {"item_id": "3753126157", "resolved_id": "3753126181", "given_url": "https://towardsdatascience.com/yolov7-a-deep-dive-into-the-current-state-of-the-art-for-object-detection-ce3ffedeeaeb?source=rss----7f60cf5620c9---4", "given_title": "YOLOv7: A deep dive into the current state-of-the-art for object detection ", "favorite": "0", "status": "1", "time_added": "1669420033", "time_updated": "1669667177", "time_read": "1669667176", "time_favorited": "0", "sort_id": 51, "resolved_title": "YOLOv7: A Deep Dive into the Current State-of-the-Art for Object Detection", "resolved_url": "https://towardsdatascience.com/yolov7-a-deep-dive-into-the-current-state-of-the-art-for-object-detection-ce3ffedeeaeb", "excerpt": "Shortly after its publication, YOLOv7 is the fastest and most accurate real-time object detection model for computer vision tasks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "14382", "lang": "en", "time_to_read": 65, "top_image_url": "https://miro.medium.com/max/1200/1*wMUHb5UizMu6QSWRfw8SKw.png", "tags": {"deep-learning": {"item_id": "3753126157", "tag": "deep-learning"}, "machine-vision": {"item_id": "3753126157", "tag": "machine-vision"}, "object-detection": {"item_id": "3753126157", "tag": "object-detection"}}, "authors": {"150596160": {"item_id": "3753126157", "author_id": "150596160", "name": "Chris Hughes", "url": "https://medium.com/@chris.p.hughes10"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 5567}, "3912311165": {"item_id": "3912311165", "resolved_id": "3912311165", "given_url": "https://venturebeat.com/ai/mit-csail-unveils-photoguard-an-ai-defense-against-unauthorized-image-manipulation/", "given_title": "MIT CSAIL unveils PhotoGuard, an AI defense against unauthorized image mani", "favorite": "0", "status": "1", "time_added": "1690844899", "time_updated": "1691369003", "time_read": "1691369003", "time_favorited": "0", "sort_id": 52, "resolved_title": "MIT CSAIL unveils PhotoGuard, an AI defense against unauthorized image manipulation", "resolved_url": "https://venturebeat.com/ai/mit-csail-unveils-photoguard-an-ai-defense-against-unauthorized-image-manipulation/", "excerpt": "Head over to our on-demand library to view sessions from VB Transform 2023. Register Here But concerns are arising about the potential misuse of user-friendly generative AI models, which can enable the creation of inappropriate or harmful digital content.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1070", "lang": "en", "time_to_read": 5, "top_image_url": "https://venturebeat.com/wp-content/uploads/2023/07/cfr0z3n_a_humanoid_robot_stands_in_a_red-lit_darkroom_looking_a_4a22ff40-1e9b-417d-812a-03c074a20ddb.png?w=1200&strip=all", "tags": {"machine-vision": {"item_id": "3912311165", "tag": "machine-vision"}}, "authors": {"170973531": {"item_id": "3912311165", "author_id": "170973531", "name": "Victor Dey", "url": "https://venturebeat.com/author/victordey/"}}, "image": {"item_id": "3912311165", "src": "https://venturebeat.com/wp-content/uploads/2023/07/cfr0z3n_a_humanoid_robot_stands_in_a_red-lit_darkroom_looking_a_4a22ff40-1e9b-417d-812a-03c074a20ddb.png?fit=750%2C420&strip=all", "width": "750", "height": "420"}, "images": {"1": {"item_id": "3912311165", "image_id": "1", "src": "https://venturebeat.com/wp-content/uploads/2023/07/cfr0z3n_a_humanoid_robot_stands_in_a_red-lit_darkroom_looking_a_4a22ff40-1e9b-417d-812a-03c074a20ddb.png?fit=750%2C420&strip=all", "width": "750", "height": "420", "credit": "", "caption": ""}}, "domain_metadata": {"name": "VentureBeat", "logo": "https://logo.clearbit.com/venturebeat.com?size=800", "greyscale_logo": "https://logo.clearbit.com/venturebeat.com?size=800&greyscale=true"}, "listen_duration_estimate": 414}, "3879139370": {"item_id": "3879139370", "resolved_id": "3879139370", "given_url": "https://www.allaboutcircuits.com/technical-articles/what-is-an-image-processor-turns-out-the-answer-is-hazy/", "given_title": "What is an Image Processor? Turns Out the Answer is Hazy", "favorite": "0", "status": "1", "time_added": "1685727571", "time_updated": "1691368086", "time_read": "1690159034", "time_favorited": "0", "sort_id": 53, "resolved_title": "", "resolved_url": "https://www.allaboutcircuits.com/technical-articles/what-is-an-image-processor-turns-out-the-answer-is-hazy/", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"cameras": {"item_id": "3879139370", "tag": "cameras"}, "machine-vision": {"item_id": "3879139370", "tag": "machine-vision"}, "semiconductors": {"item_id": "3879139370", "tag": "semiconductors"}}, "listen_duration_estimate": 0}, "3601370210": {"item_id": "3601370210", "resolved_id": "3601370210", "given_url": "https://www.engadget.com/mit-computer-vision-algorithm-identifies-images-down-to-the-pixel-130051112.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1672167095", "time_updated": "1672243463", "time_read": "1672243462", "time_favorited": "0", "sort_id": 54, "resolved_title": "MIT's newest computer vision algorithm identifies images down to the pixel", "resolved_url": "https://www.engadget.com/mit-computer-vision-algorithm-identifies-images-down-to-the-pixel-130051112.html", "excerpt": "For humans, identifying items in a scene — whether that’s an avocado or an Aventador, a pile of mashed potatoes or an alien mothership — is as simple as looking at them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "740", "lang": "en", "time_to_read": 3, "amp_url": "https://www.engadget.com/amp/mit-computer-vision-algorithm-identifies-images-down-to-the-pixel-130051112.html", "top_image_url": "https://s.yimg.com/os/creatr-uploaded-images/2022-04/bb03e290-c00b-11ec-9656-f63c96120141", "tags": {"machine-vision": {"item_id": "3601370210", "tag": "machine-vision"}, "semantic-segmentation": {"item_id": "3601370210", "tag": "semantic-segmentation"}}, "image": {"item_id": "3601370210", "src": "https://s.yimg.com/uu/api/res/1.2/5IMfhwrp_wRi.gTrlkg43g--~B/Zmk9ZmlsbDtoPTQ1Mjt3PTY3NTthcHBpZD15dGFjaHlvbg--/https://s.yimg.com/os/creatr-uploaded-images/2022-04/bb03e290-c00b-11ec-9656-f63c96120141.cf.jpg", "width": "6468", "height": "4329"}, "images": {"1": {"item_id": "3601370210", "image_id": "1", "src": "https://s.yimg.com/uu/api/res/1.2/5IMfhwrp_wRi.gTrlkg43g--~B/Zmk9ZmlsbDtoPTQ1Mjt3PTY3NTthcHBpZD15dGFjaHlvbg--/https://s.yimg.com/os/creatr-uploaded-images/2022-04/bb03e290-c00b-11ec-9656-f63c96120141.cf.jpg", "width": "6468", "height": "4329", "credit": "", "caption": ""}, "2": {"item_id": "3601370210", "image_id": "2", "src": "https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2022-04%2F70e22b90-c006-11ec-beef-b33cba4a592b&thumbnail=675%2C&client=49kdj93ncb8s938hkdo&signature=ce5886d973a1b5c29bd281b4772823028314ea49", "width": "0", "height": "0", "credit": "MIT CSAIL", "caption": ""}, "3": {"item_id": "3601370210", "image_id": "3", "src": "https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2022-04%2F70e279b0-c006-11ec-9edf-f3fefbbab4cc&thumbnail=675%2C&client=49kdj93ncb8s938hkdo&signature=1797d347a92bb8cb8608984a27ba147b6e8703b6", "width": "0", "height": "0", "credit": "MIT CSAIL", "caption": ""}, "4": {"item_id": "3601370210", "image_id": "4", "src": "https://s.yimg.com/uu/api/res/1.2/K5N.2RVMY9tICnj06m36Ww--~B/Zmk9ZmlsbDtoPTE3MTtweW9mZj0wO3c9MjUwO2FwcGlkPXl0YWNoeW9u/https://s.yimg.com/os/creatr-uploaded-images/2022-04/05ad8340-c08a-11ec-b6dc-8a7add20239e.cf.jpg", "width": "640", "height": "421", "credit": "", "caption": ""}, "5": {"item_id": "3601370210", "image_id": "5", "src": "https://s.yimg.com/uu/api/res/1.2/sNMUpeDuXf_q6_Nl.Sk4zw--~B/Zmk9ZmlsbDtoPTE3MTtweW9mZj0wO3c9MjUwO2FwcGlkPXl0YWNoeW9u/https://s.yimg.com/os/creatr-uploaded-images/2022-03/ffd75390-9fed-11ec-b564-454e9eb7c931.cf.jpg", "width": "640", "height": "421", "credit": "", "caption": ""}, "6": {"item_id": "3601370210", "image_id": "6", "src": "https://s.yimg.com/uu/api/res/1.2/JxxE..q6AruNu4oes2kLJA--~B/Zmk9ZmlsbDtoPTE3MTtweW9mZj0wO3c9MjUwO2FwcGlkPXl0YWNoeW9u/https://s.yimg.com/os/creatr-images/2019-10/c18ed690-e6df-11e9-99ff-7080a87d6109.cf.jpg", "width": "640", "height": "421", "credit": "", "caption": ""}, "7": {"item_id": "3601370210", "image_id": "7", "src": "https://s.yimg.com/uu/api/res/1.2/AauNHVbLD3QWdW9X9NLpRQ--~B/Zmk9ZmlsbDtoPTE3MTtweW9mZj0wO3c9MjUwO2FwcGlkPXl0YWNoeW9u/https://s.yimg.com/os/creatr-uploaded-images/2022-04/68aec0e0-c16a-11ec-bfdd-3b04e2bab3dc.cf.jpg", "width": "640", "height": "421", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Engadget", "logo": "https://logo.clearbit.com/engadget.com?size=800", "greyscale_logo": "https://logo.clearbit.com/engadget.com?size=800&greyscale=true"}, "listen_duration_estimate": 286}, "3272805962": {"item_id": "3272805962", "resolved_id": "3272805967", "given_url": "https://www.fastcompany.com/90611504/deep-nostalgia-ai-brings-your-photos-to-life-just-like-in-the-harry-potter-movies?partner=feedburner&utm_source=feedburner&utm_medium=feed&utm_campaign=feedburner+fastcompany&utm_content=feedburner", "given_title": "Deep Nostalgia AI brings your photos to life just like in the ‘Harry Potter", "favorite": "0", "status": "1", "time_added": "1614945891", "time_updated": "1638708525", "time_read": "1615077848", "time_favorited": "0", "sort_id": 55, "resolved_title": "Deep Nostalgia AI brings your photos to life just like in the ‘Harry Potter’ movies", "resolved_url": "https://www.fastcompany.com/90611504/deep-nostalgia-ai-brings-your-photos-to-life-just-like-in-the-harry-potter-movies", "excerpt": "Bring great-great-great grandma back to life using deep learning.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "466", "lang": "en", "top_image_url": "https://images.fastcompany.net/image/upload/w_1280,f_auto,q_auto,fl_lossy/wp-cms/uploads/2021/03/p-1-deep-nostalgia-ai-brings-your-photos-to-life-just-like-in-the-harry-potter-movies.jpg", "tags": {"deep-learning": {"item_id": "3272805962", "tag": "deep-learning"}, "machine-vision": {"item_id": "3272805962", "tag": "machine-vision"}, "video": {"item_id": "3272805962", "tag": "video"}}, "authors": {"38811411": {"item_id": "3272805962", "author_id": "38811411", "name": "Michael Grothaus", "url": "https://www.fastcompany.com/user/michael-grothaus"}}, "domain_metadata": {"name": "Fast Company", "logo": "https://logo.clearbit.com/fastcompany.com?size=800", "greyscale_logo": "https://logo.clearbit.com/fastcompany.com?size=800&greyscale=true"}, "listen_duration_estimate": 180}, "3328297229": {"item_id": "3328297229", "resolved_id": "3328297275", "given_url": "https://www.kdnuggets.com/2021/05/essential-linear-algebra-data-science-machine-learning.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1621079863", "time_updated": "1671277463", "time_read": "1621168532", "time_favorited": "0", "sort_id": 56, "resolved_title": "Essential Linear Algebra for Data Science and Machine Learning", "resolved_url": "https://www.kdnuggets.com/essential-linear-algebra-for-data-science-and-machine-learning.html/", "excerpt": "Image by Benjamin O. Tayo. Linear Algebra is a branch of mathematics that is extremely useful in data science and machine learning. Linear algebra is the most important math skill in machine learning. Most machine learning models can be expressed in matrix form.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1159", "lang": "en", "time_to_read": 5, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/Fig1-essential-linear-algebra-data-science-machine-learning.jpg", "tags": {"linear-algebra": {"item_id": "3328297229", "tag": "linear-algebra"}, "machine-vision": {"item_id": "3328297229", "tag": "machine-vision"}}, "authors": {"137281314": {"item_id": "3328297229", "author_id": "137281314", "name": "Benjamin Obi Tayo", "url": ""}}, "image": {"item_id": "3328297229", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig1-essential-linear-algebra-data-science-machine-learning.jpg", "width": "90", "height": "0"}, "images": {"1": {"item_id": "3328297229", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig1-essential-linear-algebra-data-science-machine-learning.jpg", "width": "90", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3328297229", "image_id": "2", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig2-essential-linear-algebra-data-science-machine-learning.jpg", "width": "90", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3328297229", "image_id": "3", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig3-essential-linear-algebra-data-science-machine-learning.jpg", "width": "90", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3328297229", "image_id": "4", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig4-essential-linear-algebra-data-science-machine-learning.jpg", "width": "90", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3328297229", "image_id": "5", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig5-essential-linear-algebra-data-science-machine-learning.jpg", "width": "90", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3328297229", "image_id": "6", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig6-essential-linear-algebra-data-science-machine-learning.jpg", "width": "350", "height": "77", "credit": "", "caption": ""}, "7": {"item_id": "3328297229", "image_id": "7", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig7-essential-linear-algebra-data-science-machine-learning.jpg", "width": "350", "height": "172", "credit": "", "caption": ""}, "8": {"item_id": "3328297229", "image_id": "8", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig8-essential-linear-algebra-data-science-machine-learning.jpg", "width": "350", "height": "168", "credit": "", "caption": ""}, "9": {"item_id": "3328297229", "image_id": "9", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig9-essential-linear-algebra-data-science-machine-learning.jpg", "width": "90", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3328297229", "image_id": "10", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig10-essential-linear-algebra-data-science-machine-learning.jpg", "width": "350", "height": "155", "credit": "", "caption": ""}, "11": {"item_id": "3328297229", "image_id": "11", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig11-essential-linear-algebra-data-science-machine-learning.jpg", "width": "90", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3328297229", "image_id": "12", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig12-essential-linear-algebra-data-science-machine-learning.jpg", "width": "317", "height": "155", "credit": "", "caption": ""}, "13": {"item_id": "3328297229", "image_id": "13", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig13-essential-linear-algebra-data-science-machine-learning.jpg", "width": "179", "height": "78", "credit": "", "caption": ""}, "14": {"item_id": "3328297229", "image_id": "14", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig14-essential-linear-algebra-data-science-machine-learning.jpg", "width": "284", "height": "71", "credit": "", "caption": ""}, "15": {"item_id": "3328297229", "image_id": "15", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig16-essential-linear-algebra-data-science-machine-learning.jpg", "width": "228", "height": "71", "credit": "", "caption": ""}, "16": {"item_id": "3328297229", "image_id": "16", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig15-essential-linear-algebra-data-science-machine-learning.jpg", "width": "184", "height": "56", "credit": "", "caption": ""}, "17": {"item_id": "3328297229", "image_id": "17", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig17-essential-linear-algebra-data-science-machine-learning.jpg", "width": "289", "height": "73", "credit": "", "caption": ""}, "18": {"item_id": "3328297229", "image_id": "18", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig18-essential-linear-algebra-data-science-machine-learning.jpg", "width": "299", "height": "84", "credit": "", "caption": ""}, "19": {"item_id": "3328297229", "image_id": "19", "src": "https://www.kdnuggets.com/wp-content/uploads/Fig19-essential-linear-algebra-data-science-machine-learning.jpg", "width": "223", "height": "68", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 449}, "3915107517": {"item_id": "3915107517", "resolved_id": "3915107517", "given_url": "https://www.marktechpost.com/2023/08/05/this-ai-research-introduces-a-novel-two-stage-pose-distillation-for-whole-body-pose-estimation/", "given_title": "This AI Research Introduces a Novel Two-Stage Pose Distillation for Whole-B", "favorite": "0", "status": "1", "time_added": "1691319683", "time_updated": "1691365884", "time_read": "1691365884", "time_favorited": "0", "sort_id": 57, "resolved_title": "This AI Research Introduces a Novel Two-Stage Pose Distillation for Whole-Body Pose Estimation", "resolved_url": "https://www.marktechpost.com/2023/08/05/this-ai-research-introduces-a-novel-two-stage-pose-distillation-for-whole-body-pose-estimation/", "excerpt": "Numerous human-centric perception, comprehension, and creation tasks depend on whole-body pose estimation, including 3D whole-body mesh recovery, human-object interaction, and posture-conditioned human image and motion production.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "693", "lang": "en", "time_to_read": 3, "top_image_url": "https://www.marktechpost.com/wp-content/uploads/2023/08/Screenshot-2023-08-05-at-6.35.24-PM.png", "tags": {"machine-vision": {"item_id": "3915107517", "tag": "machine-vision"}}, "authors": {"166902541": {"item_id": "3915107517", "author_id": "166902541", "name": "Aneesh Tickoo", "url": "https://www.marktechpost.com/author/aneesh-tickoo/"}}, "image": {"item_id": "3915107517", "src": "https://www.marktechpost.com/wp-content/uploads/2023/08/Screenshot-2023-08-05-at-6.35.24-PM.png", "width": "696", "height": "406"}, "images": {"1": {"item_id": "3915107517", "image_id": "1", "src": "https://www.marktechpost.com/wp-content/uploads/2023/08/Screenshot-2023-08-05-at-6.35.24-PM.png", "width": "696", "height": "406", "credit": "", "caption": "https://arxiv.org/abs/2307.15880"}, "2": {"item_id": "3915107517", "image_id": "2", "src": "https://lh6.googleusercontent.com/Yrld_GoHxalJi_5F-UsaTS8PnSadmdZ3ECQZbt3_vSzMOsDVlFhvgoBr0ONyq4S-rgWvazeEUfmSMNaObl27ypFk11_G_Gk2A8Uu9i0Z6309zR5hxK7-9dvkRoCBd29CQGYJ7ZJWoUx10QhfP6hj8ZI", "width": "0", "height": "0", "credit": "", "caption": "Figure 1 shows a comparison between their model and comparable models for COCO-WholeBody’s whole-body posture estimation."}}, "listen_duration_estimate": 268}, "3936160043": {"item_id": "3936160043", "resolved_id": "3936160043", "given_url": "https://www.marktechpost.com/2023/09/16/mit-researchers-created-a-new-annotated-synthetic-dataset-of-images-that-depict-a-wide-range-of-scenarios-to-help-machine-learning-models-understand-the-concepts-in-a-scene/", "given_title": "MIT Researchers Created a New Annotated Synthetic Dataset of Images that De", "favorite": "0", "status": "1", "time_added": "1694866491", "time_updated": "1694977375", "time_read": "1694977375", "time_favorited": "0", "sort_id": 58, "resolved_title": "MIT Researchers Created a New Annotated Synthetic Dataset of Images that Depict a Wide Range of Scenarios to Help Machine-Learning Models Understand the Concepts in a Scene", "resolved_url": "https://www.marktechpost.com/2023/09/16/mit-researchers-created-a-new-annotated-synthetic-dataset-of-images-that-depict-a-wide-range-of-scenarios-to-help-machine-learning-models-understand-the-concepts-in-a-scene/", "excerpt": "Large-scale pre-trained Vision and language models have demonstrated remarkable performance in numerous applications, allowing for the replacement of a fixed set of supported classes with zero-shot open vocabulary reasoning over (nearly arbitrary) natural language queries.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "884", "lang": "en", "time_to_read": 4, "amp_url": "https://www.marktechpost.com/2023/09/16/mit-researchers-created-a-new-annotated-synthetic-dataset-of-images-that-depict-a-wide-range-of-scenarios-to-help-machine-learning-models-understand-the-concepts-in-a-scene/?amp", "top_image_url": "https://www.marktechpost.com/wp-content/uploads/2023/09/Screenshot-2023-09-16-at-4.25.14-AM.png", "tags": {"datasets": {"item_id": "3936160043", "tag": "datasets"}, "machine-vision": {"item_id": "3936160043", "tag": "machine-vision"}}, "authors": {"174215351": {"item_id": "3936160043", "author_id": "174215351", "name": "Dhanshree Shripad Shenwai", "url": "https://www.marktechpost.com/author/dhanshree0078/"}}, "image": {"item_id": "3936160043", "src": "https://www.marktechpost.com/wp-content/uploads/2023/09/Screenshot-2023-09-16-at-4.25.14-AM.png", "width": "696", "height": "451"}, "images": {"1": {"item_id": "3936160043", "image_id": "1", "src": "https://www.marktechpost.com/wp-content/uploads/2023/09/Screenshot-2023-09-16-at-4.25.14-AM.png", "width": "696", "height": "451", "credit": "", "caption": "https://synthetic-vic.github.io/"}}, "listen_duration_estimate": 342}, "3993975985": {"item_id": "3993975985", "resolved_id": "3993975985", "given_url": "https://www.marktechpost.com/2024/01/14/lets-go-shopping-lgs-dataset-a-large-scale-public-dataset-with-15m-image-caption-pairs-from-publicly-available-e-commerce-websites/", "given_title": "‘Let’s Go Shopping (LGS)’ Dataset: A Large-Scale Public Dataset with 15M Im", "favorite": "0", "status": "1", "time_added": "1705234871", "time_updated": "1705475944", "time_read": "1705475944", "time_favorited": "0", "sort_id": 59, "resolved_title": "‘Let’s Go Shopping (LGS)’ Dataset: A Large-Scale Public Dataset with 15M Image-Caption Pairs from Publicly Available E-commerce Websites", "resolved_url": "https://www.marktechpost.com/2024/01/14/lets-go-shopping-lgs-dataset-a-large-scale-public-dataset-with-15m-image-caption-pairs-from-publicly-available-e-commerce-websites/", "excerpt": "Developing large-scale datasets has been critical in computer vision and natural language processing. These datasets, rich in visual and textual information, are fundamental to developing algorithms capable of understanding and interpreting images.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "537", "lang": "en", "amp_url": "https://www.marktechpost.com/2024/01/14/lets-go-shopping-lgs-dataset-a-large-scale-public-dataset-with-15m-image-caption-pairs-from-publicly-available-e-commerce-websites/?amp", "top_image_url": "https://www.marktechpost.com/wp-content/uploads/2024/01/Screenshot-2024-01-14-at-4.05.26-AM.png", "tags": {"datasets": {"item_id": "3993975985", "tag": "datasets"}, "ecommerce": {"item_id": "3993975985", "tag": "ecommerce"}, "machine-vision": {"item_id": "3993975985", "tag": "machine-vision"}, "prodmgmt": {"item_id": "3993975985", "tag": "prodmgmt"}}, "authors": {"186984820": {"item_id": "3993975985", "author_id": "186984820", "name": "Muhammad Athar Ganaie", "url": "https://www.marktechpost.com/author/muhammad-athar-ganaie/"}}, "image": {"item_id": "3993975985", "src": "https://www.marktechpost.com/wp-content/uploads/2024/01/Screenshot-2024-01-14-at-4.05.26-AM.png", "width": "696", "height": "370"}, "images": {"1": {"item_id": "3993975985", "image_id": "1", "src": "https://www.marktechpost.com/wp-content/uploads/2024/01/Screenshot-2024-01-14-at-4.05.26-AM.png", "width": "696", "height": "370", "credit": "", "caption": "https://arxiv.org/abs/2401.04575"}, "2": {"item_id": "3993975985", "image_id": "2", "src": "https://lh7-us.googleusercontent.com/P2rgjX2kd0r5fJPofE7pFOmvArJBGrQyHgsNF_ZTj0lcPW0lnuv0XqyK5vq-AWlnFQ_KZys9RsMx_PMkkGibd44Yw8yTtFjSbm2NIngKNYPg-biS-iZWvmJZfQm5JVsi7qUT7yNGzl_mFUD9RXF6z4M", "width": "0", "height": "0", "credit": "", "caption": "https://arxiv.org/abs/2401.04575"}}, "listen_duration_estimate": 208}, "3071048716": {"item_id": "3071048716", "resolved_id": "3071048716", "given_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4285011/", "given_title": "The Child Affective Facial Expression (CAFE) set: validity and reliability ", "favorite": "0", "status": "1", "time_added": "1596658711", "time_updated": "1706623079", "time_read": "1608290375", "time_favorited": "0", "sort_id": 60, "resolved_title": "The Child Affective Facial Expression (CAFE) set: validity and reliability from untrained adults", "resolved_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4285011/", "excerpt": "Emotional development is one of the largest and most productive areas of psychological research. For decades, researchers have been fascinated by how humans respond to, detect, and interpret emotional facial expressions.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4990", "lang": "en", "time_to_read": 23, "top_image_url": "https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0", "tags": {"datasets": {"item_id": "3071048716", "tag": "datasets"}, "machine-vision": {"item_id": "3071048716", "tag": "machine-vision"}}, "authors": {"103979161": {"item_id": "3071048716", "author_id": "103979161", "name": "ude.sregtur.ygolohcysp@eubolv", "url": "mailto:dev@null"}, "184226456": {"item_id": "3071048716", "author_id": "184226456", "name": "Vanessa LoBue", "url": "https://pubmed.ncbi.nlm.nih.gov/?term=LoBue%20V%5BAuthor%5D"}, "184226457": {"item_id": "3071048716", "author_id": "184226457", "name": "Cat Thrasher", "url": "https://pubmed.ncbi.nlm.nih.gov/?term=Thrasher%20C%5BAuthor%5D"}}, "image": {"item_id": "3071048716", "src": "https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&p=PMC3&id=4285011_fpsyg-05-01532-g0001.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3071048716", "image_id": "1", "src": "https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&p=PMC3&id=4285011_fpsyg-05-01532-g0001.jpg", "width": "0", "height": "0", "credit": "", "caption": "Examples of each of the posed facial expressions in the CAFE set."}, "2": {"item_id": "3071048716", "image_id": "2", "src": "https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&p=PMC3&id=4285011_fpsyg-05-01532-g0002.jpg", "width": "0", "height": "0", "credit": "", "caption": "Percent accuracy for each category of facial expression in the full CAFE set at Time 1."}, "3": {"item_id": "3071048716", "image_id": "3", "src": "https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&p=PMC3&id=4285011_fpsyg-05-01532-g0003.jpg", "width": "0", "height": "0", "credit": "bi", "caption": "Distribution of difficulty"}}, "domain_metadata": {"name": "National Institutes of Health", "logo": "https://logo.clearbit.com/nih.gov?size=800", "greyscale_logo": "https://logo.clearbit.com/nih.gov?size=800&greyscale=true"}, "listen_duration_estimate": 1932}, "3366588236": {"item_id": "3366588236", "resolved_id": "3364082081", "given_url": "https://www.quantamagazine.org/same-or-different-ai-cant-tell-20210623/?utm_source=DamnInteresting&fbclid=IwAR0tGsjpYIg0UnsKf7ZN_qDqfU0-KFWFKTEUbGxNhzy7scUzixyn8HJDG6s", "given_title": "", "favorite": "0", "status": "1", "time_added": "1624714070", "time_updated": "1638708525", "time_read": "1624744021", "time_favorited": "0", "sort_id": 61, "resolved_title": "Same or Different? The Question Flummoxes Neural Networks.", "resolved_url": "https://www.quantamagazine.org/same-or-different-ai-cant-tell-20210623/", "excerpt": "For all their triumphs, AI systems can’t seem to generalize the concepts of “same” and “different.” Without that, researchers worry, the quest to create truly intelligent machines may be hopeless.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1250", "lang": "en", "time_to_read": 6, "top_image_url": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2021/06/Same_different_1200_Social.jpg", "tags": {"deep-learning": {"item_id": "3366588236", "tag": "deep-learning"}, "machine-learning": {"item_id": "3366588236", "tag": "machine-learning"}, "machine-vision": {"item_id": "3366588236", "tag": "machine-vision"}}, "authors": {"39714489": {"item_id": "3366588236", "author_id": "39714489", "name": "John Pavlus", "url": "https://www.quantamagazine.org/authors/john-pavlus/"}}, "image": {"item_id": "3366588236", "src": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2021/06/Same_different_2880x1620_Lede.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3366588236", "image_id": "1", "src": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2021/06/Same_different_2880x1620_Lede.jpg", "width": "0", "height": "0", "credit": "", "caption": "Samuel Velasco/Quanta Magazine"}}, "domain_metadata": {"name": "Quanta Magazine", "logo": "https://logo.clearbit.com/quantamagazine.org?size=800", "greyscale_logo": "https://logo.clearbit.com/quantamagazine.org?size=800&greyscale=true"}, "listen_duration_estimate": 484}, "3574495398": {"item_id": "3574495398", "resolved_id": "3574495398", "given_url": "https://www.scientificamerican.com/podcast/episode/are-you-better-than-a-machine-at-spotting-a-deepfake/", "given_title": "Are You Better Than a Machine at Spotting a Deepfake?", "favorite": "0", "status": "1", "time_added": "1647367987", "time_updated": "1647382673", "time_read": "1647382673", "time_favorited": "0", "sort_id": 62, "resolved_title": "Are You Better Than a Machine at Spotting a Deepfake?", "resolved_url": "https://www.scientificamerican.com/podcast/episode/are-you-better-than-a-machine-at-spotting-a-deepfake/", "excerpt": "New research shows that detecting digital fakes generated by machine learning might be a job best done with humans still in the loop. Sarah Vitak is a maker, scientist, radio producer, writer, science communicator and artist.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "66", "lang": "en", "top_image_url": "https://static.scientificamerican.com/sciam/cache/file/FF9411E3-6975-4B44-BD7E6544E9363865.jpg", "tags": {"deepfakes": {"item_id": "3574495398", "tag": "deepfakes"}, "face-recognition": {"item_id": "3574495398", "tag": "face-recognition"}, "machine-vision": {"item_id": "3574495398", "tag": "machine-vision"}}, "authors": {"148243024": {"item_id": "3574495398", "author_id": "148243024", "name": "Sarah Vitak", "url": "https://www.scientificamerican.com/author/sarah-vitak/"}}, "image": {"item_id": "3574495398", "src": "https://static.scientificamerican.com/sciam/cache/file/FF9411E3-6975-4B44-BD7E6544E9363865_source.jpg?w=590&h=800&4FCF1E89-619B-4E61-87F5E10A4E8FDDE3", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3574495398", "image_id": "1", "src": "https://static.scientificamerican.com/sciam/cache/file/FF9411E3-6975-4B44-BD7E6544E9363865_source.jpg?w=590&h=800&4FCF1E89-619B-4E61-87F5E10A4E8FDDE3", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Scientific American", "logo": "https://logo.clearbit.com/scientificamerican.com?size=800", "greyscale_logo": "https://logo.clearbit.com/scientificamerican.com?size=800&greyscale=true"}, "listen_duration_estimate": 26}, "3413588467": {"item_id": "3413588467", "resolved_id": "3324385965", "given_url": "https://www.technologyreview.com/2021/05/05/1024613/stop-ai-recognizing-your-face-selfies-machine-learning-facial-recognition-clearview/?utm_medium=tr_social&utm_campaign=site_visitor.unpaid.engagement&utm_source=Facebook", "given_title": "How to stop AI from recognizing your face in selfies | MIT Technology Revie", "favorite": "0", "status": "1", "time_added": "1642087701", "time_updated": "1687908742", "time_read": "1642095730", "time_favorited": "0", "sort_id": 63, "resolved_title": "How to stop AI from recognizing your face in selfies", "resolved_url": "https://www.technologyreview.com/2021/05/05/1024613/stop-ai-recognizing-your-face-selfies-machine-learning-facial-recognition-clearview/", "excerpt": "Uploading personal photos to the internet can feel like letting go. Who else will have access to them, what will they do with them—and which machine-learning algorithms will they help train?", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1070", "lang": "en", "time_to_read": 5, "amp_url": "https://www.technologyreview.com/2021/05/05/1024613/stop-ai-recognizing-your-face-selfies-machine-learning-facial-recognition-clearview/amp/", "top_image_url": "https://wp.technologyreview.com/wp-content/uploads/2021/05/james-barr-L_f7x_Uv5Qs-unsplash.jpg?resize=1200,600", "tags": {"machine-vision": {"item_id": "3413588467", "tag": "machine-vision"}}, "authors": {"25561932": {"item_id": "3413588467", "author_id": "25561932", "name": "Will Douglas Heaven", "url": ""}}, "image": {"item_id": "3413588467", "src": "https://wp.technologyreview.com/wp-content/uploads/2021/05/james-barr-L_f7x_Uv5Qs-unsplash.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3413588467", "image_id": "1", "src": "https://wp.technologyreview.com/wp-content/uploads/2021/05/james-barr-L_f7x_Uv5Qs-unsplash.jpg", "width": "0", "height": "0", "credit": "Ms Tech | Unsplash", "caption": ""}, "2": {"item_id": "3413588467", "image_id": "2", "src": "https://wp.technologyreview.com/wp-content/uploads/2021/05/willselfies.jpg", "width": "579", "height": "393", "credit": "", "caption": ""}}, "domain_metadata": {"name": "MIT Technology Review", "logo": "https://logo.clearbit.com/technologyreview.com?size=800", "greyscale_logo": "https://logo.clearbit.com/technologyreview.com?size=800&greyscale=true"}, "listen_duration_estimate": 414}, "3732131883": {"item_id": "3732131883", "resolved_id": "3732131883", "given_url": "https://www.technologyreview.com/2022/10/25/1060426/a-search-engine-for-shapes/", "given_title": "A search engine for shapes", "favorite": "0", "status": "1", "time_added": "1666739927", "time_updated": "1666783774", "time_read": "1666783773", "time_favorited": "0", "sort_id": 64, "resolved_title": "A search engine for shapes", "resolved_url": "https://www.technologyreview.com/2022/10/25/1060426/a-search-engine-for-shapes/", "excerpt": "Imagine you’re an automobile manufacturer. You have warehouse after warehouse full of parts. You’d like to use some of those parts in a new model and save on design and production costs. But you can’t find those parts through a text search. You don’t know what they’re called.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "418", "lang": "en", "amp_url": "https://www.technologyreview.com/2022/10/25/1060426/a-search-engine-for-shapes/amp/", "top_image_url": "https://wp.technologyreview.com/wp-content/uploads/2022/09/ND22_MIT_notes-Tan-thumb.jpg?resize=1200,600", "tags": {"machine-vision": {"item_id": "3732131883", "tag": "machine-vision"}, "semantic-search": {"item_id": "3732131883", "tag": "semantic-search"}, "startups": {"item_id": "3732131883", "tag": "startups"}}, "authors": {"370284": {"item_id": "3732131883", "author_id": "370284", "name": "Ken Shulman", "url": ""}}, "image": {"item_id": "3732131883", "src": "https://wp.technologyreview.com/wp-content/uploads/2022/09/ND22_MIT_notes-Tan.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3732131883", "image_id": "1", "src": "https://wp.technologyreview.com/wp-content/uploads/2022/09/ND22_MIT_notes-Tan.jpg", "width": "0", "height": "0", "credit": "Courtesy Photo", "caption": ""}}, "domain_metadata": {"name": "MIT Technology Review", "logo": "https://logo.clearbit.com/technologyreview.com?size=800", "greyscale_logo": "https://logo.clearbit.com/technologyreview.com?size=800&greyscale=true"}, "listen_duration_estimate": 162}, "3830048336": {"item_id": "3830048336", "resolved_id": "3830048336", "given_url": "https://www.tomshardware.com/news/nvidia-tackles-chipmaking-process-claims-40x-speed-up-with-culitho", "given_title": "", "favorite": "0", "status": "1", "time_added": "1679419487", "time_updated": "1679424710", "time_read": "1679424709", "time_favorited": "0", "sort_id": 65, "resolved_title": "Nvidia Tackles Chipmaking Process, Claims 40X Speed Up with cuLitho", "resolved_url": "https://www.tomshardware.com/news/nvidia-tackles-chipmaking-process-claims-40x-speed-up-with-culitho", "excerpt": "At GTC 2023, Nvidia announced its new cuLitho software library for speeding up a critical bottleneck in the semiconductor manufacturing workflow. The new library speeds computational lithography, a technique used to create photomasks for chip production.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "710", "lang": "en", "time_to_read": 3, "top_image_url": "https://cdn.mos.cms.futurecdn.net/Vu6N9RDjut8Yy6FiGKNSCB-1200-80.png", "tags": {"gpus": {"item_id": "3830048336", "tag": "gpus"}, "lithography": {"item_id": "3830048336", "tag": "lithography"}, "machine-vision": {"item_id": "3830048336", "tag": "machine-vision"}, "semiconductors": {"item_id": "3830048336", "tag": "semiconductors"}}, "authors": {"121060879": {"item_id": "3830048336", "author_id": "121060879", "name": "Paul Alcorn", "url": "https://www.tomshardware.com/author/paul-alcorn"}}, "domain_metadata": {"name": "Tom's Hardware", "logo": "https://logo.clearbit.com/tomshardware.com?size=800", "greyscale_logo": "https://logo.clearbit.com/tomshardware.com?size=800&greyscale=true"}, "listen_duration_estimate": 275}, "3803320564": {"item_id": "3803320564", "resolved_id": "3803320564", "given_url": "https://www.toptal.com/designers/ux/virtual-clothing-try-on", "given_title": "Shopping for Apparel in an Online World: UI/UX Design for Virtual Clothing ", "favorite": "0", "status": "1", "time_added": "1675949244", "time_updated": "1676033773", "time_read": "1676033773", "time_favorited": "0", "sort_id": 66, "resolved_title": "Shopping for Apparel in an Online World: UI/UX Design for Virtual Clothing Try-on", "resolved_url": "https://www.toptal.com/designers/ux/virtual-clothing-try-on", "excerpt": "Buying clothes online is challenging. According to the National Retail Federation, the clothing industry has the second-highest return rate (after auto parts) of any other sector.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2214", "lang": "en", "time_to_read": 10, "top_image_url": "https://bs-uploads.toptal.io/blackfish-uploads/components/seo/content/og_image_file/og_image/1160359/UI-UX-Design-for-Virtual-Clothing-Try-On_Technology_Social__1_-bca6c6bfca76c09aeaca1d62696dbc61.png", "tags": {"clothes": {"item_id": "3803320564", "tag": "clothes"}, "ecommerce": {"item_id": "3803320564", "tag": "ecommerce"}, "machine-vision": {"item_id": "3803320564", "tag": "machine-vision"}, "ui-ux": {"item_id": "3803320564", "tag": "ui-ux"}}, "authors": {"20960652": {"item_id": "3803320564", "author_id": "20960652", "name": "Laurence Brothers", "url": ""}}, "image": {"item_id": "3803320564", "src": "https://bs-uploads.toptal.io/blackfish-uploads/public-files/Untitled-1f460c41f609acafe6408ea3c92ac242.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3803320564", "image_id": "1", "src": "https://bs-uploads.toptal.io/blackfish-uploads/public-files/Untitled-1f460c41f609acafe6408ea3c92ac242.jpg", "width": "0", "height": "0", "credit": "", "caption": "The YourFit experience by 3DLook instructs shoppers on how to take images of themselves, then shows how clothing will look on them."}, "2": {"item_id": "3803320564", "image_id": "2", "src": "https://bs-uploads.toptal.io/blackfish-uploads/public-files/Untitled-83b1591438462d1dd7a89933214c063e.png", "width": "0", "height": "0", "credit": "", "caption": "Walmart’s virtual try-on option lets shoppers visualize how a piece of clothing might look on someone whose body type closely resembles their own."}, "3": {"item_id": "3803320564", "image_id": "3", "src": "https://bs-uploads.toptal.io/blackfish-uploads/public-files/Internal-04__1_-207eb9d4ccd6a9f33d625a013b4c3513.png", "width": "0", "height": "0", "credit": "", "caption": "The Ray-Ban app provides clear, conversational instructions for trying on glasses, to provide customers with the most accurate view of what glasses will look like on them."}}, "listen_duration_estimate": 857}, "3403298073": {"item_id": "3403298073", "resolved_id": "3403298073", "given_url": "https://www.vice.com/en/article/k78ygn/researchers-create-master-faces-to-bypass-facial-recognition", "given_title": "", "favorite": "0", "status": "1", "time_added": "1628710912", "time_updated": "1628775331", "time_read": "1628775330", "time_favorited": "0", "sort_id": 67, "resolved_title": "Researchers Create 'Master Faces' to Bypass Facial Recognition", "resolved_url": "https://www.vice.com/en/article/k78ygn/researchers-create-master-faces-to-bypass-facial-recognition", "excerpt": "In their paper, researchers at the Blavatnik School of Computer Science and the School of Electrical Engineering in Tel Aviv detail how they successfully created nine \"master key\" faces that are able to impersonate almost half the faces in a dataset of three leading face recognition systems.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "503", "lang": "en", "amp_url": "https://www.vice.com/amp/en/article/k78ygn/researchers-create-master-faces-to-bypass-facial-recognition", "top_image_url": "https://video-images.vice.com/articles/6111605f1540c500957240e0/lede/1628529155600-gettyimages-607358443.jpeg?image-resize-opts=Y3JvcD0xeHc6MC44NDUzNzU3MjI1NDMzNTI2eGg7Y2VudGVyLGNlbnRlciZyZXNpemU9MTIwMDoqJnJlc2l6ZT0xMjAwOio", "tags": {"deep-learning": {"item_id": "3403298073", "tag": "deep-learning"}, "machine-vision": {"item_id": "3403298073", "tag": "machine-vision"}}, "authors": {"152131252": {"item_id": "3403298073", "author_id": "152131252", "name": "Radhamely De Leon", "url": "https://www.vice.com/en/contributor/radhamely-de-leon"}}, "image": {"item_id": "3403298073", "src": "https://video-images.vice.com/articles/6111605f1540c500957240e0/lede/1628529155600-gettyimages-607358443.jpeg?crop=1xw:0.8453757225433526xh;center,center&resize=20:*", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3403298073", "image_id": "1", "src": "https://video-images.vice.com/articles/6111605f1540c500957240e0/lede/1628529155600-gettyimages-607358443.jpeg?crop=1xw:0.8453757225433526xh;center,center&resize=20:*", "width": "0", "height": "0", "credit": "Image: Getty Images", "caption": ""}, "2": {"item_id": "3403298073", "image_id": "2", "src": "https://video-images.vice.com/_uncategorized/1628528999696-image1.png", "width": "518", "height": "494", "credit": "", "caption": ""}}, "domain_metadata": {"name": "VICE", "logo": "https://logo.clearbit.com/vice.com?size=800", "greyscale_logo": "https://logo.clearbit.com/vice.com?size=800&greyscale=true"}, "listen_duration_estimate": 195}, "3856536341": {"item_id": "3856536341", "resolved_id": "3855385252", "given_url": "https://www.vice.com/en/article/pkapb7/a-photographer-tried-to-get-his-photos-removed-from-an-ai-dataset-he-got-an-invoice-insteadit", "given_title": "", "favorite": "0", "status": "1", "time_added": "1682855488", "time_updated": "1682887497", "time_read": "1682887496", "time_favorited": "0", "sort_id": 68, "resolved_title": "A Photographer Tried to Get His Photos Removed from an AI Dataset. He Got an Invoice Instead.", "resolved_url": "https://www.vice.com/en/article/pkapb7/a-photographer-tried-to-get-his-photos-removed-from-an-ai-dataset-he-got-an-invoice-instead", "excerpt": "The photographer, Robert Kneschke, found out in February that his photographs were being used to train AI through a site called Have I Been Trained? This website allowed him to search through LAION-5B, which is a dataset of over 5.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1132", "lang": "en", "time_to_read": 5, "top_image_url": "https://video-images.vice.com/articles/644aa47ad6ce2f860ec5afb2/lede/1682613792698-your-paragraph-text-97.jpeg?image-resize-opts=Y3JvcD0xeHc6MXhoO2NlbnRlcixjZW50ZXImcmVzaXplPTEyMDA6KiZyZXNpemU9MTIwMDoq", "tags": {"intellectual-property": {"item_id": "3856536341", "tag": "intellectual-property"}, "machine-vision": {"item_id": "3856536341", "tag": "machine-vision"}}, "authors": {"169058973": {"item_id": "3856536341", "author_id": "169058973", "name": "Chloe Xiang", "url": "https://www.vice.com/en/contributor/chloe-xiang"}}, "image": {"item_id": "3856536341", "src": "https://video-images.vice.com/articles/644aa47ad6ce2f860ec5afb2/lede/1682613792698-your-paragraph-text-97.jpeg?crop=1xw:1xh;center,center&resize=20:*", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3856536341", "image_id": "1", "src": "https://video-images.vice.com/articles/644aa47ad6ce2f860ec5afb2/lede/1682613792698-your-paragraph-text-97.jpeg?crop=1xw:1xh;center,center&resize=20:*", "width": "0", "height": "0", "credit": "Image: Mareen Fischinger via www.robertkneschke.de", "caption": ""}}, "domain_metadata": {"name": "VICE", "logo": "https://logo.clearbit.com/vice.com?size=800", "greyscale_logo": "https://logo.clearbit.com/vice.com?size=800&greyscale=true"}, "listen_duration_estimate": 438}}, "error": nil, "search_meta": {"search_type": "normal"}, "since": 1709419462}