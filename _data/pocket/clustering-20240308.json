{"status": 1, "complete": 1, "list": {"3038762160": {"item_id": "3038762160", "resolved_id": "3038762177", "given_url": "https://towardsdatascience.com/geographic-clustering-with-hdbscan-ef8cb0ed6051?source=rss----7f60cf5620c9---4", "given_title": "", "favorite": "0", "status": "1", "time_added": "1691350021", "time_updated": "1691350112", "time_read": "1691350112", "time_favorited": "0", "sort_id": 0, "resolved_title": "Geographic Clustering with HDBSCAN", "resolved_url": "https://towardsdatascience.com/geographic-clustering-with-hdbscan-ef8cb0ed6051", "excerpt": "Your smartphone knows when you are at home or the office. At least, mine does, and can even tell me when to leave to get at one of my common destinations on time. We all accept that our smart devices collect information about our preferences and send them over to the cloud for processing.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2519", "lang": "en", "time_to_read": 11, "top_image_url": "https://miro.medium.com/max/1200/0*0wrFL9wnGaoyaCvo", "tags": {"clustering": {"item_id": "3038762160", "tag": "clustering"}, "machine-learning": {"item_id": "3038762160", "tag": "machine-learning"}}, "authors": {"96574908": {"item_id": "3038762160", "author_id": "96574908", "name": "João Paulo Figueira", "url": "https://medium.com/@joao.figueira"}}, "image": {"item_id": "3038762160", "src": "https://miro.medium.com/fit/c/56/56/1*Phe2m6kjW8twwdl5zwDbEA.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3038762160", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*Phe2m6kjW8twwdl5zwDbEA.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3038762160", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*0wrFL9wnGaoyaCvo", "width": "700", "height": "467", "credit": "Martin Sanchez on Unsplash", "caption": ""}, "3": {"item_id": "3038762160", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*Qi9Zn8jsHoEkgCeqVZY7aA.png", "width": "700", "height": "424", "credit": "", "caption": "Cluster number 2 displays a distinct set of outlying points to the northeast. The outlier score for each point reflects on its color, with blue points having a low score and red points a high score."}, "4": {"item_id": "3038762160", "image_id": "4", "src": "https://miro.medium.com/max/994/1*oNeKSysdw2yWSKi1BVaGNg.png", "width": "497", "height": "496", "credit": "selecting an outlier score threshold of 0.8, we retain over 97.85% of the cluster points", "caption": ""}, "5": {"item_id": "3038762160", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*EJCn-vI2UQasnPRZEHsenw.png", "width": "700", "height": "424", "credit": "pasting all hexagons together, we create a hive-like representation of the cluster. Nevertheless, we want to keep the outline only", "caption": ""}, "6": {"item_id": "3038762160", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*y0ottTs1HLEu0E5kdYnKWA.png", "width": "700", "height": "424", "credit": "", "caption": "The same cluster as above but now with all the hexagons merged into a single shape."}, "7": {"item_id": "3038762160", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*-kOK1mnkro-gaqrh4Hq1Yw.png", "width": "700", "height": "423", "credit": "", "caption": "These islands sow up due to the point dispersion and the fixed H3 level used to represent the hexagons."}, "8": {"item_id": "3038762160", "image_id": "8", "src": "https://miro.medium.com/max/892/1*Jn0_GLnhvOHAsOrshvtjZQ.png", "width": "446", "height": "302", "credit": "hexagon", "caption": "The above cluster represented as a graph. Note the two obvious components, and how the nodes in the larger component connect. Each edge is a neighbor relationship. To link the lonely node to the larger component, we will have to add at least another node"}, "9": {"item_id": "3038762160", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*elT5e5SweUxmKEhHJRkK7w.png", "width": "700", "height": "429", "credit": "", "caption": "A named cluster in the intersection of Packard Road and Carpenter Road."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 975}, "3890375205": {"item_id": "3890375205", "resolved_id": "3890375220", "given_url": "https://towardsdatascience.com/unsupervised-learning-series-exploring-hierarchical-clustering-15d992467aa8?source=rss----7f60cf5620c9---4", "given_title": "", "favorite": "0", "status": "1", "time_added": "1687265647", "time_updated": "1690156788", "time_read": "1690156788", "time_favorited": "0", "sort_id": 1, "resolved_title": "Unsupervised Learning Series — Exploring Hierarchical Clustering", "resolved_url": "https://towardsdatascience.com/unsupervised-learning-series-exploring-hierarchical-clustering-15d992467aa8", "excerpt": "In my last post of the Unsupervised Learning Series, we explored one of the most famous clustering methods, the K-means Clustering. In this post, we are going to discuss the methods behind another important clustering technique — hierarchical clustering!", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2474", "lang": "en", "time_to_read": 11, "top_image_url": "https://miro.medium.com/v2/resize:fit:1000/0*0EQ1vH_CYS43q0Uh", "tags": {"clustering": {"item_id": "3890375205", "tag": "clustering"}, "machine-learning": {"item_id": "3890375205", "tag": "machine-learning"}}, "authors": {"144900013": {"item_id": "3890375205", "author_id": "144900013", "name": "Ivo Bernardo", "url": "https://ivopbernardo.medium.com"}}, "image": {"item_id": "3890375205", "src": "https://miro.medium.com/v2/resize:fill:88:88/2*OczqDN_cXCcFg4vCuWuREQ.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3890375205", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/2*OczqDN_cXCcFg4vCuWuREQ.png", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3890375205", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 958}, "2973890900": {"item_id": "2973890900", "resolved_id": "2973890900", "given_url": "https://juanitorduz.github.io/spectral_clustering/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1588727682", "time_updated": "1612385105", "time_read": "1588808459", "time_favorited": "0", "sort_id": 2, "resolved_title": "Getting Started with Spectral Clustering", "resolved_url": "https://juanitorduz.github.io/spectral_clustering/", "excerpt": "In this post I want to explore the ideas behind spectral clustering. I do not intend to develop the theory. Instead, I will unravel a practical example to illustrate and motivate the intuition behind each step of the spectral clustering algorithm. I particularly recommend two references:", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3003", "lang": "en", "time_to_read": 14, "tags": {"clustering": {"item_id": "2973890900", "tag": "clustering"}, "machine-learning": {"item_id": "2973890900", "tag": "machine-learning"}}, "image": {"item_id": "2973890900", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_6_0.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2973890900", "image_id": "1", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_6_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2973890900", "image_id": "2", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_10_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2973890900", "image_id": "3", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_12_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2973890900", "image_id": "4", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_14_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2973890900", "image_id": "5", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_17_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2973890900", "image_id": "6", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_29_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2973890900", "image_id": "7", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_31_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2973890900", "image_id": "8", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_37_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2973890900", "image_id": "9", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_42_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2973890900", "image_id": "10", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_45_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2973890900", "image_id": "11", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_47_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2973890900", "image_id": "12", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_53_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "2973890900", "image_id": "13", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_55_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "2973890900", "image_id": "14", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_57_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "2973890900", "image_id": "15", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_60_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "2973890900", "image_id": "16", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_62_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "2973890900", "image_id": "17", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_66_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "2973890900", "image_id": "18", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_68_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "2973890900", "image_id": "19", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_69_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "2973890900", "image_id": "20", "src": "https://juanitorduz.github.io/images/spectral_clustering_files/spectral_clustering_71_0.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1162}, "2111553096": {"item_id": "2111553096", "resolved_id": "2111553096", "given_url": "https://stepupanalytics.com/beginners-guide-to-statistical-cluster-analysis-in-detail-part-1/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1579958794", "time_updated": "1612385105", "time_read": "1582142665", "time_favorited": "0", "sort_id": 3, "resolved_title": "StepUp Analytics", "resolved_url": "https://www.stepupanalytics.com/beginners-guide-to-statistical-cluster-analysis-in-detail-part-1/", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"clustering": {"item_id": "2111553096", "tag": "clustering"}, "machine-learning": {"item_id": "2111553096", "tag": "machine-learning"}}, "listen_duration_estimate": 0}, "3588323542": {"item_id": "3588323542", "resolved_id": "3578818030", "given_url": "https://link.medium.com/ctsNVqOMVob", "given_title": "", "favorite": "0", "status": "1", "time_added": "1649006789", "time_updated": "1649451096", "time_read": "1649451096", "time_favorited": "0", "sort_id": 4, "resolved_title": "Louvain’s Algorithm for Community Detection in Python", "resolved_url": "https://towardsdatascience.com/louvains-algorithm-for-community-detection-in-python-95ff7f675306", "excerpt": "This article will cover the fundamental intuition behind community detection and Louvain’s algorithm. It will also showcase how to implement Louvain’s algorithm to a network of your choice using the NetworkX and Python-Louvaine module. The following is the structure of the article:", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1456", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/1200/1*SZO7fJFlgsoEptAYSmY0-w.png", "tags": {"clustering": {"item_id": "3588323542", "tag": "clustering"}, "machine-learning": {"item_id": "3588323542", "tag": "machine-learning"}, "python": {"item_id": "3588323542", "tag": "python"}}, "authors": {"146064079": {"item_id": "3588323542", "author_id": "146064079", "name": "Vatsal", "url": "https://vatsal12-p.medium.com"}}, "image": {"item_id": "3588323542", "src": "https://miro.medium.com/max/1400/1*SZO7fJFlgsoEptAYSmY0-w.png", "width": "700", "height": "383"}, "images": {"1": {"item_id": "3588323542", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*SZO7fJFlgsoEptAYSmY0-w.png", "width": "700", "height": "383", "credit": "", "caption": "Image taken by Ethan Unzicker from Unsplash"}, "2": {"item_id": "3588323542", "image_id": "2", "src": "https://miro.medium.com/max/1048/1*L6P9X1y82u7yEaFtV-Aw2g.png", "width": "524", "height": "120", "credit": "2", "caption": "Formula to calculate modularity on a weighted network. Image taken from Wikipedia"}, "3": {"item_id": "3588323542", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*GiYng_A_2x4g-s-yWRJv5Q.png", "width": "700", "height": "74", "credit": "2", "caption": "Image taken from Wikipedia"}, "4": {"item_id": "3588323542", "image_id": "4", "src": "https://miro.medium.com/max/800/1*ntpsTWUglfnFmjKxIQya6w.png", "width": "400", "height": "184", "credit": "", "caption": "Network statistics. Image provided by the author."}, "5": {"item_id": "3588323542", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*1N4eOVH1d1PZiLn-pSFprw.png", "width": "700", "height": "470", "credit": "", "caption": "How the randomly generated network looks. Image provided by the author."}, "6": {"item_id": "3588323542", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*4eSXqJYAhdBHyg_NXge0Hw.png", "width": "700", "height": "486", "credit": "", "caption": "Network with the nodes coloured by their corresponding communities. Image provided by the author."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 564}, "3707964870": {"item_id": "3707964870", "resolved_id": "3707964887", "given_url": "https://towardsdatascience.com/19-examples-of-merging-plots-to-maximize-your-clustering-scatter-plot-87e8f1bb5fd2?source=rss----7f60cf5620c9---4", "given_title": "19 Examples of Merging plots to Maximize your Clustering Scatter plot", "favorite": "0", "status": "1", "time_added": "1663777547", "time_updated": "1706656364", "time_read": "1665774173", "time_favorited": "0", "sort_id": 5, "resolved_title": "19 Examples of Merging plots to Maximize your Clustering Scatter plot", "resolved_url": "https://towardsdatascience.com/19-examples-of-merging-plots-to-maximize-your-clustering-scatter-plot-87e8f1bb5fd2", "excerpt": "I'm a big fan of superhero movies. Typically, many superheroes have extraordinary abilities, bodies, or powers. However, some superheroes are just ordinary guys, for example, Tony Stark (aka Iron man). The thing that makes him a superhero is the Iron man's armor.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1880", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/1200/1*Kt9znlQcR2oO3utt723N2w.jpeg", "tags": {"clustering": {"item_id": "3707964870", "tag": "clustering"}, "machine-learning": {"item_id": "3707964870", "tag": "machine-learning"}, "visualization": {"item_id": "3707964870", "tag": "visualization"}}, "authors": {"166324910": {"item_id": "3707964870", "author_id": "166324910", "name": "Boriharn K", "url": "https://medium.com/@borih.k"}}, "image": {"item_id": "3707964870", "src": "https://miro.medium.com/max/1400/1*Kt9znlQcR2oO3utt723N2w.jpeg", "width": "700", "height": "0"}, "images": {"1": {"item_id": "3707964870", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*Kt9znlQcR2oO3utt723N2w.jpeg", "width": "700", "height": "0", "credit": "Marjan Blan on Unsplash", "caption": ""}, "2": {"item_id": "3707964870", "image_id": "2", "src": "https://miro.medium.com/max/1802/1*a_pwWNgfb3fHn6C1tbWCJQ.png", "width": "463", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3707964870", "image_id": "3", "src": "https://miro.medium.com/max/1680/1*fOIEsRlq-0GSr50JxjK1Nw.png", "width": "538", "height": "0", "credit": "", "caption": "The first image is a basic scatter plot. The second image shows the result of merging the scatter plot with other plots to extract more information. Images by the author."}, "4": {"item_id": "3707964870", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*ktSFUsGcCHmGUPFTKGHn1g.png", "width": "700", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3707964870", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*P6BPtSJrYYRf5sdC5gg02w.png", "width": "700", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3707964870", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*AZnXtqfh-SR6-Nw326im2A.png", "width": "700", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3707964870", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*XHao-jRuQxZCQZbV2_F5gA.png", "width": "700", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3707964870", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*jTFZp_91R7J3vxK7zM6tOg.png", "width": "700", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3707964870", "image_id": "9", "src": "https://miro.medium.com/max/1334/1*LExaxaesCtGYKUsCXbZWmw.png", "width": "667", "height": "0", "credit": "", "caption": "Scatter plot showing results applying K-mean clustering to the dataset. Image by the author."}, "10": {"item_id": "3707964870", "image_id": "10", "src": "https://miro.medium.com/max/1230/1*awg35NuDG2OnqAueS2u-3A.png", "width": "334", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3707964870", "image_id": "11", "src": "https://miro.medium.com/max/1230/1*TxNsKWwH8DZrSw0seDFRmQ.png", "width": "334", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3707964870", "image_id": "12", "src": "https://miro.medium.com/max/1416/1*c7pzwAHIxdAx7w1DjWKglQ.png", "width": "334", "height": "0", "credit": "", "caption": "Scatter plots for use as a background or overlay. Images by the author."}, "13": {"item_id": "3707964870", "image_id": "13", "src": "https://miro.medium.com/max/1230/1*qx77Ued2dgQj0-bu5Hid0w.png", "width": "334", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "3707964870", "image_id": "14", "src": "https://miro.medium.com/max/1230/1*uFaB41CXTLO-6pLZ19NP0w.png", "width": "334", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "3707964870", "image_id": "15", "src": "https://miro.medium.com/max/1230/1*f2JhzIVyLrp6B6DX0y8rbA.png", "width": "334", "height": "0", "credit": "KDE", "caption": "Kernel Density Estimation"}, "16": {"item_id": "3707964870", "image_id": "16", "src": "https://miro.medium.com/max/1400/1*_2AtQcuCekHBNvWdjquF3A.png", "width": "700", "height": "0", "credit": "", "caption": "Hexbin plot with transparent background. Image by the author."}, "17": {"item_id": "3707964870", "image_id": "17", "src": "https://miro.medium.com/max/1400/1*kkTJcLwdV8aN973b907-Jg.png", "width": "700", "height": "0", "credit": "", "caption": "Hexbin plot with transparent background and marginal axes. Images by the author."}, "18": {"item_id": "3707964870", "image_id": "18", "src": "https://miro.medium.com/max/1230/1*ks5_GEJiZ_MJTaN_l9N10w.png", "width": "500", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "3707964870", "image_id": "19", "src": "https://miro.medium.com/max/1416/1*P0pRfLNb_8MDreMvCkfHEw.png", "width": "500", "height": "0", "credit": "", "caption": "The first image: line plots connecting data points to centroids and average lines. The second image: the first image with marginal axes. Images by the author."}, "20": {"item_id": "3707964870", "image_id": "20", "src": "https://miro.medium.com/max/1230/1*Qoa8xG2Kdkb-d5nqBabRJg.png", "width": "500", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "3707964870", "image_id": "21", "src": "https://miro.medium.com/max/1416/1*0O4kGM6eCaa7Rd_eagUJ5g.png", "width": "500", "height": "0", "credit": "", "caption": "The first image is a regression plot with transparent background. The second image is the first image with marginal axes. Images by the author."}, "22": {"item_id": "3707964870", "image_id": "22", "src": "https://miro.medium.com/max/1400/1*ovoEiqSa8i1SLLj07XwISA.png", "width": "700", "height": "0", "credit": "", "caption": "scatter plot + KDE plot"}, "23": {"item_id": "3707964870", "image_id": "23", "src": "https://miro.medium.com/max/1400/1*FxvAEjGmT_pvlll4voTR1A.png", "width": "700", "height": "0", "credit": "", "caption": "scatter plot + hexbin plot"}, "24": {"item_id": "3707964870", "image_id": "24", "src": "https://miro.medium.com/max/1400/1*mos87cYMWeEjsOb0YQhMrw.png", "width": "700", "height": "0", "credit": "", "caption": "scatter plot + regression plot"}, "25": {"item_id": "3707964870", "image_id": "25", "src": "https://miro.medium.com/max/1400/1*B9e9hyksL63sRLuj93MnBQ.png", "width": "700", "height": "0", "credit": "", "caption": "joint scatter plot + KDE plot"}, "26": {"item_id": "3707964870", "image_id": "26", "src": "https://miro.medium.com/max/1400/1*xHgBIPfVSE8N7oVn5IQqGg.png", "width": "700", "height": "0", "credit": "", "caption": "joint scatter plot + hexbin plot"}, "27": {"item_id": "3707964870", "image_id": "27", "src": "https://miro.medium.com/max/1400/1*WtT3pG7Q8zkzz6JvH3P8uA.png", "width": "700", "height": "0", "credit": "", "caption": "joint scatter plot + line plot"}, "28": {"item_id": "3707964870", "image_id": "28", "src": "https://miro.medium.com/max/1400/1*Ndm0tPBiBk8TaY_6xzBbHg.png", "width": "700", "height": "0", "credit": "", "caption": "joint scatter plot + regression plot"}, "29": {"item_id": "3707964870", "image_id": "29", "src": "https://miro.medium.com/max/1400/1*mMwp0bUoNjuzEqGhQCAjKg.png", "width": "700", "height": "0", "credit": "", "caption": "joint scatter plot + KDE plot + hexbin plot"}, "30": {"item_id": "3707964870", "image_id": "30", "src": "https://miro.medium.com/max/1400/1*lRSE5H63eJ4M52ixQRswoQ.png", "width": "700", "height": "0", "credit": "", "caption": "joint scatter plot + KDE plot + regression plot"}, "31": {"item_id": "3707964870", "image_id": "31", "src": "https://miro.medium.com/max/1400/1*EX9k58cTCW4Ljv_qMvvpmg.png", "width": "700", "height": "0", "credit": "", "caption": "joint scatter plot + KDE plot + line plot"}, "32": {"item_id": "3707964870", "image_id": "32", "src": "https://miro.medium.com/max/1400/1*7dIBHpxbRFwjSq50TivCmA.png", "width": "700", "height": "0", "credit": "", "caption": "joint scatter plot + hexbin plot + regression plot"}, "33": {"item_id": "3707964870", "image_id": "33", "src": "https://miro.medium.com/max/1400/1*g6_4IaE2do6EUOIiS-Zqmg.png", "width": "700", "height": "0", "credit": "", "caption": "joint scatter plot + hexbin plot + line plot"}, "34": {"item_id": "3707964870", "image_id": "34", "src": "https://miro.medium.com/max/1400/1*jGNfSqAT-Tu8KQlZtcDUQw.png", "width": "700", "height": "0", "credit": "", "caption": "joint scatter plot + regression plot + line plot"}, "35": {"item_id": "3707964870", "image_id": "35", "src": "https://miro.medium.com/max/1400/1*scSVRjaq3ZLd4XE2usIxtQ.png", "width": "700", "height": "0", "credit": "", "caption": "joint scatter plot + KDE plot + hexbin plot + line plot"}, "36": {"item_id": "3707964870", "image_id": "36", "src": "https://miro.medium.com/max/1400/1*RpFCfgUvkc1adjRHksD-dA.png", "width": "700", "height": "0", "credit": "", "caption": "joint scatter plot + KDE plot + hexbin plot + regression plot"}, "37": {"item_id": "3707964870", "image_id": "37", "src": "https://miro.medium.com/max/1400/1*Fai6z82674ZB30WA49qspA.png", "width": "700", "height": "0", "credit": "", "caption": "joint scatter plot + hexbin plot + regression plot + line plot"}, "38": {"item_id": "3707964870", "image_id": "38", "src": "https://miro.medium.com/max/1400/1*SsD5AV-Rnd8L8mgIL_Q2Mg.png", "width": "700", "height": "0", "credit": "", "caption": "joint scatter plot + KDE plot + regression plot + line plot"}, "39": {"item_id": "3707964870", "image_id": "39", "src": "https://miro.medium.com/max/1400/1*QYnwVytalQyp5WVv9DvOaA.png", "width": "700", "height": "0", "credit": "", "caption": "joint scatter plot + KDE plot + hexbin plot + line plot + regression plot"}, "40": {"item_id": "3707964870", "image_id": "40", "src": "https://miro.medium.com/max/1400/1*sKDxq13ueIZOQjTu8RWPxg.png", "width": "700", "height": "0", "credit": "with no fill color", "caption": "joint scatter plot + KDE plot + hexbin plot + line plot"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 728}, "3899425940": {"item_id": "3899425940", "resolved_id": "3899425940", "given_url": "https://www.r-bloggers.com/2023/07/a-gentle-introduction-to-k-means-clustering-in-r-feat-tidyclust/", "given_title": "A Gentle Introduction to K-Means Clustering in R (Feat. Tidyclust)", "favorite": "0", "status": "1", "time_added": "1688670266", "time_updated": "1688725598", "time_read": "1688725598", "time_favorited": "0", "sort_id": 6, "resolved_title": "A Gentle Introduction to K-Means Clustering in R (Feat. Tidyclust)", "resolved_url": "https://www.r-bloggers.com/2023/07/a-gentle-introduction-to-k-means-clustering-in-r-feat-tidyclust/", "excerpt": "To be successful as a Data Scientist, you’re often put in positions where you need to find groups within your data. One key business use-case is finding clusters of customers that behave similarly.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "1641", "lang": "en", "time_to_read": 7, "amp_url": "https://www.r-bloggers.com/2023/07/a-gentle-introduction-to-k-means-clustering-in-r-feat-tidyclust/amp/", "top_image_url": "https://www.business-science.io/assets/063_tidyclust_thumb.jpg", "tags": {"clustering": {"item_id": "3899425940", "tag": "clustering"}, "machine-learning": {"item_id": "3899425940", "tag": "machine-learning"}, "_r_": {"item_id": "3899425940", "tag": "_r_"}}, "authors": {"115572003": {"item_id": "3899425940", "author_id": "115572003", "name": "Business Science", "url": "https://www.r-bloggers.com/author/business-science/"}}, "image": {"item_id": "3899425940", "src": "http://img.youtube.com/vi/QYcrjrwKswc/0.jpg", "width": "480", "height": "360"}, "images": {"1": {"item_id": "3899425940", "image_id": "1", "src": "http://img.youtube.com/vi/QYcrjrwKswc/0.jpg", "width": "480", "height": "360", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "3899425940", "video_id": "1", "src": "https://www.youtube.com/embed/QYcrjrwKswc", "width": "450", "height": "450", "type": "1", "vid": "QYcrjrwKswc", "length": "0"}}, "domain_metadata": {"name": "R-bloggers", "logo": "https://logo.clearbit.com/r-bloggers.com?size=800", "greyscale_logo": "https://logo.clearbit.com/r-bloggers.com?size=800&greyscale=true"}, "listen_duration_estimate": 635}, "3673792527": {"item_id": "3673792527", "resolved_id": "3673792539", "given_url": "https://towardsdatascience.com/an-introduction-to-graph-partitioning-algorithms-and-community-detection-29e7c962d10e?source=rss----7f60cf5620c9---4", "given_title": "An Introduction to Graph Partitioning Algorithms and Community Detection", "favorite": "0", "status": "1", "time_added": "1659528720", "time_updated": "1659653800", "time_read": "1659653801", "time_favorited": "0", "sort_id": 7, "resolved_title": "An Introduction to Graph Partitioning Algorithms and Community Detection", "resolved_url": "https://towardsdatascience.com/an-introduction-to-graph-partitioning-algorithms-and-community-detection-29e7c962d10e", "excerpt": "Graph partitioning has been a long-lasting problem and has a wide range of applications. This post shares the methodology for graph partitioning with both theoretical explanations and practical implementations of some popular graph partitioning algorithms with python codes.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1909", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/1200/0*arWl57BFDl1ke9Rk", "tags": {"clustering": {"item_id": "3673792527", "tag": "clustering"}, "graphs": {"item_id": "3673792527", "tag": "graphs"}, "machine-learning": {"item_id": "3673792527", "tag": "machine-learning"}, "python": {"item_id": "3673792527", "tag": "python"}}, "authors": {"149804591": {"item_id": "3673792527", "author_id": "149804591", "name": "Shanon Hong", "url": "https://hongxuenong.medium.com"}}, "image": {"item_id": "3673792527", "src": "https://miro.medium.com/max/1400/0*arWl57BFDl1ke9Rk", "width": "700", "height": "394"}, "images": {"1": {"item_id": "3673792527", "image_id": "1", "src": "https://miro.medium.com/max/1400/0*arWl57BFDl1ke9Rk", "width": "700", "height": "394", "credit": "D koi on Unsplash", "caption": ""}, "2": {"item_id": "3673792527", "image_id": "2", "src": "https://miro.medium.com/max/1176/1*QICWN4C8vWMtSq9atWMvYQ.png", "width": "588", "height": "301", "credit": "", "caption": "Simple Illustration of Cut. Image by Author"}, "3": {"item_id": "3673792527", "image_id": "3", "src": "https://miro.medium.com/max/694/1*sSD0IFXXN9F7Af09zsOerA.png", "width": "347", "height": "56", "credit": "", "caption": ""}, "4": {"item_id": "3673792527", "image_id": "4", "src": "https://miro.medium.com/max/1078/1*NGHOKfNvBh-rQMTyi4DA7g.png", "width": "539", "height": "340", "credit": "1", "caption": "An example of trivial solutions by min-cut. Figure from"}, "5": {"item_id": "3673792527", "image_id": "5", "src": "https://miro.medium.com/max/876/1*H5wKwXrz2z5Dc98YtZgzAQ.png", "width": "438", "height": "118", "credit": "", "caption": ""}, "6": {"item_id": "3673792527", "image_id": "6", "src": "https://miro.medium.com/max/1128/1*PHEpXSPmf_zqD_4WG7IIOw.png", "width": "564", "height": "138", "credit": "", "caption": ""}, "7": {"item_id": "3673792527", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*ym5KuCEgmN9SzQaUlG5qCQ.png", "width": "700", "height": "280", "credit": "", "caption": "Graph with two connected components. Image by Author"}, "8": {"item_id": "3673792527", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*8p5BQqnFOzbc-MhfSIcS5A.png", "width": "700", "height": "283", "credit": "", "caption": "Graph with one connected component. Image by Author"}, "9": {"item_id": "3673792527", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*6O5CtSi5Cl2W-J6TJvTerA.png", "width": "700", "height": "275", "credit": "", "caption": "Graph with three natural clusters. Image by Author"}, "10": {"item_id": "3673792527", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*2aFmkZLewXSrJQV4aQtusw.png", "width": "700", "height": "255", "credit": "", "caption": "Illustration of clustering on eigenvectors. Image by Author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 739}, "2743596867": {"item_id": "2743596867", "resolved_id": "2743596899", "given_url": "https://www.kdnuggets.com/2019/10/clustering-metrics-better-elbow-method.html", "given_title": "Clustering Metrics Better Than the Elbow Method", "favorite": "0", "status": "1", "time_added": "1569934848", "time_updated": "1612385105", "time_read": "1576355220", "time_favorited": "0", "sort_id": 8, "resolved_title": "Clustering Metrics Better Than the Elbow Method", "resolved_url": "https://www.kdnuggets.com/clustering-metrics-better-than-the-elbow-method.html", "excerpt": "We show what metric to use for visualizing and determining an optimal number of clusters much better than the usual practice — elbow method. Clustering is an important part of the machine learning pipeline for business or scientific enterprises utilizing data science.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "1262", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/602/1*2MKKujl2jG7DLoZ6O-mK9w.png", "tags": {"clustering": {"item_id": "2743596867", "tag": "clustering"}, "machine-learning": {"item_id": "2743596867", "tag": "machine-learning"}}, "authors": {"113019713": {"item_id": "2743596867", "author_id": "113019713", "name": "Tirthajyoti Sarkar", "url": "https://www.kdnuggets.com/author/tirthajyoti-sarkar"}}, "image": {"item_id": "2743596867", "src": "http://img.youtube.com/vi/5TPldC_dC0s/0.jpg", "width": "480", "height": "360"}, "images": {"1": {"item_id": "2743596867", "image_id": "1", "src": "http://img.youtube.com/vi/5TPldC_dC0s/0.jpg", "width": "480", "height": "360", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "2743596867", "video_id": "1", "src": "https://www.youtube.com/embed/5TPldC_dC0s?list=PLmNPvQr9Tf-ZSDLwOzxpvY-HrE0yv-8Fy", "width": "665", "height": "382", "type": "1", "vid": "5TPldC_dC0s", "length": "0"}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 489}, "3080576151": {"item_id": "3080576151", "resolved_id": "3080576167", "given_url": "https://towardsdatascience.com/clustering-using-convex-hulls-fddafeaa963c?source=rss----7f60cf5620c9---4", "given_title": "Clustering Using Convex Hulls", "favorite": "0", "status": "1", "time_added": "1597484990", "time_updated": "1612385105", "time_read": "1607569787", "time_favorited": "0", "sort_id": 9, "resolved_title": "Clustering Using Convex Hulls", "resolved_url": "https://towardsdatascience.com/clustering-using-convex-hulls-fddafeaa963c", "excerpt": "I recently came across the article titled High-dimensional data clustering by using local affine/convex hulls by Hakan Cevikalp in Pattern Recognition Letters. It proposes a novel algorithm to cluster high-dimensional data using local affine/convex hulls.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1524", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/1200/1*THA9SlnZEM5pl7xnnlsFrw.png", "tags": {"clustering": {"item_id": "3080576151", "tag": "clustering"}, "machine-learning": {"item_id": "3080576151", "tag": "machine-learning"}}, "authors": {"143178758": {"item_id": "3080576151", "author_id": "143178758", "name": "Vijini Mallawaarachchi", "url": "https://vijini.medium.com"}}, "image": {"item_id": "3080576151", "src": "https://miro.medium.com/fit/c/56/56/2*pTTsurl-IeDfoG86mmVGQQ.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3080576151", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*pTTsurl-IeDfoG86mmVGQQ.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3080576151", "image_id": "2", "src": "https://miro.medium.com/max/1000/1*rk8DDgeMACxJSXtdFs0ysg.png", "width": "500", "height": "456", "credit": "Image by Author", "caption": "Fig 1. The convex hull of a set of nails"}, "3": {"item_id": "3080576151", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*woTl_QjdCRfv2odzEyZwCg.png", "width": "700", "height": "459", "credit": "Image by Author", "caption": "Fig 2. Initial scatter plot of the dataset"}, "4": {"item_id": "3080576151", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*uaQEBEUnxfWc6P57P0OzUQ.png", "width": "700", "height": "459", "credit": "Image by Author", "caption": "Fig 3. Initial clustering of the seed points using K-means"}, "5": {"item_id": "3080576151", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*_GsDEJwOqqbuGxeViZU8Qw.png", "width": "700", "height": "459", "credit": "Image by Author", "caption": "Fig 4. Convex hulls of each cluster"}, "6": {"item_id": "3080576151", "image_id": "6", "src": "https://miro.medium.com/max/1000/1*V4RGFsuR9XYdgNX3cji-UA.png", "width": "500", "height": "354", "credit": "Image by Author", "caption": "Fig 5. The distance from a point to its projection on to a convex hull"}, "7": {"item_id": "3080576151", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*THA9SlnZEM5pl7xnnlsFrw.png", "width": "700", "height": "459", "credit": "Image by Author", "caption": "Fig 6. Final result with convex hulls"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 590}, "1099830301": {"item_id": "1099830301", "resolved_id": "1099830301", "given_url": "https://github.com/CoAxLab/DeBaCl", "given_title": "CoAxLab/DeBaCl: Density Based Clustering (DeBaCl) Toolbox", "favorite": "1", "status": "1", "time_added": "1707438194", "time_updated": "1707528025", "time_read": "1707528025", "time_favorited": "1448837553", "sort_id": 10, "resolved_title": "DeBaCl: DEnsity-BAsed CLustering", "resolved_url": "https://github.com/CoAxLab/DeBaCl", "excerpt": "DeBaCl is a Python library for density-based clustering with level set trees. Level set trees are a statistically-principled way to represent the topology of a probability density function. This representation is particularly useful for several core tasks in statistics:", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "519", "lang": "en", "top_image_url": "https://opengraph.githubassets.com/f84fdf4e2a1680183e79a638acf927fc0934dc8ff1341697b474c4a4f5170d9c/CoAxLab/DeBaCl", "tags": {"clustering": {"item_id": "1099830301", "tag": "clustering"}}, "image": {"item_id": "1099830301", "src": "https://camo.githubusercontent.com/81e798343ab741a838a7cffb0f0a2b26cfe6bda1d978f8a9ea0dd4aeb09661c2/68747470733a2f2f7472617669732d63692e6f72672f436f41784c61622f44654261436c2e7376673f6272616e63683d646576", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1099830301", "image_id": "1", "src": "https://camo.githubusercontent.com/81e798343ab741a838a7cffb0f0a2b26cfe6bda1d978f8a9ea0dd4aeb09661c2/68747470733a2f2f7472617669732d63692e6f72672f436f41784c61622f44654261436c2e7376673f6272616e63683d646576", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1099830301", "image_id": "2", "src": "https://camo.githubusercontent.com/1b24d5b15a3b31e578cb9aaf421f535833b8c099cde35cacebb9b432c8473a77/687474703a2f2f6769746875626261646765732e6865726f6b756170702e636f6d2f436f41784c61622f44654261436c2f70756c6c73", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "1099830301", "image_id": "3", "src": "https://camo.githubusercontent.com/adae85fd311264dd7cf86b1cae0c2ab32c272dc70f162b7b8eb38d8ca9c0980d/687474703a2f2f6769746875626261646765732e6865726f6b756170702e636f6d2f436f41784c61622f44654261436c2f697373756573", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "1099830301", "image_id": "4", "src": "https://camo.githubusercontent.com/c71d568cfe54b661a81d4cef89ba54b60038a3421597d4530918237eb5cfc6b1/687474703a2f2f696d672e736869656c64732e696f2f3a6c6963656e73652d6273642d626c75652e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "1099830301", "image_id": "5", "src": "https://camo.githubusercontent.com/13b35d1db0e1109febc53e49a3663792a0b66cc042fe9155e9f734916a3bfc96/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f64656261636c2f62616467652f3f76657273696f6e3d6d6173746572", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "1099830301", "image_id": "6", "src": "https://github.com/CoAxLab/DeBaCl/blob/master/docs/readme_tree.png", "width": "0", "height": "480", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 201}, "3137784929": {"item_id": "3137784929", "resolved_id": "3137784942", "given_url": "https://towardsdatascience.com/dbscan-a-density-based-unsupervised-algorithm-for-fraud-detection-887c0f1016e9?source=rss----7f60cf5620c9---4", "given_title": "DBSCAN — a density-based unsupervised algorithm for fraud detection", "favorite": "0", "status": "1", "time_added": "1602337427", "time_updated": "1612385105", "time_read": "1602372674", "time_favorited": "0", "sort_id": 11, "resolved_title": "DBSCAN — a density-based unsupervised algorithm for fraud detection", "resolved_url": "https://towardsdatascience.com/dbscan-a-density-based-unsupervised-algorithm-for-fraud-detection-887c0f1016e9", "excerpt": "According to a recent report financial losses due to fraudulent transactions have reached about $17 billion USD, with as many as 5% of consumers experiencing fraud incidents of some kind. In light of such a big volume of financial losses, every industry is taking fraud detection seriously.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "550", "lang": "en", "time_to_read": 3, "top_image_url": "https://miro.medium.com/max/1200/0*wj-K6Wb02-RIrGJh", "tags": {"clustering": {"item_id": "3137784929", "tag": "clustering"}, "machine-learning": {"item_id": "3137784929", "tag": "machine-learning"}}, "authors": {"143047002": {"item_id": "3137784929", "author_id": "143047002", "name": "Mahbubul Alam", "url": "https://mab-datasc.medium.com"}}, "image": {"item_id": "3137784929", "src": "https://miro.medium.com/max/2000/0*wj-K6Wb02-RIrGJh", "width": "1000", "height": "750"}, "images": {"1": {"item_id": "3137784929", "image_id": "1", "src": "https://miro.medium.com/max/2000/0*wj-K6Wb02-RIrGJh", "width": "1000", "height": "750", "credit": "Patrick Tomasso on Unsplash", "caption": ""}, "2": {"item_id": "3137784929", "image_id": "2", "src": "https://miro.medium.com/fit/c/56/56/1*KtWIx0Sw5cHXBb4GeQiJBg.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "3": {"item_id": "3137784929", "image_id": "3", "src": "https://miro.medium.com/max/972/1*SLX7NbUKbE4i7UNJnDTtNQ.png", "width": "486", "height": "117", "credit": "", "caption": ""}, "4": {"item_id": "3137784929", "image_id": "4", "src": "https://miro.medium.com/max/788/1*eRPIfGmXi7eGNsqIF3aoRg.png", "width": "394", "height": "264", "credit": "", "caption": "Scatterplot of two-dimensional data"}, "5": {"item_id": "3137784929", "image_id": "5", "src": "https://miro.medium.com/max/780/1*FgxV2V8uqz9KBjjwHTW_yg.png", "width": "390", "height": "265", "credit": "", "caption": "Outlier values detected in purple color"}, "6": {"item_id": "3137784929", "image_id": "6", "src": "https://miro.medium.com/max/512/1*4sRTWzVoWbz0yUCNeSPB-g.png", "width": "256", "height": "195", "credit": "", "caption": "Dataframe of outliers"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 213}, "3759979171": {"item_id": "3759979171", "resolved_id": "3759979171", "given_url": "https://towardsdatascience.com/density-based-clustering-dbscan-vs-hdbscan-39e02af990c7", "given_title": "Density-Based Clustering: DBSCAN vs. HDBSCAN", "favorite": "0", "status": "1", "time_added": "1670276382", "time_updated": "1670276625", "time_read": "1670276625", "time_favorited": "0", "sort_id": 12, "resolved_title": "Density-Based Clustering: DBSCAN vs. HDBSCAN", "resolved_url": "https://towardsdatascience.com/density-based-clustering-dbscan-vs-hdbscan-39e02af990c7", "excerpt": "Cluster Analysis is a pertinent domain in data science that enables the grouping of similar objects into distinct subgroups. While there are different families of clustering algorithms, the most widely known is K-Means.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1017", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/1*32QG4MjNBvhoXHVxCE85_A.jpeg", "tags": {"clustering": {"item_id": "3759979171", "tag": "clustering"}, "machine-learning": {"item_id": "3759979171", "tag": "machine-learning"}}, "authors": {"145560853": {"item_id": "3759979171", "author_id": "145560853", "name": "Thomas A Dorfer", "url": "https://thomasdorfer.medium.com"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 394}, "3148206024": {"item_id": "3148206024", "resolved_id": "3148206042", "given_url": "https://towardsdatascience.com/handling-outliers-in-clusters-using-silhouette-analysis-5a7d51118dac?source=rss----7f60cf5620c9---4", "given_title": "Handling Outliers in Clusters using Silhouette Analysis", "favorite": "0", "status": "1", "time_added": "1603281316", "time_updated": "1612385105", "time_read": "1604360669", "time_favorited": "0", "sort_id": 13, "resolved_title": "Handling Outliers in Clusters using Silhouette Analysis", "resolved_url": "https://towardsdatascience.com/handling-outliers-in-clusters-using-silhouette-analysis-5a7d51118dac", "excerpt": "The real-world data often has a lot of outlier values. The cause of outliers can be data corruption or failure to record data. The handling of outliers is very important during the data preprocessing pipeline as the presence of outliers can prevent the model to perform best.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "625", "lang": "en", "time_to_read": 3, "top_image_url": "https://miro.medium.com/max/1200/1*chza-aot9rDFie3H8bZQJA.jpeg", "tags": {"clustering": {"item_id": "3148206024", "tag": "clustering"}, "machine-learning": {"item_id": "3148206024", "tag": "machine-learning"}}, "authors": {"143943089": {"item_id": "3148206024", "author_id": "143943089", "name": "Satyam Kumar", "url": "https://satyam-kumar.medium.com"}}, "image": {"item_id": "3148206024", "src": "https://miro.medium.com/fit/c/56/56/1*rvyM1yFu5JbnOueKTiWweQ.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3148206024", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*rvyM1yFu5JbnOueKTiWweQ.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3148206024", "image_id": "2", "src": "https://miro.medium.com/max/1280/1*E7XSHnwqxpuEqav5okZovg.png", "width": "640", "height": "426", "credit": "", "caption": "Image by Gerd Altmann from Pixabay"}, "3": {"item_id": "3148206024", "image_id": "3", "src": "https://miro.medium.com/max/456/0*TjZyK0cT1GFbseNB.png", "width": "228", "height": "56", "credit": "", "caption": ""}, "4": {"item_id": "3148206024", "image_id": "4", "src": "https://miro.medium.com/max/902/0*rIN3QMUESXIks3GM.png", "width": "451", "height": "330", "credit": "Image by Author", "caption": ""}, "5": {"item_id": "3148206024", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*3q4HWWqGxWVjKyRzgOv3Vw.jpeg", "width": "700", "height": "252", "credit": "Image by Author", "caption": ""}, "6": {"item_id": "3148206024", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*chza-aot9rDFie3H8bZQJA.jpeg", "width": "700", "height": "1686", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 242}, "3140253273": {"item_id": "3140253273", "resolved_id": "3140253289", "given_url": "https://towardsdatascience.com/how-to-cluster-images-based-on-visual-similarity-cd6e7209fe34?source=rss----7f60cf5620c9---4", "given_title": "How to cluster images based on visual similarity", "favorite": "0", "status": "1", "time_added": "1602586790", "time_updated": "1638708525", "time_read": "1604361156", "time_favorited": "0", "sort_id": 14, "resolved_title": "How to cluster images based on visual similarity", "resolved_url": "https://towardsdatascience.com/how-to-cluster-images-based-on-visual-similarity-cd6e7209fe34", "excerpt": "In this tutorial, I'm going to walk you through using a pre-trained neural network to extract a feature vector from images and cluster the images based on how similar the feature vectors are.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1062", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/0*RARg2hIOV2DCGO-h", "tags": {"clustering": {"item_id": "3140253273", "tag": "clustering"}, "deep-learning": {"item_id": "3140253273", "tag": "deep-learning"}, "vision": {"item_id": "3140253273", "tag": "vision"}}, "authors": {"140656943": {"item_id": "3140253273", "author_id": "140656943", "name": "Gabe Flomo", "url": "https://medium.com/@gabeflomo821"}}, "image": {"item_id": "3140253273", "src": "https://miro.medium.com/fit/c/56/56/2*i_XHzhbfOqybNBQmvtK30g.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3140253273", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*i_XHzhbfOqybNBQmvtK30g.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3140253273", "image_id": "2", "src": "https://miro.medium.com/max/2000/0*RARg2hIOV2DCGO-h", "width": "1000", "height": "667", "credit": "Pietro Jeng on Unsplash", "caption": ""}, "3": {"item_id": "3140253273", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*xIIBn2Yajg4naTqJif7q1w.png", "width": "700", "height": "134", "credit": "", "caption": ""}, "4": {"item_id": "3140253273", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*wiGcYoDls0bInqoq8ixPqA.png", "width": "700", "height": "202", "credit": "", "caption": ""}, "5": {"item_id": "3140253273", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*cHlZ4tJp91n5DODlS-oZXQ.png", "width": "700", "height": "72", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 411}, "3926638911": {"item_id": "3926638911", "resolved_id": "3926638922", "given_url": "https://towardsdatascience.com/how-to-implement-hierarchical-clustering-for-direct-marketing-campaigns-with-python-code-ef897f52d1c5?source=rss----7f60cf5620c9---4", "given_title": "How to Implement Hierarchical Clustering for Direct Marketing Campaigns— wi", "favorite": "0", "status": "1", "time_added": "1693245798", "time_updated": "1693251258", "time_read": "1693251258", "time_favorited": "0", "sort_id": 15, "resolved_title": "How to Implement Hierarchical Clustering for Direct Marketing Campaigns", "resolved_url": "https://towardsdatascience.com/how-to-implement-hierarchical-clustering-for-direct-marketing-campaigns-with-python-code-ef897f52d1c5", "excerpt": "Imagine being a Data Scientist at a leading financial institution, and your task is to assist your team in categorizing existing clients into distinct profiles:low , average , medium and platinum for loan approval.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "254", "lang": "en", "top_image_url": "https://miro.medium.com/v2/resize:fit:1000/0*SY9vggAPaLBYEdiM", "tags": {"clustering": {"item_id": "3926638911", "tag": "clustering"}, "prodmgmt": {"item_id": "3926638911", "tag": "prodmgmt"}}, "authors": {"147066353": {"item_id": "3926638911", "author_id": "147066353", "name": "Zoumana Keita", "url": "https://zoumanakeita.medium.com"}}, "image": {"item_id": "3926638911", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*Se9SLHlvVxMoYooDaI91uA.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3926638911", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*Se9SLHlvVxMoYooDaI91uA.png", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3926638911", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 98}, "3806934566": {"item_id": "3806934566", "resolved_id": "3806934584", "given_url": "https://towardsdatascience.com/how-to-improve-clustering-accuracy-with-bayesian-gaussian-mixture-models-2ef8bb2d603f?source=rss----7f60cf5620c9---4", "given_title": "How to Improve Clustering Accuracy with Bayesian Gaussian Mixture Models", "favorite": "0", "status": "1", "time_added": "1676464474", "time_updated": "1676493823", "time_read": "1676493823", "time_favorited": "0", "sort_id": 16, "resolved_title": "How to Improve Clustering Accuracy with Bayesian Gaussian Mixture Models", "resolved_url": "https://towardsdatascience.com/how-to-improve-clustering-accuracy-with-bayesian-gaussian-mixture-models-2ef8bb2d603f", "excerpt": "In the real world you will often find that data follows a certain probability distribution. Whether it is a Gaussian (or normal) distribution, Weibull distribution, Poisson distribution, exponential distribution etc., will depend on the specific data.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "6607", "lang": "en", "time_to_read": 30, "top_image_url": "https://miro.medium.com/max/1200/1*FQGPsq4zoCvdZ0LOqpry4g.jpeg", "tags": {"clustering": {"item_id": "3806934566", "tag": "clustering"}, "gaussian": {"item_id": "3806934566", "tag": "gaussian"}, "machine-learning": {"item_id": "3806934566", "tag": "machine-learning"}}, "authors": {"170737472": {"item_id": "3806934566", "author_id": "170737472", "name": "Mike Clayton", "url": "https://medium.com/@maclayton"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 2558}, "2927519098": {"item_id": "2927519098", "resolved_id": "2927506869", "given_url": "https://towardsdatascience.com/how-to-use-dbscan-effectively-ed212c02e62?source=rss----7f60cf5620c9---4", "given_title": "How to Use DBSCAN Effectively", "favorite": "0", "status": "1", "time_added": "1585145351", "time_updated": "1612385105", "time_read": "1585715069", "time_favorited": "0", "sort_id": 17, "resolved_title": "How to Use DBSCAN Effectively", "resolved_url": "https://towardsdatascience.com/how-to-use-dbscan-effectively-ed212c02e62", "excerpt": "DBSCAN is an extremely powerful clustering algorithm. The acronym stands for Density-based Spatial Clustering of Applications with Noise. As the name suggests, the algorithm uses density to gather points in space to form clusters. The algorithm can be very fast once it is properly implemented.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1162", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/1*Zj0qAtMDenWQg2LMrJyFxw.png", "tags": {"clustering": {"item_id": "2927519098", "tag": "clustering"}, "machine-learning": {"item_id": "2927519098", "tag": "machine-learning"}}, "authors": {"143178758": {"item_id": "2927519098", "author_id": "143178758", "name": "Vijini Mallawaarachchi", "url": "https://vijini.medium.com"}}, "image": {"item_id": "2927519098", "src": "https://miro.medium.com/fit/c/56/56/2*pTTsurl-IeDfoG86mmVGQQ.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2927519098", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*pTTsurl-IeDfoG86mmVGQQ.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2927519098", "image_id": "2", "src": "https://miro.medium.com/max/3000/1*TKTPIW8zH6ztYr_xx0beGA.png", "width": "1500", "height": "1500", "credit": "", "caption": "Fig 1. Visualization of original clusters"}, "3": {"item_id": "2927519098", "image_id": "3", "src": "https://miro.medium.com/max/3000/1*LtxOKx0xeNiblnCuVOFJDQ.png", "width": "1500", "height": "1500", "credit": "", "caption": "Fig 2. DBSCAN with eps=0.5"}, "4": {"item_id": "2927519098", "image_id": "4", "src": "https://miro.medium.com/max/12000/1*Zj0qAtMDenWQg2LMrJyFxw.png", "width": "6000", "height": "3000", "credit": "", "caption": "Fig 3. DBSCAN at varying eps values"}, "5": {"item_id": "2927519098", "image_id": "5", "src": "https://miro.medium.com/max/3000/1*l5Bpk-lnIYf3u2BM_Ti75w.png", "width": "1500", "height": "1500", "credit": "", "caption": "Distance variation at the 10th neighbour"}, "6": {"item_id": "2927519098", "image_id": "6", "src": "https://miro.medium.com/max/3600/1*09FRSSndDp4ohnjhZ2UIdw.png", "width": "1800", "height": "1800", "credit": "", "caption": "The plot of Knee Point"}, "7": {"item_id": "2927519098", "image_id": "7", "src": "https://miro.medium.com/max/3000/1*0kZQew8VPzXW49gEDxY5XQ.png", "width": "1500", "height": "1500", "credit": "", "caption": "DBSCAN with Auto-detected Eps"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 450}, "3703769052": {"item_id": "3703769052", "resolved_id": "3703769052", "given_url": "https://towardsdatascience.com/introduction-to-embedding-clustering-and-similarity-11dd80b00061", "given_title": "Introduction to Embedding, Clustering, and Similarity", "favorite": "0", "status": "1", "time_added": "1663269182", "time_updated": "1673901753", "time_read": "1663289992", "time_favorited": "0", "sort_id": 18, "resolved_title": "Introduction to Embedding, Clustering, and Similarity", "resolved_url": "https://towardsdatascience.com/introduction-to-embedding-clustering-and-similarity-11dd80b00061", "excerpt": "In this post, we give a general introduction to embedding, similarity, and clustering, which are the basics to most ML and essential to understanding the Latent Space.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3024", "lang": "en", "time_to_read": 14, "top_image_url": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*aKGHxGmlyyA1kO6y", "tags": {"autoencoders": {"item_id": "3703769052", "tag": "autoencoders"}, "clustering": {"item_id": "3703769052", "tag": "clustering"}, "machine-learning": {"item_id": "3703769052", "tag": "machine-learning"}, "model-compression": {"item_id": "3703769052", "tag": "model-compression"}}, "authors": {"172289546": {"item_id": "3703769052", "author_id": "172289546", "name": "Mathias Grønne", "url": "https://medium.com/@mathiasgronne"}}, "image": {"item_id": "3703769052", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*0Ju5M1MDffvgQOdLkL-yLA.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3703769052", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*0Ju5M1MDffvgQOdLkL-yLA.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3703769052", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1171}, "3278892286": {"item_id": "3278892286", "resolved_id": "3278892345", "given_url": "https://towardsdatascience.com/introduction-to-hierarchical-clustering-part-3-spatial-clustering-1f8cbd451173?source=rss----7f60cf5620c9---4", "given_title": "Introduction to hierarchical clustering (Part 3 — Spatial clustering)", "favorite": "0", "status": "1", "time_added": "1615559753", "time_updated": "1615565129", "time_read": "1615565129", "time_favorited": "0", "sort_id": 19, "resolved_title": "Introduction to hierarchical clustering (Part 3", "resolved_url": "https://towardsdatascience.com/introduction-to-hierarchical-clustering-part-3-spatial-clustering-1f8cbd451173", "excerpt": "In our attempt to cluster crimes in London in the previous article, we ignored the spatial dimension of the data in performing the clustering. Thus, this article seeks to remedy this by explicitly accounting for this.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1591", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/1200/0*vChASz7ILutoo7GY", "tags": {"clustering": {"item_id": "3278892286", "tag": "clustering"}, "machine-learning": {"item_id": "3278892286", "tag": "machine-learning"}, "spatial": {"item_id": "3278892286", "tag": "spatial"}}, "authors": {"142042741": {"item_id": "3278892286", "author_id": "142042741", "name": "Philip Wilkinson", "url": "https://philip-wilkinson.medium.com"}}, "image": {"item_id": "3278892286", "src": "https://miro.medium.com/fit/c/56/56/1*JlXwVf5GztcY3BfL5xfdtw.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3278892286", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*JlXwVf5GztcY3BfL5xfdtw.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3278892286", "image_id": "2", "src": "https://miro.medium.com/max/2000/0*vChASz7ILutoo7GY", "width": "1000", "height": "707", "credit": "Kafai Liu on Unsplash", "caption": ""}, "3": {"item_id": "3278892286", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*hvVMTc4aQk77gX0sPK9O2w.jpeg", "width": "700", "height": "462", "credit": "", "caption": "Left: Rooks, Right: Queens"}, "4": {"item_id": "3278892286", "image_id": "4", "src": "https://miro.medium.com/max/2000/1*IqqAWP3wqWseiQnfdwis0Q.png", "width": "1000", "height": "372", "credit": "", "caption": "Right: Whole of London, Left: Canary Wharf"}, "5": {"item_id": "3278892286", "image_id": "5", "src": "https://miro.medium.com/max/1394/1*ab7s7fccgfGLPqkXlmcSfQ.png", "width": "697", "height": "599", "credit": "", "caption": ""}, "6": {"item_id": "3278892286", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*jUZ2PJlDIvIolPJNPHWz-A.png", "width": "700", "height": "478", "credit": "", "caption": ""}, "7": {"item_id": "3278892286", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*ZVY1n0icMDvAwjXjjUp38A.png", "width": "700", "height": "812", "credit": "", "caption": ""}, "8": {"item_id": "3278892286", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*DovRz6RiAVvRUrP_wWs8hw.png", "width": "700", "height": "700", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 616}, "3145821306": {"item_id": "3145821306", "resolved_id": "3145821364", "given_url": "https://towardsdatascience.com/silhouette-method-better-than-elbow-method-to-find-optimal-clusters-378d62ff6891?source=rss----7f60cf5620c9---4", "given_title": "Silhouette Method — Better than Elbow Method to find Optimal Clusters", "favorite": "0", "status": "1", "time_added": "1603052216", "time_updated": "1612385105", "time_read": "1604360802", "time_favorited": "0", "sort_id": 20, "resolved_title": "Silhouette Method — Better than Elbow Method to find Optimal Clusters", "resolved_url": "https://towardsdatascience.com/silhouette-method-better-than-elbow-method-to-find-optimal-clusters-378d62ff6891", "excerpt": "Hyperparameters are model configurations properties that define the model and remain constants during the training of the model. The design of the model can be changed by tuning the hyperparameters.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1114", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/640/1*GsstWuZUuQDSBTwT3PYoGA.jpeg", "tags": {"clustering": {"item_id": "3145821306", "tag": "clustering"}, "machine-learning": {"item_id": "3145821306", "tag": "machine-learning"}}, "authors": {"143943089": {"item_id": "3145821306", "author_id": "143943089", "name": "Satyam Kumar", "url": "https://satyam-kumar.medium.com"}}, "image": {"item_id": "3145821306", "src": "https://miro.medium.com/fit/c/56/56/1*rvyM1yFu5JbnOueKTiWweQ.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3145821306", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*rvyM1yFu5JbnOueKTiWweQ.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3145821306", "image_id": "2", "src": "https://miro.medium.com/max/1280/1*GsstWuZUuQDSBTwT3PYoGA.jpeg", "width": "640", "height": "360", "credit": "", "caption": "Image by Mediamodifier from Pixabay"}, "3": {"item_id": "3145821306", "image_id": "3", "src": "https://miro.medium.com/max/918/1*VP1ilPn4SYoigi2vxMAQ6g.png", "width": "459", "height": "289", "credit": "Image by Author", "caption": ""}, "4": {"item_id": "3145821306", "image_id": "4", "src": "https://miro.medium.com/max/2600/1*R0r2umHV83jFF97S8iSQCQ.png", "width": "1300", "height": "424", "credit": "Image by Author", "caption": ""}, "5": {"item_id": "3145821306", "image_id": "5", "src": "https://miro.medium.com/max/456/1*fOlkxm7NXLSopIA02flxng.png", "width": "228", "height": "56", "credit": "", "caption": ""}, "6": {"item_id": "3145821306", "image_id": "6", "src": "https://miro.medium.com/max/902/1*cNzzMupO355ohnVqXnvxEA.png", "width": "451", "height": "330", "credit": "Image by Author", "caption": ""}, "7": {"item_id": "3145821306", "image_id": "7", "src": "https://miro.medium.com/max/892/1*FDahPZQHWMxaZSSf369NHA.png", "width": "446", "height": "287", "credit": "Image by Author", "caption": ""}, "8": {"item_id": "3145821306", "image_id": "8", "src": "https://miro.medium.com/max/2650/1*yZjgg9p_FmZh-NIoR1yI5Q.jpeg", "width": "1325", "height": "2975", "credit": "Image by Author", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 431}, "3890693710": {"item_id": "3890693710", "resolved_id": "3890693710", "given_url": "https://dev.to/rajaniraiyn/spectral-clustering-algorithm-demystified-d8i", "given_title": "Spectral Clustering Algorithm Demystified", "favorite": "0", "status": "1", "time_added": "1687289375", "time_updated": "1687347366", "time_read": "1687347366", "time_favorited": "0", "sort_id": 21, "resolved_title": "Spectral Clustering Algorithm Demystified", "resolved_url": "https://dev.to/rajaniraiyn/spectral-clustering-algorithm-demystified-d8i", "excerpt": "Spectral clustering is a method of clustering data points based on their similarity or affinity, rather than their distance or compactness.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "577", "lang": "", "top_image_url": "https://dev.to/social_previews/article/1506956.png", "tags": {"clustering": {"item_id": "3890693710", "tag": "clustering"}, "machine-learning": {"item_id": "3890693710", "tag": "machine-learning"}}, "domain_metadata": {"name": "The Practical Dev", "logo": "https://logo.clearbit.com/dev.to?size=800", "greyscale_logo": "https://logo.clearbit.com/dev.to?size=800&greyscale=true"}, "listen_duration_estimate": 223}, "3646179710": {"item_id": "3646179710", "resolved_id": "3646179710", "given_url": "https://towardsdatascience.com/three-performance-evaluation-metrics-of-clustering-when-ground-truth-labels-are-not-available-ee08cb3ff4fb", "given_title": "Three Performance Evaluation Metrics of Clustering When Ground Truth Labels", "favorite": "0", "status": "1", "time_added": "1656014338", "time_updated": "1656028608", "time_read": "1656028607", "time_favorited": "0", "sort_id": 22, "resolved_title": "Three Performance Evaluation Metrics of Clustering When Ground Truth Labels Are Not Available", "resolved_url": "https://towardsdatascience.com/three-performance-evaluation-metrics-of-clustering-when-ground-truth-labels-are-not-available-ee08cb3ff4fb", "excerpt": "Model evaluation is always an important step in a machine learning pipeline because it tells us how good the model is at describing the data. When talking about model evaluations, we are more often referring to that in supervised learning models, where the true labels of the data are available.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1543", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/1200/0*zCZ8k6ts7VZnwz_f", "tags": {"clustering": {"item_id": "3646179710", "tag": "clustering"}, "machine-learning": {"item_id": "3646179710", "tag": "machine-learning"}, "metrics": {"item_id": "3646179710", "tag": "metrics"}}, "authors": {"144157136": {"item_id": "3646179710", "author_id": "144157136", "name": "Yufeng", "url": "https://jianan-lin.medium.com"}}, "image": {"item_id": "3646179710", "src": "https://miro.medium.com/max/1400/0*zCZ8k6ts7VZnwz_f", "width": "700", "height": "467"}, "images": {"1": {"item_id": "3646179710", "image_id": "1", "src": "https://miro.medium.com/max/1400/0*zCZ8k6ts7VZnwz_f", "width": "700", "height": "467", "credit": "Simon Moog on Unsplash", "caption": ""}, "2": {"item_id": "3646179710", "image_id": "2", "src": "https://miro.medium.com/max/1112/1*0cYUfWLFW6SEyLSmpVh3DQ.png", "width": "556", "height": "236", "credit": "Image by author", "caption": "Example of an inter-cluster distance and an intra-cluster distance in a GOOD clustering result. Cluster labels highlighted by three colors."}, "3": {"item_id": "3646179710", "image_id": "3", "src": "https://miro.medium.com/max/582/1*qA_lPZ24pwh8YiQRaQWy1w.png", "width": "291", "height": "213", "credit": "Image by author", "caption": "Example of an inter-cluster distance and an intra-cluster distance in a BAD clustering result. Cluster labels highlighted by three colors."}, "4": {"item_id": "3646179710", "image_id": "4", "src": "https://miro.medium.com/max/928/1*mapFkMc7uIS0TelD2fM7sw.png", "width": "464", "height": "134", "credit": "Image by author", "caption": "intra-cluster distance definition."}, "5": {"item_id": "3646179710", "image_id": "5", "src": "https://miro.medium.com/max/880/1*MXgplz3B9B8lxZfZ6UicNw.png", "width": "440", "height": "118", "credit": "Image by author", "caption": "inter-cluster distance definition."}, "6": {"item_id": "3646179710", "image_id": "6", "src": "https://miro.medium.com/max/1056/1*LqIe6XaNCV-83STPu9gcQA.png", "width": "528", "height": "126", "credit": "Image by author", "caption": "Silhouette score definition."}, "7": {"item_id": "3646179710", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*gxXRXvJR3jrqxQh92j56Gw.png", "width": "700", "height": "135", "credit": "", "caption": ""}, "8": {"item_id": "3646179710", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*pcdM7E98pZ3yvrawriTYCg.png", "width": "700", "height": "467", "credit": "Image by author", "caption": "Good clustering result example that is rewarded by Calinski-Harabasz Index"}, "9": {"item_id": "3646179710", "image_id": "9", "src": "https://miro.medium.com/max/508/1*nMfGG_BJj78aMltIEdWYmg.png", "width": "254", "height": "116", "credit": "Image by author", "caption": "Similarity calculation in Davies-Bouldin index."}, "10": {"item_id": "3646179710", "image_id": "10", "src": "https://miro.medium.com/max/476/1*xOeIqLdJuttyl3xjuEM3pg.png", "width": "238", "height": "76", "credit": "", "caption": ""}, "11": {"item_id": "3646179710", "image_id": "11", "src": "https://miro.medium.com/max/512/1*rmQnwjKB64XkKP9kEsNpyg.png", "width": "256", "height": "108", "credit": "image by author", "caption": "Davies-Bouldin index calculation"}, "12": {"item_id": "3646179710", "image_id": "12", "src": "https://miro.medium.com/max/1400/0*3P58loG4tXY5L16r", "width": "700", "height": "467", "credit": "Artem Kniaz on Unsplash", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 597}, "2739528856": {"item_id": "2739528856", "resolved_id": "2739528856", "given_url": "https://www.kdnuggets.com/2019/09/hierarchical-clustering.html", "given_title": "What is Hierarchical Clustering?", "favorite": "0", "status": "1", "time_added": "1569593523", "time_updated": "1612385105", "time_read": "1569859842", "time_favorited": "0", "sort_id": 23, "resolved_title": "What is Hierarchical Clustering?", "resolved_url": "https://www.kdnuggets.com/2019/09/hierarchical-clustering.html", "excerpt": "What is Clustering?? Clustering is a technique that groups similar objects such that the objects in the same group are more similar to each other than the objects in the other groups. The group of similar objects is called a Cluster.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1502", "lang": "en", "time_to_read": 7, "tags": {"clustering": {"item_id": "2739528856", "tag": "clustering"}, "machine-learning": {"item_id": "2739528856", "tag": "machine-learning"}}, "image": {"item_id": "2739528856", "src": "https://miro.medium.com/max/666/1*hm9-QiOveg7_BjbEkOXamg.png", "width": "100", "height": "0"}, "images": {"1": {"item_id": "2739528856", "image_id": "1", "src": "https://miro.medium.com/max/666/1*hm9-QiOveg7_BjbEkOXamg.png", "width": "100", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 581}}, "error": nil, "search_meta": {"search_type": "normal"}, "since": 1709934511}