{"status": 1, "complete": 1, "list": {"3651162538": {"item_id": "3651162538", "resolved_id": "3651162538", "given_url": "http://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html", "given_title": "Minerva: Solving Quantitative Reasoning Problems with Language Models", "favorite": "0", "status": "1", "time_added": "1656617557", "time_updated": "1657065526", "time_read": "1657065525", "time_favorited": "0", "sort_id": 0, "resolved_title": "Minerva: Solving Quantitative Reasoning Problems with Language Models", "resolved_url": "http://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html", "excerpt": "Language models have demonstrated remarkable performance on a variety of natural language tasks — indeed, a general lesson from many works, including BERT, GPT-3, Gopher, and PaLM, has been that neural networks trained on diverse data at large scale in an unsupervised way can perform well on a var", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1026", "lang": "en", "time_to_read": 5, "top_image_url": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png", "tags": {"deep-learning": {"item_id": "3651162538", "tag": "deep-learning"}, "nlp": {"item_id": "3651162538", "tag": "nlp"}}, "image": {"item_id": "3651162538", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgpHov9BD2yiBEDrAWZUQxDYWRIuofmpbWVJaJPDPrE-2BbT3B_15-R4n22yNnDVs_8Vkea-Y-ykOHaB6mCKwkLYkBDBoS1r8NX2u4KsCpNC53GAM_8seK6L_90CJCmhC4ML9SSVY03lErXDQd6Pp-ysGsANdvNcqur7lMARO7h4RtDtf6Y7UlNYuEjjQ/s1999/image5.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3651162538", "image_id": "1", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgpHov9BD2yiBEDrAWZUQxDYWRIuofmpbWVJaJPDPrE-2BbT3B_15-R4n22yNnDVs_8Vkea-Y-ykOHaB6mCKwkLYkBDBoS1r8NX2u4KsCpNC53GAM_8seK6L_90CJCmhC4ML9SSVY03lErXDQd6Pp-ysGsANdvNcqur7lMARO7h4RtDtf6Y7UlNYuEjjQ/s1999/image5.png", "width": "0", "height": "0", "credit": "", "caption": "Solving a multi-step problem: A question from the MATH dataset and Minerva’s solution. The model writes down a line equation, simplifies it, substitutes a variable, and solves for y."}, "2": {"item_id": "3651162538", "image_id": "2", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjIOaSDE8P-ubM5OvUkbjEFtEvs21SKAI3F3dwa4dbRuKKiq1cQPG1unZGyJrtxJFLiG8mfViwz2vDd2BrHd-E8UFKTOf2WB5r4L-EpO3BQY-zu5Z4yW1EfVmSrFvNzYfKXSruQgdPTiwgeZGUNdPUHKFSUIMUGCxWBRsV_KWO72PqlFPDUBFe_MLBgBg/s2272/image.png", "width": "0", "height": "0", "credit": "left", "caption": "Example questions from the Joint Entrance Examination Main Math 2020 exam taken each year by almost 2M Indian high-school students intended to study engineering and similar fields"}, "3": {"item_id": "3651162538", "image_id": "3", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEivwDKms-EUCz7cz8H0c8Q5KHe97juJHfPWbuTf1y6hdCMS8xE1mLs3-x1znGaMPzrvjj87k750VhmDZYen3U056ou78Sn2ENZ0Zxv-aRBQ3doXpDZpIpY7D-yLgc4Vvi_-FagkBYy8IioKWPwV61Ri9l2B3LZu7mSVPuGnoC626f0tyZnTrT0iiGuM7Q/s1999/image1.png", "width": "0", "height": "0", "credit": "", "caption": "A dataset for quantitative reasoning: Careful data processing preserves mathematical information, allowing the model to learn mathematics at a higher level."}, "4": {"item_id": "3651162538", "image_id": "4", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgTupKiVyR5dIslWNgdzXAVJcGJXFmQCPD2Md23ceVdLwcIYtGODTrEE0Jj_cM7NLt-4pR9Yk47WjvbWWJJBroqYxRvWKciUTk-1AWJZXGdnUuXQzMq41nDJFFdhwXq73Gi2T880waPoqTxX6N9B444DM4u6Hwo6Ygt2NPT2nOMr8chsx1q2YhSl3NmyQ/s1896/image2.png", "width": "0", "height": "0", "credit": "", "caption": "Evaluation results on MATH and MMLU-STEM, which include high school and college level questions covering a range of STEM topics."}, "5": {"item_id": "3651162538", "image_id": "5", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjbE_3M_iZVTPpV-fM6rnv2T0k48RiTXWVtQIan4NEm953gsIuZXNc6t59_WABUjTZD1NHM2SDXQ-4gFCQrou3ekA3Ly3US4LYVO5Qfqkj0FfNMMucP97Omr1Taq9fdRL0x_VbsTih3oyMwave84GPjddFPtadp1fgcNkcTeGolfIBvjLj2SsIfJ9vs9A/s1999/image8.png", "width": "0", "height": "0", "credit": "", "caption": "Calculation mistake: The model incorrectly cancels the square root on both sides of the equation."}, "6": {"item_id": "3651162538", "image_id": "6", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg0hsddb9-V6t0H2wSDN0UPNY--wVNwZYKUEpAroQVs0Zlb-UW5w60anhm-S8--hk1E7Ht6Gb-3QzQD70h3RQQDIR8OBgq8CW3dKnmHamLlZKH3CYCV2TeLB9PAI84UMKBP8l-eiI-SafFGbqlTy9OAYspIP240hKD8It73Gnx1I0RdSdElS7jj4l267A/s1999/image3.png", "width": "0", "height": "0", "credit": "", "caption": "Reasoning mistake: The model computes the number of free throws at the fourth practice, but then uses this number as the final answer for the first practice."}, "7": {"item_id": "3651162538", "image_id": "7", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgjB2ctso8XO1RgQdVp5f5OVCxxTqaCL23tGnHaLcxU5JgemoNYFwHYKPsAXmqhu3Ht4mBaC8m_DGap1w1bNwfqd7eAQAGzx21M6kRTleyCmCI_1QYS5BM3X01HZ2PGkIA11shPHAOEvJO7n6yi7nAiTTLhoENdxom9ITom8pp5DNQBoI7PJdqc78T1Zg/s1999/image6.png", "width": "0", "height": "0", "credit": "", "caption": "Solving a problem using calculus and trigonometry: A question from the MATH dataset asking for the speed of a particle in circular motion. Minerva finds a correct step-by-step solution. In the process, Minerva computes a time derivative and applies a trigonometric identity."}}, "listen_duration_estimate": 397}, "2993634562": {"item_id": "2993634562", "resolved_id": "2993634562", "given_url": "http://amacfie.github.io/2020/05/21/comment-ranking/", "given_title": "Comment Ranking Algorithms: Hacker News vs. YouTube vs. Reddit", "favorite": "0", "status": "1", "time_added": "1590318143", "time_updated": "1612385105", "time_read": "1591031817", "time_favorited": "0", "sort_id": 1, "resolved_title": "Comment ranking algorithms: Hacker News vs. YouTube vs. Reddit", "resolved_url": "http://amacfie.github.io/2020/05/21/comment-ranking/", "excerpt": "Comments on social sites have to be sorted somehow. How do big platforms do it – is it some complicated mix of recommender systems, learning-to-rank algorithms, Markov decision processes, neural networks, and learning automata? Well, maybe in some cases but often it’s just a simple formula.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "786", "lang": "en", "time_to_read": 4, "tags": {"machine-learning": {"item_id": "2993634562", "tag": "machine-learning"}, "nlp": {"item_id": "2993634562", "tag": "nlp"}}, "listen_duration_estimate": 304}, "3052552802": {"item_id": "3052552802", "resolved_id": "3052552802", "given_url": "http://hedonometer.org/words/labMT-en-v1/", "given_title": "Hedonometer", "favorite": "0", "status": "1", "time_added": "1595076740", "time_updated": "1597023182", "time_read": "1597023182", "time_favorited": "0", "sort_id": 2, "resolved_title": "Hedonometer word list: labMT-en-v1", "resolved_url": "https://hedonometer.org/words/labMT-en-v1/", "excerpt": "Each of the sets of words (and individual words themselves) can be queried through the API (in addition to the CSV and Excel version available from the table above). For this set, the endpoint for json is: https://hedonometer.org/api/v1/words/?format=json&wordlist__title=labMT-en-v1.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "275", "lang": "en", "top_image_url": "http://hedonometer.org/static/hedonometer/graphics/hedonometer-logo.png", "tags": {"nlp": {"item_id": "3052552802", "tag": "nlp"}}, "listen_duration_estimate": 106}, "2407676761": {"item_id": "2407676761", "resolved_id": "2407676761", "given_url": "http://jalammar.github.io/illustrated-bert/", "given_title": "The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) – J", "favorite": "0", "status": "1", "time_added": "1584704762", "time_updated": "1638708525", "time_read": "1585739665", "time_favorited": "0", "sort_id": 3, "resolved_title": "The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)", "resolved_url": "https://jalammar.github.io/illustrated-bert/", "excerpt": "Translations: Chinese (Simplified), French 1, French 2, Japanese, Korean, Persian, Russian, Spanish The year 2018 has been an inflection point for machine learning models handling text (or more accurately, Natural Language Processing or NLP for short).", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "2940", "lang": "en", "time_to_read": 13, "tags": {"bert": {"item_id": "2407676761", "tag": "bert"}, "deep-learning": {"item_id": "2407676761", "tag": "deep-learning"}, "nlp": {"item_id": "2407676761", "tag": "nlp"}}, "authors": {"83096926": {"item_id": "2407676761", "author_id": "83096926", "name": "Jay Alammar", "url": ""}}, "image": {"item_id": "2407676761", "src": "https://jalammar.github.io/images/bert-transfer-learning.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2407676761", "image_id": "1", "src": "https://jalammar.github.io/images/bert-transfer-learning.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2407676761", "image_id": "2", "src": "https://jalammar.github.io/images/BERT-classification-spam.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2407676761", "image_id": "3", "src": "https://jalammar.github.io/images/bert-base-bert-large.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2407676761", "image_id": "4", "src": "https://jalammar.github.io/images/bert-base-bert-large-encoders.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2407676761", "image_id": "5", "src": "https://jalammar.github.io/images/bert-input-output.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2407676761", "image_id": "6", "src": "https://jalammar.github.io/images/bert-encoders-input.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2407676761", "image_id": "7", "src": "https://jalammar.github.io/images/bert-output-vector.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2407676761", "image_id": "8", "src": "https://jalammar.github.io/images/bert-classifier.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2407676761", "image_id": "9", "src": "https://jalammar.github.io/images/vgg-net-classifier.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2407676761", "image_id": "10", "src": "https://jalammar.github.io/images/glove-embedding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2407676761", "image_id": "11", "src": "https://jalammar.github.io/images/vector-boxes.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2407676761", "image_id": "12", "src": "https://jalammar.github.io/images/elmo-embedding-robin-williams.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "2407676761", "image_id": "13", "src": "https://jalammar.github.io/images/elmo-word-embedding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "2407676761", "image_id": "14", "src": "https://jalammar.github.io/images/Bert-language-modeling.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "2407676761", "image_id": "15", "src": "https://jalammar.github.io/images/elmo-forward-backward-language-model-embedding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "2407676761", "image_id": "16", "src": "https://jalammar.github.io/images/elmo-embedding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "2407676761", "image_id": "17", "src": "https://jalammar.github.io/images/openai-transformer-1.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "2407676761", "image_id": "18", "src": "https://jalammar.github.io/images/openai-transformer-language-modeling.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "2407676761", "image_id": "19", "src": "https://jalammar.github.io/images/openai-transformer-sentence-classification.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "2407676761", "image_id": "20", "src": "https://jalammar.github.io/images/openai-input%20transformations.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "2407676761", "image_id": "21", "src": "https://jalammar.github.io/images/BERT-language-modeling-masked-lm.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "2407676761", "image_id": "22", "src": "https://jalammar.github.io/images/bert-next-sentence-prediction.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "23": {"item_id": "2407676761", "image_id": "23", "src": "https://jalammar.github.io/images/bert-tasks.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "2407676761", "image_id": "24", "src": "https://jalammar.github.io/images/bert-contexualized-embeddings.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "2407676761", "image_id": "25", "src": "https://jalammar.github.io/images/bert-feature-extraction-contextualized-embeddings.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "2407676761", "video_id": "1", "src": "https://www.youtube.com/embed/ioGry-89gqE", "width": "560", "height": "315", "type": "1", "vid": "ioGry-89gqE", "length": "0"}}, "listen_duration_estimate": 1138}, "1360719066": {"item_id": "1360719066", "resolved_id": "1360719066", "given_url": "http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/", "given_title": "Google's trained Word2Vec model in Python · Chris McCormick", "favorite": "0", "status": "1", "time_added": "1516938496", "time_updated": "1609553264", "time_read": "1518401831", "time_favorited": "0", "sort_id": 4, "resolved_title": "Google's trained Word2Vec model in Python · Chris McCormick", "resolved_url": "http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/", "excerpt": "In this post I’m going to describe how to get Google’s pre-trained Word2Vec model up and running in Python to play with. As an interface to word2vec, I decided to go with a Python package called gensim.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "745", "lang": "en", "time_to_read": 3, "tags": {"nlp": {"item_id": "1360719066", "tag": "nlp"}, "word2vec": {"item_id": "1360719066", "tag": "word2vec"}}, "listen_duration_estimate": 288}, "1929137419": {"item_id": "1929137419", "resolved_id": "1929137419", "given_url": "http://multithreaded.stitchfix.com/blog/2017/10/25/word-tensors/", "given_title": "Word Tensors", "favorite": "0", "status": "1", "time_added": "1508339692", "time_updated": "1611284679", "time_read": "1514420822", "time_favorited": "0", "sort_id": 5, "resolved_title": "Word Tensors", "resolved_url": "https://multithreaded.stitchfix.com/blog/2017/10/25/word-tensors/", "excerpt": "In the previous post, we saw that we can get word vectors by factorizing a 2D matrix of word co-occurrences. But what do we get if we factorize a 3D tensor?", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "770", "lang": "en", "time_to_read": 4, "top_image_url": "https://multithreaded.stitchfix.com/assets/posts/2017-10-25-word-tensors/fig_008.gif", "tags": {"nlp": {"item_id": "1929137419", "tag": "nlp"}}, "image": {"item_id": "1929137419", "src": "https://multithreaded.stitchfix.com/assets/posts/2017-10-25-word-tensors/fig_008.gif", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1929137419", "image_id": "1", "src": "https://multithreaded.stitchfix.com/assets/posts/2017-10-25-word-tensors/fig_008.gif", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 298}, "3432099323": {"item_id": "3432099323", "resolved_id": "3432099323", "given_url": "http://spacy.pythonhumanities.com/intro.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1631706352", "time_updated": "1633110745", "time_read": "1633110744", "time_favorited": "0", "sort_id": 6, "resolved_title": "INTRODUCTION TO SPACY 3 — Introduction to spaCy 3", "resolved_url": "http://spacy.pythonhumanities.com/intro.html", "excerpt": "Mattingly, William. Introduction to spaCy 3, 2021 (1st ed.). spacy.pythonhumanities.com.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "10", "lang": "", "tags": {"nlp": {"item_id": "3432099323", "tag": "nlp"}, "spacy": {"item_id": "3432099323", "tag": "spacy"}}, "image": {"item_id": "3432099323", "src": "http://spacy.pythonhumanities.com/_images/freecodecampfull.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3432099323", "image_id": "1", "src": "http://spacy.pythonhumanities.com/_images/freecodecampfull.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3432099323", "image_id": "2", "src": "http://spacy.pythonhumanities.com/_images/data_science_lab_logo.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3432099323", "image_id": "3", "src": "http://spacy.pythonhumanities.com/_images/si_logo.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3432099323", "image_id": "4", "src": "http://spacy.pythonhumanities.com/_images/ushmm_logo.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 4}, "3442726847": {"item_id": "3442726847", "resolved_id": "3442491524", "given_url": "http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1070341", "given_title": "Topic Modeling: Algorithms, Techniques, and Application", "favorite": "0", "status": "1", "time_added": "1632823390", "time_updated": "1633110267", "time_read": "1633110266", "time_favorited": "0", "sort_id": 7, "resolved_title": "Topic Modeling: Algorithms, Techniques, and Application", "resolved_url": "https://www.datasciencecentral.com/profiles/blogs/topic-modeling-algorithms-techniques-and-application", "excerpt": "Used in unsupervised machine learning tasks, Topic Modeling is treated as a form of tagging and primarily used for information retrieval wherein it helps in query expansion. It is vastly used in mapping user preference in topics across search engineers.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "891", "lang": "en", "time_to_read": 4, "top_image_url": "https://storage.ning.com/topology/rest/1.0/file/get/9614740653?profile=RESIZE_710x", "tags": {"machine-learning": {"item_id": "3442726847", "tag": "machine-learning"}, "nlp": {"item_id": "3442726847", "tag": "nlp"}, "topic-modeling": {"item_id": "3442726847", "tag": "topic-modeling"}}, "authors": {"148404155": {"item_id": "3442726847", "author_id": "148404155", "name": "Roger Max", "url": "https://www.datasciencecentral.com/profile/cogitotech"}}, "image": {"item_id": "3442726847", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9614740653?profile=RESIZE_710x", "width": "720", "height": "0"}, "images": {"1": {"item_id": "3442726847", "image_id": "1", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9614740653?profile=RESIZE_710x", "width": "720", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3442726847", "image_id": "2", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9612657289?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3442726847", "image_id": "3", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9612682493?profile=RESIZE_710x", "width": "636", "height": "164", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Data Science Central", "logo": "https://logo.clearbit.com/datasciencecentral.com?size=800", "greyscale_logo": "https://logo.clearbit.com/datasciencecentral.com?size=800&greyscale=true"}, "listen_duration_estimate": 345}, "2830789773": {"item_id": "2830789773", "resolved_id": "2830760324", "given_url": "http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:916808", "given_title": "Top NLP Algorithms & Concepts", "favorite": "0", "status": "1", "time_added": "1577052055", "time_updated": "1608303059", "time_read": "1577120201", "time_favorited": "0", "sort_id": 8, "resolved_title": "Top NLP Algorithms & Concepts", "resolved_url": "https://www.datasciencecentral.com/profiles/blogs/top-nlp-algorithms-amp-concepts", "excerpt": "Today, one of the most popular tasks in Data Science is processing information presented in the text form.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2026", "lang": "en", "time_to_read": 9, "top_image_url": "https://storage.ning.com/topology/rest/1.0/file/get/3780583691?profile=RESIZE_710x", "tags": {"nlp": {"item_id": "2830789773", "tag": "nlp"}}, "authors": {"89353532": {"item_id": "2830789773", "author_id": "89353532", "name": "Igor Bobriakov", "url": "https://www.datasciencecentral.com/profile/IogrBobriakov"}}, "image": {"item_id": "2830789773", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780583691?profile=RESIZE_710x", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2830789773", "image_id": "1", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780583691?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2830789773", "image_id": "2", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780584426?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2830789773", "image_id": "3", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780585864?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2830789773", "image_id": "4", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780586526?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2830789773", "image_id": "5", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780587432?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2830789773", "image_id": "6", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780587886?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2830789773", "image_id": "7", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780588496?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2830789773", "image_id": "8", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780589634?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2830789773", "image_id": "9", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780590128?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2830789773", "image_id": "10", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780590625?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2830789773", "image_id": "11", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780591414?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2830789773", "image_id": "12", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780591744?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "2830789773", "image_id": "13", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780592986?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "2830789773", "image_id": "14", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780593498?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "2830789773", "image_id": "15", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780594023?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "2830789773", "image_id": "16", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780594470?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "2830789773", "image_id": "17", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780594929?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "2830789773", "image_id": "18", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780595757?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Data Science Central", "logo": "https://logo.clearbit.com/datasciencecentral.com?size=800", "greyscale_logo": "https://logo.clearbit.com/datasciencecentral.com?size=800&greyscale=true"}, "listen_duration_estimate": 784}, "1096569162": {"item_id": "1096569162", "resolved_id": "1096569162", "given_url": "http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1622248019", "time_updated": "1638708525", "time_read": "1622249139", "time_favorited": "0", "sort_id": 9, "resolved_title": "", "resolved_url": "http://wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"convolutions": {"item_id": "1096569162", "tag": "convolutions"}, "deep-learning": {"item_id": "1096569162", "tag": "deep-learning"}, "nlp": {"item_id": "1096569162", "tag": "nlp"}}, "listen_duration_estimate": 0}, "1151025792": {"item_id": "1151025792", "resolved_id": "1151025792", "given_url": "http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/", "given_title": "Attention and Memory in Deep Learning and NLP – WildML", "favorite": "0", "status": "1", "time_added": "1622248138", "time_updated": "1638708525", "time_read": "1622249126", "time_favorited": "0", "sort_id": 10, "resolved_title": "", "resolved_url": "http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"deep-learning": {"item_id": "1151025792", "tag": "deep-learning"}, "nlp": {"item_id": "1151025792", "tag": "nlp"}}, "listen_duration_estimate": 0}, "1556184520": {"item_id": "1556184520", "resolved_id": "1556184520", "given_url": "https://adeshpande3.github.io/adeshpande3.github.io/Deep-Learning-Research-Review-Week-3-Natural-Language-Processing", "given_title": "Deep Learning Research Review Week 3: Natural Language Processing – Adit De", "favorite": "0", "status": "1", "time_added": "1518132874", "time_updated": "1611285424", "time_read": "1528501305", "time_favorited": "0", "sort_id": 11, "resolved_title": "Adit Deshpande – Engineering at Forward : UCLA CS '19", "resolved_url": "https://adeshpande3.github.io/adeshpande3.github.io/Deep-Learning-Research-Review-Week-3-Natural-Language-Processing", "excerpt": "The Last 5 Years In Deep Learning We've come quite a long way Read More", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "14", "lang": "en", "tags": {"nlp": {"item_id": "1556184520", "tag": "nlp"}}, "authors": {"53325162": {"item_id": "1556184520", "author_id": "53325162", "name": "Adit Deshpande", "url": ""}}, "image": {"item_id": "1556184520", "src": "https://adeshpande3.github.io/adeshpande3.github.io/assets/Cover11th.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1556184520", "image_id": "1", "src": "https://adeshpande3.github.io/adeshpande3.github.io/assets/Cover11th.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 5}, "3680766248": {"item_id": "3680766248", "resolved_id": "3680766248", "given_url": "https://aman.ai/primers/ai/", "given_title": "Primers • AI", "favorite": "0", "status": "1", "time_added": "1695412124", "time_updated": "1695566827", "time_read": "1695566827", "time_favorited": "0", "sort_id": 12, "resolved_title": "Primers • AI", "resolved_url": "https://aman.ai/primers/ai/", "excerpt": "Overview Here’s a hand-picked selection of articles on AI fundamentals/concepts that cover the entire process of building neural nets to training them to evaluating results.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "26", "lang": "en", "tags": {"nlp": {"item_id": "3680766248", "tag": "nlp"}}, "listen_duration_estimate": 10}, "3813438729": {"item_id": "3813438729", "resolved_id": "3813438729", "given_url": "https://arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/", "given_title": "Meta unveils a new large language model that can run on a single GPU", "favorite": "0", "status": "1", "time_added": "1677275847", "time_updated": "1677353638", "time_read": "1677353638", "time_favorited": "0", "sort_id": 13, "resolved_title": "Meta unveils a new large language model that can run on a single GPU [Updated]", "resolved_url": "https://arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/", "excerpt": "On Friday, Meta announced a new AI-powered large language model (LLM) called LLaMA-13B that it claims can outperform OpenAI's GPT-3 model despite being \"10x smaller.\" Smaller-sized AI models could lead to running ChatGPT-style language assistants locally on devices such as PCs and smartphones.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "621", "lang": "", "amp_url": "https://arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/amp/", "top_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/meta_llm_hero_1-640x360.jpg", "tags": {"chatgpt": {"item_id": "3813438729", "tag": "chatgpt"}, "deep-learning": {"item_id": "3813438729", "tag": "deep-learning"}, "generative": {"item_id": "3813438729", "tag": "generative"}, "nlp": {"item_id": "3813438729", "tag": "nlp"}}, "authors": {"171668034": {"item_id": "3813438729", "author_id": "171668034", "name": "Benj Edwards", "url": "https://arstechnica.com/author/benjedwards/"}}, "image": {"item_id": "3813438729", "src": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/meta_llm_hero_1-800x450.jpg", "width": "640", "height": "360"}, "images": {"1": {"item_id": "3813438729", "image_id": "1", "src": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/meta_llm_hero_1-800x450.jpg", "width": "640", "height": "360", "credit": "Benj Edwards / Ars Technica", "caption": "Benj Edwards / Ars Technica"}}, "domain_metadata": {"name": "Ars Technica", "logo": "https://logo.clearbit.com/arstechnica.com?size=800", "greyscale_logo": "https://logo.clearbit.com/arstechnica.com?size=800&greyscale=true"}, "listen_duration_estimate": 240}, "2957192960": {"item_id": "2957192960", "resolved_id": "2957192966", "given_url": "https://arxiv.org/abs/2004.08900", "given_title": "The Cost of Training NLP Models: A Concise Overview", "favorite": "0", "status": "1", "time_added": "1587721532", "time_updated": "1638708525", "time_read": "1587745451", "time_favorited": "0", "sort_id": 14, "resolved_title": "Title:The Cost of Training NLP Models: A Concise Overview", "resolved_url": "https://arxiv.org/abs/2004.08900v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"deep-learning": {"item_id": "2957192960", "tag": "deep-learning"}, "nlp": {"item_id": "2957192960", "tag": "nlp"}}, "authors": {"63240129": {"item_id": "2957192960", "author_id": "63240129", "name": "cs cs.LG cs.NE", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3763435562": {"item_id": "3763435562", "resolved_id": "3763435562", "given_url": "https://arxiv.org/pdf/2212.03551.pdf", "given_title": "2212.03551.pdf", "favorite": "0", "status": "1", "time_added": "1670772971", "time_updated": "1675817032", "time_read": "1670778218", "time_favorited": "0", "sort_id": 15, "resolved_title": "", "resolved_url": "https://arxiv.org/pdf/2212.03551.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"arxiv": {"item_id": "3763435562", "tag": "arxiv"}, "chatgpt": {"item_id": "3763435562", "tag": "chatgpt"}, "deep-learning": {"item_id": "3763435562", "tag": "deep-learning"}, "nlp": {"item_id": "3763435562", "tag": "nlp"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "1810493990": {"item_id": "1810493990", "resolved_id": "1810493990", "given_url": "https://blog.acolyer.org/2017/07/06/using-word-embedding-to-enable-semantic-queries-on-relational-databases/", "given_title": "Using word embedding to enable semantic queries on relational databases", "favorite": "0", "status": "1", "time_added": "1499341877", "time_updated": "1611439292", "time_read": "1514398142", "time_favorited": "0", "sort_id": 16, "resolved_title": "Using word embedding to enable semantic queries on relational databases", "resolved_url": "https://blog.acolyer.org/2017/07/06/using-word-embedding-to-enable-semantic-queries-on-relational-databases/", "excerpt": "As I’m sure some of you have figured out, I’ve started to work through a collection of papers from SIGMOD’17. Strictly speaking, this paper comes from the DEEM workshop held in conjunction with SIGMOD, but it sparked my imagination and I hope you’ll enjoy it too.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1160", "lang": "en", "time_to_read": 5, "tags": {"nlp": {"item_id": "1810493990", "tag": "nlp"}}, "authors": {"136059453": {"item_id": "1810493990", "author_id": "136059453", "name": "Adrian Colyer", "url": "https://blog.acolyer.org/author/adriancolyer/"}}, "image": {"item_id": "1810493990", "src": "https://blog.acolyer.org/wp-content/uploads/2017/07/ci-queries-fig-1.jpeg?w=520", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1810493990", "image_id": "1", "src": "https://blog.acolyer.org/wp-content/uploads/2017/07/ci-queries-fig-1.jpeg?w=520", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1810493990", "image_id": "2", "src": "https://blog.acolyer.org/wp-content/uploads/2017/07/ci-queries-fig-2.jpeg?w=520", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "1810493990", "image_id": "3", "src": "https://blog.acolyer.org/wp-content/uploads/2017/07/ci-queries-fig-3.jpeg?w=520", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "1810493990", "image_id": "4", "src": "https://blog.acolyer.org/wp-content/uploads/2017/07/ci-queries-fig-4.jpeg?w=520", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"logo": "https://logo.clearbit.com/acolyer.org?size=800", "greyscale_logo": "https://logo.clearbit.com/acolyer.org?size=800&greyscale=true"}, "listen_duration_estimate": 449}, "2042649607": {"item_id": "2042649607", "resolved_id": "2042649607", "given_url": "https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e", "given_title": "How to solve 90% of NLP problems: a step-by-step guide", "favorite": "1", "status": "1", "time_added": "1516819667", "time_updated": "1611277790", "time_read": "1528501359", "time_favorited": "1516843265", "sort_id": 17, "resolved_title": "How to solve 90% of NLP problems: a step-by-step guide", "resolved_url": "https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e", "excerpt": "For more content like this, follow Insight and Emmanuel on Twitter. Whether you are an established company or working to launch a new service, you can always leverage text data to validate, improve, and expand the functionalities of your product.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3030", "lang": "en", "time_to_read": 14, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*J8-5VgoWtMsIJhyHAuljSw.png", "tags": {"nlp": {"item_id": "2042649607", "tag": "nlp"}}, "authors": {"91666533": {"item_id": "2042649607", "author_id": "91666533", "name": "Emmanuel Ameisen", "url": "https://medium.com/@emmanuelameisen"}}, "image": {"item_id": "2042649607", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*u2FiBL9mzFPx7pj87aWxgw.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "2042649607", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*u2FiBL9mzFPx7pj87aWxgw.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "2042649607", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*bVN8Kd_RsjRN8JuKIc6U0w.png", "width": "24", "height": "24", "credit": "", "caption": ""}}, "listen_duration_estimate": 1173}, "2106961496": {"item_id": "2106961496", "resolved_id": "2106961496", "given_url": "https://blog.rinesi.com/using-artificial-intelligence-to-understand-brands/", "given_title": "Using Artificial Intelligence to Understand Brands", "favorite": "0", "status": "1", "time_added": "1522783999", "time_updated": "1656518434", "time_read": "1528501211", "time_favorited": "0", "sort_id": 18, "resolved_title": "Using Artificial Intelligence to Understand Brands", "resolved_url": "https://blog.rinesi.com/using-artificial-intelligence-to-understand-brands/", "excerpt": "Artificial Intelligence techniques behind automated translation and other NLP (Natural Language Processing) applications doesn't just work at the level of words and phrases, but give us quantitative data about the meaning people assign to different concepts, including brands.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1296", "lang": "en", "time_to_read": 6, "amp_url": "https://blog.rinesi.com/using-artificial-intelligence-to-understand-brands/amp/", "tags": {"brandmgmt": {"item_id": "2106961496", "tag": "brandmgmt"}, "marketing": {"item_id": "2106961496", "tag": "marketing"}, "nlp": {"item_id": "2106961496", "tag": "nlp"}}, "authors": {"66729017": {"item_id": "2106961496", "author_id": "66729017", "name": "Marcelo", "url": "https://blog.rinesi.com/author/admin/"}}, "image": {"item_id": "2106961496", "src": "https://blog.rinesi.com/wp-content/uploads/2018/03/isometric_projections.png", "width": "1000", "height": "800"}, "images": {"1": {"item_id": "2106961496", "image_id": "1", "src": "https://blog.rinesi.com/wp-content/uploads/2018/03/isometric_projections.png", "width": "1000", "height": "800", "credit": "", "caption": ""}, "2": {"item_id": "2106961496", "image_id": "2", "src": "https://blog.rinesi.com/wp-content/uploads/2018/03/android_isometric_projections.png", "width": "1000", "height": "800", "credit": "", "caption": ""}, "3": {"item_id": "2106961496", "image_id": "3", "src": "https://blog.rinesi.com/wp-content/uploads/2018/03/concept_geometry.png", "width": "1000", "height": "800", "credit": "", "caption": ""}}, "listen_duration_estimate": 502}, "2145003012": {"item_id": "2145003012", "resolved_id": "2145003012", "given_url": "https://building.lang.ai/understanding-what-is-behind-sentiment-analysis-part-ii-9307926d1435", "given_title": "Understanding what is behind Sentiment Analysis (Part II)", "favorite": "0", "status": "1", "time_added": "1524173894", "time_updated": "1610315023", "time_read": "1525203350", "time_favorited": "0", "sort_id": 19, "resolved_title": "Understanding what is behind Sentiment Analysis (Part II)", "resolved_url": "https://building.lang.ai/understanding-what-is-behind-sentiment-analysis-part-ii-9307926d1435", "excerpt": "Hint! Check Part I first, where we introduced a simple algorithm to analyze the sentiment of a given document. In this article we will talk about different modifications that might help us improve the performance of our classifier.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1160", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/0*C3NmcJgvF0da8w6A.", "tags": {"nlp": {"item_id": "2145003012", "tag": "nlp"}, "sentiment-analysis": {"item_id": "2145003012", "tag": "sentiment-analysis"}}, "authors": {"150043643": {"item_id": "2145003012", "author_id": "150043643", "name": "Enrique Fueyo", "url": "https://medium.com/@efueyo"}}, "image": {"item_id": "2145003012", "src": "https://miro.medium.com/max/1400/0*C3NmcJgvF0da8w6A.", "width": "700", "height": "466"}, "images": {"1": {"item_id": "2145003012", "image_id": "1", "src": "https://miro.medium.com/max/1400/0*C3NmcJgvF0da8w6A.", "width": "700", "height": "466", "credit": "Hannes Wolf on Unsplash", "caption": ""}}, "listen_duration_estimate": 449}, "3824289621": {"item_id": "3824289621", "resolved_id": "3824289627", "given_url": "https://cocktailpeanut.github.io/dalai/#/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1678707382", "time_updated": "1678882332", "time_read": "1678882332", "time_favorited": "0", "sort_id": 20, "resolved_title": "cocktailpeanut/dalai", "resolved_url": "https://github.com/cocktailpeanut/dalai", "excerpt": "Run LLaMA and Alpaca on your computer. Both alpaca and llama working on your computer!", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "1794", "lang": "en", "time_to_read": 8, "top_image_url": "https://opengraph.githubassets.com/17560ced9fe722110f4c540433743ce56a26b8052fe2525fcde957d9d0d2bd59/cocktailpeanut/dalai", "tags": {"deep-learning": {"item_id": "3824289621", "tag": "deep-learning"}, "llama": {"item_id": "3824289621", "tag": "llama"}, "nlp": {"item_id": "3824289621", "tag": "nlp"}}, "authors": {"179263246": {"item_id": "3824289621", "author_id": "179263246", "name": "cocktailpeanut", "url": "https://github.com/cocktailpeanut/dalai/commits?author=cocktailpeanut"}}, "image": {"item_id": "3824289621", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/npx2.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3824289621", "image_id": "1", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/npx2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3824289621", "image_id": "2", "src": "https://github.com/cocktailpeanut/dalai/raw/main/docs/alpaca.gif", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3824289621", "image_id": "3", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/alpaca_7b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3824289621", "image_id": "4", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/alpaca_13b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3824289621", "image_id": "5", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/7b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3824289621", "image_id": "6", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/13b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3824289621", "image_id": "7", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/30b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3824289621", "image_id": "8", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/65b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3824289621", "image_id": "9", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/vs.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 694}, "2562484658": {"item_id": "2562484658", "resolved_id": "2562484658", "given_url": "https://course.spacy.io", "given_title": "", "favorite": "0", "status": "1", "time_added": "1555865963", "time_updated": "1608994915", "time_read": "1567118910", "time_favorited": "0", "sort_id": 21, "resolved_title": "Advanced NLP with spaCy · A free online course", "resolved_url": "https://course.spacy.io", "excerpt": "spaCy is a modern Python library for industrial-strength Natural Language Processing. In this free and interactive online course, you'll learn how to use spaCy to build advanced natural language understanding systems, using both rule-based and machine learning approaches.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "78", "lang": "en", "top_image_url": "https://course.spacy.io/social.jpg", "tags": {"nlp": {"item_id": "2562484658", "tag": "nlp"}, "spacy": {"item_id": "2562484658", "tag": "spacy"}}, "image": {"item_id": "2562484658", "src": "https://d33wubrfki0l68.cloudfront.net/bbc6af123d06eae18b352e1d39ee41b889a3211a/22ee7/profile.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2562484658", "image_id": "1", "src": "https://d33wubrfki0l68.cloudfront.net/bbc6af123d06eae18b352e1d39ee41b889a3211a/22ee7/profile.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 30}, "3578809072": {"item_id": "3578809072", "resolved_id": "3578809072", "given_url": "https://dev.to/evgeniykrasnokutsky/ai-virtual-assistant-technology-guide-2022-3n3i", "given_title": "AI Virtual Assistant Technology Guide 2022", "favorite": "0", "status": "1", "time_added": "1647887454", "time_updated": "1691368576", "time_read": "1647891457", "time_favorited": "0", "sort_id": 22, "resolved_title": "AI Virtual Assistant Technology Guide 2022", "resolved_url": "https://dev.to/evgeniykrasnokutsky/ai-virtual-assistant-technology-guide-2022-3n3i", "excerpt": "They can help you get an appointment or order a pizza, find the best ticket deals and bring your attention to the fact you are spending a lot on entertainment instead of investments. We are talking about AI virtual assistants, which have already become a familiar part of our daily lives.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2968", "lang": "en", "time_to_read": 13, "top_image_url": "https://res.cloudinary.com/practicaldev/image/fetch/s--SNzowUws--/c_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8auc5yhbd3ofsn3mlm9a.jpg", "tags": {"chatbots": {"item_id": "3578809072", "tag": "chatbots"}, "deep-learning": {"item_id": "3578809072", "tag": "deep-learning"}, "machine-learning": {"item_id": "3578809072", "tag": "machine-learning"}, "nlp": {"item_id": "3578809072", "tag": "nlp"}}, "image": {"item_id": "3578809072", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--1RvfWUaY--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8auc5yhbd3ofsn3mlm9a.jpg", "width": "1000", "height": "420"}, "images": {"1": {"item_id": "3578809072", "image_id": "1", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--1RvfWUaY--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8auc5yhbd3ofsn3mlm9a.jpg", "width": "1000", "height": "420", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The Practical Dev", "logo": "https://logo.clearbit.com/dev.to?size=800", "greyscale_logo": "https://logo.clearbit.com/dev.to?size=800&greyscale=true"}, "listen_duration_estimate": 1149}, "3786537949": {"item_id": "3786537949", "resolved_id": "3786537949", "given_url": "https://dev.to/kanehooper/how-to-generate-gpt-output-in-json-format-for-ruby-developers-3g66", "given_title": "How to Generate GPT Output in JSON Format for Ruby developers", "favorite": "0", "status": "1", "time_added": "1673705157", "time_updated": "1673709872", "time_read": "1673709872", "time_favorited": "0", "sort_id": 23, "resolved_title": "How to Generate GPT Output in JSON Format for Ruby developers", "resolved_url": "https://dev.to/kanehooper/how-to-generate-gpt-output-in-json-format-for-ruby-developers-3g66", "excerpt": "I was playing around with OpenAI (GPT-3) today, building a reasonably complicated email parser for a client. I was running into issues working with the AI’s response. Because OpenAI (GPT-3) is based on a natural language model the response is always a string.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "953", "lang": "en", "time_to_read": 4, "top_image_url": "https://res.cloudinary.com/practicaldev/image/fetch/s--yBI7g7sx--/c_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7h0uf9iznpt957i5jjte.png", "tags": {"chatgpt": {"item_id": "3786537949", "tag": "chatgpt"}, "nlp": {"item_id": "3786537949", "tag": "nlp"}, "ruby": {"item_id": "3786537949", "tag": "ruby"}}, "image": {"item_id": "3786537949", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--ev6EsQqx--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7h0uf9iznpt957i5jjte.png", "width": "1000", "height": "420"}, "images": {"1": {"item_id": "3786537949", "image_id": "1", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--ev6EsQqx--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7h0uf9iznpt957i5jjte.png", "width": "1000", "height": "420", "credit": "", "caption": ""}, "2": {"item_id": "3786537949", "image_id": "2", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--PyrVTYxW--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/y2w8zhqx43yb0rt7dr86.png", "width": "880", "height": "242", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The Practical Dev", "logo": "https://logo.clearbit.com/dev.to?size=800", "greyscale_logo": "https://logo.clearbit.com/dev.to?size=800&greyscale=true"}, "listen_duration_estimate": 369}, "3131731071": {"item_id": "3131731071", "resolved_id": "3131731071", "given_url": "https://dev.to/seattledataguy/3-natural-language-processing-tools-from-aws-to-python-4g0i", "given_title": "3 Natural Language Processing Tools From AWS to Python", "favorite": "1", "status": "1", "time_added": "1601837294", "time_updated": "1604361616", "time_read": "1604361616", "time_favorited": "1604361615", "sort_id": 24, "resolved_title": "3 Natural Language Processing Tools From AWS to Python", "resolved_url": "https://dev.to/seattledataguy/3-natural-language-processing-tools-from-aws-to-python-4g0i", "excerpt": "Photo by Eric Krull on Unsplash. Parsing and processing documents can provide a lot of value for almost every department in a company. This is one of the many use cases where natural language processing (or NLP) can come in handy.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1567", "lang": "en", "time_to_read": 7, "top_image_url": "https://res.cloudinary.com/practicaldev/image/fetch/s--3gUnuga4--/c_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/i/wk3oaogumwclm8cnfzg8.jpeg", "tags": {"nlp": {"item_id": "3131731071", "tag": "nlp"}}, "image": {"item_id": "3131731071", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--soou0XgS--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/i/wk3oaogumwclm8cnfzg8.jpeg", "width": "1000", "height": "420"}, "images": {"1": {"item_id": "3131731071", "image_id": "1", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--soou0XgS--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/i/wk3oaogumwclm8cnfzg8.jpeg", "width": "1000", "height": "420", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The Practical Dev", "logo": "https://logo.clearbit.com/dev.to?size=800", "greyscale_logo": "https://logo.clearbit.com/dev.to?size=800&greyscale=true"}, "listen_duration_estimate": 607}, "3248632724": {"item_id": "3248632724", "resolved_id": "3248632724", "given_url": "https://developer.nvidia.com/blog/achieving-high-quality-search-and-recommendation-results-with-deepnlp/", "given_title": "Achieving High-Quality Search and Recommendation Results with DeepNLP", "favorite": "0", "status": "1", "time_added": "1612482220", "time_updated": "1638708525", "time_read": "1612564847", "time_favorited": "0", "sort_id": 25, "resolved_title": "Achieving High-Quality Search and Recommendation Results with DeepNLP", "resolved_url": "https://developer.nvidia.com/blog/achieving-high-quality-search-and-recommendation-results-with-deepnlp/", "excerpt": "Speech and natural language processing (NLP) have become the foundation for most of the AI development in the enterprise today, as textual data represents a significant portion of unstructured content.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2047", "lang": "en", "time_to_read": 9, "top_image_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2021/02/DeText.png", "tags": {"deep-learning": {"item_id": "3248632724", "tag": "deep-learning"}, "nlp": {"item_id": "3248632724", "tag": "nlp"}, "recommenders": {"item_id": "3248632724", "tag": "recommenders"}, "search": {"item_id": "3248632724", "tag": "search"}}, "authors": {"146399023": {"item_id": "3248632724", "author_id": "146399023", "name": "Weiwei Guo", "url": "https://developer.nvidia.com/blog/author/wguo/"}}, "image": {"item_id": "3248632724", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2021/02/DeText-625x618.png", "width": "313", "height": "309"}, "images": {"1": {"item_id": "3248632724", "image_id": "1", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2021/02/DeText-625x618.png", "width": "313", "height": "309", "credit": "", "caption": ""}, "2": {"item_id": "3248632724", "image_id": "2", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2021/02/DeText_Figure1-625x392.png", "width": "580", "height": "363", "credit": "", "caption": ""}, "3": {"item_id": "3248632724", "image_id": "3", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2021/02/DeText_Figure2-625x335.png", "width": "625", "height": "335", "credit": "", "caption": ""}, "4": {"item_id": "3248632724", "image_id": "4", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2021/02/DeText_Figure3-625x281.png", "width": "625", "height": "281", "credit": "", "caption": ""}, "5": {"item_id": "3248632724", "image_id": "5", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2021/02/DeText_Figure4.png", "width": "370", "height": "201", "credit": "", "caption": ""}, "6": {"item_id": "3248632724", "image_id": "6", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2021/02/DeText_Figure5-625x282.png", "width": "625", "height": "282", "credit": "", "caption": ""}}, "listen_duration_estimate": 792}, "2527446600": {"item_id": "2527446600", "resolved_id": "2527446600", "given_url": "https://explosion.ai/blog/spacy-v2-1", "given_title": "Introducing spaCy v2.1 · Blog · Explosion AI", "favorite": "1", "status": "1", "time_added": "1553890345", "time_updated": "1608996724", "time_read": "1554139599", "time_favorited": "1553884651", "sort_id": 26, "resolved_title": "Introducing spaCy v2.1", "resolved_url": "https://explosion.ai/blog/spacy-v2-1", "excerpt": "Version 2.1 of the spaCy Natural Language Processing library includes a huge number of features, improvements and bug fixes. In this post, we highlight some of the things we’re especially pleased with, and explain some of the most challenging parts of preparing this big release.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4078", "lang": "en", "time_to_read": 19, "top_image_url": "https://explosion.ai/static/0ac670174a723e28b644b61ae1a79725/724c8/spacy-v2-1_social.jpg", "tags": {"nlp": {"item_id": "2527446600", "tag": "nlp"}, "spacy": {"item_id": "2527446600", "tag": "spacy"}}, "authors": {"26881224": {"item_id": "2527446600", "author_id": "26881224", "name": "Matthew Honnibal", "url": ""}}, "image": {"item_id": "2527446600", "src": "https://explosion.ai/ee7cb97da2fde8dd5b3a4fcacd9f4646/spacy-v2-1_tokenization1.svg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2527446600", "image_id": "1", "src": "https://explosion.ai/ee7cb97da2fde8dd5b3a4fcacd9f4646/spacy-v2-1_tokenization1.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2527446600", "image_id": "2", "src": "https://explosion.ai/90448173fa8f9a338d5f5f6824c5b4ca/spacy-v2-1_tokenization2.svg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1579}, "2348338280": {"item_id": "2348338280", "resolved_id": "2348338280", "given_url": "https://flowingdata.com/2018/10/09/measuring-the-varied-sentiments-of-good-and-bad-words/", "given_title": "Measuring the varied sentiments of good and bad words", "favorite": "0", "status": "1", "time_added": "1539079748", "time_updated": "1609435653", "time_read": "1539372417", "time_favorited": "0", "sort_id": 27, "resolved_title": "Measuring the varied sentiments of good and bad words", "resolved_url": "https://flowingdata.com/2018/10/09/measuring-the-varied-sentiments-of-good-and-bad-words/", "excerpt": "FlowingData", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "0", "lang": "en", "top_image_url": "https://i1.wp.com/flowingdata.com/wp-content/uploads/2018/10/How-good-is-good.jpg?fit=1024%2C1112&ssl=1", "tags": {"nlp": {"item_id": "2348338280", "tag": "nlp"}, "sentiment-analysis": {"item_id": "2348338280", "tag": "sentiment-analysis"}}, "authors": {"97075242": {"item_id": "2348338280", "author_id": "97075242", "name": "a survey", "url": "https://flowingdata.com/2018/07/06/how-people-interpret-probability-through-words/"}}, "image": {"item_id": "2348338280", "src": "https://i1.wp.com/flowingdata.com/wp-content/uploads/2018/10/How-good-is-good.jpg?w=1024&ssl=1", "width": "750", "height": "814"}, "images": {"1": {"item_id": "2348338280", "image_id": "1", "src": "https://i1.wp.com/flowingdata.com/wp-content/uploads/2018/10/How-good-is-good.jpg?w=1024&ssl=1", "width": "750", "height": "814", "credit": "", "caption": ""}}, "domain_metadata": {"name": "FlowingData", "logo": "https://logo.clearbit.com/flowingdata.com?size=800", "greyscale_logo": "https://logo.clearbit.com/flowingdata.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3284119894": {"item_id": "3284119894", "resolved_id": "3284119897", "given_url": "https://gist.github.com/4730bcac4701bddaa6c7c125119c4bfb", "given_title": "Using spaCy 3.0 to build a custom NER model", "favorite": "0", "status": "1", "time_added": "1616080478", "time_updated": "1616191981", "time_read": "1616191981", "time_favorited": "0", "sort_id": 28, "resolved_title": "blog.md", "resolved_url": "https://gist.github.com/zachlim98/4730bcac4701bddaa6c7c125119c4bfb", "excerpt": "Explosion makes spaCy, a free open-source library for NLP in Python. Recently, they released an update to version 3.1 and this update changed quite a few things from v2, breaking many of the tutorials that were found on Medium previously.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "937", "lang": "en", "time_to_read": 4, "top_image_url": "https://github.githubassets.com/images/modules/gists/gist-og-image.png", "tags": {"nlp": {"item_id": "3284119894", "tag": "nlp"}, "spacy": {"item_id": "3284119894", "tag": "spacy"}}, "authors": {"55835546": {"item_id": "3284119894", "author_id": "55835546", "name": "262588213843476", "url": ""}}, "image": {"item_id": "3284119894", "src": "https://user-images.githubusercontent.com/68678549/111624482-b9118500-8826-11eb-91e2-c93cba6ac1f6.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3284119894", "image_id": "1", "src": "https://user-images.githubusercontent.com/68678549/111624482-b9118500-8826-11eb-91e2-c93cba6ac1f6.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3284119894", "image_id": "2", "src": "https://user-images.githubusercontent.com/68678549/111624344-86678c80-8826-11eb-963a-819caa75db47.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3284119894", "image_id": "3", "src": "https://user-images.githubusercontent.com/68678549/111624385-93847b80-8826-11eb-8bb1-f86307fbf523.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 363}, "1687599061": {"item_id": "1687599061", "resolved_id": "1687599061", "given_url": "https://gist.github.com/aparrish/f21f6abbf2367e8eb23438558207e1c3", "given_title": "NLP Concepts with spaCy. Code examples released under CC0 https://creativec", "favorite": "0", "status": "1", "time_added": "1519231465", "time_updated": "1611276157", "time_read": "1528501280", "time_favorited": "0", "sort_id": 29, "resolved_title": "NLP Concepts with spaCy. Code examples released under CC0 https : //creativecommons.org/choose/zero/, other text released under CC BY 4.0 https : //creativecommons.org/licenses/by/4.0/", "resolved_url": "https://gist.github.com/aparrish/f21f6abbf2367e8eb23438558207e1c3", "excerpt": "spacy_intro.ipynb Sorry, something went wrong. Reload? Sorry, we cannot display this file. Sorry, this file is invalid so it cannot be displayed. Viewer requires iframe.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "27", "lang": "en", "top_image_url": "https://github.githubassets.com/images/modules/gists/gist-og-image.png", "tags": {"nlp": {"item_id": "1687599061", "tag": "nlp"}, "spacy": {"item_id": "1687599061", "tag": "spacy"}}, "authors": {"55835546": {"item_id": "1687599061", "author_id": "55835546", "name": "262588213843476", "url": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 10}, "2121453683": {"item_id": "2121453683", "resolved_id": "2121453683", "given_url": "https://github.com/agnusmaximus/Word2Bits", "given_title": "", "favorite": "0", "status": "1", "time_added": "1521546858", "time_updated": "1638708525", "time_read": "1528501274", "time_favorited": "0", "sort_id": 30, "resolved_title": "Word2Bits - Quantized Word Vectors", "resolved_url": "https://github.com/agnusmaximus/Word2Bits", "excerpt": "Word2Bits extends the Word2Vec algorithm to output high quality quantized word vectors that take 8x-16x less storage than regular word vectors. Read the details at https://arxiv.org/abs/1803.05651. Quantized word vectors are word vectors where each parameter is one of 2^bitlevel values.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "679", "lang": "en", "time_to_read": 3, "top_image_url": "https://opengraph.githubassets.com/079027bdad6cc62d253bff6742b0931818e9351ad5957aadd02fd75882233c6d/agnusmaximus/Word2Bits", "tags": {"deep-learning": {"item_id": "2121453683", "tag": "deep-learning"}, "nlp": {"item_id": "2121453683", "tag": "nlp"}, "text": {"item_id": "2121453683", "tag": "text"}}, "image": {"item_id": "2121453683", "src": "https://github.com/agnusmaximus/Word2Bits/blob/master/images/visualize_nearest_man.png?raw=true", "width": "400", "height": "300"}, "images": {"1": {"item_id": "2121453683", "image_id": "1", "src": "https://github.com/agnusmaximus/Word2Bits/blob/master/images/visualize_nearest_man.png?raw=true", "width": "400", "height": "300", "credit": "", "caption": ""}, "2": {"item_id": "2121453683", "image_id": "2", "src": "https://github.com/agnusmaximus/Word2Bits/blob/master/images/visualize_nearest_science.png?raw=true", "width": "400", "height": "300", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 263}, "3493082056": {"item_id": "3493082056", "resolved_id": "3493082056", "given_url": "https://github.com/bjpcjp/gensim-lessons", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638239964", "time_updated": "1642376786", "time_read": "1642374687", "time_favorited": "0", "sort_id": 31, "resolved_title": "", "resolved_url": "https://github.com/bjpcjp/gensim-lessons", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"gensim": {"item_id": "3493082056", "tag": "gensim"}, "nlp": {"item_id": "3493082056", "tag": "nlp"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3493082057": {"item_id": "3493082057", "resolved_id": "3493082057", "given_url": "https://github.com/bjpcjp/NLP_workshop/blob/master/NLP_demo.ipynb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638239964", "time_updated": "1642447228", "time_read": "1642447228", "time_favorited": "0", "sort_id": 32, "resolved_title": "", "resolved_url": "https://github.com/bjpcjp/NLP_workshop/blob/master/NLP_demo.ipynb", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"github": {"item_id": "3493082057", "tag": "github"}, "nlp": {"item_id": "3493082057", "tag": "nlp"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3493082202": {"item_id": "3493082202", "resolved_id": "3493082202", "given_url": "https://github.com/bjpcjp/spaCy_hello_world/blob/master/spaCy_101.ipynb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638239964", "time_updated": "1642376783", "time_read": "1642373383", "time_favorited": "0", "sort_id": 33, "resolved_title": "", "resolved_url": "https://github.com/bjpcjp/spaCy_hello_world/blob/master/spaCy_101.ipynb", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"nlp": {"item_id": "3493082202", "tag": "nlp"}, "spacy": {"item_id": "3493082202", "tag": "spacy"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "2049895208": {"item_id": "2049895208", "resolved_id": "1549737851", "given_url": "https://github.com/explosion/spacy-notebooks/blob/master/notebooks/lightning_tour.ipynb", "given_title": "spacy-notebooks/lightning_tour.ipynb at master · explosion/spacy-notebooks", "favorite": "0", "status": "1", "time_added": "1517241939", "time_updated": "1609553444", "time_read": "1517498332", "time_favorited": "0", "sort_id": 34, "resolved_title": "spaCy Jupyter notebooks", "resolved_url": "https://github.com/explosion/spacy-notebooks", "excerpt": "An ongoing collection of Jupyter notebooks (formerly iPython notebooks) of easy-to-run spaCy examples and tutorials. To get started, simply fork or clone this repository, navigate to the new directory and run the notebook server:", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "183", "lang": "en", "top_image_url": "https://opengraph.githubassets.com/ce0b7d647c5f80e3defbdcff2c6125daebbaf768a3a5d13e9805cca074e0fc49/explosion/spacy-notebooks", "tags": {"nlp": {"item_id": "2049895208", "tag": "nlp"}, "spacy": {"item_id": "2049895208", "tag": "spacy"}}, "image": {"item_id": "2049895208", "src": "https://camo.githubusercontent.com/322f0474ab0e0976bc8922177b9c5c3cc656e8315ef8e47113a280ea00dba765/68747470733a2f2f6578706c6f73696f6e2e61692f6173736574732f696d672f6c6f676f2e737667", "width": "125", "height": "125"}, "images": {"1": {"item_id": "2049895208", "image_id": "1", "src": "https://camo.githubusercontent.com/322f0474ab0e0976bc8922177b9c5c3cc656e8315ef8e47113a280ea00dba765/68747470733a2f2f6578706c6f73696f6e2e61692f6173736574732f696d672f6c6f676f2e737667", "width": "125", "height": "125", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 71}, "3245405094": {"item_id": "3245405094", "resolved_id": "3245405094", "given_url": "https://github.com/explosion/spaCy/releases/tag/v3.0.0", "given_title": "Release v3.0.0: Transformer-based pipelines, new training system, project t", "favorite": "0", "status": "1", "time_added": "1612201107", "time_updated": "1612201117", "time_read": "1612201117", "time_favorited": "0", "sort_id": 35, "resolved_title": "Release v3.0.0 : Transformer-based pipelines, new training system, project templates, custom models, improved component API, type hints & lots more · explosion/spaCy", "resolved_url": "https://github.com/explosion/spaCy/releases/tag/v3.0.0", "excerpt": "📣NEW: Want to make the transition from spaCy v2 to spaCy v3 as smooth as possible for you and your organization? We're now offering commercial migration support for your spaCy pipelines! We've put a lot of work into making it easy to upgrade your existing code and training workflows – but custo", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1488", "lang": "en", "time_to_read": 7, "top_image_url": "https://opengraph.githubassets.com/0db1cc0d55bdc29f3832a6ad863c412a610c3bd2facb1dcb7f0c37aa0cb15a87/explosion/spaCy", "tags": {"nlp": {"item_id": "3245405094", "tag": "nlp"}, "spacy": {"item_id": "3245405094", "tag": "spacy"}}, "image": {"item_id": "3245405094", "src": "https://avatars.githubusercontent.com/u/13643239?s=40&v=4", "width": "20", "height": "20"}, "images": {"1": {"item_id": "3245405094", "image_id": "1", "src": "https://avatars.githubusercontent.com/u/13643239?s=40&v=4", "width": "20", "height": "20", "credit": "", "caption": ""}, "2": {"item_id": "3245405094", "image_id": "2", "src": "https://user-images.githubusercontent.com/13643239/106374435-ddeb8f00-6383-11eb-99f4-c2f2570d5bb7.png", "width": "300", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3245405094", "image_id": "3", "src": "https://user-images.githubusercontent.com/13643239/106374436-df1cbc00-6383-11eb-905a-d5db2ca598d3.png", "width": "300", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3245405094", "image_id": "4", "src": "https://user-images.githubusercontent.com/13643239/106374432-d926db00-6383-11eb-8b3c-5173dd5cec7d.png", "width": "300", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 576}, "3644752612": {"item_id": "3644752612", "resolved_id": "3644752612", "given_url": "https://github.com/features/copilot", "given_title": "GitHub Copilot · Your AI pair programmer", "favorite": "0", "status": "1", "time_added": "1655831659", "time_updated": "1706833159", "time_read": "1655906808", "time_favorited": "0", "sort_id": 36, "resolved_title": "Your AI pair programmer", "resolved_url": "https://github.com/features/copilot", "excerpt": "GitHub Copilot uses the OpenAI Codex to suggest code and entire functions in real-time, right from your editor.", "is_article": "1", "is_index": "1", "has_video": "1", "has_image": "0", "word_count": "18", "lang": "en", "top_image_url": "https://github.githubassets.com/images/modules/site/social-cards/copilot-ga.png", "tags": {"github": {"item_id": "3644752612", "tag": "github"}, "nlp": {"item_id": "3644752612", "tag": "nlp"}, "programming": {"item_id": "3644752612", "tag": "programming"}}, "videos": {"1": {"item_id": "3644752612", "video_id": "1", "src": "https://github.githubassets.com/images/modules/site/copilot/hero/bg@2x.hevc.mov", "width": "1920", "height": "780", "type": "5", "vid": "", "length": "0"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 7}, "2372493903": {"item_id": "2372493903", "resolved_id": "2372493903", "given_url": "https://github.com/google-research/bert", "given_title": "google-research/bert: TensorFlow code and pre-trained models for BERT", "favorite": "0", "status": "1", "time_added": "1584714536", "time_updated": "1638708525", "time_read": "1585739684", "time_favorited": "0", "sort_id": 37, "resolved_title": "BERT", "resolved_url": "https://github.com/google-research/bert", "excerpt": "This is a release of 24 smaller BERT models (English only, uncased, trained with WordPiece masking) referenced in Well-Read Students Learn Better: On the Importance of Pre-training Compact Models.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "6259", "lang": "en", "time_to_read": 28, "top_image_url": "https://opengraph.githubassets.com/a2aeea07f9f1ad16e1b95e2ee17846238b7786ecdfcbaed273edbe951bc8f84e/google-research/bert", "tags": {"bert": {"item_id": "2372493903", "tag": "bert"}, "deep-learning": {"item_id": "2372493903", "tag": "deep-learning"}, "nlp": {"item_id": "2372493903", "tag": "nlp"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 2423}, "2042828590": {"item_id": "2042828590", "resolved_id": "2042828609", "given_url": "https://github.com/hundredblocks/concrete_NLP_tutorial/blob/master/NLP_notebook.ipynb", "given_title": "concrete_NLP_tutorial/NLP_notebook.ipynb at master · hundredblocks/concrete", "favorite": "0", "status": "1", "time_added": "1516834117", "time_updated": "1609553192", "time_read": "1517511181", "time_favorited": "0", "sort_id": 38, "resolved_title": "NLP Workshop for ODSC 2017", "resolved_url": "https://github.com/hundredblocks/concrete_NLP_tutorial", "excerpt": "Feel free to follow along in this notebook, or download it and run it yourself. Instructions below. Run python -m gensim.downloader --download word2vec-google-news-300 or follow the instructions in the gensim documentation.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "68", "lang": "en", "top_image_url": "https://opengraph.githubassets.com/c26418cd323f202cf30674a524fa2fcde415bdebd4fbf0ca2abd8f12da7bfb98/hundredblocks/concrete_NLP_tutorial", "tags": {"nlp": {"item_id": "2042828590", "tag": "nlp"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 26}, "2779288222": {"item_id": "2779288222", "resolved_id": "2779288231", "given_url": "https://github.com/microsoft/nlp-recipes/blob/master/README.md", "given_title": "", "favorite": "0", "status": "1", "time_added": "1575546778", "time_updated": "1608317879", "time_read": "1576355721", "time_favorited": "0", "sort_id": 39, "resolved_title": "NLP Best Practices", "resolved_url": "https://github.com/microsoft/nlp-recipes", "excerpt": "In recent years, natural language processing (NLP) has seen quick growth in quality and usability, and this has helped to drive business adoption of artificial intelligence (AI) solutions. In the last few years, researchers have been applying newer deep learning methods to NLP.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1510", "lang": "en", "time_to_read": 7, "top_image_url": "https://opengraph.githubassets.com/63e24ddad77650e67d54a0ee40188d5a99718b592f98c0626c6f5892e2a73de4/microsoft/nlp-recipes", "tags": {"nlp": {"item_id": "2779288222", "tag": "nlp"}}, "image": {"item_id": "2779288222", "src": "https://github.com/microsoft/nlp-recipes/blob/master/NLP-Logo.png", "width": "300", "height": "0"}, "images": {"1": {"item_id": "2779288222", "image_id": "1", "src": "https://github.com/microsoft/nlp-recipes/blob/master/NLP-Logo.png", "width": "300", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2779288222", "image_id": "2", "src": "https://camo.githubusercontent.com/64631c0bf2f8b0c02a78deac3c91f8d45af5511118dbcdd5235af7215ffe34c8/68747470733a2f2f6465762e617a7572652e636f6d2f626573742d7072616374696365732f6e6c702f5f617069732f6275696c642f7374617475732f6370755f696e746567726174696f6e5f74657374735f6c696e75783f6272616e63684e616d653d6d6173746572", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2779288222", "image_id": "3", "src": "https://camo.githubusercontent.com/86854bbd5063f5a9e25bf5e6b5f1cb1c584edff016bec0fc94bf79aef9501363/68747470733a2f2f6465762e617a7572652e636f6d2f626573742d7072616374696365732f6e6c702f5f617069732f6275696c642f7374617475732f6370755f696e746567726174696f6e5f74657374735f6c696e75783f6272616e63684e616d653d73746167696e67", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2779288222", "image_id": "4", "src": "https://camo.githubusercontent.com/d0c8a35115824ee3a5aa81441708daddaffc49f4bd3ec5a26a7688321763ae7d/68747470733a2f2f6465762e617a7572652e636f6d2f626573742d7072616374696365732f6e6c702f5f617069732f6275696c642f7374617475732f6770755f696e746567726174696f6e5f74657374735f6c696e75783f6272616e63684e616d653d6d6173746572", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2779288222", "image_id": "5", "src": "https://camo.githubusercontent.com/aa8a42831de9e2c6cac6164de2574f52f85d12e7c12e22cf9d62f166f5191069/68747470733a2f2f6465762e617a7572652e636f6d2f626573742d7072616374696365732f6e6c702f5f617069732f6275696c642f7374617475732f6770755f696e746567726174696f6e5f74657374735f6c696e75783f6272616e63684e616d653d73746167696e67", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 585}, "2250998206": {"item_id": "2250998206", "resolved_id": "2250998206", "given_url": "https://github.com/mukund109/word-mesh/", "given_title": "mukund109/word-mesh: A context-preserving word cloud generator", "favorite": "0", "status": "1", "time_added": "1531145996", "time_updated": "1610141809", "time_read": "1536189793", "time_favorited": "0", "sort_id": 40, "resolved_title": "word-mesh", "resolved_url": "https://github.com/mukund109/word-mesh", "excerpt": "word-mesh A wordcloud/wordmesh generator that allows users to extract keywords from text, and create a simple and interpretable wordcloud.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "847", "lang": "en", "time_to_read": 4, "top_image_url": "https://opengraph.githubassets.com/108956b0e334165ee4e94ba2200dd22eebc83f36c66ec5210555293a2dfd3d43/mukund109/word-mesh", "tags": {"nlp": {"item_id": "2250998206", "tag": "nlp"}, "python": {"item_id": "2250998206", "tag": "python"}, "spacy": {"item_id": "2250998206", "tag": "spacy"}}, "image": {"item_id": "2250998206", "src": "https://github.com/mukund109/word-mesh/raw/master/examples/animation.gif", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2250998206", "image_id": "1", "src": "https://github.com/mukund109/word-mesh/raw/master/examples/animation.gif", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2250998206", "image_id": "2", "src": "https://github.com/mukund109/word-mesh/blob/master/examples/Jobs-speech-scores.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2250998206", "image_id": "3", "src": "https://github.com/mukund109/word-mesh/blob/master/examples/Jobs-speech-cooccurence-demo.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2250998206", "image_id": "4", "src": "https://github.com/mukund109/word-mesh/blob/master/examples/trump_hillary_debate_adj.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2250998206", "image_id": "5", "src": "https://github.com/mukund109/word-mesh/blob/master/examples/Belgium-Brazil.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2250998206", "image_id": "6", "src": "https://github.com/mukund109/word-mesh/blob/master/examples/Belgium-Brazil-cooccurence.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 328}, "3114654732": {"item_id": "3114654732", "resolved_id": "3114654732", "given_url": "https://github.com/snakers4/silero-models", "given_title": "", "favorite": "0", "status": "1", "time_added": "1655759733", "time_updated": "1691368273", "time_read": "1655776079", "time_favorited": "0", "sort_id": 41, "resolved_title": "Silero Models", "resolved_url": "https://github.com/snakers4/silero-models", "excerpt": "Silero Models: pre-trained enterprise-grade STT / TTS models and benchmarks. Enterprise-grade STT made refreshingly simple (seriously, see benchmarks). We provide quality comparable to Google's STT (and sometimes even better) and we are not Google.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1371", "lang": "en", "time_to_read": 6, "top_image_url": "https://opengraph.githubassets.com/740b5927c5f5a522d8b4d5b0f0065f1eb9f9c084ad77d6525d5d597e7bd37260/snakers4/silero-models", "tags": {"nlp": {"item_id": "3114654732", "tag": "nlp"}, "speaking": {"item_id": "3114654732", "tag": "speaking"}, "speech-recognition": {"item_id": "3114654732", "tag": "speech-recognition"}}, "image": {"item_id": "3114654732", "src": "https://camo.githubusercontent.com/469ff93c7a7abf795c79b54da7e8e8ccc45169581d0f70c742b077297ccc996a/687474703a2f2f696d672e736869656c64732e696f2f62616467652f456d61696c2d677261792e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d676d61696c", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3114654732", "image_id": "1", "src": "https://camo.githubusercontent.com/469ff93c7a7abf795c79b54da7e8e8ccc45169581d0f70c742b077297ccc996a/687474703a2f2f696d672e736869656c64732e696f2f62616467652f456d61696c2d677261792e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d676d61696c", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3114654732", "image_id": "2", "src": "https://camo.githubusercontent.com/0a6c70c93a2bd6edf6bd12b192f16b555b0d44196f1f6681b6fc2c008b984049/687474703a2f2f696d672e736869656c64732e696f2f62616467652f54656c656772616d2d626c75652e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d74656c656772616d", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3114654732", "image_id": "3", "src": "https://camo.githubusercontent.com/091b393bcffab6ba5ffac979d1eea1c5a455c992a48817543f1f3cdc1c1a82f0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d474e552532304147504c253230332e302d6c69676874677265792e7376673f7374796c653d666f722d7468652d6261646765", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3114654732", "image_id": "4", "src": "https://camo.githubusercontent.com/da016db654c9d98c3ce4413b056036b679344d0f3c6f8097de470ff44a214e6b/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f6f70656e5f7374742f74696572732f646f6e6174696f6e2f62616467652e7376673f6c6162656c3d646f6e6174696f6e7326636f6c6f723d627269676874677265656e", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3114654732", "image_id": "5", "src": "https://camo.githubusercontent.com/de9f0f92183f48ef49677fe252d6defff4c6f7118cdc7cff0fc919b2979dd82f/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f6f70656e5f7374742f74696572732f6261636b65722f62616467652e7376673f6c6162656c3d6261636b65727326636f6c6f723d627269676874677265656e", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3114654732", "image_id": "6", "src": "https://camo.githubusercontent.com/bb760f2a14832063a5c977ea940a0916e03b40c9fc528e11e6bc7f5a57dfc385/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f6f70656e5f7374742f74696572732f73706f6e736f722f62616467652e7376673f6c6162656c3d73706f6e736f727326636f6c6f723d627269676874677265656e", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3114654732", "image_id": "7", "src": "https://user-images.githubusercontent.com/12515440/89997349-b3523080-dc94-11ea-9906-ca2e8bc50535.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3114654732", "image_id": "8", "src": "https://camo.githubusercontent.com/75d9f73dc0c3c586c77cb0ccf43840f5506c4c4285a5b38410532f5290229018/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f546f7263682d4875622d7265643f6c6f676f3d7079746f726368267374796c653d666f722d7468652d6261646765", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 531}, "2632918070": {"item_id": "2632918070", "resolved_id": "2632918070", "given_url": "https://graceavery.com/word2vec-fish-music-bass/", "given_title": "Word2vec: fish   music = bass | graceavery", "favorite": "0", "status": "1", "time_added": "1562464581", "time_updated": "1638708525", "time_read": "1566341788", "time_favorited": "0", "sort_id": 42, "resolved_title": "Word2vec: fish + music = bass", "resolved_url": "https://graceavery.com/word2vec-fish-music-bass/", "excerpt": "Everyone seems to overlook how FUNNY word2vec is! GPT-2 has gotten lots of playful attention, but word2vec never had its day in the sun. Everyone mentions the example “king – man + woman = queen”, but no one mentions the delightful “yeti – snow + economics = homo economicus”.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1807", "lang": "en", "time_to_read": 8, "tags": {"deep-learning": {"item_id": "2632918070", "tag": "deep-learning"}, "nlp": {"item_id": "2632918070", "tag": "nlp"}}, "authors": {"113852009": {"item_id": "2632918070", "author_id": "113852009", "name": "grace", "url": "https://graceavery.com/author/grace/"}}, "image": {"item_id": "2632918070", "src": "https://graceavery.com/wp-content/uploads/word2vec1-1024x453.png", "width": "512", "height": "227"}, "images": {"1": {"item_id": "2632918070", "image_id": "1", "src": "https://graceavery.com/wp-content/uploads/word2vec1-1024x453.png", "width": "512", "height": "227", "credit": "", "caption": ""}, "2": {"item_id": "2632918070", "image_id": "2", "src": "https://graceavery.com/wp-content/uploads/word2vec2-1024x655.png", "width": "512", "height": "328", "credit": "", "caption": ""}}, "listen_duration_estimate": 699}, "1597226852": {"item_id": "1597226852", "resolved_id": "1597226852", "given_url": "https://huggingface.co/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1570371635", "time_updated": "1608338208", "time_read": "1576355394", "time_favorited": "0", "sort_id": 43, "resolved_title": "The AI community building the future.", "resolved_url": "https://huggingface.co/", "excerpt": "Build, train and deploy state of the art models powered by the reference open source in machine learning.", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "18", "lang": "", "top_image_url": "https://huggingface.co/front/thumbnails/v2-2.png", "tags": {"nlp": {"item_id": "1597226852", "tag": "nlp"}}, "listen_duration_estimate": 7}, "2885117488": {"item_id": "2885117488", "resolved_id": "2885117488", "given_url": "https://huggingface.co/blog/how-to-train", "given_title": "", "favorite": "0", "status": "1", "time_added": "1581772106", "time_updated": "1638708525", "time_read": "1582142974", "time_favorited": "0", "sort_id": 44, "resolved_title": "How to train a new language model from scratch using Transformers and Tokenizers", "resolved_url": "https://huggingface.co/blog/how-to-train", "excerpt": "Over the past few months, we made several improvements to our transformers and tokenizers libraries, with the goal of making it easier than ever to train a new language model from scratch.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1690", "lang": "en", "time_to_read": 8, "top_image_url": "https://huggingface.co/blog/assets/01_how-to-train/how-to-train_blogpost.png", "tags": {"deep-learning": {"item_id": "2885117488", "tag": "deep-learning"}, "nlp": {"item_id": "2885117488", "tag": "nlp"}}, "image": {"item_id": "2885117488", "src": "https://colab.research.google.com/assets/colab-badge.svg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2885117488", "image_id": "1", "src": "https://colab.research.google.com/assets/colab-badge.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2885117488", "image_id": "2", "src": "https://huggingface.co/blog/assets/01_how-to-train/eo.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2885117488", "image_id": "3", "src": "https://huggingface.co/blog/assets/01_how-to-train/oscar.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2885117488", "image_id": "4", "src": "https://huggingface.co/blog/assets/01_how-to-train/tensorboard.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2885117488", "image_id": "5", "src": "https://huggingface.co/blog/assets/01_how-to-train/conll-2003.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2885117488", "image_id": "6", "src": "https://huggingface.co/blog/assets/01_how-to-train/model_page.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 654}, "2537566309": {"item_id": "2537566309", "resolved_id": "2537566309", "given_url": "https://jalammar.github.io/illustrated-word2vec/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1553771458", "time_updated": "1612385105", "time_read": "1553882458", "time_favorited": "0", "sort_id": 45, "resolved_title": "The Illustrated Word2vec", "resolved_url": "https://jalammar.github.io/illustrated-word2vec/", "excerpt": "“There is in all things a pattern that is part of our universe. It has symmetry, elegance, and grace - those qualities you find always in that which the true artist captures.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "4391", "lang": "en", "time_to_read": 20, "tags": {"machine-learning": {"item_id": "2537566309", "tag": "machine-learning"}, "nlp": {"item_id": "2537566309", "tag": "nlp"}}, "authors": {"83096926": {"item_id": "2537566309", "author_id": "83096926", "name": "Jay Alammar", "url": ""}}, "image": {"item_id": "2537566309", "src": "http://img.youtube.com/vi/ISPId9Lhc1g/0.jpg", "width": "480", "height": "360"}, "images": {"1": {"item_id": "2537566309", "image_id": "1", "src": "http://img.youtube.com/vi/ISPId9Lhc1g/0.jpg", "width": "480", "height": "360", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "2537566309", "video_id": "1", "src": "https://www.youtube.com/embed/ISPId9Lhc1g", "width": "560", "height": "315", "type": "1", "vid": "ISPId9Lhc1g", "length": "0"}}, "listen_duration_estimate": 1700}, "3832449628": {"item_id": "3832449628", "resolved_id": "3832449628", "given_url": "https://johanwind.github.io/2023/03/23/rwkv_overview.html", "given_title": "Hacker News", "favorite": "1", "status": "1", "time_added": "1680186586", "time_updated": "1680276982", "time_read": "1680276982", "time_favorited": "1680276968", "sort_id": 46, "resolved_title": "The RWKV language model: An RNN with the advantages of a transformer", "resolved_url": "https://johanwind.github.io/2023/03/23/rwkv_overview.html", "excerpt": "For a while, I’ve been following and contributing to the RWKV language model, an open source large language model with great potential. As ChatGPT and large language models in general have gotten a lot of attention recently, I think it’s a good time to write about RWKV.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "867", "lang": "en", "time_to_read": 4, "tags": {"deep-learning": {"item_id": "3832449628", "tag": "deep-learning"}, "nlp": {"item_id": "3832449628", "tag": "nlp"}, "rnns": {"item_id": "3832449628", "tag": "rnns"}, "transformers": {"item_id": "3832449628", "tag": "transformers"}}, "image": {"item_id": "3832449628", "src": "https://johanwind.github.io/images/rwkv_benchmark.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3832449628", "image_id": "1", "src": "https://johanwind.github.io/images/rwkv_benchmark.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 336}, "1876518428": {"item_id": "1876518428", "resolved_id": "1876518428", "given_url": "https://machinethoughts.wordpress.com/2017/09/01/deep-meaning-beyond-thought-vectors/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1505357687", "time_updated": "1611284784", "time_read": "1528501391", "time_favorited": "0", "sort_id": 47, "resolved_title": "Deep Meaning Beyond Thought Vectors", "resolved_url": "https://machinethoughts.wordpress.com/2017/09/01/deep-meaning-beyond-thought-vectors/", "excerpt": "I ended my last post by saying that I might write a follow-up post on current work that seems to exhibit progress toward natural language understanding.   I am going to discuss a couple sampled papers but of course these are not the only promising papers.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1820", "lang": "en", "time_to_read": 8, "amp_url": "https://machinethoughts.wordpress.com/2017/09/01/deep-meaning-beyond-thought-vectors/amp/", "top_image_url": "https://machinethoughts.files.wordpress.com/2017/08/screen-shot-2017-08-31-at-6-21-40-pm.png", "tags": {"nlp": {"item_id": "1876518428", "tag": "nlp"}}, "authors": {"29165137": {"item_id": "1876518428", "author_id": "29165137", "name": "McAllester", "url": "https://machinethoughts.wordpress.com/author/dmcallester/"}}, "image": {"item_id": "1876518428", "src": "https://machinethoughts.files.wordpress.com/2017/08/screen-shot-2017-08-31-at-3-30-47-pm.png?w=640", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1876518428", "image_id": "1", "src": "https://machinethoughts.files.wordpress.com/2017/08/screen-shot-2017-08-31-at-3-30-47-pm.png?w=640", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1876518428", "image_id": "2", "src": "https://machinethoughts.files.wordpress.com/2017/08/screen-shot-2017-08-31-at-3-45-46-pm.png?w=640", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "1876518428", "image_id": "3", "src": "https://machinethoughts.files.wordpress.com/2017/08/screen-shot-2017-08-31-at-6-13-14-pm.png?w=640", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "1876518428", "image_id": "4", "src": "https://machinethoughts.files.wordpress.com/2017/08/screen-shot-2017-08-31-at-6-21-40-pm.png?w=640", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 705}, "2884922097": {"item_id": "2884922097", "resolved_id": "2884922097", "given_url": "https://medium.com/@lukas_1583/serving-gpt-2-in-google-cloud-platform-9ea07a69c87d", "given_title": "", "favorite": "0", "status": "1", "time_added": "1581818862", "time_updated": "1638708525", "time_read": "1581818879", "time_favorited": "0", "sort_id": 48, "resolved_title": "Serving GPT-2 in Google Cloud Platform", "resolved_url": "https://medium.com/@lukas_1583/serving-gpt-2-in-google-cloud-platform-9ea07a69c87d", "excerpt": "Our mission at Deepdesk is to unburden contact centers by applying AI. We provide real time response recommendations (think Smart Compose), and automation of repetitive dialogs. We do this by training Machine Learning models with actual conversations.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "743", "lang": "en", "time_to_read": 3, "top_image_url": "https://miro.medium.com/max/1080/1*tI33WFWKB6VyEj__mmolkw.jpeg", "tags": {"deep-learning": {"item_id": "2884922097", "tag": "deep-learning"}, "nlp": {"item_id": "2884922097", "tag": "nlp"}}, "authors": {"128425585": {"item_id": "2884922097", "author_id": "128425585", "name": "Lukas Batteau", "url": "https://medium.com/@lukas_1583"}}, "image": {"item_id": "2884922097", "src": "https://miro.medium.com/max/2160/1*tI33WFWKB6VyEj__mmolkw.jpeg", "width": "1080", "height": "675"}, "images": {"1": {"item_id": "2884922097", "image_id": "1", "src": "https://miro.medium.com/max/2160/1*tI33WFWKB6VyEj__mmolkw.jpeg", "width": "1080", "height": "675", "credit": "", "caption": ""}, "2": {"item_id": "2884922097", "image_id": "2", "src": "https://miro.medium.com/max/4982/1*k9k9vHSTMbq05zLvLDfy5Q.jpeg", "width": "2491", "height": "780", "credit": "", "caption": ""}, "3": {"item_id": "2884922097", "image_id": "3", "src": "https://miro.medium.com/max/1600/1*cgA9c-1cZylUderYmjCHjw.png", "width": "400", "height": "226", "credit": "", "caption": ""}, "4": {"item_id": "2884922097", "image_id": "4", "src": "https://miro.medium.com/max/3608/1*8QQXaOCYMbDv5gpu5sZWaA.png", "width": "1804", "height": "272", "credit": "", "caption": ""}, "5": {"item_id": "2884922097", "image_id": "5", "src": "https://miro.medium.com/max/2692/1*RMihOIP0_GPSreMYvAmjgg.jpeg", "width": "1346", "height": "427", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 288}, "2609365987": {"item_id": "2609365987", "resolved_id": "2609365987", "given_url": "https://medium.com/eliiza-ai/a-tour-of-awesome-features-of-spacy-part-1-2-58b32425954f", "given_title": "A tour of awesome features of spaCy (part 1/2) – Eliiza-AI – Medium", "favorite": "0", "status": "1", "time_added": "1561957869", "time_updated": "1608576038", "time_read": "1566877614", "time_favorited": "0", "sort_id": 49, "resolved_title": "A tour of awesome features of spaCy (part 1/2)", "resolved_url": "https://medium.com/eliiza-ai/a-tour-of-awesome-features-of-spacy-part-1-2-58b32425954f", "excerpt": "A few weeks ago I started working on a text summarisation project and I needed a Natural Language Processing library with comprehensive features. The project had several potentially computationally expensive components where I wanted to try out different things.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1144", "lang": "", "top_image_url": "https://miro.medium.com/max/1200/1*vc7ZrlbLFYg316e5RtOBRg.png", "tags": {"nlp": {"item_id": "2609365987", "tag": "nlp"}}, "authors": {"103132012": {"item_id": "2609365987", "author_id": "103132012", "name": "Nuszk", "url": "https://medium.com/@anamamatelashvili"}}, "image": {"item_id": "2609365987", "src": "https://miro.medium.com/max/1600/1*vc7ZrlbLFYg316e5RtOBRg.png", "width": "700", "height": "269"}, "images": {"1": {"item_id": "2609365987", "image_id": "1", "src": "https://miro.medium.com/max/1600/1*vc7ZrlbLFYg316e5RtOBRg.png", "width": "700", "height": "269", "credit": "", "caption": ""}, "2": {"item_id": "2609365987", "image_id": "2", "src": "https://miro.medium.com/max/1600/1*FVLg_nIrFKuX0vk-kl6EXw.png", "width": "700", "height": "42", "credit": "", "caption": ""}, "3": {"item_id": "2609365987", "image_id": "3", "src": "https://miro.medium.com/max/1600/1*PhFYSBFFD3FXMgjTIHUqyg.png", "width": "700", "height": "41", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 443}, "2609388613": {"item_id": "2609388613", "resolved_id": "2609388613", "given_url": "https://medium.com/eliiza-ai/a-tour-of-awesome-features-of-spacy-part-2-2-d7bd628a81ce", "given_title": "A tour of awesome features of spaCy (part 2/2) - Eliiza-AI - Medium", "favorite": "0", "status": "1", "time_added": "1564431883", "time_updated": "1608569301", "time_read": "1566339956", "time_favorited": "0", "sort_id": 50, "resolved_title": "A tour of awesome features of spaCy (part 2/2)", "resolved_url": "https://medium.com/eliiza-ai/a-tour-of-awesome-features-of-spacy-part-2-2-d7bd628a81ce", "excerpt": "In the first part of this overview of spaCy we went over the features of the large English pretrained model that spaCy comes with. In this part I would like to discuss using pretraining to transfer learning to subsequent machine learning tasks. Full code for the post can be found on GitHub.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "925", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/max/1200/1*xGYsNSBR3oILg24XFR3RdA.png", "tags": {"nlp": {"item_id": "2609388613", "tag": "nlp"}}, "authors": {"103132012": {"item_id": "2609388613", "author_id": "103132012", "name": "Nuszk", "url": "https://medium.com/@anamamatelashvili"}}, "image": {"item_id": "2609388613", "src": "https://miro.medium.com/max/4120/1*xGYsNSBR3oILg24XFR3RdA.png", "width": "2060", "height": "752"}, "images": {"1": {"item_id": "2609388613", "image_id": "1", "src": "https://miro.medium.com/max/4120/1*xGYsNSBR3oILg24XFR3RdA.png", "width": "2060", "height": "752", "credit": "", "caption": ""}, "2": {"item_id": "2609388613", "image_id": "2", "src": "https://miro.medium.com/max/1600/1*_URZ6WwErqFQ9x-rwXVZJQ.png", "width": "700", "height": "320", "credit": "", "caption": ""}, "3": {"item_id": "2609388613", "image_id": "3", "src": "https://miro.medium.com/max/1600/1*RF7GE6gOxHtNeldIP9yJXA.png", "width": "700", "height": "487", "credit": "", "caption": ""}, "4": {"item_id": "2609388613", "image_id": "4", "src": "https://miro.medium.com/max/1600/1*YQRkJ8fdXFEwbF3W52FUTQ.png", "width": "700", "height": "487", "credit": "", "caption": ""}, "5": {"item_id": "2609388613", "image_id": "5", "src": "https://miro.medium.com/max/1600/1*fNkVuhVvBBre_dOiRf3xqQ.png", "width": "700", "height": "493", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 358}, "2302178486": {"item_id": "2302178486", "resolved_id": "2132141089", "given_url": "https://medium.com/machine-learning-in-practice/over-150-of-the-best-machine-learning-nlp-and-python-tutorials-ive-found-ffce2939bd78#hn", "given_title": "Over 150 of the Best Machine Learning, NLP, and Python Tutorials I’ve Found", "favorite": "1", "status": "1", "time_added": "1582773536", "time_updated": "1638708525", "time_read": "1583785007", "time_favorited": "1582773706", "sort_id": 51, "resolved_title": "Over 150 of the Best Machine Learning, NLP, and Python Tutorials I’ve Found", "resolved_url": "https://medium.com/machine-learning-in-practice/over-150-of-the-best-machine-learning-nlp-and-python-tutorials-ive-found-ffce2939bd78", "excerpt": "While machine learning has a rich history dating back to 1959, the field is evolving at an unprecedented rate. In a recent article, I discussed why the broader artificial intelligence field is booming and likely will for some time to come.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1673", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1200/1*R8bEkSHE65EpgwmA_H0ABA.png", "tags": {"deep-learning": {"item_id": "2302178486", "tag": "deep-learning"}, "machine-learning": {"item_id": "2302178486", "tag": "machine-learning"}, "nlp": {"item_id": "2302178486", "tag": "nlp"}}, "authors": {"143598617": {"item_id": "2302178486", "author_id": "143598617", "name": "Robbie Allen", "url": "https://robbieallen.medium.com"}}, "image": {"item_id": "2302178486", "src": "https://miro.medium.com/fit/c/96/96/2*pMKzIh-dW5etk_Gfrh0tXw.jpeg", "width": "48", "height": "48"}, "images": {"1": {"item_id": "2302178486", "image_id": "1", "src": "https://miro.medium.com/fit/c/96/96/2*pMKzIh-dW5etk_Gfrh0tXw.jpeg", "width": "48", "height": "48", "credit": "", "caption": ""}, "2": {"item_id": "2302178486", "image_id": "2", "src": "https://miro.medium.com/max/2548/1*R8bEkSHE65EpgwmA_H0ABA.png", "width": "1274", "height": "1043", "credit": "", "caption": "Einstein’s desk a few hours after his death. Source: LIFE Magazine"}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 648}, "3106397394": {"item_id": "3106397394", "resolved_id": "3106397394", "given_url": "https://medium.com/rapids-ai/state-of-the-art-nlp-at-scale-with-rapids-huggingface-and-dask-a885c19ce87b", "given_title": "", "favorite": "0", "status": "1", "time_added": "1617461903", "time_updated": "1638708525", "time_read": "1617546158", "time_favorited": "0", "sort_id": 52, "resolved_title": "State of the art NLP at scale with RAPIDS, HuggingFace and Dask", "resolved_url": "https://medium.com/rapids-ai/state-of-the-art-nlp-at-scale-with-rapids-huggingface-and-dask-a885c19ce87b", "excerpt": "Modern natural language processing (NLP) mixes modeling, feature engineering, and general text processing. Deep learning NLP models can provide fantastic performance for tasks like named-entity recognition (NER), sentiment classification, and text summarization.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1016", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/0*w9WCIHyMuQ9h5Pee", "tags": {"dask": {"item_id": "3106397394", "tag": "dask"}, "deep-learning": {"item_id": "3106397394", "tag": "deep-learning"}, "gpus": {"item_id": "3106397394", "tag": "gpus"}, "nlp": {"item_id": "3106397394", "tag": "nlp"}, "nvidia": {"item_id": "3106397394", "tag": "nvidia"}}, "authors": {"138755693": {"item_id": "3106397394", "author_id": "138755693", "name": "Vibhu Jawa", "url": "https://medium.com/@vibhujawa"}}, "image": {"item_id": "3106397394", "src": "https://miro.medium.com/max/2550/1*E99P4x4anW9ziECVSqO1xQ.png", "width": "1275", "height": "203"}, "images": {"1": {"item_id": "3106397394", "image_id": "1", "src": "https://miro.medium.com/max/2550/1*E99P4x4anW9ziECVSqO1xQ.png", "width": "1275", "height": "203", "credit": "", "caption": ""}, "2": {"item_id": "3106397394", "image_id": "2", "src": "https://miro.medium.com/max/1742/0*eCtirKVYGeEZjmg4", "width": "871", "height": "521", "credit": "", "caption": "NLP workflow using Rapids and HuggingFace"}, "3": {"item_id": "3106397394", "image_id": "3", "src": "https://miro.medium.com/max/3096/0*w9WCIHyMuQ9h5Pee", "width": "1548", "height": "1082", "credit": "", "caption": "Example of NER in action from https://huggingface.co/dslim/bert-base-NER"}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 393}, "2532354906": {"item_id": "2532354906", "resolved_id": "2532354906", "given_url": "https://monkeylearn.com/blog/aspect-based-sentiment-analysis/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1553293264", "time_updated": "1638708525", "time_read": "1567115034", "time_favorited": "0", "sort_id": 53, "resolved_title": "Guide to Aspect-Based Sentiment Analysis", "resolved_url": "https://monkeylearn.com/blog/aspect-based-sentiment-analysis/", "excerpt": "If you thought sentiment analysis was pretty neat, then prepare to be blown away by an even more advanced text analysis technique: aspect-based sentiment analysis.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2605", "lang": "en", "time_to_read": 12, "top_image_url": "https://monkeylearn.com/static/4688cdc9da9b930344235a2b7bddee91/Aspect-based-Sentiment-Analysis-Social-2.png", "tags": {"deep-learning": {"item_id": "2532354906", "tag": "deep-learning"}, "nlp": {"item_id": "2532354906", "tag": "nlp"}, "sentiment-analysis": {"item_id": "2532354906", "tag": "sentiment-analysis"}}, "image": {"item_id": "2532354906", "src": "https://d33wubrfki0l68.cloudfront.net/a0a5c4df5927c34145ea7d3e1cf300e6f9bd514a/e4e45/static/b8a7bff833a6c47d89d6d2d7e38a162d/28bdc/opinion_unit-ex.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2532354906", "image_id": "1", "src": "https://d33wubrfki0l68.cloudfront.net/a0a5c4df5927c34145ea7d3e1cf300e6f9bd514a/e4e45/static/b8a7bff833a6c47d89d6d2d7e38a162d/28bdc/opinion_unit-ex.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2532354906", "image_id": "2", "src": "https://d33wubrfki0l68.cloudfront.net/bc9678968ad4312215b45f083cf92df9546c980e/f10af/static/8169d032170501bd0382eb263a3b6d9c/ca7fb/choose-model.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2532354906", "image_id": "3", "src": "https://d33wubrfki0l68.cloudfront.net/9a451c0030099ce793b6dab7ed5879d8ee05583e/f9022/static/f36fed41a39dc01c3f5b692ca95e7d1d/04dd0/choose-classification.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2532354906", "image_id": "4", "src": "https://d33wubrfki0l68.cloudfront.net/6aaf42c9bd34b8136386db31f3ce9116b725ae50/1e642/static/acda0e37460c38fe24e23fee942766ca/ca7fb/import-data.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2532354906", "image_id": "5", "src": "https://d33wubrfki0l68.cloudfront.net/a9875a6a41cb28a078c9b03f7ee9dad23e11fc28/9c73b/static/fa738dc0169d5e94f9d46ebb0ae818ac/52c6a/e0738a3a91694929969f652f7115adfd.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2532354906", "image_id": "6", "src": "https://d33wubrfki0l68.cloudfront.net/2c9bf2f815f0d3f128c02bacbf13d50c6cab0f58/9860e/static/568bc978ee522ab5ccd3c5b8bf64fc8f/42cbc/d65c65dbd3e74fef89cbe6eb5b8918cb.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2532354906", "image_id": "7", "src": "https://d33wubrfki0l68.cloudfront.net/33fc3edc0d5b00288db9973a9a969d6dec8b2229/2e79a/static/d34feee0f45961e3fc6acc0a63627533/5f864/define-tags.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2532354906", "image_id": "8", "src": "https://d33wubrfki0l68.cloudfront.net/2c9bf2f815f0d3f128c02bacbf13d50c6cab0f58/ba80b/static/568bc978ee522ab5ccd3c5b8bf64fc8f/42cbc/61c7bb0b5dd24c4caaf420dd5b5dbeab.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2532354906", "image_id": "9", "src": "https://d33wubrfki0l68.cloudfront.net/def9be6edbd19b5d2e02c84c33fe13adce9132bf/0fa5c/static/5899e3902d303d7239fca4b930e0b77f/ac7a9/ml-studio.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1008}, "2853842311": {"item_id": "2853842311", "resolved_id": "2853835317", "given_url": "https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools?utm_source=linkedin&utm_medium=post&utm_campaign=blog-eda-nlp-tools&utm_content=blog", "given_title": "", "favorite": "0", "status": "1", "time_added": "1579111234", "time_updated": "1608264358", "time_read": "1582142817", "time_favorited": "0", "sort_id": 54, "resolved_title": "Exploratory Data Analysis for Natural Language Processing: A Complete Guide to Python Tools", "resolved_url": "https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools", "excerpt": "Exploratory data analysis is one of the most important parts of any machine learning workflow and Natural Language Processing is no different. But which tools you should choose to explore and visualize text data efficiently?", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "3738", "lang": "en", "time_to_read": 17, "amp_url": "https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools/amp", "top_image_url": "https://neptune.ai/wp-content/uploads/Exploratory-Data-Analysis-for-Natural-Language-Processing.jpg", "tags": {"nlp": {"item_id": "2853842311", "tag": "nlp"}}, "image": {"item_id": "2853842311", "src": "https://i2.wp.com/neptune.ai/wp-content/uploads/output1.png?fit=979%2C146&ssl=1", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2853842311", "image_id": "1", "src": "https://i2.wp.com/neptune.ai/wp-content/uploads/output1.png?fit=979%2C146&ssl=1", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2853842311", "image_id": "2", "src": "https://i1.wp.com/neptune.ai/wp-content/uploads/output2.png?fit=691%2C131&ssl=1", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2853842311", "image_id": "3", "src": "https://i0.wp.com/neptune.ai/wp-content/uploads/output3.png?fit=764%2C172&ssl=1", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2853842311", "image_id": "4", "src": "https://i0.wp.com/neptune.ai/wp-content/uploads/output4.png?fit=787%2C52&ssl=1", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2853842311", "image_id": "5", "src": "https://i1.wp.com/neptune.ai/wp-content/uploads/news_image.png?fit=658%2C495&ssl=1", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2853842311", "image_id": "6", "src": "https://i1.wp.com/neptune.ai/wp-content/uploads/output7.png?fit=785%2C103&ssl=1", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2853842311", "image_id": "7", "src": "https://i0.wp.com/neptune.ai/wp-content/uploads/output9.png?fit=786%2C133&ssl=1", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2853842311", "image_id": "8", "src": "https://i1.wp.com/neptune.ai/wp-content/uploads/output11.png?fit=788%2C139&ssl=1", "width": "0", "height": "0", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "2853842311", "video_id": "1", "src": "https://neptune.ai/wp-content/uploads/pyldavis-1.mp4", "width": "0", "height": "0", "type": "5", "vid": "", "length": "0"}}, "listen_duration_estimate": 1447}, "1776203289": {"item_id": "1776203289", "resolved_id": "1776203289", "given_url": "https://opendatascience.com/blog/topic-modeling-with-lda-introduction/", "given_title": "Topic Modeling with LDA Introduction", "favorite": "0", "status": "1", "time_added": "1496952418", "time_updated": "1612385105", "time_read": "1514398171", "time_favorited": "0", "sort_id": 55, "resolved_title": "Open Data Science - Your Data Science and AI News Source", "resolved_url": "https://opendatascience.com/blog/topic-modeling-with-lda-introduction/", "excerpt": "Organizations need to update their Go-To-Market (GTM) strategies to include external data and data architectures need to evolve to better incorporate external data into data pipelines.", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "622", "lang": "en", "time_to_read": 3, "top_image_url": "https://opendatascience.com/wp-content/uploads/goliath/highresodsclogo.png", "tags": {"lda": {"item_id": "1776203289", "tag": "lda"}, "machine-learning": {"item_id": "1776203289", "tag": "machine-learning"}, "nlp": {"item_id": "1776203289", "tag": "nlp"}}, "image": {"item_id": "1776203289", "src": "https://opendatascience.com/wp-content/uploads/2022/12/books-gf35ce9151_640.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1776203289", "image_id": "1", "src": "https://opendatascience.com/wp-content/uploads/2022/12/books-gf35ce9151_640.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1776203289", "image_id": "2", "src": "https://opendatascience.com/wp-content/uploads/2022/12/tftop-70x70.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "1776203289", "image_id": "3", "src": "https://opendatascience.com/wp-content/uploads/2022/12/boston-g9afdbd173_640-70x70.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "1776203289", "image_id": "4", "src": "https://opendatascience.com/wp-content/uploads/2022/12/toptalks-70x70.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "1776203289", "image_id": "5", "src": "https://opendatascience.com/wp-content/uploads/2022/11/Bris-542-70x70.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "1776203289", "image_id": "6", "src": "https://opendatascience.com/wp-content/uploads/2022/11/Kay-2-70x70.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "1776203289", "image_id": "7", "src": "https://opendatascience.com/wp-content/uploads/2022/12/restop.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "1776203289", "image_id": "8", "src": "https://opendatascience.com/wp-content/uploads/2022/12/AdobeStock_81889030-70x70.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "1776203289", "image_id": "9", "src": "https://opendatascience.com/wp-content/uploads/2022/12/mltopnew-70x70.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "1776203289", "image_id": "10", "src": "https://opendatascience.com/wp-content/uploads/2022/12/JTtop-70x70.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "1776203289", "image_id": "11", "src": "https://opendatascience.com/wp-content/uploads/2022/12/matplot-70x70.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "1776203289", "image_id": "12", "src": "https://opendatascience.com/wp-content/uploads/2022/12/trexttop-70x70.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "1776203289", "image_id": "13", "src": "https://opendatascience.com/wp-content/uploads/2022/11/tst-70x70.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "1776203289", "image_id": "14", "src": "https://opendatascience.com/wp-content/uploads/2022/12/Untitled-design-10.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "1776203289", "image_id": "15", "src": "https://opendatascience.com/wp-content/uploads/2022/12/Untitled-design-9-70x70.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "1776203289", "image_id": "16", "src": "https://opendatascience.com/wp-content/uploads/2022/12/Untitled-design-8-70x70.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "1776203289", "image_id": "17", "src": "https://opendatascience.com/wp-content/uploads/2022/12/aigeneratedart-70x70.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "1776203289", "image_id": "18", "src": "https://opendatascience.com/wp-content/uploads/2022/12/toptalks.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "1776203289", "image_id": "19", "src": "https://opendatascience.com/wp-content/uploads/wordpress-popular-posts/40770-featured-75x75.png", "width": "75", "height": "75", "credit": "", "caption": "The Ten Most Important Data Science GitHub Repositories for 2022"}, "20": {"item_id": "1776203289", "image_id": "20", "src": "https://opendatascience.com/wp-content/uploads/wordpress-popular-posts/40732-featured-75x75.png", "width": "75", "height": "75", "credit": "", "caption": "Enabling Resilient Machine Learning Systems"}, "21": {"item_id": "1776203289", "image_id": "21", "src": "https://opendatascience.com/wp-content/uploads/wordpress-popular-posts/33353-featured-75x75.jpg", "width": "75", "height": "75", "credit": "", "caption": "What is Pruning in Machine Learning?"}, "22": {"item_id": "1776203289", "image_id": "22", "src": "https://opendatascience.com/wp-content/uploads/2022/10/man-hacker-coding-html-and-programming-on-screen-l-RH74UW6-750x491.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "23": {"item_id": "1776203289", "image_id": "23", "src": "https://opendatascience.com/wp-content/uploads/2021/09/hiring-3535383_640-70x70.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "1776203289", "image_id": "24", "src": "https://opendatascience.com/wp-content/uploads/2022/10/money-gd9af2cf5d_640-70x70.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "1776203289", "image_id": "25", "src": "https://opendatascience.com/wp-content/uploads/2022/09/hiring-gc754b3716_640-640x300-1-70x70.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "26": {"item_id": "1776203289", "image_id": "26", "src": "https://opendatascience.com/wp-content/uploads/2022/09/edited_DSC_0773-copy-70x70.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "27": {"item_id": "1776203289", "image_id": "27", "src": "https://opendatascience.com/wp-content/uploads/2022/09/programmer-using-laptop-and-pc-information-coding-7MQUQ2T-1-70x70.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "28": {"item_id": "1776203289", "image_id": "28", "src": "https://opendatascience.com/wp-content/uploads/2022/08/people-gc156bb546_640-70x70.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 241}, "2475751064": {"item_id": "2475751064", "resolved_id": "2475751064", "given_url": "https://paperswithcode.com/task/sentiment-analysis", "given_title": "Browse the State-of-the-Art in Machine Learning | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572893", "time_updated": "1608572902", "time_read": "1608572902", "time_favorited": "0", "sort_id": 56, "resolved_title": "Sentiment Analysis", "resolved_url": "https://paperswithcode.com/task/sentiment-analysis", "excerpt": "Sentiment analysis is the task of classifying the polarity of a given text. For instance, a text-based tweet can be categorized into either \"positive\", \"negative\", or \"neutral\". Given the text and accompanying labels, a model can be trained to predict the correct sentiment.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "125", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/sentiment-analysis.png", "tags": {"nlp": {"item_id": "2475751064", "tag": "nlp"}, "sentiment-analysis": {"item_id": "2475751064", "tag": "sentiment-analysis"}}, "image": {"item_id": "2475751064", "src": "https://paperswithcode.com/media/sota-thumbs/sentiment-analysis-multi-domain-sentimen-small_6324e3d1.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2475751064", "image_id": "1", "src": "https://paperswithcode.com/media/sota-thumbs/sentiment-analysis-multi-domain-sentimen-small_6324e3d1.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2475751064", "image_id": "2", "src": "https://paperswithcode.com/media/sota-thumbs/sentiment-analysis-binary-classification2-small_de2e991f.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2475751064", "image_id": "3", "src": "https://paperswithcode.com/media/sota-thumbs/sentiment-analysis-fine-grained-classifi-small_cf319796.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2475751064", "image_id": "4", "src": "https://paperswithcode.com/media/sota-thumbs/sentiment-analysis-semeval-small_7ae45c26.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2475751064", "image_id": "5", "src": "https://paperswithcode.com/media/sota-thumbs/machine-translation-german-to-english-iw-small_64989c26.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 48}, "1845073823": {"item_id": "1845073823", "resolved_id": "1845073823", "given_url": "https://prodi.gy/", "given_title": "Prodigy - Radically efficient machine teaching", "favorite": "0", "status": "1", "time_added": "1517243653", "time_updated": "1706830781", "time_read": "1517498413", "time_favorited": "0", "sort_id": 57, "resolved_title": "Prodigy · An annotation tool for AI, Machine Learning & NLP", "resolved_url": "https://prodi.gy", "excerpt": "✨ Starting the web server on port 8080... Open the app in your browser and start annotating! Prodigy is a scriptable annotation tool so efficient that data scientists can do the annotation themselves, enabling a new level of rapid iteration.", "is_article": "0", "is_index": "1", "has_video": "1", "has_image": "1", "word_count": "741", "lang": "en", "time_to_read": 3, "top_image_url": "https://prodi.gy/static/social_light-5104af7729ee2f7f9b1ebaa1adaefe3d.jpg", "tags": {"nlp": {"item_id": "1845073823", "tag": "nlp"}, "text": {"item_id": "1845073823", "tag": "text"}}, "image": {"item_id": "1845073823", "src": "http://img.youtube.com/vi/59BKHO_xBPA/0.jpg", "width": "480", "height": "360"}, "images": {"1": {"item_id": "1845073823", "image_id": "1", "src": "http://img.youtube.com/vi/59BKHO_xBPA/0.jpg", "width": "480", "height": "360", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "1845073823", "video_id": "1", "src": "https://www.youtube-nocookie.com/embed/59BKHO_xBPA?color=white&modestbranding=1&rel=0", "width": "560", "height": "315", "type": "1", "vid": "59BKHO_xBPA", "length": "0"}}, "listen_duration_estimate": 287}, "1946236250": {"item_id": "1946236250", "resolved_id": "1946236250", "given_url": "https://radimrehurek.com/gensim/models/fasttext.html", "given_title": "", "favorite": "1", "status": "1", "time_added": "1516842174", "time_updated": "1609553182", "time_read": "1517594970", "time_favorited": "1517594968", "sort_id": 58, "resolved_title": "Gensim : topic modelling for humans", "resolved_url": "https://radimrehurek.com/gensim/models/fasttext.html", "excerpt": "Learn word representations via fastText: Enriching Word Vectors with Subword Information. This module allows training word embeddings from a training corpus with the additional ability to obtain word vectors for out-of-vocabulary words.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "5919", "lang": "en", "time_to_read": 27, "top_image_url": "https://radimrehurek.com/gensim/_static/images/Gensim-OG-Image.jpg", "tags": {"gensim": {"item_id": "1946236250", "tag": "gensim"}, "nlp": {"item_id": "1946236250", "tag": "nlp"}}, "listen_duration_estimate": 2291}, "4003433946": {"item_id": "4003433946", "resolved_id": "4003433946", "given_url": "https://shyam.blog/posts/beyond-self-attention/", "given_title": "Beyond Self-Attention: How a Small Language Model Predicts the Next Token", "favorite": "0", "status": "1", "time_added": "1707098922", "time_updated": "1708582784", "time_read": "1708582784", "time_favorited": "0", "sort_id": 59, "resolved_title": "Beyond Self-Attention: How a Small Language Model Predicts the Next Token", "resolved_url": "https://shyam.blog/posts/beyond-self-attention", "excerpt": "I trained a small (~10 million parameter) transformer following Andrej Karpathy’s excellent tutorial, Let’s build GPT: from scratch, in code, spelled out. After getting it working, I wanted to understand, as deeply as possible, what it was doing internally and how it produced its results.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "19701", "lang": "", "tags": {"llms": {"item_id": "4003433946", "tag": "llms"}, "nlp": {"item_id": "4003433946", "tag": "nlp"}}, "image": {"item_id": "4003433946", "src": "https://shyam.blog/posts/images/a9f2adc6c1c25ebb263caf42df37f4429c4ed44eda0a0a228cba52b7a00aeb9d.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "4003433946", "image_id": "1", "src": "https://shyam.blog/posts/images/a9f2adc6c1c25ebb263caf42df37f4429c4ed44eda0a0a228cba52b7a00aeb9d.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "4003433946", "image_id": "2", "src": "https://shyam.blog/posts/images/72a30adc39ebf5f278c0a257fb46f26e6d666d113736e36ce394db587110260c.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "4003433946", "image_id": "3", "src": "https://shyam.blog/posts/images/b8214cdd1f6c9466bb984529984c757d780148fb4fe44bfed7714216e12bff73.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "4003433946", "image_id": "4", "src": "https://shyam.blog/posts/images/170aed320bd4ab2e2647d8d1ef50b499b215ce1905cff1b5db6fe78dd83c3df3.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "4003433946", "image_id": "5", "src": "https://shyam.blog/posts/images/c04c3fbe83a543ea834691f8ef6c5ecdee18522f3e3e456cd9ea81209eb60b00.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "4003433946", "image_id": "6", "src": "https://shyam.blog/posts/images/e9c543696d0748c74bccfac0780e9e6a5cd7610dafc6e650fb5dab2192fc8399.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "4003433946", "image_id": "7", "src": "https://shyam.blog/posts/images/d01e3755f6278cc6f19ae5656ab3ba6fd7b4ecb59c69303db814b6cc43fb0435.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "4003433946", "image_id": "8", "src": "https://shyam.blog/posts/images/02bddd27aedd082ab84a2b5dd45dacae4e745dc49ed363df5725916e4b370844.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "4003433946", "image_id": "9", "src": "https://shyam.blog/posts/images/d82fe84ec51461c861f5fbc1c2c273935d4d8ac8ceceaeeb292d79cd5fb9ee19.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "4003433946", "image_id": "10", "src": "https://shyam.blog/posts/images/c0b6c591002c7e1f931a0bcc794b88454aab02158d1125bef2f8422dbc0e8264.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "4003433946", "image_id": "11", "src": "https://shyam.blog/posts/images/12e04e2fdd477aaa55660b4020a4ae6b9a72c55038f98009049330cfecfc4291.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "4003433946", "image_id": "12", "src": "https://shyam.blog/posts/images/24b90fb31e5e330043b12b6a3b0bf9e8bed15bbd4cd57e98f0cbdc4b393fc71f.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "4003433946", "image_id": "13", "src": "https://shyam.blog/posts/images/7fff50753ede8a54541e69eaf00215ea285f523817e8361d1fe08ac5e0c6cd8a.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "4003433946", "image_id": "14", "src": "https://shyam.blog/posts/images/a90c56ba1e72733d29a614671ad61789b5196562087c1464273da469843cb54d.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "4003433946", "image_id": "15", "src": "https://shyam.blog/posts/images/ecc30428196c016ef2970ee406b6ea46a79a2a24c1521d8843c2dc90f83ffc83.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "4003433946", "image_id": "16", "src": "https://shyam.blog/posts/images/4c4339d5f6612480cf52b0d34f2c1732c99485033c1196076543f86ec0925af5.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "4003433946", "image_id": "17", "src": "https://shyam.blog/posts/images/0dce2cb6b27518fe0a1a26685995c9050cf791b48cc4e407a080182039905dca.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "4003433946", "image_id": "18", "src": "https://shyam.blog/posts/images/37991d03eeb45809255009149e32de771715221bb9d315efb6e2aa78b26a897c.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "4003433946", "image_id": "19", "src": "https://shyam.blog/posts/images/04a243b63386cc0e853d350cb0177eeb33f2c15d2aacdaf59ddb4dc38f48b444.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "4003433946", "image_id": "20", "src": "https://shyam.blog/posts/images/a32cb4b311513c8c1bbb0af5cae1d68b1e96efeddfbde076f8e9fca02772d605.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "4003433946", "image_id": "21", "src": "https://shyam.blog/posts/images/211fa3aed3f5cbbe1a5adf41e014e27068c39ffaf21aff36c833a851b500e211.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "4003433946", "image_id": "22", "src": "https://shyam.blog/posts/images/0a46316fd1ec97000bed4b44242e7aad0809b16acd65a98507ff1b987e313291.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "23": {"item_id": "4003433946", "image_id": "23", "src": "https://shyam.blog/posts/images/fb2e608eb48c085de00f28831641ff4d49f7f3fd63b198fc3fc08d02a3cc7c45.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "4003433946", "image_id": "24", "src": "https://shyam.blog/posts/images/ec5755d7859f77e55c3bf34a432c33226741616e9b493b5eec96c716ac1e7fe5.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "4003433946", "image_id": "25", "src": "https://shyam.blog/posts/images/968e8e424522937d5366586abd902715e1cdf771fddbb2d4a36144cbe07746e2.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 7626}, "3759768466": {"item_id": "3759768466", "resolved_id": "3759768466", "given_url": "https://stratechery.com/2022/ai-homework/", "given_title": "AI Homework – Stratechery by Ben Thompson", "favorite": "0", "status": "1", "time_added": "1670275949", "time_updated": "1670454534", "time_read": "1670454533", "time_favorited": "0", "sort_id": 60, "resolved_title": "AI Homework", "resolved_url": "https://stratechery.com/2022/ai-homework/", "excerpt": "It happened to be Wednesday night when my daughter, in the midst of preparing for “The Trial of Napoleon” for her European history class, asked for help in her role as Thomas Hobbes, witness for the defense.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3331", "lang": "en", "time_to_read": 15, "top_image_url": "https://i0.wp.com/stratechery.com/wp-content/uploads/2020/03/Stratechery-2020-03-11-23.03.59.png?fit=1200%2C811&ssl=1", "tags": {"chatgpt": {"item_id": "3759768466", "tag": "chatgpt"}, "deep-learning": {"item_id": "3759768466", "tag": "deep-learning"}, "language-linguistics": {"item_id": "3759768466", "tag": "language-linguistics"}, "nlp": {"item_id": "3759768466", "tag": "nlp"}}, "authors": {"33685485": {"item_id": "3759768466", "author_id": "33685485", "name": "Ben Thompson", "url": "https://stratechery.com/author/stratechery/"}}, "image": {"item_id": "3759768466", "src": "https://149384716.v2.pressablecdn.com/wp-content/uploads/2022/09/stratechery-update-marketing.png", "width": "600", "height": "600"}, "images": {"1": {"item_id": "3759768466", "image_id": "1", "src": "https://149384716.v2.pressablecdn.com/wp-content/uploads/2022/09/stratechery-update-marketing.png", "width": "600", "height": "600", "credit": "", "caption": ""}, "2": {"item_id": "3759768466", "image_id": "2", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-9.png?resize=640%2C508&ssl=1", "width": "640", "height": "508", "credit": "", "caption": ""}, "3": {"item_id": "3759768466", "image_id": "3", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-1.png?resize=640%2C295&ssl=1", "width": "640", "height": "295", "credit": "", "caption": ""}, "4": {"item_id": "3759768466", "image_id": "4", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-2.png?resize=640%2C262&ssl=1", "width": "640", "height": "262", "credit": "", "caption": ""}, "5": {"item_id": "3759768466", "image_id": "5", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-3.png?resize=640%2C567&ssl=1", "width": "640", "height": "567", "credit": "", "caption": ""}, "6": {"item_id": "3759768466", "image_id": "6", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-4.png?resize=640%2C528&ssl=1", "width": "640", "height": "528", "credit": "", "caption": ""}, "7": {"item_id": "3759768466", "image_id": "7", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-5.png?resize=640%2C237&ssl=1", "width": "640", "height": "237", "credit": "", "caption": ""}, "8": {"item_id": "3759768466", "image_id": "8", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-6.png?resize=640%2C251&ssl=1", "width": "640", "height": "251", "credit": "", "caption": ""}, "9": {"item_id": "3759768466", "image_id": "9", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-7.png?resize=640%2C285&ssl=1", "width": "640", "height": "285", "credit": "", "caption": ""}, "10": {"item_id": "3759768466", "image_id": "10", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-8.png?resize=640%2C335&ssl=1", "width": "640", "height": "335", "credit": "", "caption": ""}, "11": {"item_id": "3759768466", "image_id": "11", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2020/03/Stratechery-2020-03-11-23.03.59.png?resize=640%2C433&ssl=1", "width": "640", "height": "433", "credit": "", "caption": ""}, "12": {"item_id": "3759768466", "image_id": "12", "src": "https://149384716.v2.pressablecdn.com/wp-content/uploads/2022/09/stratechery-interviews-marketing.png", "width": "600", "height": "600", "credit": "", "caption": ""}, "13": {"item_id": "3759768466", "image_id": "13", "src": "https://149384716.v2.pressablecdn.com/wp-content/uploads/2022/09/dithering-marketing.png", "width": "600", "height": "600", "credit": "", "caption": ""}, "14": {"item_id": "3759768466", "image_id": "14", "src": "https://149384716.v2.pressablecdn.com/wp-content/uploads/2022/09/sharptech-marketing-2.png", "width": "600", "height": "600", "credit": "", "caption": ""}, "15": {"item_id": "3759768466", "image_id": "15", "src": "https://149384716.v2.pressablecdn.com/wp-content/uploads/2022/10/Sharp-China-Yellow-1024x1024.png", "width": "667", "height": "667", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Stratechery", "logo": "https://logo.clearbit.com/stratechery.com?size=800", "greyscale_logo": "https://logo.clearbit.com/stratechery.com?size=800&greyscale=true"}, "listen_duration_estimate": 1289}, "3627136730": {"item_id": "3627136730", "resolved_id": "3627136735", "given_url": "https://t.co/HiVTXNmIFZ?ssr=true", "given_title": "", "favorite": "0", "status": "1", "time_added": "1653640945", "time_updated": "1653689211", "time_read": "1653689211", "time_favorited": "0", "sort_id": 61, "resolved_title": "Using Linguistic Features - spaCy shorts", "resolved_url": "https://www.youtube.com/watch?v=BoyLPiXXEYA", "excerpt": "When you're just getting started it might be more pragmatic to leverage linguistic features than to immediately train a machine learning pipeline. In this video, we demonstrate how you might be able to use these features to find products that people purchased from customer service logs. \n\nTHIS TUTOR", "is_article": "0", "is_index": "0", "has_video": "2", "has_image": "1", "word_count": "0", "lang": "en", "tags": {"nlp": {"item_id": "3627136730", "tag": "nlp"}, "spacy": {"item_id": "3627136730", "tag": "spacy"}}, "authors": {"123507371": {"item_id": "3627136730", "author_id": "123507371", "name": "Explosion", "url": "https://www.youtube.com/channel/UCFduT4kW_eLDbEW6XoA5F0A"}}, "image": {"item_id": "3627136730", "src": "https://i.ytimg.com/vi/BoyLPiXXEYA/mqdefault.jpg", "width": "320", "height": "180"}, "images": {"1": {"item_id": "3627136730", "image_id": "1", "src": "https://i.ytimg.com/vi/BoyLPiXXEYA/mqdefault.jpg", "width": "320", "height": "180", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "3627136730", "video_id": "1", "src": "http://www.youtube.com/watch?v=BoyLPiXXEYA", "width": "0", "height": "0", "type": "1", "vid": "BoyLPiXXEYA", "length": "597"}}, "domain_metadata": {"name": "YouTube", "logo": "https://logo.clearbit.com/youtube.com?size=800", "greyscale_logo": "https://logo.clearbit.com/youtube.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3210738206": {"item_id": "3210738206", "resolved_id": "3210738206", "given_url": "https://theaisummer.com/transformer/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1621036985", "time_updated": "1638708525", "time_read": "1621356967", "time_favorited": "0", "sort_id": 62, "resolved_title": "How Transformers work in deep learning and NLP: an intuitive introduction", "resolved_url": "https://theaisummer.com/transformer/", "excerpt": "The famous paper “Attention is all you need” in 2017 changed the way we were thinking about attention. With enough data, matrix multiplications, linear layers, and layer normalization we can perform state-of-the-art-machine-translation.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "3778", "lang": "en", "time_to_read": 17, "top_image_url": "https://theaisummer.com/static/6122618d7e1466853e88473ba375cdc7/ee604/transformer.png", "tags": {"deep-learning": {"item_id": "3210738206", "tag": "deep-learning"}, "nlp": {"item_id": "3210738206", "tag": "nlp"}, "transformers": {"item_id": "3210738206", "tag": "transformers"}}, "authors": {"136374887": {"item_id": "3210738206", "author_id": "136374887", "name": "Nikolas Adaloglou", "url": "https://theaisummer.com/author/Nikolas-Adaloglou/"}}, "image": {"item_id": "3210738206", "src": "https://theaisummer.com/static/c9a851690a62f1faaf054430ca35ab20/c7dcc/tokenization.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3210738206", "image_id": "1", "src": "https://theaisummer.com/static/c9a851690a62f1faaf054430ca35ab20/c7dcc/tokenization.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3210738206", "image_id": "2", "src": "https://theaisummer.com/static/257848131da90edbf099aa8c4bf392c4/27524/input-processing-tokenization-embedding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3210738206", "image_id": "3", "src": "https://theaisummer.com/static/a662e9c10a5401d1bd1ccdce52dfdbd6/eb645/positional-encoding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3210738206", "image_id": "4", "src": "https://theaisummer.com/static/2e000851b686eb35c6c3c06522437715/26a94/attention-as-database-query.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3210738206", "image_id": "5", "src": "https://theaisummer.com/static/ebfe1b1dbab018e608a77f85457e52db/16caa/vector-similarity.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3210738206", "image_id": "6", "src": "https://theaisummer.com/static/4022cf02281d234e0e85fa44ad08b4e2/9f933/self-attention-probability-score-matrix.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3210738206", "image_id": "7", "src": "https://theaisummer.com/static/56773616d30b9dcb31aa792f2d701276/3096d/key-query-value.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3210738206", "image_id": "8", "src": "https://theaisummer.com/static/3ed7199184645f3e632d17ab6441244f/63a68/layer-norm.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3210738206", "image_id": "9", "src": "https://theaisummer.com/static/f6068bcb3559a017af003c2bde071bcf/e3b18/encoders-attention-with-normalizarion.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3210738206", "image_id": "10", "src": "https://theaisummer.com/static/dc71435f329458ee5cc09cb2ea09ebf8/7bc0b/encoder-without-multi-head.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3210738206", "image_id": "11", "src": "https://theaisummer.com/static/9dc2e417714211a5166ece483b862d75/442cb/parallel-multi-head-attention.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3210738206", "image_id": "12", "src": "https://theaisummer.com/static/bba48bd14e38ede88ac1cacd8a638d6d/a4078/multi-head-attention.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3210738206", "image_id": "13", "src": "https://theaisummer.com/static/18072c01858310b080b3b6d9b4950175/e45a9/encoder.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "3210738206", "image_id": "14", "src": "https://theaisummer.com/static/7d6c2aa7af90f14cf44d533cbf88726e/8ff13/decoder.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1462}, "3489021339": {"item_id": "3489021339", "resolved_id": "3489021339", "given_url": "https://thecleverprogrammer.com/2021/11/24/add-labels-to-a-dataset-for-sentiment-analysis/", "given_title": "Add Labels to a Dataset for Sentiment Analysis", "favorite": "0", "status": "1", "time_added": "1637779746", "time_updated": "1638137577", "time_read": "1638137577", "time_favorited": "0", "sort_id": 63, "resolved_title": "Add Labels to a Dataset for Sentiment Analysis", "resolved_url": "https://thecleverprogrammer.com/2021/11/24/add-labels-to-a-dataset-for-sentiment-analysis/", "excerpt": "A data scientist has to spend a lot of time preparing a dataset for any data science task because the data we get has a lot of errors, and sometimes it is not labeled. Adding labels to a dataset is very important before you can use it to solve a problem.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "469", "lang": "en", "top_image_url": "https://thecleverprogrammer.com/wp-content/uploads/2021/11/Learn-to-Add-Labels-to-Unlabeled-Data-for-Sentiment-Analysis.png", "tags": {"labeling": {"item_id": "3489021339", "tag": "labeling"}, "nlp": {"item_id": "3489021339", "tag": "nlp"}, "sentiment-analysis": {"item_id": "3489021339", "tag": "sentiment-analysis"}}, "authors": {"2481845": {"item_id": "3489021339", "author_id": "2481845", "name": "Facebook", "url": ""}}, "listen_duration_estimate": 182}, "3123102629": {"item_id": "3123102629", "resolved_id": "3123102629", "given_url": "https://thegradient.pub/ai-democratization-in-the-era-of-gpt-3/", "given_title": "AI Democratization in the Era of GPT-3", "favorite": "0", "status": "1", "time_added": "1601114010", "time_updated": "1638708525", "time_read": "1604362158", "time_favorited": "0", "sort_id": 64, "resolved_title": "AI Democratization in the Era of GPT-3", "resolved_url": "https://thegradient.pub/ai-democratization-in-the-era-of-gpt-3/", "excerpt": "On September 22nd, Microsoft announced that “Microsoft is teaming up with OpenAI to exclusively license GPT-3”.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1816", "lang": "en", "time_to_read": 8, "top_image_url": "https://thegradient.pub/content/images/2020/09/main.jpg", "tags": {"bert": {"item_id": "3123102629", "tag": "bert"}, "deep-learning": {"item_id": "3123102629", "tag": "deep-learning"}, "nlp": {"item_id": "3123102629", "tag": "nlp"}}, "listen_duration_estimate": 703}, "2251535572": {"item_id": "2251535572", "resolved_id": "2251535572", "given_url": "https://thegradient.pub/nlp-imagenet/", "given_title": "https://thegradient.pub/nlp-imagenet/", "favorite": "0", "status": "1", "time_added": "1531302138", "time_updated": "1609455245", "time_read": "1531660209", "time_favorited": "0", "sort_id": 65, "resolved_title": "NLP's ImageNet moment has arrived", "resolved_url": "https://thegradient.pub/nlp-imagenet/", "excerpt": "Big changes are underway in the world of Natural Language Processing (NLP). The long reign of word vectors as NLP’s core representation technique has seen an exciting new line of challengers emerge: ELMo[1], ULMFiT[2], and the OpenAI transformer[3].", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2983", "lang": "en", "time_to_read": 14, "top_image_url": "https://thegradient.pub/content/images/2018/07/lm-objective.png", "tags": {"nlp": {"item_id": "2251535572", "tag": "nlp"}}, "image": {"item_id": "2251535572", "src": "https://thegradient.pub/content/images/2018/07/image_0.png", "width": "450", "height": "0"}, "images": {"1": {"item_id": "2251535572", "image_id": "1", "src": "https://thegradient.pub/content/images/2018/07/image_0.png", "width": "450", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2251535572", "image_id": "2", "src": "https://thegradient.pub/content/images/2018/07/image_1.png", "width": "450", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2251535572", "image_id": "3", "src": "https://thegradient.pub/content/images/2018/07/image_2.png", "width": "450", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2251535572", "image_id": "4", "src": "https://thegradient.pub/content/images/2018/07/image_3.png", "width": "450", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2251535572", "image_id": "5", "src": "https://thegradient.pub/content/images/2018/07/image_4.png", "width": "450", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2251535572", "image_id": "6", "src": "https://thegradient.pub/content/images/2018/07/image_5-1.png", "width": "450", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2251535572", "image_id": "7", "src": "https://thegradient.pub/content/images/2018/07/image_6-1.png", "width": "450", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2251535572", "image_id": "8", "src": "https://thegradient.pub/content/images/2018/07/image_7.png", "width": "450", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2251535572", "image_id": "9", "src": "https://thegradient.pub/content/images/2018/07/image_8.png", "width": "450", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2251535572", "image_id": "10", "src": "https://thegradient.pub/content/images/2018/07/image_9.png", "width": "450", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2251535572", "image_id": "11", "src": "https://thegradient.pub/content/images/2018/07/image_10.png", "width": "450", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1155}, "3118473699": {"item_id": "3118473699", "resolved_id": "3118473699", "given_url": "https://thenextweb.com/neural/2020/09/21/ai-devs-created-a-lean-mean-gpt-3-beating-machine-that-uses-99-9-fewer-parameters/", "given_title": "AI devs created a lean, mean, GPT-3-beating machine that uses 99.9% fewer p", "favorite": "0", "status": "1", "time_added": "1600721897", "time_updated": "1671724937", "time_read": "1604362443", "time_favorited": "0", "sort_id": 66, "resolved_title": "AI devs created a lean, mean, GPT-3-beating machine that uses 99.9% fewer parameters", "resolved_url": "https://thenextweb.com/neural/2020/09/21/ai-devs-created-a-lean-mean-gpt-3-beating-machine-that-uses-99-9-fewer-parameters/", "excerpt": "AI researchers from the Ludwig Maximilian University (LMU) of Munich have developed a bite-sized text generator capable of besting OpenAI‘s state of the art GPT-3 using only a tiny fraction of its parameters.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "417", "lang": "en", "amp_url": "https://thenextweb.com/neural/2020/09/21/ai-devs-created-a-lean-mean-gpt-3-beating-machine-that-uses-99-9-fewer-parameters/amp/", "top_image_url": "https://img-cdn.tnwcdn.com/image/neural?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2017%2F07%2Frobots.jpg&signature=5fcc857cf86c3835a880c08cf8a93783", "tags": {"bert": {"item_id": "3118473699", "tag": "bert"}, "chatbots": {"item_id": "3118473699", "tag": "chatbots"}, "deep-learning": {"item_id": "3118473699", "tag": "deep-learning"}, "nlp": {"item_id": "3118473699", "tag": "nlp"}}, "authors": {"89295889": {"item_id": "3118473699", "author_id": "89295889", "name": "Tristan Greene", "url": "https://thenextweb.com/author/tristangreen"}}, "image": {"item_id": "3118473699", "src": "https://img-cdn.tnwcdn.com/image?fit=1280%2C720&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2017%2F07%2Frobots.jpg&signature=68c051012433431a2dcc7fcb04f7a374", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3118473699", "image_id": "1", "src": "https://img-cdn.tnwcdn.com/image?fit=1280%2C720&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2017%2F07%2Frobots.jpg&signature=68c051012433431a2dcc7fcb04f7a374", "width": "0", "height": "0", "credit": "Rog01", "caption": ""}}, "domain_metadata": {"name": "The Next Web", "logo": "https://logo.clearbit.com/thenextweb.com?size=800", "greyscale_logo": "https://logo.clearbit.com/thenextweb.com?size=800&greyscale=true"}, "listen_duration_estimate": 161}, "3338137195": {"item_id": "3338137195", "resolved_id": "3338137195", "given_url": "https://thenextweb.com/news/understanding-transformers-the-machine-learning-model-behind-gpt-3-machine-learning-ai-syndication", "given_title": "Understanding Transformers, the machine learning model behind GPT-3", "favorite": "0", "status": "1", "time_added": "1621684487", "time_updated": "1671724937", "time_read": "1621693599", "time_favorited": "0", "sort_id": 67, "resolved_title": "Understanding Transformers, the machine learning model behind GPT-3", "resolved_url": "https://thenextweb.com/news/understanding-transformers-the-machine-learning-model-behind-gpt-3-machine-learning-ai-syndication", "excerpt": "You know that expression When you have a hammer, everything looks like a nail? Well, in machine learning, it seems like we really have discovered a magical hammer for which everything is, in fact, a nail, and they’re called Transformers.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2012", "lang": "en", "time_to_read": 9, "amp_url": "https://thenextweb.com/news/understanding-transformers-the-machine-learning-model-behind-gpt-3-machine-learning-ai-syndication/amp", "top_image_url": "https://img-cdn.tnwcdn.com/image/neural?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2021%2F05%2FAI-Transformers-abstract-hed.jpg&signature=7dad3d13328b212e6fc49afed1eb2819", "tags": {"chatbots": {"item_id": "3338137195", "tag": "chatbots"}, "deep-learning": {"item_id": "3338137195", "tag": "deep-learning"}, "nlp": {"item_id": "3338137195", "tag": "nlp"}, "transformers": {"item_id": "3338137195", "tag": "transformers"}}, "authors": {"64134674": {"item_id": "3338137195", "author_id": "64134674", "name": "Dale Markowitz", "url": ""}}, "image": {"item_id": "3338137195", "src": "https://img-cdn.tnwcdn.com/image?fit=1280%2C720&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2021%2F05%2FAI-Transformers-abstract-hed.jpg&signature=0bc21b935991e6805f4be8f370556d70", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3338137195", "image_id": "1", "src": "https://img-cdn.tnwcdn.com/image?fit=1280%2C720&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2021%2F05%2FAI-Transformers-abstract-hed.jpg&signature=0bc21b935991e6805f4be8f370556d70", "width": "0", "height": "0", "credit": "", "caption": "Image by: Shutterstock"}, "2": {"item_id": "3338137195", "image_id": "2", "src": "https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2021/05/renn.png", "width": "2880", "height": "960", "credit": "RNN", "caption": "A typical Recurrent Neural Network"}, "3": {"item_id": "3338137195", "image_id": "3", "src": "https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2021/05/screen-shot-2021-05-06-at-12.12.21-pm-1.png", "width": "1024", "height": "1416", "credit": "", "caption": "Transformer diagram from the original paper"}}, "domain_metadata": {"name": "The Next Web", "logo": "https://logo.clearbit.com/thenextweb.com?size=800", "greyscale_logo": "https://logo.clearbit.com/thenextweb.com?size=800&greyscale=true"}, "listen_duration_estimate": 779}, "2916170851": {"item_id": "2916170851", "resolved_id": "2916170851", "given_url": "https://tldrthis.com/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1584276641", "time_updated": "1638708525", "time_read": "1585739737", "time_favorited": "0", "sort_id": 68, "resolved_title": "Summarize any in a click.", "resolved_url": "https://tldrthis.com/", "excerpt": "TLDR This helps you summarize any piece of text into concise, easy to digest content so you can free yourself from information overload. INTRODUCING OUR ✨ NEW ✨ PARAPHRASING TOOL We know how hard it is to find the right voice for your audience.", "is_article": "0", "is_index": "1", "has_video": "1", "has_image": "1", "word_count": "433", "lang": "en", "top_image_url": "https://tldrthis.com/static/images/tldrthis-krishna.jpg", "tags": {"deep-learning": {"item_id": "2916170851", "tag": "deep-learning"}, "nlp": {"item_id": "2916170851", "tag": "nlp"}}, "image": {"item_id": "2916170851", "src": "https://tldrthis.com/static/images/landing/harvard.svg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2916170851", "image_id": "1", "src": "https://tldrthis.com/static/images/landing/harvard.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2916170851", "image_id": "2", "src": "https://tldrthis.com/static/images/landing/stanford.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2916170851", "image_id": "3", "src": "https://tldrthis.com/static/images/landing/mit.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2916170851", "image_id": "4", "src": "https://tldrthis.com/static/images/landing/ucl.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2916170851", "image_id": "5", "src": "https://tldrthis.com/static/images/landing/cambridge.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2916170851", "image_id": "6", "src": "https://tldrthis.com/static/images/landing/toronto.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2916170851", "image_id": "7", "src": "https://tldrthis.com/static/images/landing/auckland.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2916170851", "image_id": "8", "src": "https://tldrthis.com/static/images/landing/auto_summary.png", "width": "528", "height": "396", "credit": "", "caption": ""}, "9": {"item_id": "2916170851", "image_id": "9", "src": "https://tldrthis.com/static/images/landing/article_metadata.png", "width": "300", "height": "200", "credit": "", "caption": ""}, "10": {"item_id": "2916170851", "image_id": "10", "src": "https://tldrthis.com/static/images/landing/distraction_free.png", "width": "528", "height": "396", "credit": "", "caption": ""}, "11": {"item_id": "2916170851", "image_id": "11", "src": "https://tldrthis.com/static/images/landing/harekrishna.png", "width": "528", "height": "396", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "2916170851", "video_id": "1", "src": "https://tldrthis.com/static/videos/tldrthis-narad.mp4", "width": "0", "height": "0", "type": "5", "vid": "", "length": "0"}}, "listen_duration_estimate": 168}, "3250473658": {"item_id": "3250473658", "resolved_id": "3250470714", "given_url": "https://towardsdatascience.com/10-nlp-terms-every-data-scientist-should-know-43d3291643c0?source=rss----7f60cf5620c9---4", "given_title": "10 NLP Terms Every Data Scientist Should Know", "favorite": "0", "status": "1", "time_added": "1612699076", "time_updated": "1706633668", "time_read": "1612731440", "time_favorited": "0", "sort_id": 69, "resolved_title": "10 NLP Terms Every Data Scientist Should Know", "resolved_url": "https://towardsdatascience.com/10-nlp-terms-every-data-scientist-should-know-43d3291643c0", "excerpt": "Sara A. Metwalli When you decide to learn a new skill, there are often multiple challenges that you need to overcome until you master that skill.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1736", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1200/0*SVjnJ82jWSbE7Vac", "tags": {"glossaries": {"item_id": "3250473658", "tag": "glossaries"}, "nlp": {"item_id": "3250473658", "tag": "nlp"}, "text": {"item_id": "3250473658", "tag": "text"}}, "authors": {"141607202": {"item_id": "3250473658", "author_id": "141607202", "name": "Sara A. Metwalli", "url": "https://saraametwalli.medium.com"}}, "image": {"item_id": "3250473658", "src": "https://miro.medium.com/fit/c/56/56/1*BY6sCRisdVuk5GyPL_q7rw.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3250473658", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*BY6sCRisdVuk5GyPL_q7rw.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3250473658", "image_id": "2", "src": "https://miro.medium.com/max/2000/0*SVjnJ82jWSbE7Vac", "width": "1000", "height": "667", "credit": "Raphael Schaller on Unsplash", "caption": ""}, "3": {"item_id": "3250473658", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*vBXSks6jyJc_PfINSnnYuA.png", "width": "700", "height": "306", "credit": "made using Canva", "caption": "Image by the author"}, "4": {"item_id": "3250473658", "image_id": "4", "src": "https://miro.medium.com/max/406/0*3TbxvL8G5B9TQ__1", "width": "203", "height": "19", "credit": "", "caption": ""}, "5": {"item_id": "3250473658", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*oMvhe-OoDnwkcc-7GirU7w.png", "width": "700", "height": "367", "credit": "made using Canva", "caption": "Image by the author"}, "6": {"item_id": "3250473658", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*1PI3cLYRg6v8mwE4hnF4sw.png", "width": "700", "height": "208", "credit": "made using Canva", "caption": "Image by the author"}, "7": {"item_id": "3250473658", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*ngEM2gXF8DTjdf8kpzw5_A.png", "width": "700", "height": "319", "credit": "made using Canva", "caption": "Image by the author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 672}, "3244764736": {"item_id": "3244764736", "resolved_id": "3244764748", "given_url": "https://towardsdatascience.com/12-twitter-sentiment-analysis-algorithms-compared-23e2d2c63d90?source=rss----7f60cf5620c9---4", "given_title": "12 Twitter Sentiment Analysis Algorithms Compared", "favorite": "0", "status": "1", "time_added": "1612135854", "time_updated": "1672661751", "time_read": "1612206824", "time_favorited": "0", "sort_id": 70, "resolved_title": "12 Twitter Sentiment Analysis Algorithms Compared", "resolved_url": "https://towardsdatascience.com/12-twitter-sentiment-analysis-algorithms-compared-23e2d2c63d90", "excerpt": "Sentiment analysis is used to determine if the sentiment in a piece of text is positive, negative, or neutral. Sentiment analysis is a form of natural language processing and is part of a subcategory of NLP techniques known as information extraction.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1711", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1200/0*kJawLKlRt398g2xy.jpg", "tags": {"benchmarks": {"item_id": "3244764736", "tag": "benchmarks"}, "nlp": {"item_id": "3244764736", "tag": "nlp"}, "sentiment-analysis": {"item_id": "3244764736", "tag": "sentiment-analysis"}, "twitter": {"item_id": "3244764736", "tag": "twitter"}}, "authors": {"143247225": {"item_id": "3244764736", "author_id": "143247225", "name": "Steve Shwartz", "url": "https://sshwartz.medium.com"}}, "image": {"item_id": "3244764736", "src": "https://miro.medium.com/fit/c/56/56/1*MIpbYP4_VauLiIJj3yqAMg.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3244764736", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*MIpbYP4_VauLiIJj3yqAMg.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3244764736", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*kJawLKlRt398g2xy.jpg", "width": "700", "height": "467", "credit": "", "caption": "Photo: Farknot Architect / iStockPhoto"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 662}, "3843379627": {"item_id": "3843379627", "resolved_id": "3843379627", "given_url": "https://towardsdatascience.com/4-ways-of-question-answering-in-langchain-188c6707cc5a", "given_title": "4 Ways to Do Question Answering in LangChain", "favorite": "0", "status": "1", "time_added": "1681147626", "time_updated": "1706833159", "time_read": "1681438078", "time_favorited": "0", "sort_id": 71, "resolved_title": "4 Ways to Do Question Answering in LangChain", "resolved_url": "https://towardsdatascience.com/4-ways-of-question-answering-in-langchain-188c6707cc5a", "excerpt": "Are you interested in chatting with your own documents, whether it is a text file, a PDF, or a website? LangChain makes it easy for you to do question answering with your documents.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1248", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*7T_1_MmNT7KxDIbPxr-zdw.jpeg", "tags": {"langchain": {"item_id": "3843379627", "tag": "langchain"}, "nlp": {"item_id": "3843379627", "tag": "nlp"}, "pdfs": {"item_id": "3843379627", "tag": "pdfs"}, "programming": {"item_id": "3843379627", "tag": "programming"}}, "authors": {"144787845": {"item_id": "3843379627", "author_id": "144787845", "name": "Sophia Yang", "url": "https://sophiamyang.medium.com"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 483}, "3235122757": {"item_id": "3235122757", "resolved_id": "3235118943", "given_url": "https://towardsdatascience.com/6-nlp-techniques-every-data-scientist-should-know-7cdea012e5c3?source=rss----7f60cf5620c9---4", "given_title": "6 NLP Techniques Every Data Scientist Should Know", "favorite": "0", "status": "1", "time_added": "1611225590", "time_updated": "1706633668", "time_read": "1611235389", "time_favorited": "0", "sort_id": 72, "resolved_title": "6 NLP Techniques Every Data Scientist Should Know", "resolved_url": "https://towardsdatascience.com/6-nlp-techniques-every-data-scientist-should-know-7cdea012e5c3", "excerpt": "Sara A. Metwalli Natural language processing is perhaps the most talked-about subfield of data science. It’s interesting, it’s promising, and it can transform the way we see technology today. Not just technology, but it can also transform the way we perceive human languages.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1487", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/1200/0*sHsN9tN8foiCv0f8", "tags": {"glossaries": {"item_id": "3235122757", "tag": "glossaries"}, "nlp": {"item_id": "3235122757", "tag": "nlp"}}, "authors": {"141607202": {"item_id": "3235122757", "author_id": "141607202", "name": "Sara A. Metwalli", "url": "https://saraametwalli.medium.com"}}, "image": {"item_id": "3235122757", "src": "https://miro.medium.com/fit/c/56/56/1*BY6sCRisdVuk5GyPL_q7rw.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3235122757", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*BY6sCRisdVuk5GyPL_q7rw.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3235122757", "image_id": "2", "src": "https://miro.medium.com/max/12000/0*sHsN9tN8foiCv0f8", "width": "6000", "height": "4000", "credit": "Sai Kiran Anagani on Unsplash", "caption": ""}, "3": {"item_id": "3235122757", "image_id": "3", "src": "https://miro.medium.com/max/4450/1*9QnH8llyI9hEqllyx1TxVQ.png", "width": "2225", "height": "932", "credit": "", "caption": "Image by the author, made using Canva"}, "4": {"item_id": "3235122757", "image_id": "4", "src": "https://miro.medium.com/max/4446/1*wK3686AUz6HwmeTB8YtmEw.png", "width": "2223", "height": "529", "credit": "", "caption": "Image by the author, made using Canva"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 576}, "3688457669": {"item_id": "3688457669", "resolved_id": "3688457689", "given_url": "https://towardsdatascience.com/7-spacy-features-to-boost-your-nlp-pipelines-and-save-time-9e12d18c3742?source=rss----7f60cf5620c9---4", "given_title": "7  spaCy Features To Boost Your NLP Pipelines And Save Time", "favorite": "0", "status": "1", "time_added": "1661360058", "time_updated": "1661360528", "time_read": "1661360527", "time_favorited": "0", "sort_id": 73, "resolved_title": "7 spaCy Features To Boost Your NLP Pipelines And Save Time", "resolved_url": "https://towardsdatascience.com/7-spacy-features-to-boost-your-nlp-pipelines-and-save-time-9e12d18c3742", "excerpt": "While I was working on an NLP project lately, I came to revisit the spaCy library and try out many of its core functionalities to perform low-level linguistic tasks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2174", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/max/1200/0*G_zd_szVbx_kB3s_", "tags": {"nlp": {"item_id": "3688457669", "tag": "nlp"}, "python": {"item_id": "3688457669", "tag": "python"}, "spacy": {"item_id": "3688457669", "tag": "spacy"}}, "authors": {"154826635": {"item_id": "3688457669", "author_id": "154826635", "name": "Ahmed Besbes", "url": "https://ahmedbesbes.medium.com"}}, "image": {"item_id": "3688457669", "src": "https://miro.medium.com/max/1400/0*G_zd_szVbx_kB3s_", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3688457669", "image_id": "1", "src": "https://miro.medium.com/max/1400/0*G_zd_szVbx_kB3s_", "width": "0", "height": "0", "credit": "Lucas Kapla on Unsplash", "caption": ""}, "2": {"item_id": "3688457669", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*Msgw6gAoy9nwK7cCXCYECg.png", "width": "0", "height": "0", "credit": "", "caption": "Screenshot by the author"}, "3": {"item_id": "3688457669", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*X8pER9LXL2oLIevZQ-U_IQ.png", "width": "0", "height": "0", "credit": "", "caption": "Screenshot by the author"}, "4": {"item_id": "3688457669", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*mBh3LcrS3MaCvAEH1bJgpQ.png", "width": "0", "height": "0", "credit": "", "caption": "Screenshot by the author"}, "5": {"item_id": "3688457669", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*0u9Gv7zQ_fN_F7PNLj1jzg.png", "width": "0", "height": "0", "credit": "", "caption": "Screenshot by the author"}, "6": {"item_id": "3688457669", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*hUD13XbN03L7s3ZdCe049w.png", "width": "0", "height": "0", "credit": "", "caption": "Screenshot by the author"}, "7": {"item_id": "3688457669", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*WAkuDmnqemLO4LSz0K23kQ.png", "width": "0", "height": "0", "credit": "", "caption": "Screenshot by the author"}, "8": {"item_id": "3688457669", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*zWHsnB0Xjf9YQt26c1FHjg.png", "width": "0", "height": "0", "credit": "", "caption": "Screenshot by the author"}, "9": {"item_id": "3688457669", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*299HCxXxwfvEybJ6nrhNgg.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 842}, "3178955873": {"item_id": "3178955873", "resolved_id": "3178955890", "given_url": "https://towardsdatascience.com/a-beginners-guide-to-use-bert-for-the-first-time-2e99b8c5423?source=rss----7f60cf5620c9---4", "given_title": "A Beginner’s Guide to Use BERT for the First Time", "favorite": "0", "status": "1", "time_added": "1605880848", "time_updated": "1638708525", "time_read": "1608290463", "time_favorited": "0", "sort_id": 74, "resolved_title": "A Beginner’s Guide to Use BERT for the First Time", "resolved_url": "https://towardsdatascience.com/a-beginners-guide-to-use-bert-for-the-first-time-2e99b8c5423", "excerpt": "BERT has become a new standard for Natural Language Processing (NLP). It achieved a whole new state-of-the-art on eleven NLP task, including text classification, sequence labeling, question answering, and many more. Even better, it can also give incredible results using only a small amount of data.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1086", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/0*w3-dy3whMFXPz2XI", "tags": {"bert": {"item_id": "3178955873", "tag": "bert"}, "deep-learning": {"item_id": "3178955873", "tag": "deep-learning"}, "nlp": {"item_id": "3178955873", "tag": "nlp"}}, "authors": {"142700337": {"item_id": "3178955873", "author_id": "142700337", "name": "Arfinda Ilmania", "url": "https://medium.com/@arfinda"}}, "image": {"item_id": "3178955873", "src": "https://miro.medium.com/fit/c/56/56/1*qmzNM2JZ7ryilbnKElpCLg.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3178955873", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*qmzNM2JZ7ryilbnKElpCLg.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3178955873", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*w3-dy3whMFXPz2XI", "width": "700", "height": "472", "credit": "Jamie Street on Unsplash", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 420}, "2826286356": {"item_id": "2826286356", "resolved_id": "2826286356", "given_url": "https://towardsdatascience.com/a-list-of-beginner-friendly-nlp-projects-using-pre-trained-models-dc4768b4bec0", "given_title": "A list of beginner-friendly NLP projects–using pre-trained models", "favorite": "0", "status": "1", "time_added": "1577135427", "time_updated": "1608303299", "time_read": "1582142883", "time_favorited": "0", "sort_id": 75, "resolved_title": "A list of beginner-friendly NLP projects—using pre-trained models", "resolved_url": "https://towardsdatascience.com/a-list-of-beginner-friendly-nlp-projects-using-pre-trained-models-dc4768b4bec0", "excerpt": "If you’re interested in studying machine learning from the ground up, there are plenty of great resources. Organizations like fast.ai have made it so that anyone with a vaguely technical background can learn the foundations of machine learning and train their own models.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1901", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/freeze/max/1200/1*4U7dYUhHf25zz0DPaUOW8g.gif", "tags": {"nlp": {"item_id": "2826286356", "tag": "nlp"}}, "authors": {"121401171": {"item_id": "2826286356", "author_id": "121401171", "name": "Caleb Kaiser", "url": "https://towardsdatascience.com/@calebkaiser"}}, "image": {"item_id": "2826286356", "src": "https://miro.medium.com/max/3640/1*4U7dYUhHf25zz0DPaUOW8g.gif", "width": "1820", "height": "1024"}, "images": {"1": {"item_id": "2826286356", "image_id": "1", "src": "https://miro.medium.com/max/3640/1*4U7dYUhHf25zz0DPaUOW8g.gif", "width": "1820", "height": "1024", "credit": "", "caption": ""}, "2": {"item_id": "2826286356", "image_id": "2", "src": "https://miro.medium.com/max/2000/0*hY9lzmjh-Bzp6oBo.png", "width": "1000", "height": "708", "credit": "Google", "caption": ""}, "3": {"item_id": "2826286356", "image_id": "3", "src": "https://miro.medium.com/max/1308/1*BHV8uGUfkgiPAHTMAETPbA.gif", "width": "654", "height": "494", "credit": "Reply.ai", "caption": ""}, "4": {"item_id": "2826286356", "image_id": "4", "src": "https://miro.medium.com/max/1200/1*GEoO5nihfGIV0myJEiVLjA.gif", "width": "600", "height": "293", "credit": "TabNine Blog", "caption": ""}, "5": {"item_id": "2826286356", "image_id": "5", "src": "https://miro.medium.com/max/1284/1*y4Z_D6eSOY-S0TBHRPUhWw.png", "width": "642", "height": "212", "credit": "", "caption": ""}, "6": {"item_id": "2826286356", "image_id": "6", "src": "https://miro.medium.com/max/1520/1*jYmyrolTMaUSeUEqSvhCTQ.png", "width": "760", "height": "792", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 736}, "3939751190": {"item_id": "3939751190", "resolved_id": "3939751190", "given_url": "https://towardsdatascience.com/a-taxonomy-of-natural-language-processing-dfc790cb4c01", "given_title": "A Taxonomy of Natural Language Processing", "favorite": "0", "status": "1", "time_added": "1695495995", "time_updated": "1695566820", "time_read": "1695566820", "time_favorited": "0", "sort_id": 76, "resolved_title": "A Taxonomy of Natural Language Processing", "resolved_url": "https://towardsdatascience.com/a-taxonomy-of-natural-language-processing-dfc790cb4c01", "excerpt": "This post is based on our RANLP 2023 paper “Exploring the Landscape of Natural Language Processing Research”. You can read more details there.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2456", "lang": "en", "time_to_read": 11, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*zdTGd6X0DqcckNw1LpajUg.jpeg", "tags": {"nlp": {"item_id": "3939751190", "tag": "nlp"}}, "authors": {"161387383": {"item_id": "3939751190", "author_id": "161387383", "name": "Tim Schopf", "url": "https://medium.com/@tim.schopf"}}, "image": {"item_id": "3939751190", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*U4qYoEIZFs3CW6eFsQhkbg.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3939751190", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*U4qYoEIZFs3CW6eFsQhkbg.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3939751190", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 951}, "3729122879": {"item_id": "3729122879", "resolved_id": "3729122879", "given_url": "https://towardsdatascience.com/an-introduction-to-topic-noise-models-c48fe77e32a6", "given_title": "An Introduction to Topic-Noise Models", "favorite": "0", "status": "1", "time_added": "1666380815", "time_updated": "1667158943", "time_read": "1667158943", "time_favorited": "0", "sort_id": 77, "resolved_title": "An Introduction to Topic-Noise Models", "resolved_url": "https://towardsdatascience.com/an-introduction-to-topic-noise-models-c48fe77e32a6", "excerpt": "Words matter. And these days, it can be hard to cut through the noise to find the words that matter the most.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "4652", "lang": "en", "time_to_read": 21, "top_image_url": "https://miro.medium.com/max/1200/1*FDNKErODYHsvE0K6LaXe9A.jpeg", "tags": {"machine-learning": {"item_id": "3729122879", "tag": "machine-learning"}, "nlp": {"item_id": "3729122879", "tag": "nlp"}, "topic-noise": {"item_id": "3729122879", "tag": "topic-noise"}}, "authors": {"173701641": {"item_id": "3729122879", "author_id": "173701641", "name": "Lisa Singh", "url": "https://people.cs.georgetown.edu/~singh/"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1801}, "3299602017": {"item_id": "3299602017", "resolved_id": "3299602017", "given_url": "https://towardsdatascience.com/arabic-nlp-unique-challenges-and-their-solutions-d99e8a87893d", "given_title": "Arabic NLP: Unique Challenges and Their Solutions", "favorite": "0", "status": "1", "time_added": "1617711630", "time_updated": "1617882689", "time_read": "1617882688", "time_favorited": "0", "sort_id": 78, "resolved_title": "Arabic NLP: Unique Challenges and Their Solutions", "resolved_url": "https://towardsdatascience.com/arabic-nlp-unique-challenges-and-their-solutions-d99e8a87893d", "excerpt": "In this article, I provide a concise and to-the-point overview of the challenges of working with Arabic text in NLP projects…and the tools available to overcome them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1720", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1024/1*C3brWAPH-sTk9b18F2hYFw.jpeg", "tags": {"language-linguistics": {"item_id": "3299602017", "tag": "language-linguistics"}, "nlp": {"item_id": "3299602017", "tag": "nlp"}}, "authors": {"142421856": {"item_id": "3299602017", "author_id": "142421856", "name": "Richard Pelgrim", "url": "https://richardpelgrim.medium.com"}}, "image": {"item_id": "3299602017", "src": "https://miro.medium.com/fit/c/56/56/1*kb3CwkF_5Rwyml6t8RmxwA.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3299602017", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*kb3CwkF_5Rwyml6t8RmxwA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3299602017", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*C3brWAPH-sTk9b18F2hYFw.jpeg", "width": "700", "height": "445", "credit": "", "caption": "image under license to Richard Pelgrim"}, "3": {"item_id": "3299602017", "image_id": "3", "src": "https://miro.medium.com/max/500/1*K3ETbVW_mCmyQO67eq4auA.gif", "width": "250", "height": "141", "credit": "", "caption": "image via https://giphy.com/gifs/flaticons-xsWJYMcYexVQJbHzLS"}, "4": {"item_id": "3299602017", "image_id": "4", "src": "https://miro.medium.com/max/790/1*TzVGCkUSkWz1nFp_IRu-hw.png", "width": "395", "height": "128", "credit": "", "caption": "source: en.wikipedia.org"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 666}, "3759988798": {"item_id": "3759988798", "resolved_id": "3759979257", "given_url": "https://towardsdatascience.com/beginners-guide-to-diffusion-models-8c3435ccb4ae?source=rss----7f60cf5620c9---4", "given_title": "Beginner’s Guide to Diffusion Models", "favorite": "0", "status": "1", "time_added": "1670325950", "time_updated": "1670443306", "time_read": "1670443305", "time_favorited": "0", "sort_id": 79, "resolved_title": "Beginner’s Guide to Diffusion Models", "resolved_url": "https://towardsdatascience.com/beginners-guide-to-diffusion-models-8c3435ccb4ae", "excerpt": "Recently, there has been an increased interest in OpenAI’s DALL-E, Stable Diffusion (the free alternative of DALL-E), and Midjourney (hosted on a Discord server). While AI-generated art is very cool, what is even more captivating is how it works in the first place.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1428", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/512/1*xQrGG_weuH-N2kynjThfwg.png", "tags": {"deep-learning": {"item_id": "3759988798", "tag": "deep-learning"}, "nlp": {"item_id": "3759988798", "tag": "nlp"}, "stable-diffusion": {"item_id": "3759988798", "tag": "stable-diffusion"}}, "authors": {"114410845": {"item_id": "3759988798", "author_id": "114410845", "name": "Yang Chun Wei", "url": "https://medium.com/@yangcw"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 553}, "2921680090": {"item_id": "2921680090", "resolved_id": "2921675959", "given_url": "https://towardsdatascience.com/build-a-bert-sci-kit-transformer-59d60ddd54a5?source=rss----7f60cf5620c9---4", "given_title": "Build a BERT Sci-kit Transformer", "favorite": "1", "status": "1", "time_added": "1584698450", "time_updated": "1584700696", "time_read": "1584700696", "time_favorited": "1584700672", "sort_id": 80, "resolved_title": "Build a BERT Sci-kit Transformer", "resolved_url": "https://towardsdatascience.com/build-a-bert-sci-kit-transformer-59d60ddd54a5", "excerpt": "Getting state of the art results in NLP used to be a harrowing task. You’d have to design all kinds of pipelines, do part of speech tagging, link these to knowledge bases, lemmatize your words, and build crazy parsers. Now just throw your task at BERT and you’ll probably do pretty well.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1823", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/focal/595/313/51/43/1*nWbf_KWFnSNfbeMZSiMrJw.png", "tags": {"nlp": {"item_id": "2921680090", "tag": "nlp"}}, "authors": {"145313746": {"item_id": "2921680090", "author_id": "145313746", "name": "Nicolas Bertagnolli", "url": "https://nbertagnolli.medium.com"}}, "image": {"item_id": "2921680090", "src": "https://miro.medium.com/fit/c/56/56/0*9hAWHt7LIeG3Zk_8", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2921680090", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/0*9hAWHt7LIeG3Zk_8", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2921680090", "image_id": "2", "src": "https://miro.medium.com/max/1190/1*nWbf_KWFnSNfbeMZSiMrJw.png", "width": "595", "height": "374", "credit": "Image by Author", "caption": "BERT as a Transformer"}, "3": {"item_id": "2921680090", "image_id": "3", "src": "https://miro.medium.com/max/4000/1*_I0Cc6fzScAUrH8eUebfbg.png", "width": "2000", "height": "1200", "credit": "", "caption": ""}, "4": {"item_id": "2921680090", "image_id": "4", "src": "https://miro.medium.com/max/4000/1*BVejfQhdZAsJv8gRjSjJ0w.png", "width": "2000", "height": "2000", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 706}, "3114620928": {"item_id": "3114620928", "resolved_id": "3114620951", "given_url": "https://towardsdatascience.com/compare-amazon-textract-with-tesseract-ocr-ocr-nlp-use-case-43ad7cd48748?source=rss----7f60cf5620c9---4", "given_title": "Compare Amazon Textract with Tesseract OCR — OCR & NLP Use Case", "favorite": "0", "status": "1", "time_added": "1600367428", "time_updated": "1604363999", "time_read": "1604363999", "time_favorited": "0", "sort_id": 81, "resolved_title": "Compare Amazon Textract with Tesseract OCR — OCR & NLP Use Case", "resolved_url": "https://towardsdatascience.com/compare-amazon-textract-with-tesseract-ocr-ocr-nlp-use-case-43ad7cd48748", "excerpt": "What is OCR anyway and why the buzz? Artificial Intelligence (AI) enables entities with Human Intelligence (us) process data at a large scale — faster and cheaper. Unarguably, a large portion of data is saved digitally- easy to read and analyze.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1034", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/1*OtzhATqOP3YleD2h1rV17A.jpeg", "tags": {"nlp": {"item_id": "3114620928", "tag": "nlp"}, "ocr": {"item_id": "3114620928", "tag": "ocr"}}, "authors": {"141702191": {"item_id": "3114620928", "author_id": "141702191", "name": "Manoj Kukreja", "url": "https://mkukreja1.medium.com"}}, "image": {"item_id": "3114620928", "src": "https://miro.medium.com/max/1400/1*OtzhATqOP3YleD2h1rV17A.jpeg", "width": "700", "height": "467"}, "images": {"1": {"item_id": "3114620928", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*OtzhATqOP3YleD2h1rV17A.jpeg", "width": "700", "height": "467", "credit": "", "caption": "Image by Felix Wolf from Pixabay"}, "2": {"item_id": "3114620928", "image_id": "2", "src": "https://miro.medium.com/max/1384/1*LFBUeOb75RGVE3KeXRvvHQ.png", "width": "692", "height": "273", "credit": "", "caption": "Image by Gerd Altmann from Pixabay"}, "3": {"item_id": "3114620928", "image_id": "3", "src": "https://miro.medium.com/max/1360/1*rulZJi4HxVjtrZ08nJ6FMw.jpeg", "width": "680", "height": "383", "credit": "", "caption": "Image by Author — typewritten.jpg"}, "4": {"item_id": "3114620928", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*xq_LCuuC349SUcLRReOtZQ.png", "width": "700", "height": "261", "credit": "", "caption": ""}, "5": {"item_id": "3114620928", "image_id": "5", "src": "https://miro.medium.com/max/1126/1*eu_NVoeJ1FEwWNvpcZNC3Q.jpeg", "width": "563", "height": "750", "credit": "", "caption": "Image by Author — handwritten.jpg"}, "6": {"item_id": "3114620928", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*8whZ9j8GxtTGiYz-Lj7p8w.png", "width": "700", "height": "253", "credit": "", "caption": "Image by Author"}, "7": {"item_id": "3114620928", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*FqzDx6PTvbIfrDilKpUYNQ.jpeg", "width": "700", "height": "965", "credit": "", "caption": "Image by Author — invoice-sample.jpg"}, "8": {"item_id": "3114620928", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*PT8poS_RbvOgQivCieqcTQ.png", "width": "700", "height": "312", "credit": "", "caption": "Image By Author"}, "9": {"item_id": "3114620928", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*cbA-3pK5si-WrJKsr6JJmg.png", "width": "700", "height": "320", "credit": "", "caption": "Image By Author"}, "10": {"item_id": "3114620928", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*TIuoq0dertFi5hJ9J35H9Q.png", "width": "700", "height": "436", "credit": "", "caption": "Image by Author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 400}, "3240077566": {"item_id": "3240077566", "resolved_id": "3240077595", "given_url": "https://towardsdatascience.com/cross-topic-argument-mining-learning-how-to-classify-texts-1d9e5c00c4cc?source=rss----7f60cf5620c9---4", "given_title": "Cross-Topic Argument Mining: Learning How to Classify Texts", "favorite": "0", "status": "1", "time_added": "1611684431", "time_updated": "1638708525", "time_read": "1611746344", "time_favorited": "0", "sort_id": 82, "resolved_title": "Cross-Topic Argument Mining: Learning How to Classify Texts", "resolved_url": "https://towardsdatascience.com/cross-topic-argument-mining-learning-how-to-classify-texts-1d9e5c00c4cc", "excerpt": "Argument mining, or argumentation mining, is one of the research topics in natural language processing (NLP) and knowledge representation learning. Argumentation deals with logical reasoning and is inherent to human intelligence.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2218", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/max/1200/0*V7bXCvUPDw5rIedZ", "tags": {"classification": {"item_id": "3240077566", "tag": "classification"}, "deep-learning": {"item_id": "3240077566", "tag": "deep-learning"}, "nlp": {"item_id": "3240077566", "tag": "nlp"}, "text": {"item_id": "3240077566", "tag": "text"}}, "authors": {"143989528": {"item_id": "3240077566", "author_id": "143989528", "name": "Stephen Adhisaputra", "url": "https://stephenadhi.medium.com"}}, "image": {"item_id": "3240077566", "src": "https://miro.medium.com/max/15850/0*V7bXCvUPDw5rIedZ", "width": "7925", "height": "5286"}, "images": {"1": {"item_id": "3240077566", "image_id": "1", "src": "https://miro.medium.com/max/15850/0*V7bXCvUPDw5rIedZ", "width": "7925", "height": "5286", "credit": "Etienne Boulanger on Unsplash", "caption": ""}, "2": {"item_id": "3240077566", "image_id": "2", "src": "https://miro.medium.com/max/1984/1*aAQq-1SwdK-KorJVbM7R7Q.png", "width": "992", "height": "418", "credit": "", "caption": "Topic distribution — Image by Author"}, "3": {"item_id": "3240077566", "image_id": "3", "src": "https://miro.medium.com/max/1044/1*Y3MpWYz5IiZ5KBaNdcDkaw.png", "width": "522", "height": "344", "credit": "", "caption": "Label distribution — Image by Author"}, "4": {"item_id": "3240077566", "image_id": "4", "src": "https://miro.medium.com/max/3256/1*np4zvM2OrOl9z2mhvgKepA.png", "width": "1628", "height": "613", "credit": "", "caption": "Argument mining pipeline — Image by Author"}, "5": {"item_id": "3240077566", "image_id": "5", "src": "https://miro.medium.com/max/1696/1*2Ja8WBvyQnWUCLOBH7j-5A.png", "width": "848", "height": "345", "credit": "", "caption": "Example sentences — Image by Author"}, "6": {"item_id": "3240077566", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*BZUAUu8RU4IIVBkmfuveCw.png", "width": "700", "height": "271", "credit": "", "caption": "One-hot encoding — Image by Author"}, "7": {"item_id": "3240077566", "image_id": "7", "src": "https://miro.medium.com/max/1262/1*QH9zQGmo2QUrQ_YvF7Bebw.png", "width": "631", "height": "442", "credit": "", "caption": "List of vocabulary — Image by Author"}, "8": {"item_id": "3240077566", "image_id": "8", "src": "https://miro.medium.com/max/1430/1*QcG4AIgtTYyXYWd7FOIRGQ.png", "width": "715", "height": "805", "credit": "", "caption": "Word frequency distribution — Image by Author"}, "9": {"item_id": "3240077566", "image_id": "9", "src": "https://miro.medium.com/max/1038/1*drMwgH8RLOErYpJGL-2wKQ.png", "width": "519", "height": "374", "credit": "", "caption": "Deep learning model in Tensorflow — Image by Author"}, "10": {"item_id": "3240077566", "image_id": "10", "src": "https://miro.medium.com/max/916/1*MhDi5X0SM2usJxvDoKoO_A.png", "width": "458", "height": "211", "credit": "", "caption": "In-topic classification report— Image by Author"}, "11": {"item_id": "3240077566", "image_id": "11", "src": "https://miro.medium.com/max/904/1*VmDdCmQvQ-dFO0S72T9WWA.png", "width": "452", "height": "197", "credit": "", "caption": "Cross-topic classification report — Image by Author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 859}, "2425497913": {"item_id": "2425497913", "resolved_id": "2425497913", "given_url": "https://towardsdatascience.com/deconstructing-bert-distilling-6-patterns-from-100-million-parameters-b49113672f77", "given_title": "", "favorite": "0", "status": "1", "time_added": "1545646586", "time_updated": "1609364713", "time_read": "1567126263", "time_favorited": "0", "sort_id": 83, "resolved_title": "Deconstructing BERT: Distilling 6 Patterns from 100 Million Parameters", "resolved_url": "https://towardsdatascience.com/deconstructing-bert-distilling-6-patterns-from-100-million-parameters-b49113672f77", "excerpt": "The year 2018 marked a turning point for the field of Natural Language Processing, with a series of deep-learning models achieving state-of-the-art results on NLP tasks ranging from question answering to sentiment classification.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1301", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/1*dDp0F9AGCuP8MaieI2y3ww.jpeg", "tags": {"bert": {"item_id": "2425497913", "tag": "bert"}, "nlp": {"item_id": "2425497913", "tag": "nlp"}}, "authors": {"100355842": {"item_id": "2425497913", "author_id": "100355842", "name": "Jesse Vig", "url": "https://medium.com/@JesseVig"}}, "image": {"item_id": "2425497913", "src": "https://miro.medium.com/fit/c/56/56/1*zQrkxE0uEq3x6Jn9Z0QGQg.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2425497913", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*zQrkxE0uEq3x6Jn9Z0QGQg.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2425497913", "image_id": "2", "src": "https://miro.medium.com/max/2682/1*dDp0F9AGCuP8MaieI2y3ww.jpeg", "width": "1341", "height": "660", "credit": "", "caption": ""}, "3": {"item_id": "2425497913", "image_id": "3", "src": "https://miro.medium.com/max/928/1*kvcBEC6in6UYS4J3Im311w.gif", "width": "464", "height": "478", "credit": "", "caption": ""}, "4": {"item_id": "2425497913", "image_id": "4", "src": "https://miro.medium.com/max/3200/1*EPiYy22Tox5wTSWHsCg60Q.jpeg", "width": "1600", "height": "900", "credit": "“i”", "caption": "Pattern 1: Attention to next word. Left: attention weights for all tokens. Right: attention weights for selected token"}, "5": {"item_id": "2425497913", "image_id": "5", "src": "https://miro.medium.com/max/3200/1*6y97rGDQRnnxfkyw-a2png.jpeg", "width": "1600", "height": "900", "credit": "“went”", "caption": "Pattern 2: Attention to previous word. Left: attention weights for all tokens. Right: attention weights for selected token"}, "6": {"item_id": "2425497913", "image_id": "6", "src": "https://miro.medium.com/max/3200/1*GsrsVlaMMc_U_dGVNJ0xmg.jpeg", "width": "1600", "height": "900", "credit": "“store”", "caption": "Pattern 3: Attention to identical/related tokens. Left: attention weights for all tokens. Right: attention weights for selected token"}, "7": {"item_id": "2425497913", "image_id": "7", "src": "https://miro.medium.com/max/3200/1*Zcu9TBZaxyAIGigR_jGnfA.jpeg", "width": "1600", "height": "900", "credit": "“store”", "caption": "Pattern 4: Attention to identical/related words in other sentence. Left: attention weights for all tokens. Right: attention weights for selected token"}, "8": {"item_id": "2425497913", "image_id": "8", "src": "https://miro.medium.com/max/3200/1*OPL0NDQJWh611mveG-Gulg.jpeg", "width": "1600", "height": "900", "credit": "“##berries”", "caption": "Pattern 5: Attention to other words predictive of word. Left: attention weights for all tokens. Right: attention weights for selected token"}, "9": {"item_id": "2425497913", "image_id": "9", "src": "https://miro.medium.com/max/3200/1*1weap1WGmkTsjk5feb457g.jpeg", "width": "1600", "height": "900", "credit": "“store”", "caption": "Pattern 6: Attention to delimiter tokens. Left: attention weights for all tokens. Right: attention weights for selected token"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 504}, "3299711636": {"item_id": "3299711636", "resolved_id": "3299711636", "given_url": "https://towardsdatascience.com/deploy-an-nlp-pipeline-flask-heroku-bert-f13a302efd9d", "given_title": "Deploy an NLP pipeline. Flask Heroku Bert.", "favorite": "0", "status": "1", "time_added": "1617710975", "time_updated": "1619827576", "time_read": "1619827576", "time_favorited": "0", "sort_id": 84, "resolved_title": "Deploy an NLP pipeline. Flask+Heroku+Bert.", "resolved_url": "https://towardsdatascience.com/deploy-an-nlp-pipeline-flask-heroku-bert-f13a302efd9d", "excerpt": "Very often, as a data scientist, you may be faced with a task that includes a complete pipeline: from the data collection up to deploy the app on the server. I bumped into such an odd job in the interview process during the job search.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1328", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/0*5mrPjkeY-esxQrL-.jpg", "tags": {"bert": {"item_id": "3299711636", "tag": "bert"}, "flask": {"item_id": "3299711636", "tag": "flask"}, "heroku": {"item_id": "3299711636", "tag": "heroku"}, "nlp": {"item_id": "3299711636", "tag": "nlp"}}, "authors": {"145392180": {"item_id": "3299711636", "author_id": "145392180", "name": "Galina Blokh", "url": "https://galinablokh.medium.com"}}, "image": {"item_id": "3299711636", "src": "https://miro.medium.com/fit/c/56/56/1*as0c7sy9--Gb1AaY7w-ceg.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3299711636", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*as0c7sy9--Gb1AaY7w-ceg.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3299711636", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*5mrPjkeY-esxQrL-.jpg", "width": "700", "height": "451", "credit": "Pixabay on Pexels.com", "caption": ""}, "3": {"item_id": "3299711636", "image_id": "3", "src": "https://miro.medium.com/max/2000/1*J0d9rteybVdPNzEXLyR0Hg.png", "width": "1000", "height": "384", "credit": "", "caption": "Pic.1 File →Settings →Project Structure."}, "4": {"item_id": "3299711636", "image_id": "4", "src": "https://miro.medium.com/max/2000/1*ybMR3VWdOjWb5l_aX7P5Wg.png", "width": "1000", "height": "548", "credit": "", "caption": "Pic.2 File →Settings →Languages & Frameworks →Template Languages"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 514}, "2989295701": {"item_id": "2989295701", "resolved_id": "2989295710", "given_url": "https://towardsdatascience.com/evolution-of-language-models-n-grams-word-embeddings-attention-transformers-a688151825d2?source=rss----7f60cf5620c9---4", "given_title": "Evolution of Language Models: N-Grams, Word Embeddings, Attention & Transfo", "favorite": "0", "status": "1", "time_added": "1589972656", "time_updated": "1638708525", "time_read": "1589992096", "time_favorited": "0", "sort_id": 85, "resolved_title": "Evolution of Language Models: N-Grams, Word Embeddings, Attention & Transformers", "resolved_url": "https://towardsdatascience.com/evolution-of-language-models-n-grams-word-embeddings-attention-transformers-a688151825d2", "excerpt": "You’d be surprised at how young this domain really is. But first and foremost, let’s lay the foundations on what a Language Model is.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1376", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/0*rWhSy2fLidHCYxPH", "tags": {"deep-learning": {"item_id": "2989295701", "tag": "deep-learning"}, "nlp": {"item_id": "2989295701", "tag": "nlp"}}, "authors": {"122128265": {"item_id": "2989295701", "author_id": "122128265", "name": "Timothy Tan", "url": "https://medium.com/@timothyguang"}}, "image": {"item_id": "2989295701", "src": "https://miro.medium.com/max/8082/0*rWhSy2fLidHCYxPH", "width": "4041", "height": "2274"}, "images": {"1": {"item_id": "2989295701", "image_id": "1", "src": "https://miro.medium.com/max/8082/0*rWhSy2fLidHCYxPH", "width": "4041", "height": "2274", "credit": "", "caption": "ImagPhoto by Johannes Plenio on Unsplash"}, "2": {"item_id": "2989295701", "image_id": "2", "src": "https://miro.medium.com/fit/c/56/56/2*gti5sGCeF7oMGhTzYTftzw.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "3": {"item_id": "2989295701", "image_id": "3", "src": "https://miro.medium.com/max/9856/0*VOcBo3hN4Og-Twm5", "width": "4928", "height": "3264", "credit": "Tim Bish on Unsplash", "caption": ""}, "4": {"item_id": "2989295701", "image_id": "4", "src": "https://miro.medium.com/max/2400/1*Jqfn9m-2wC5pfLpcwzk2Ug.png", "width": "1200", "height": "400", "credit": "RNN", "caption": "A diagram for a one-unit recurrent neural network"}, "5": {"item_id": "2989295701", "image_id": "5", "src": "https://miro.medium.com/max/2400/1*-4NZcM5LFHnf7Xp0Cyeu0Q.png", "width": "1200", "height": "534", "credit": "LSTM", "caption": "A diagram for a one-unit Long Short-Term Memory"}, "6": {"item_id": "2989295701", "image_id": "6", "src": "https://miro.medium.com/max/1192/1*Nj81Dc6OpYT9G9kgT3DOrA.png", "width": "596", "height": "509", "credit": "source", "caption": "The first neural language model by Bengio et al. 2003"}, "7": {"item_id": "2989295701", "image_id": "7", "src": "https://miro.medium.com/max/1570/1*Kv0ZBh7nCi2TDDHJbmvBBw.png", "width": "785", "height": "480", "credit": "source", "caption": "Word2Vec models. The CBOW architecture predicts the current word based on the context, and the Skip-gram predicts surrounding words given the current word. By Mikolov et al. 2013"}, "8": {"item_id": "2989295701", "image_id": "8", "src": "https://miro.medium.com/max/1544/1*kvKfEwc-Dpq6MMzoEofaxw.png", "width": "772", "height": "374", "credit": "Source", "caption": "Overall accuracy on the word analogy task Glove vs CBOW vs Skip-Gram by Pennington et al. 2014"}, "9": {"item_id": "2989295701", "image_id": "9", "src": "https://miro.medium.com/max/17656/0*_m4Ir6Z2Dtz4mOy-", "width": "8828", "height": "11092", "credit": "Science in HD on Unsplash", "caption": ""}, "10": {"item_id": "2989295701", "image_id": "10", "src": "https://miro.medium.com/max/1702/1*lpfua6ajFawoMWDCx8r4Zw.png", "width": "851", "height": "364", "credit": "white indicates the attended regions, underlines indicated the corresponding word", "caption": "Examples of attending to the correct object"}, "11": {"item_id": "2989295701", "image_id": "11", "src": "https://miro.medium.com/max/11730/0*qnvcP9ztmZrruGSF", "width": "5865", "height": "3672", "credit": "Mitchell Luo on Unsplash", "caption": ""}, "12": {"item_id": "2989295701", "image_id": "12", "src": "https://miro.medium.com/max/924/1*sOqN2gebImOhGIfpoNKsHQ.png", "width": "462", "height": "690", "credit": "source", "caption": "The Transformer — model architecture by Vaswani et al. 2017"}, "13": {"item_id": "2989295701", "image_id": "13", "src": "https://miro.medium.com/max/960/1*h3gPsTR1A3Oa8XTQGMjG5g.gif", "width": "480", "height": "270", "credit": "source", "caption": "“P” GIF by Sesame Street, 23 March 2016"}, "14": {"item_id": "2989295701", "image_id": "14", "src": "https://miro.medium.com/max/960/1*sdoJ3O2cZiPTrrm9WezNmQ.gif", "width": "480", "height": "320", "credit": "source", "caption": "Happy So Excited GIF By GIPHY Studios Originals, 18 November 2016"}, "15": {"item_id": "2989295701", "image_id": "15", "src": "https://miro.medium.com/max/960/1*-kEiThMHgEtKFk3w9ioJ7g.gif", "width": "480", "height": "270", "credit": "source", "caption": "Amazing Season 6 GIF By Bachelor In Paradise, 7 August 2019"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 533}, "3296076806": {"item_id": "3296076806", "resolved_id": "3296071431", "given_url": "https://towardsdatascience.com/foundations-of-nlp-explained-visually-beam-search-how-it-works-1586b9849a24?source=rss----7f60cf5620c9---4", "given_title": "Foundations of NLP Explained Visually: Beam Search, How it Works | by Ketan", "favorite": "0", "status": "1", "time_added": "1617313437", "time_updated": "1617546180", "time_read": "1617546180", "time_favorited": "0", "sort_id": 86, "resolved_title": "Foundations of NLP Explained Visually: Beam Search, How It Works", "resolved_url": "https://towardsdatascience.com/foundations-of-nlp-explained-visually-beam-search-how-it-works-1586b9849a24", "excerpt": "Many NLP applications such as machine translation, chatbots, text summarization, and language models generate some text as their output. In addition applications like image captioning or automatic speech recognition (ie.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1748", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/770/1*tEjhWqUgjX37VnT7gJN-4g.png", "tags": {"nlp": {"item_id": "3296076806", "tag": "nlp"}, "search": {"item_id": "3296076806", "tag": "search"}}, "authors": {"142118215": {"item_id": "3296076806", "author_id": "142118215", "name": "Ketan Doshi", "url": "https://ketanhdoshi.medium.com"}}, "image": {"item_id": "3296076806", "src": "https://miro.medium.com/fit/c/56/56/1*ZpFBF1tIJfdXWqSjIk1DKg.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3296076806", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*ZpFBF1tIJfdXWqSjIk1DKg.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3296076806", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*GqR_ZQubZEsYBRIx", "width": "700", "height": "1049", "credit": "Casey Horner on Unsplash", "caption": ""}, "3": {"item_id": "3296076806", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*GkG_5wg57IpkU8F84nJubQ.png", "width": "700", "height": "404", "credit": "Image by Author", "caption": "Sequence-to-Sequence Model for Machine Translation"}, "4": {"item_id": "3296076806", "image_id": "4", "src": "https://miro.medium.com/max/680/1*nId-RZloZiVUdFQFK31xcg.png", "width": "340", "height": "220", "credit": "Image by Author", "caption": "Probabilities for each character in the vocabulary, for each position in the output sequence"}, "5": {"item_id": "3296076806", "image_id": "5", "src": "https://miro.medium.com/max/680/1*MZGM7BnSm-L2n025P__HIg.png", "width": "340", "height": "400", "credit": "Image by Author", "caption": "The model predicts an output sentence based on the probabilities"}, "6": {"item_id": "3296076806", "image_id": "6", "src": "https://miro.medium.com/max/600/1*IWNtDrXdepfzJUIshnQOAg.png", "width": "300", "height": "450", "credit": "Image by Author", "caption": "Greedy Search"}, "7": {"item_id": "3296076806", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*tEjhWqUgjX37VnT7gJN-4g.png", "width": "700", "height": "410", "credit": "Image by Author", "caption": "Beam Search example, with width = 2"}, "8": {"item_id": "3296076806", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*dLHChU897ypcetDRRqnMIw.png", "width": "700", "height": "262", "credit": "Image by Author", "caption": "An LSTM-based Sequence-to-Sequence model"}, "9": {"item_id": "3296076806", "image_id": "9", "src": "https://miro.medium.com/max/830/1*unlaSs5XI_68iq3chlqfVQ.png", "width": "415", "height": "460", "credit": "Image by Author", "caption": "Character probabilities for the first position"}, "10": {"item_id": "3296076806", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*rh5LUbc1xh8sWeMMBN0jjA.png", "width": "700", "height": "370", "credit": "Image by Author", "caption": "Character probabilities for the second position"}, "11": {"item_id": "3296076806", "image_id": "11", "src": "https://miro.medium.com/max/1018/1*Zz8a8X4MZsjWJEA_9Io7fg.png", "width": "509", "height": "443", "credit": "Image by Author", "caption": "Calculate probabilities for character-pairs in the first two positions"}, "12": {"item_id": "3296076806", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*4rlMOAAHW9Q9KaT2i4bUyw.png", "width": "700", "height": "419", "credit": "Image by Author", "caption": "The model picks the two best character pairs based on the combined probability"}, "13": {"item_id": "3296076806", "image_id": "13", "src": "https://miro.medium.com/max/1400/1*Nnka3yYpNo6m3JeermN-1g.png", "width": "700", "height": "317", "credit": "Image by Author", "caption": "Character probabilities for the third position"}, "14": {"item_id": "3296076806", "image_id": "14", "src": "https://miro.medium.com/max/800/1*TJbVv78IecgcfBoCcDfQHw.png", "width": "400", "height": "630", "credit": "Image by Author", "caption": "Calculate probabilities for character-triples in the first three positions"}, "15": {"item_id": "3296076806", "image_id": "15", "src": "https://miro.medium.com/max/1400/1*2edhf25eROJAj1RgTnlChQ.png", "width": "700", "height": "367", "credit": "Image by Author", "caption": "The model picks the two best character triples based on the combined probability"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 677}, "2964257723": {"item_id": "2964257723", "resolved_id": "2964257749", "given_url": "https://towardsdatascience.com/good-grams-how-to-find-predictive-n-grams-for-your-problem-c04a5f320b39?source=rss----7f60cf5620c9---4", "given_title": "Good Grams: How to Find Predictive N-Grams for your Problem", "favorite": "0", "status": "1", "time_added": "1588001544", "time_updated": "1589542085", "time_read": "1589542085", "time_favorited": "0", "sort_id": 87, "resolved_title": "Good Grams: How to Find Predictive N-Grams for your Problem", "resolved_url": "https://towardsdatascience.com/good-grams-how-to-find-predictive-n-grams-for-your-problem-c04a5f320b39", "excerpt": "Nowadays NLP feels like it’s just about applying BERT and getting state of the art results on your problem. Often times, I find that grabbing a few good informative words can help too. Usually, I’ll have an expert come to me and say these five words are really predictive for this class.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1452", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/1034/1*aVCNljbK3V8Fp8j4DW-dGA.png", "tags": {"nlp": {"item_id": "2964257723", "tag": "nlp"}}, "authors": {"145313746": {"item_id": "2964257723", "author_id": "145313746", "name": "Nicolas Bertagnolli", "url": "https://nbertagnolli.medium.com"}}, "image": {"item_id": "2964257723", "src": "https://miro.medium.com/fit/c/56/56/0*9hAWHt7LIeG3Zk_8", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2964257723", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/0*9hAWHt7LIeG3Zk_8", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2964257723", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*aVCNljbK3V8Fp8j4DW-dGA.png", "width": "700", "height": "881", "credit": "", "caption": "Photo Credit: Kendrick Mills"}, "3": {"item_id": "2964257723", "image_id": "3", "src": "https://miro.medium.com/max/984/1*xBpB_9NIfHyXPN4Gk2umCw.png", "width": "492", "height": "492", "credit": "", "caption": ""}, "4": {"item_id": "2964257723", "image_id": "4", "src": "https://miro.medium.com/max/1008/1*N_wkHTrw8Ck8-GsNDYZrzA.png", "width": "504", "height": "504", "credit": "", "caption": ""}, "5": {"item_id": "2964257723", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*t0YDmd-_2FyQytK6czPcug.png", "width": "700", "height": "490", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 562}, "3349863342": {"item_id": "3349863342", "resolved_id": "3349859421", "given_url": "https://towardsdatascience.com/gpt-3-scared-you-meet-wu-dao-2-0-a-monster-of-1-75-trillion-parameters-832cd83db484?source=rss----7f60cf5620c9---4", "given_title": "Wu Dao 2.0: A Monster of 1.75 Trillion Parameters | by Alberto Romero | Med", "favorite": "0", "status": "1", "time_added": "1622981802", "time_updated": "1678841327", "time_read": "1623032387", "time_favorited": "0", "sort_id": 88, "resolved_title": "GPT-3 Scared You? Meet Wu Dao 2.0: A Monster of 1.75 Trillion Parameters", "resolved_url": "https://towardsdatascience.com/gpt-3-scared-you-meet-wu-dao-2-0-a-monster-of-1-75-trillion-parameters-832cd83db484", "excerpt": "We’re living exciting times in AI. OpenAI shocked the world a year ago with GPT-3. Two weeks ago Google presented LaMDA and MUM, two AIs that will revolutionize chatbots and the search engine, respectively.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1283", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/0*BMnNj-LkuKhMm-f8", "tags": {"chatbots": {"item_id": "3349863342", "tag": "chatbots"}, "deep-learning": {"item_id": "3349863342", "tag": "deep-learning"}, "nlp": {"item_id": "3349863342", "tag": "nlp"}}, "authors": {"144430834": {"item_id": "3349863342", "author_id": "144430834", "name": "Alberto Romero", "url": "https://albertoromgar.medium.com"}}, "image": {"item_id": "3349863342", "src": "https://miro.medium.com/fit/c/56/56/2*oMdIZBsnK8EFhQLUaAB5ZA.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3349863342", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*oMdIZBsnK8EFhQLUaAB5ZA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3349863342", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*BMnNj-LkuKhMm-f8", "width": "700", "height": "467", "credit": "GR Stocks on Unsplash", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 497}, "3113705339": {"item_id": "3113705339", "resolved_id": "3113695592", "given_url": "https://towardsdatascience.com/gpt-3-transformers-and-the-wild-world-of-nlp-9993d8bb1314?source=rss----7f60cf5620c9---4", "given_title": "GPT-3, transformers and the wild world of NLP", "favorite": "0", "status": "1", "time_added": "1600342908", "time_updated": "1671724937", "time_read": "1604364034", "time_favorited": "0", "sort_id": 89, "resolved_title": "GPT-3, transformers and the wild world of NLP", "resolved_url": "https://towardsdatascience.com/gpt-3-transformers-and-the-wild-world-of-nlp-9993d8bb1314", "excerpt": "The tech world is so full of fascinating demons. Every now and then, we get to be awed, not without a hint of horror, by a new development. The natural language processing (NLP) model GPT-3 recently developed by OpenAI is exactly a such creature.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3131", "lang": "en", "time_to_read": 14, "top_image_url": "https://miro.medium.com/max/1200/1*NdJ19yLbvv1NII7nEUJdeQ.jpeg", "tags": {"chatbots": {"item_id": "3113705339", "tag": "chatbots"}, "deep-learning": {"item_id": "3113705339", "tag": "deep-learning"}, "nlp": {"item_id": "3113705339", "tag": "nlp"}}, "authors": {"140045115": {"item_id": "3113705339", "author_id": "140045115", "name": "Lingyi", "url": "https://medium.com/@lingyi_99090"}}, "image": {"item_id": "3113705339", "src": "https://miro.medium.com/fit/c/56/56/1*RqUcf_dNPSsAou2_u4p80w.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3113705339", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*RqUcf_dNPSsAou2_u4p80w.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3113705339", "image_id": "2", "src": "https://miro.medium.com/max/2000/1*NdJ19yLbvv1NII7nEUJdeQ.jpeg", "width": "1000", "height": "328", "credit": "", "caption": "兰亭集序 Image from: https://zh.wikipedia.org/wiki/%E8%98%AD%E4%BA%AD%E9%9B%86%E5%BA%8F"}, "3": {"item_id": "3113705339", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*COTw6edFBflp1-tFgZAwJA.png", "width": "700", "height": "394", "credit": "", "caption": "If you hate blurry pictures, click here to find original slides."}, "4": {"item_id": "3113705339", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*6IVEekFIZNqgCZeUAFiY0Q.jpeg", "width": "700", "height": "394", "credit": "", "caption": "If you hate blurry pictures, click here to find original slides."}, "5": {"item_id": "3113705339", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*nc4ju2hgOVrVpXwJWwCJvA.jpeg", "width": "700", "height": "394", "credit": "", "caption": "If you hate blurry pictures, click here to find original slides."}, "6": {"item_id": "3113705339", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*v0olcYtRwIaqOFK5Iyc7sQ.jpeg", "width": "700", "height": "394", "credit": "", "caption": "If you hate blurry pictures, click here to find original slides."}, "7": {"item_id": "3113705339", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*2D0wGNjPGzQoDeymyr6mDA.jpeg", "width": "700", "height": "394", "credit": "", "caption": "If you hate blurry pictures, click here to find original slides."}, "8": {"item_id": "3113705339", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*8lTURSxryeTF4rT7-I2lTA.jpeg", "width": "700", "height": "394", "credit": "", "caption": "If you hate blurry pictures, click here to find original slides."}, "9": {"item_id": "3113705339", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*KQhcK_T6w8O4el9YDBMV7g.png", "width": "700", "height": "260", "credit": "", "caption": "This is an image from Google’s paper on T5"}, "10": {"item_id": "3113705339", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*whyBi5CzQolxOkUNyX-cgQ.png", "width": "700", "height": "216", "credit": "", "caption": "XLNet, RoBERTa, ALBERT and Electra achieve on-par performance with T5–3B with much smaller architecture. If you hate blurry pictures, click here to find original slides."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1212}, "3251024562": {"item_id": "3251024562", "resolved_id": "3251024592", "given_url": "https://towardsdatascience.com/how-to-tell-stories-with-sentiment-analysis-f94cf9f8ca71?source=rss----7f60cf5620c9---4", "given_title": "How to Tell Stories with Sentiment Analysis", "favorite": "0", "status": "1", "time_added": "1612730907", "time_updated": "1612929386", "time_read": "1612929386", "time_favorited": "0", "sort_id": 90, "resolved_title": "How to Tell Stories with Sentiment Analysis", "resolved_url": "https://towardsdatascience.com/how-to-tell-stories-with-sentiment-analysis-f94cf9f8ca71", "excerpt": "Last week, I published “The QAnon Timeline: Four Years, 5,000 Drops and Countless Failed Prophecies.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1734", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1024/0*oISKrIddhEUrO2mV.jpeg", "tags": {"nlp": {"item_id": "3251024562", "tag": "nlp"}, "sentiment-analysis": {"item_id": "3251024562", "tag": "sentiment-analysis"}}, "authors": {"146517439": {"item_id": "3251024562", "author_id": "146517439", "name": "Edward Tian", "url": "https://edward-the6.medium.com"}}, "image": {"item_id": "3251024562", "src": "https://miro.medium.com/fit/c/56/56/1*gf1xQCMBb7jAMRmYv37xpg.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3251024562", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*gf1xQCMBb7jAMRmYv37xpg.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3251024562", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*2A10W2MWUCCkDqav.png", "width": "700", "height": "365", "credit": "", "caption": ""}, "3": {"item_id": "3251024562", "image_id": "3", "src": "https://miro.medium.com/max/1400/0*iXyI5WuabMbjk7IO.png", "width": "700", "height": "212", "credit": "", "caption": ""}, "4": {"item_id": "3251024562", "image_id": "4", "src": "https://miro.medium.com/max/1400/0*DonCKKsvyQrf52N_.png", "width": "700", "height": "301", "credit": "", "caption": ""}, "5": {"item_id": "3251024562", "image_id": "5", "src": "https://miro.medium.com/max/1400/0*oISKrIddhEUrO2mV.jpeg", "width": "700", "height": "582", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 671}, "2802544858": {"item_id": "2802544858", "resolved_id": "2802544858", "given_url": "https://towardsdatascience.com/lit-bert-nlp-transfer-learning-in-3-steps-272a866570db", "given_title": "Lit BERT: NLP Transfer Learning In 3 Steps - Towards Data Science", "favorite": "0", "status": "1", "time_added": "1574697541", "time_updated": "1608320049", "time_read": "1576355704", "time_favorited": "0", "sort_id": 91, "resolved_title": "Lit BERT: NLP Transfer Learning In 3 Steps", "resolved_url": "https://towardsdatascience.com/lit-bert-nlp-transfer-learning-in-3-steps-272a866570db", "excerpt": "BERT (Devlin, et al, 2018) is perhaps the most popular NLP approach to transfer learning. The implementation by Huggingface offers a lot of nice features and abstracts away details behind a beautiful API.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "609", "lang": "en", "time_to_read": 3, "top_image_url": "https://miro.medium.com/freeze/max/440/1*S0pwe67pA780cdQETmGblw.gif", "tags": {"bert": {"item_id": "2802544858", "tag": "bert"}, "nlp": {"item_id": "2802544858", "tag": "nlp"}}, "authors": {"143974353": {"item_id": "2802544858", "author_id": "143974353", "name": "William Falcon", "url": "https://william-falcon.medium.com"}}, "image": {"item_id": "2802544858", "src": "https://miro.medium.com/fit/c/56/56/2*5MyOk9_y7SuFWEI8iHD5VA.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2802544858", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*5MyOk9_y7SuFWEI8iHD5VA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2802544858", "image_id": "2", "src": "https://miro.medium.com/max/880/1*S0pwe67pA780cdQETmGblw.gif", "width": "440", "height": "300", "credit": "", "caption": ""}, "3": {"item_id": "2802544858", "image_id": "3", "src": "https://miro.medium.com/max/960/1*26KhEb6qbk-QYWvB5ZLlPg.gif", "width": "480", "height": "360", "credit": "", "caption": ""}, "4": {"item_id": "2802544858", "image_id": "4", "src": "https://miro.medium.com/max/2964/1*wMEaNthMSqMCV4Lp1EG-9g.png", "width": "1482", "height": "578", "credit": "", "caption": ""}, "5": {"item_id": "2802544858", "image_id": "5", "src": "https://miro.medium.com/max/2996/1*69VKlkQBba9nGiatORvevw.png", "width": "1498", "height": "362", "credit": "", "caption": "Huggingface"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 236}, "3078057951": {"item_id": "3078057951", "resolved_id": "3078057991", "given_url": "https://towardsdatascience.com/overview-of-nlp-tokenization-algorithms-c41a7d5ec4f9?source=rss----7f60cf5620c9---4", "given_title": "Overview of tokenization algorithms in NLP", "favorite": "0", "status": "1", "time_added": "1597261124", "time_updated": "1606680695", "time_read": "1606680695", "time_favorited": "0", "sort_id": 92, "resolved_title": "Overview of tokenization algorithms in NLP", "resolved_url": "https://towardsdatascience.com/overview-of-nlp-tokenization-algorithms-c41a7d5ec4f9", "excerpt": "This article is an overview of tokenization algorithms, ranging from word level, character level and subword level tokenization, with emphasis on BPE, Unigram LM, WordPiece and SentencePiece. It is meant to be readable by both experts and beginners alike.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1816", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1200/0*ULGO6dZTbm0PM7dn", "tags": {"nlp": {"item_id": "3078057951", "tag": "nlp"}}, "authors": {"144407942": {"item_id": "3078057951", "author_id": "144407942", "name": "Ane Berasategi", "url": "https://anebz.medium.com"}}, "image": {"item_id": "3078057951", "src": "https://miro.medium.com/fit/c/56/56/1*ZqAEE5oqXUqvpuzpJ6jbaw.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3078057951", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*ZqAEE5oqXUqvpuzpJ6jbaw.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3078057951", "image_id": "2", "src": "https://miro.medium.com/max/5184/0*ULGO6dZTbm0PM7dn", "width": "2592", "height": "4608", "credit": "Hannah Wright on Unsplash", "caption": ""}, "3": {"item_id": "3078057951", "image_id": "3", "src": "https://miro.medium.com/max/1600/1*7_s0e2RuWz5_0GYwqQzFlQ.png", "width": "800", "height": "294", "credit": "", "caption": "Example of subword tokenization"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 703}, "3020316884": {"item_id": "3020316884", "resolved_id": "3020316908", "given_url": "https://towardsdatascience.com/part-4-semantic-segmentation-b42c3792833d?source=rss----7f60cf5620c9---4", "given_title": "Part 4: Semantic Segmentation", "favorite": "0", "status": "1", "time_added": "1592393106", "time_updated": "1608257170", "time_read": "1593020608", "time_favorited": "0", "sort_id": 93, "resolved_title": "Part 4: Semantic Segmentation", "resolved_url": "https://towardsdatascience.com/part-4-semantic-segmentation-b42c3792833d", "excerpt": "STUMPY is a powerful and scalable Python library for modern time series analysis and, at its core, efficiently computes something called a matrix profile.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1930", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/1200/1*BvH7UOSved1IhJao9wxmKw.jpeg", "tags": {"nlp": {"item_id": "3020316884", "tag": "nlp"}}, "authors": {"144838768": {"item_id": "3020316884", "author_id": "144838768", "name": "The Matrix Profile", "url": "https://towardsdatascience.com/the-matrix-profile-e4a679269692"}}, "image": {"item_id": "3020316884", "src": "https://miro.medium.com/fit/c/56/56/0*GcruYNWEnPDiwbjA.", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3020316884", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/0*GcruYNWEnPDiwbjA.", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3020316884", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*BvH7UOSved1IhJao9wxmKw.jpeg", "width": "700", "height": "525", "credit": "Image by Ronan Furuta", "caption": ""}, "3": {"item_id": "3020316884", "image_id": "3", "src": "https://miro.medium.com/max/822/1*NWV2vLKBciK49BAVfzvN4Q.png", "width": "411", "height": "136", "credit": "Image by Author", "caption": ""}, "4": {"item_id": "3020316884", "image_id": "4", "src": "https://miro.medium.com/max/1400/0*_hm2zzhGEj7A_6p4.png", "width": "700", "height": "216", "credit": "Image by Author", "caption": ""}, "5": {"item_id": "3020316884", "image_id": "5", "src": "https://miro.medium.com/max/1400/0*6ZY3RAJOHfIC3kAy.png", "width": "700", "height": "216", "credit": "Image by Author", "caption": ""}, "6": {"item_id": "3020316884", "image_id": "6", "src": "https://miro.medium.com/max/1400/0*IH7Ajqs8j_c8QeQ5.png", "width": "700", "height": "216", "credit": "Image by Author", "caption": ""}, "7": {"item_id": "3020316884", "image_id": "7", "src": "https://miro.medium.com/max/1400/0*17tEY3ZY5GjTTIRN.png", "width": "700", "height": "216", "credit": "Image by Author", "caption": ""}, "8": {"item_id": "3020316884", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*2EuHfmMWqcYMdoqLf5lz_Q.gif", "width": "700", "height": "210", "credit": "Image by Author", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 747}, "2965485019": {"item_id": "2965485019", "resolved_id": "2965485019", "given_url": "https://towardsdatascience.com/python-libraries-for-natural-language-processing-be0e5a35dd64", "given_title": "Python Libraries for Natural Language Processing - Towards Data Science", "favorite": "0", "status": "1", "time_added": "1588088451", "time_updated": "1638708525", "time_read": "1588089112", "time_favorited": "0", "sort_id": 94, "resolved_title": "Python Libraries for Natural Language Processing", "resolved_url": "https://towardsdatascience.com/python-libraries-for-natural-language-processing-be0e5a35dd64", "excerpt": "Claire D. Costa Python is one of the hottest programming languages in the world right now because of how gracefully it integrates with other programming languages and fits perfectly into most new project ideas as the preferred programming language of choice.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1733", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1200/1*PIpjPTlcrDyXLl2fDv34bA.png", "tags": {"deep-learning": {"item_id": "2965485019", "tag": "deep-learning"}, "nlp": {"item_id": "2965485019", "tag": "nlp"}, "python": {"item_id": "2965485019", "tag": "python"}}, "authors": {"137500960": {"item_id": "2965485019", "author_id": "137500960", "name": "Claire D. Costa", "url": "https://medium.com/@harish_6956"}}, "image": {"item_id": "2965485019", "src": "https://miro.medium.com/fit/c/56/56/2*8UE9VXSUAfwXmaMsVg_3dw.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2965485019", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*8UE9VXSUAfwXmaMsVg_3dw.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2965485019", "image_id": "2", "src": "https://miro.medium.com/max/2974/1*PIpjPTlcrDyXLl2fDv34bA.png", "width": "1487", "height": "645", "credit": "", "caption": "Python Libraries for Natural Language Processing"}, "3": {"item_id": "2965485019", "image_id": "3", "src": "https://miro.medium.com/max/752/1*yGIAhBw_KgwBIaU6j-fJJA.png", "width": "376", "height": "134", "credit": "source", "caption": "Spacy"}, "4": {"item_id": "2965485019", "image_id": "4", "src": "https://miro.medium.com/max/1556/1*y8NHPVoA8RMpgPdzIlLggw.png", "width": "778", "height": "304", "credit": "source", "caption": "NLTK — Tokenize and tag some text"}, "5": {"item_id": "2965485019", "image_id": "5", "src": "https://miro.medium.com/max/1564/1*AuzOxOTA6gsjNwLMtepUOg.png", "width": "782", "height": "206", "credit": "source", "caption": "NLTK — Identify Named Entities"}, "6": {"item_id": "2965485019", "image_id": "6", "src": "https://miro.medium.com/max/2290/1*bMF6V6I7dgg87MowKArI4g.png", "width": "1145", "height": "349", "credit": "source", "caption": "Google Trends — Pattern"}, "7": {"item_id": "2965485019", "image_id": "7", "src": "https://miro.medium.com/max/1180/1*-mMgSBLeWuZiKgGd8bFQVw.jpeg", "width": "590", "height": "430", "credit": "source", "caption": "Textblob"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 671}, "2909956296": {"item_id": "2909956296", "resolved_id": "2909931118", "given_url": "https://towardsdatascience.com/quick-introduction-to-sentiment-analysis-74bd3dfb536c?source=rss----7f60cf5620c9---4", "given_title": "Quick Introduction to Sentiment Analysis", "favorite": "0", "status": "1", "time_added": "1583770651", "time_updated": "1638708525", "time_read": "1583784758", "time_favorited": "0", "sort_id": 95, "resolved_title": "Quick Introduction to Sentiment Analysis", "resolved_url": "https://towardsdatascience.com/quick-introduction-to-sentiment-analysis-74bd3dfb536c", "excerpt": "Sentiment analysis is the automated process of determining whether a text expresses a positive, negative, or neutral opinion about a product or topic.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1421", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/1*TUqC3XRqvzErhnFC4h1Rcw@2x.png", "tags": {"deep-learning": {"item_id": "2909956296", "tag": "deep-learning"}, "nlp": {"item_id": "2909956296", "tag": "nlp"}, "sentiment-analysis": {"item_id": "2909956296", "tag": "sentiment-analysis"}}, "authors": {"153833261": {"item_id": "2909956296", "author_id": "153833261", "name": "Rachel Wolff", "url": "https://medium.com/@rachel_39895"}}, "image": {"item_id": "2909956296", "src": "https://miro.medium.com/max/1400/1*TUqC3XRqvzErhnFC4h1Rcw@2x.png", "width": "700", "height": "438"}, "images": {"1": {"item_id": "2909956296", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*TUqC3XRqvzErhnFC4h1Rcw@2x.png", "width": "700", "height": "438", "credit": "", "caption": "Source: MonkeyLearn"}, "2": {"item_id": "2909956296", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*w6FMzraZmFZw3lje", "width": "700", "height": "633", "credit": "", "caption": "Source: MonkeyLearn"}, "3": {"item_id": "2909956296", "image_id": "3", "src": "https://miro.medium.com/max/1400/0*PM18NL-TxTCy5yZ_", "width": "700", "height": "230", "credit": "", "caption": "Source: MonkeyLearn"}, "4": {"item_id": "2909956296", "image_id": "4", "src": "https://miro.medium.com/max/1400/0*8Ne8nPky1tTS9_N7", "width": "700", "height": "361", "credit": "", "caption": "Source: MonkeyLearn"}, "5": {"item_id": "2909956296", "image_id": "5", "src": "https://miro.medium.com/max/830/0*oZ_z0MIWiSm0gv7L", "width": "415", "height": "456", "credit": "", "caption": "Source: MonkeyLearn"}, "6": {"item_id": "2909956296", "image_id": "6", "src": "https://miro.medium.com/max/1400/0*_8OBKlSD9VaNewn2", "width": "700", "height": "479", "credit": "", "caption": "Source: MonkeyLearn"}, "7": {"item_id": "2909956296", "image_id": "7", "src": "https://miro.medium.com/max/1400/0*TS_ilhnJOnvuMJf-", "width": "700", "height": "467", "credit": "", "caption": "Source: MonkeyLearn"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 550}, "2898335602": {"item_id": "2898335602", "resolved_id": "2898335651", "given_url": "https://towardsdatascience.com/recommender-systems-applying-graph-and-nlp-techniques-619dbedd9ecc?source=rss----7f60cf5620c9---4", "given_title": "Beating the baseline recommender using Graph and NLP techniques in PyTorch", "favorite": "0", "status": "1", "time_added": "1582811427", "time_updated": "1608259820", "time_read": "1583785007", "time_favorited": "0", "sort_id": 96, "resolved_title": "", "resolved_url": "https://towardsdatascience.com/recommender-systems-applying-graph-and-nlp-techniques-619dbedd9ecc", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"graphs": {"item_id": "2898335602", "tag": "graphs"}, "nlp": {"item_id": "2898335602", "tag": "nlp"}, "recommenders": {"item_id": "2898335602", "tag": "recommenders"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3344104739": {"item_id": "3344104739", "resolved_id": "3344104739", "given_url": "https://towardsdatascience.com/sentiment-analysis-comparing-3-common-approaches-naive-bayes-lstm-and-vader-ab561f834f89", "given_title": "Sentiment Analysis — Comparing 3 Common Approaches: Naive Bayes, LSTM, and ", "favorite": "0", "status": "1", "time_added": "1622320672", "time_updated": "1638708525", "time_read": "1622498987", "time_favorited": "0", "sort_id": 97, "resolved_title": "Sentiment Analysis", "resolved_url": "https://towardsdatascience.com/sentiment-analysis-comparing-3-common-approaches-naive-bayes-lstm-and-vader-ab561f834f89", "excerpt": "Sentiment Analysis, or Opinion Mining, is a subfield of NLP (Natural Language Processing) that aims to extract attitudes, appraisals, opinions, and emotions from text. Inspired by the rapid migration of customer interactions to digital formats e.g.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2155", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/max/974/1*8RZ-43p0vFmdOBu1SHjyDg.png", "tags": {"deep-learning": {"item_id": "3344104739", "tag": "deep-learning"}, "machine-learning": {"item_id": "3344104739", "tag": "machine-learning"}, "nlp": {"item_id": "3344104739", "tag": "nlp"}, "sentiment-analysis": {"item_id": "3344104739", "tag": "sentiment-analysis"}}, "authors": {"141706727": {"item_id": "3344104739", "author_id": "141706727", "name": "Kevin C Lee", "url": "https://kevin-c-lee26.medium.com"}}, "image": {"item_id": "3344104739", "src": "https://miro.medium.com/fit/c/56/56/2*vB0XEUj0jbXkeAPZV5dovA.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3344104739", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*vB0XEUj0jbXkeAPZV5dovA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3344104739", "image_id": "2", "src": "https://miro.medium.com/max/1948/1*8RZ-43p0vFmdOBu1SHjyDg.png", "width": "974", "height": "489", "credit": "image by Author", "caption": "Sentiment Analysis"}, "3": {"item_id": "3344104739", "image_id": "3", "src": "https://miro.medium.com/max/3236/1*BDMmQjXmClWpyziFcgGjBQ.png", "width": "1618", "height": "562", "credit": "", "caption": "Strengths and Weaknesses Analysis"}, "4": {"item_id": "3344104739", "image_id": "4", "src": "https://miro.medium.com/max/3168/1*IkEIL4puSqD9odOnWbQsxw.png", "width": "1584", "height": "334", "credit": "", "caption": "Original Data"}, "5": {"item_id": "3344104739", "image_id": "5", "src": "https://miro.medium.com/max/1508/1*rnCFjyv4ZymoLHgpWVPC_w.png", "width": "754", "height": "378", "credit": "", "caption": "VADER Calculations"}, "6": {"item_id": "3344104739", "image_id": "6", "src": "https://miro.medium.com/max/3512/1*sGs41qiaBU8HB_y1bO5bNQ.png", "width": "1756", "height": "764", "credit": "", "caption": "Machine Learning NLP Text Classification Process"}, "7": {"item_id": "3344104739", "image_id": "7", "src": "https://miro.medium.com/max/3004/1*SgQRncVp-2WgSftO5_2AUw.png", "width": "1502", "height": "506", "credit": "Weighted Frequency Count", "caption": "Naive Bayes Data Preprocessing Pipeline"}, "8": {"item_id": "3344104739", "image_id": "8", "src": "https://miro.medium.com/max/2996/1*LH-edargGLbjeOrzHJQkpA.png", "width": "1498", "height": "560", "credit": "", "caption": "Word Embedding + LSTM Data Preprocessing Pipeline"}, "9": {"item_id": "3344104739", "image_id": "9", "src": "https://miro.medium.com/max/2376/1*u5VwJdg9dDTpo6NHVAHfxA.png", "width": "1188", "height": "546", "credit": "", "caption": "Word Embedding LSTM Architecture"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 834}, "2995423800": {"item_id": "2995423800", "resolved_id": "2995423820", "given_url": "https://towardsdatascience.com/short-technical-information-about-word2vec-glove-and-fasttext-d38e4f529ca8?source=rss----7f60cf5620c9---4", "given_title": "Short technical information about Word2Vec, GloVe and Fasttext", "favorite": "0", "status": "1", "time_added": "1590452737", "time_updated": "1612385105", "time_read": "1591030001", "time_favorited": "0", "sort_id": 98, "resolved_title": "Short technical information about Word2Vec, GloVe and Fasttext", "resolved_url": "https://towardsdatascience.com/short-technical-information-about-word2vec-glove-and-fasttext-d38e4f529ca8", "excerpt": "With the help of Deep Learning, Natural Language Processing (NLP) has evolved quickly. More and more companies are willing to treat texts faster and in large quantities, and this is why NLP is one of the dynamic areas in Artificial Intelligence research.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1957", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/754/1*rdmUrn-Qvmfpdx0nCCMNiQ.png", "tags": {"machine-learning": {"item_id": "2995423800", "tag": "machine-learning"}, "nlp": {"item_id": "2995423800", "tag": "nlp"}, "python": {"item_id": "2995423800", "tag": "python"}}, "authors": {"134683029": {"item_id": "2995423800", "author_id": "134683029", "name": "Côme Cothenet", "url": "https://medium.com/@come.cothenet"}}, "image": {"item_id": "2995423800", "src": "https://miro.medium.com/fit/c/56/56/2*bICzGN9U_HQtk8QPWBevoQ.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2995423800", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*bICzGN9U_HQtk8QPWBevoQ.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2995423800", "image_id": "2", "src": "https://miro.medium.com/max/1228/1*WNiG62Pqxp9inPfrbCNVdQ.png", "width": "614", "height": "71", "credit": "", "caption": ""}, "3": {"item_id": "2995423800", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*rdmUrn-Qvmfpdx0nCCMNiQ.png", "width": "700", "height": "485", "credit": "https://arxiv.org/abs/1310.4546", "caption": "A projection of word embedding. Here, Paris is to France what Berlin is to Germany. This is called an “analogy”."}, "4": {"item_id": "2995423800", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*igZrMFGYavGCaiZvi8e7BA.png", "width": "700", "height": "412", "credit": "https://arxiv.org/abs/1301.3781–2013", "caption": "One of the most known figure of Word2Vec, architecture of Skip-Gram and CBOW models from Mikolov"}, "5": {"item_id": "2995423800", "image_id": "5", "src": "https://miro.medium.com/max/794/1*FD9jAIHuCMVY_U_w8yIiyQ.png", "width": "397", "height": "66", "credit": "", "caption": ""}, "6": {"item_id": "2995423800", "image_id": "6", "src": "https://miro.medium.com/max/836/1*jl_GN98kkFiK2TH1yE0FOA.png", "width": "418", "height": "102", "credit": "", "caption": ""}, "7": {"item_id": "2995423800", "image_id": "7", "src": "https://miro.medium.com/max/502/1*9Cz0PCp-Lce76MRwtGsOMQ.png", "width": "251", "height": "53", "credit": "", "caption": ""}, "8": {"item_id": "2995423800", "image_id": "8", "src": "https://miro.medium.com/max/626/1*QhkAbmAZfdCM8tFN8BN4uQ.png", "width": "313", "height": "81", "credit": "", "caption": ""}, "9": {"item_id": "2995423800", "image_id": "9", "src": "https://miro.medium.com/max/608/1*XpNeK7vroOblpSA811rgcw.png", "width": "304", "height": "199", "credit": "https://arxiv.org/abs/1607.04606", "caption": "Illustration of the similarity between character n-grams in out-of-vocabulary words."}, "10": {"item_id": "2995423800", "image_id": "10", "src": "https://miro.medium.com/max/558/1*AcKvGnmM-cDzAedprZ6xQg.png", "width": "279", "height": "83", "credit": "", "caption": ""}, "11": {"item_id": "2995423800", "image_id": "11", "src": "https://miro.medium.com/max/742/1*xQTMu8gvndlpc8tZ4Y2CCA.png", "width": "371", "height": "49", "credit": "", "caption": ""}, "12": {"item_id": "2995423800", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*GRlFCi7jKegCkVnt4RUDMQ.png", "width": "700", "height": "148", "credit": "highly", "caption": "Co-occurrence probabilities and ratio with the words ice and steam in function of solid, gas, water and fashion. Since ice is more related to solid than steam, the co-occurrence ratio is high. This is the contrary considering the probe word steam. They are both equally related to water"}, "13": {"item_id": "2995423800", "image_id": "13", "src": "https://miro.medium.com/max/1144/1*6Hp_CBDa0NFjQXip1CusRQ.png", "width": "572", "height": "110", "credit": "", "caption": ""}, "14": {"item_id": "2995423800", "image_id": "14", "src": "https://miro.medium.com/max/918/1*IXdx8t-pFfit530udL4esA.png", "width": "459", "height": "107", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 758}, "3615537736": {"item_id": "3615537736", "resolved_id": "3615537747", "given_url": "https://towardsdatascience.com/solving-complex-nlp-tasks-with-5-simple-python-snippets-libraries-7d4dfab131e8?source=rss----7f60cf5620c9---4", "given_title": "Solving Complex NLP Tasks with 5 Simple Python Snippets/Libraries", "favorite": "0", "status": "1", "time_added": "1652272068", "time_updated": "1653699850", "time_read": "1653699849", "time_favorited": "0", "sort_id": 99, "resolved_title": "Solve Complex NLP Tasks with 5 Lesser-known Python Libraries", "resolved_url": "https://towardsdatascience.com/solving-complex-nlp-tasks-with-5-simple-python-snippets-libraries-7d4dfab131e8", "excerpt": "With the growth of unstructured data, it becomes increasingly imperative to implement solutions for text processing or NLP tasks. In this article, I have compiled 5 useful Python recipes for your next NLP projects.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1091", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/1*ilpt-cehP3xdyakYOZDIPw.jpeg", "tags": {"nlp": {"item_id": "3615537736", "tag": "nlp"}, "python": {"item_id": "3615537736", "tag": "python"}}, "authors": {"166315352": {"item_id": "3615537736", "author_id": "166315352", "name": "Kat Li", "url": "https://yilistats.medium.com"}}, "image": {"item_id": "3615537736", "src": "https://miro.medium.com/max/1400/1*p7dfBKz8cmpouy6qnC1B4g.png", "width": "700", "height": "327"}, "images": {"1": {"item_id": "3615537736", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*p7dfBKz8cmpouy6qnC1B4g.png", "width": "700", "height": "327", "credit": "", "caption": "Textstat grade level"}, "2": {"item_id": "3615537736", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*Zbkm9lM_vAc1vcKm0U5EUw.png", "width": "700", "height": "136", "credit": "", "caption": ""}, "3": {"item_id": "3615537736", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*kPlJOaCMOZQV3smZXQpDJQ.png", "width": "700", "height": "136", "credit": "", "caption": ""}, "4": {"item_id": "3615537736", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*ilpt-cehP3xdyakYOZDIPw.jpeg", "width": "700", "height": "467", "credit": "", "caption": "Image Source: Pixabay"}, "5": {"item_id": "3615537736", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*BOykLgQaa7payqeIiacsHg.png", "width": "700", "height": "666", "credit": "", "caption": "Visualization by Author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 422}, "3574082872": {"item_id": "3574082872", "resolved_id": "3574082897", "given_url": "https://towardsdatascience.com/text-summarization-with-nlp-textrank-vs-seq2seq-vs-bart-474943efeb09?source=rss----7f60cf5620c9---4", "given_title": "Text Summarization with NLP: TextRank vs Seq2Seq vs BART", "favorite": "0", "status": "1", "time_added": "1647348180", "time_updated": "1647528136", "time_read": "1647528136", "time_favorited": "0", "sort_id": 100, "resolved_title": "Text Summarization with NLP: TextRank vs Seq2Seq vs BART", "resolved_url": "https://towardsdatascience.com/text-summarization-with-nlp-textrank-vs-seq2seq-vs-bart-474943efeb09", "excerpt": "In this article, using NLP and Python, I will explain 3 different strategies for text summarization: the old-fashioned TextRank (with gensim), the famous Seq2Seq (with tensorflow), and the cutting edge BART (with transformers).", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4415", "lang": "en", "time_to_read": 20, "top_image_url": "https://miro.medium.com/freeze/max/1022/1*N19i0l_xNBpdYJ8Q6DNTUQ.gif", "tags": {"machine-learning": {"item_id": "3574082872", "tag": "machine-learning"}, "nlp": {"item_id": "3574082872", "tag": "nlp"}}, "authors": {"143906506": {"item_id": "3574082872", "author_id": "143906506", "name": "Mauro Di Pietro", "url": "https://mdipietro09.medium.com"}}, "image": {"item_id": "3574082872", "src": "https://miro.medium.com/max/1400/1*LgqxDMP5qD1HE_uM33zZrg.png", "width": "700", "height": "77"}, "images": {"1": {"item_id": "3574082872", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*LgqxDMP5qD1HE_uM33zZrg.png", "width": "700", "height": "77", "credit": "", "caption": "Image by author"}, "2": {"item_id": "3574082872", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*N19i0l_xNBpdYJ8Q6DNTUQ.gif", "width": "700", "height": "229", "credit": "", "caption": "Image by author"}, "3": {"item_id": "3574082872", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*ZeAjpPFgan7nWWhEmLWBJw.png", "width": "700", "height": "186", "credit": "", "caption": "Image by author"}, "4": {"item_id": "3574082872", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*ievbb9PBizCCRKcCS-m86w.png", "width": "700", "height": "408", "credit": "", "caption": "Text from CNN DailyMail dataset"}, "5": {"item_id": "3574082872", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*RmghRL_9jRKl1Yf9N5ZBYw.png", "width": "700", "height": "432", "credit": "", "caption": "Image by author"}, "6": {"item_id": "3574082872", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*f7DIFKbWr1XGLS5Jg7poUQ.png", "width": "700", "height": "66", "credit": "", "caption": "Image by author"}, "7": {"item_id": "3574082872", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*cBNfyuMus8ECO4UIkGhaiQ.png", "width": "700", "height": "42", "credit": "", "caption": "Image by author"}, "8": {"item_id": "3574082872", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*BiIUWr7PNUjcGmYU_PK00Q.png", "width": "700", "height": "135", "credit": "", "caption": "Image by author"}, "9": {"item_id": "3574082872", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*6ghJfLs6h5HEUF27UzuSTg.png", "width": "700", "height": "425", "credit": "", "caption": "Image by author"}, "10": {"item_id": "3574082872", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*LJ5QzBCqutQQ3qwNHzYg6g.png", "width": "700", "height": "143", "credit": "run the same code for both X and y", "caption": "Image by author"}, "11": {"item_id": "3574082872", "image_id": "11", "src": "https://miro.medium.com/max/1400/1*tMpSo1_YTxtbcRpFW2Y79A.png", "width": "700", "height": "235", "credit": "run the same code for both X and y", "caption": "Image by author"}, "12": {"item_id": "3574082872", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*hwlLdLyLMnGlCI7vKd_uFg.png", "width": "700", "height": "249", "credit": "N documents x Sequences max length", "caption": "Image by author"}, "13": {"item_id": "3574082872", "image_id": "13", "src": "https://miro.medium.com/max/1400/1*4QxDM9IqCMF2gyakv5Ud5Q.png", "width": "700", "height": "28", "credit": "", "caption": "Image by author"}, "14": {"item_id": "3574082872", "image_id": "14", "src": "https://miro.medium.com/max/1400/1*pzlFdvgiixFzoAa_y8siXw.png", "width": "700", "height": "213", "credit": "", "caption": "image by author"}, "15": {"item_id": "3574082872", "image_id": "15", "src": "https://miro.medium.com/max/1400/1*UI3-aAdZTTH_4Kw3iw8E5Q.png", "width": "700", "height": "377", "credit": "", "caption": "Image by author"}, "16": {"item_id": "3574082872", "image_id": "16", "src": "https://miro.medium.com/max/1400/1*2jo6-r6v_ZeQ600gX-fxTQ.png", "width": "700", "height": "220", "credit": "", "caption": "Image by author"}, "17": {"item_id": "3574082872", "image_id": "17", "src": "https://miro.medium.com/max/1400/1*mIGsEW9m8ZMzlldWUsNGqQ.png", "width": "700", "height": "383", "credit": "", "caption": "Image by author"}, "18": {"item_id": "3574082872", "image_id": "18", "src": "https://miro.medium.com/max/1400/1*8-hTaSpsI8aueElcVtpJqA.png", "width": "700", "height": "527", "credit": "", "caption": "Image by author"}, "19": {"item_id": "3574082872", "image_id": "19", "src": "https://miro.medium.com/max/1400/1*UZi1QhpK4TYHcSE5SFaQ6Q.png", "width": "700", "height": "165", "credit": "", "caption": "Image by author"}, "20": {"item_id": "3574082872", "image_id": "20", "src": "https://miro.medium.com/max/1400/1*JPk-Ha92wBmAFqpCJZonDw.png", "width": "700", "height": "323", "credit": "", "caption": "Image by author"}, "21": {"item_id": "3574082872", "image_id": "21", "src": "https://miro.medium.com/max/1400/1*eM38SBIbUB3z6DcvCu81IQ.png", "width": "700", "height": "369", "credit": "", "caption": "Image by author"}, "22": {"item_id": "3574082872", "image_id": "22", "src": "https://miro.medium.com/max/1400/1*K9qlLBIycGXtfG7I9jFB2A.gif", "width": "700", "height": "320", "credit": "", "caption": "Image by author"}, "23": {"item_id": "3574082872", "image_id": "23", "src": "https://miro.medium.com/max/1400/1*VzIFrQNOBn2-uxfrbIbO6Q.png", "width": "700", "height": "40", "credit": "", "caption": "Image by author"}, "24": {"item_id": "3574082872", "image_id": "24", "src": "https://miro.medium.com/max/1400/1*cAs0CT6UPTJRp97V42HwCw.png", "width": "700", "height": "296", "credit": "", "caption": "Image by author"}, "25": {"item_id": "3574082872", "image_id": "25", "src": "https://miro.medium.com/max/1400/1*agZMLF7w2dvsQB6_l8BhQA.png", "width": "700", "height": "37", "credit": "", "caption": "Image by author"}, "26": {"item_id": "3574082872", "image_id": "26", "src": "https://miro.medium.com/max/1400/1*ADV5NNoyzhAuBBoczY2Q7Q.png", "width": "700", "height": "359", "credit": "", "caption": "Image by author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1709}, "3397292588": {"item_id": "3397292588", "resolved_id": "3397292596", "given_url": "https://towardsdatascience.com/tokenization-algorithms-explained-e25d5f4322ac?source=rss----7f60cf5620c9---4", "given_title": "Tokenization Algorithms Explained", "favorite": "0", "status": "1", "time_added": "1627994534", "time_updated": "1628156430", "time_read": "1628156429", "time_favorited": "0", "sort_id": 101, "resolved_title": "Tokenization Algorithms Explained", "resolved_url": "https://towardsdatascience.com/tokenization-algorithms-explained-e25d5f4322ac", "excerpt": "For the uninitiated, let's start by formally introducing the concept of tokenization — Tokenization is simply a method of splitting input textual data into individual separate meaningful tokens that can be further understood and processed by machines.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1277", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/0*wshpqpXFxdh06upV", "tags": {"machine-learning": {"item_id": "3397292588", "tag": "machine-learning"}, "nlp": {"item_id": "3397292588", "tag": "nlp"}}, "authors": {"138053994": {"item_id": "3397292588", "author_id": "138053994", "name": "Sharvil Nagarkar", "url": "https://medium.com/@sharvill"}}, "image": {"item_id": "3397292588", "src": "https://miro.medium.com/fit/c/56/56/1*-D3v-PdlQDXa_rH-5MQIFg.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3397292588", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*-D3v-PdlQDXa_rH-5MQIFg.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3397292588", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*wshpqpXFxdh06upV", "width": "700", "height": "525", "credit": "Brett Jordan on Unsplash", "caption": ""}, "3": {"item_id": "3397292588", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*BjagxNsv3iOetiD7GRuP_A.png", "width": "700", "height": "137", "credit": "", "caption": "Space Tokenization"}, "4": {"item_id": "3397292588", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*fQMSAONMWrYKY50jpiZ-oA.png", "width": "700", "height": "119", "credit": "", "caption": "Space and Punctuation Tokenization"}, "5": {"item_id": "3397292588", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*MDXkR4Uepjk7wSJzghsWxw.png", "width": "700", "height": "124", "credit": "", "caption": "Rule-based Tokenization — SpaCy"}, "6": {"item_id": "3397292588", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*TetZz9T0GjShk8tIswcStg.png", "width": "700", "height": "111", "credit": "", "caption": "Character-based Tokenization"}, "7": {"item_id": "3397292588", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*Aehz4xgrEzILKVc9w1IkUA.png", "width": "700", "height": "371", "credit": "te-Pair Encoding Algorithm", "caption": ""}, "8": {"item_id": "3397292588", "image_id": "8", "src": "https://miro.medium.com/max/306/1*Ucg6hM2dUTgkc5hMxqgY7A.png", "width": "153", "height": "104", "credit": "", "caption": "where a, b are tokens in vocabulary"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 494}, "2952033401": {"item_id": "2952033401", "resolved_id": "2952025885", "given_url": "https://towardsdatascience.com/topic-modeling-articles-with-nmf-8c6b2a227a45?source=rss----7f60cf5620c9---4", "given_title": "Topic Modeling Articles with NMF", "favorite": "0", "status": "1", "time_added": "1587050425", "time_updated": "1638708525", "time_read": "1587304791", "time_favorited": "0", "sort_id": 102, "resolved_title": "Topic Modeling Articles with NMF", "resolved_url": "https://towardsdatascience.com/topic-modeling-articles-with-nmf-8c6b2a227a45", "excerpt": "Extracting topics is a good unsupervised data-mining technique to discover the underlying relationships between texts. There are many different approaches with the most popular probably being LDA but I’m going to focus on NMF.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2564", "lang": "en", "time_to_read": 12, "top_image_url": "https://miro.medium.com/max/1200/1*oAwFKQm3DJG_heudbBOY0Q.jpeg", "tags": {"deep-learning": {"item_id": "2952033401", "tag": "deep-learning"}, "nlp": {"item_id": "2952033401", "tag": "nlp"}}, "authors": {"105620742": {"item_id": "2952033401", "author_id": "105620742", "name": "Rob Salgado", "url": "https://medium.com/@robert.salgado"}}, "image": {"item_id": "2952033401", "src": "https://miro.medium.com/fit/c/56/56/1*Xu5jY5MRE7KW8GBlfAhSUA.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2952033401", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*Xu5jY5MRE7KW8GBlfAhSUA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2952033401", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*oAwFKQm3DJG_heudbBOY0Q.jpeg", "width": "700", "height": "465", "credit": "Romain Vignes on Unsplash", "caption": ""}, "3": {"item_id": "2952033401", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*vX2vG1G-6VxCfiWMbCBzOw.png", "width": "700", "height": "113", "credit": "", "caption": ""}, "4": {"item_id": "2952033401", "image_id": "4", "src": "https://miro.medium.com/max/1220/1*4sMcsbQsunalnAXp3roVkw.png", "width": "610", "height": "334", "credit": "", "caption": ""}, "5": {"item_id": "2952033401", "image_id": "5", "src": "https://miro.medium.com/max/566/1*mOK2MrHS1rz7v7sE06mitA.png", "width": "283", "height": "522", "credit": "", "caption": ""}, "6": {"item_id": "2952033401", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*T21E6myryrjVUwiz_-VYNg.png", "width": "700", "height": "294", "credit": "", "caption": ""}, "7": {"item_id": "2952033401", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*F1-YC081ESgrFWDo50zO5Q.png", "width": "700", "height": "321", "credit": "", "caption": ""}, "8": {"item_id": "2952033401", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*fzl-78rF_NwTHyL_69amcg.png", "width": "700", "height": "350", "credit": "", "caption": ""}, "9": {"item_id": "2952033401", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*5soiJmDbTcTTOd1HdeEmJg.png", "width": "700", "height": "154", "credit": "", "caption": ""}, "10": {"item_id": "2952033401", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*vVAKSfQ1seqHUsqfK79Z-g.png", "width": "700", "height": "110", "credit": "", "caption": ""}, "11": {"item_id": "2952033401", "image_id": "11", "src": "https://miro.medium.com/max/1400/1*V_pbHaRBxXXrYgg2C4Hnjw.png", "width": "700", "height": "269", "credit": "", "caption": ""}, "12": {"item_id": "2952033401", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*HYJrhAJURPijbGwLkDb__w.png", "width": "700", "height": "105", "credit": "", "caption": ""}, "13": {"item_id": "2952033401", "image_id": "13", "src": "https://miro.medium.com/max/1400/1*j1pzP4-qAF7Y6twRVL5hAA.png", "width": "700", "height": "105", "credit": "", "caption": ""}, "14": {"item_id": "2952033401", "image_id": "14", "src": "https://miro.medium.com/max/1400/1*Wuep5qPclSYqZZ2AKktvhw.png", "width": "700", "height": "106", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 993}, "3706879960": {"item_id": "3706879960", "resolved_id": "3706879980", "given_url": "https://towardsdatascience.com/topic-modeling-with-lsa-plsa-lda-nmf-bertopic-top2vec-a-comparison-5e6ce4b1e4a5?source=rss----7f60cf5620c9---4", "given_title": "Topic Modeling with LSA, pLSA, LDA, NMF, BERTopic, Top2Vec: a Comparison", "favorite": "0", "status": "1", "time_added": "1663672726", "time_updated": "1706233547", "time_read": "1665774124", "time_favorited": "0", "sort_id": 103, "resolved_title": "Topic Modeling with LSA, pLSA, LDA, NMF, BERTopic, Top2Vec: a Comparison", "resolved_url": "https://towardsdatascience.com/topic-modeling-with-lsa-plsa-lda-nmf-bertopic-top2vec-a-comparison-5e6ce4b1e4a5", "excerpt": "In Natural Language Processing (NLP), the term topic modeling encompasses a series of statistical and Deep Learning techniques to find hidden semantic structures in sets of documents. Topic modeling is an unsupervised Machine Learning problem.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4382", "lang": "en", "time_to_read": 20, "top_image_url": "https://miro.medium.com/max/1200/1*gZdKeE6uuzUrstJYuOTpYw.png", "tags": {"algorithms-math": {"item_id": "3706879960", "tag": "algorithms-math"}, "machine-learning": {"item_id": "3706879960", "tag": "machine-learning"}, "nlp": {"item_id": "3706879960", "tag": "nlp"}, "topic-modeling": {"item_id": "3706879960", "tag": "topic-modeling"}}, "authors": {"145379655": {"item_id": "3706879960", "author_id": "145379655", "name": "Nicolo Cosimo Albanese", "url": "https://nicolo-albanese.medium.com"}}, "image": {"item_id": "3706879960", "src": "https://miro.medium.com/max/1400/1*gZdKeE6uuzUrstJYuOTpYw.png", "width": "700", "height": "0"}, "images": {"1": {"item_id": "3706879960", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*gZdKeE6uuzUrstJYuOTpYw.png", "width": "700", "height": "0", "credit": "", "caption": "Image by author."}, "2": {"item_id": "3706879960", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*vLnFZ7Pz1WsKyxUpaCk78g.png", "width": "700", "height": "0", "credit": "", "caption": "Document-Term Matrix from a sample set of documents. Image by author."}, "3": {"item_id": "3706879960", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*I4uCELHdOEEimOyWm6Fmpw.png", "width": "700", "height": "0", "credit": "", "caption": "TF-IDF. Image by author."}, "4": {"item_id": "3706879960", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*HR8de7uYPKtp3b6t3hiAIw.png", "width": "700", "height": "0", "credit": "DTM", "caption": "Truncated SVD on the Document-Term Matrix"}, "5": {"item_id": "3706879960", "image_id": "5", "src": "https://miro.medium.com/max/1210/1*Gyk4uh5mFbRB9-1u2Jp5_g.png", "width": "605", "height": "0", "credit": "1999", "caption": "From Hofmann"}, "6": {"item_id": "3706879960", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*Y9_uJI0EJf7umNgnP80XIw.png", "width": "700", "height": "0", "credit": "1999", "caption": "From Hofmann"}, "7": {"item_id": "3706879960", "image_id": "7", "src": "https://miro.medium.com/max/960/1*OfiLT56R8JrtNp7y7wN7DQ.png", "width": "480", "height": "0", "credit": "2013", "caption": "Plane notation of LDA. From Barbieri⁵"}, "8": {"item_id": "3706879960", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*59XHJE4vpCUSM_hKVX6Tmg.png", "width": "700", "height": "0", "credit": "", "caption": "Image by author."}, "9": {"item_id": "3706879960", "image_id": "9", "src": "https://miro.medium.com/max/1092/1*6gGefdPQHDID1hedn_phNg.png", "width": "546", "height": "0", "credit": "", "caption": "Intertopic distance map generated by the previous code snippet. The visualization is similar to the one obtained by pyLDAvis. Image by author."}, "10": {"item_id": "3706879960", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*K251QZFnzF-cb0OG1e6igA.png", "width": "700", "height": "0", "credit": "detail", "caption": "Documents projections"}, "11": {"item_id": "3706879960", "image_id": "11", "src": "https://miro.medium.com/max/1400/1*WSfhBMOhII7QLY_PNosvMg.png", "width": "700", "height": "0", "credit": "dendrogram", "caption": "Topics hierarchical structure"}, "12": {"item_id": "3706879960", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*gJKBF6Fpx9TFJaEzgfYuzw.png", "width": "700", "height": "0", "credit": "", "caption": "Word clouds of the closest five topics to the input query “faith” generated by the previous code snippet. Image by author."}, "13": {"item_id": "3706879960", "image_id": "13", "src": "https://miro.medium.com/max/716/1*B5HqP3YuFfYdgzrS3A8zJQ.png", "width": "358", "height": "0", "credit": "", "caption": "Image by author."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1696}, "2953916020": {"item_id": "2953916020", "resolved_id": "2953916077", "given_url": "https://towardsdatascience.com/twitter-sentiment-analysis-with-node-js-ae1ed8dd8fa7?source=rss----7f60cf5620c9---4", "given_title": "Twitter Sentiment Analysis with Node.js", "favorite": "0", "status": "1", "time_added": "1587209149", "time_updated": "1587305148", "time_read": "1587305148", "time_favorited": "0", "sort_id": 104, "resolved_title": "Twitter Sentiment Analysis with Node.js", "resolved_url": "https://towardsdatascience.com/twitter-sentiment-analysis-with-node-js-ae1ed8dd8fa7", "excerpt": "Sentiment Analysis is the process of analyzing if a piece of online writing (social media posts, comments) is positive, negative or neutral. Significant progress has been made in the field of Sentiment Analysis in the past few years, this technique has been largely used in Business and Politics.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "839", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/v2/resize:fit:1000/1*vp1M37AGMOFwCvLxVm62IA.jpeg", "tags": {"nlp": {"item_id": "2953916020", "tag": "nlp"}, "nodejs": {"item_id": "2953916020", "tag": "nodejs"}, "sentiment-analysis": {"item_id": "2953916020", "tag": "sentiment-analysis"}}, "authors": {"132256372": {"item_id": "2953916020", "author_id": "132256372", "name": "Benson Ruan", "url": "https://medium.com/@bensonruan"}}, "image": {"item_id": "2953916020", "src": "https://miro.medium.com/v2/resize:fill:88:88/2*eB0UsTGy14NYw50HPnRiWw.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "2953916020", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/2*eB0UsTGy14NYw50HPnRiWw.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "2953916020", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 325}, "2050563121": {"item_id": "2050563121", "resolved_id": "2050563121", "given_url": "https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41", "given_title": "Understanding Feature Engineering (Part 3) — Traditional Methods for Text D", "favorite": "0", "status": "1", "time_added": "1523218293", "time_updated": "1671277184", "time_read": "1523289982", "time_favorited": "0", "sort_id": 105, "resolved_title": "Traditional Methods for Text Data", "resolved_url": "https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41", "excerpt": "We have covered various feature engineering strategies for dealing with structured data in the first two parts of this series. Check out Part-I: Continuous, numeric data and Part-II: Discrete, categorical data for a refresher.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3839", "lang": "en", "time_to_read": 17, "top_image_url": "https://miro.medium.com/max/1024/1*vXKKe3J-lfi1YQ7HC6onxQ.jpeg", "tags": {"feature-engineering": {"item_id": "2050563121", "tag": "feature-engineering"}, "machine-learning": {"item_id": "2050563121", "tag": "machine-learning"}, "nlp": {"item_id": "2050563121", "tag": "nlp"}, "text": {"item_id": "2050563121", "tag": "text"}}, "authors": {"142369656": {"item_id": "2050563121", "author_id": "142369656", "name": "Dipanjan (DJ) Sarkar", "url": "https://djsarkar.medium.com"}}, "image": {"item_id": "2050563121", "src": "https://miro.medium.com/fit/c/56/56/1*Wy0cxXZpX-FrMWeXsqOOpg.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2050563121", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*Wy0cxXZpX-FrMWeXsqOOpg.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2050563121", "image_id": "2", "src": "https://miro.medium.com/max/2048/1*vXKKe3J-lfi1YQ7HC6onxQ.jpeg", "width": "1024", "height": "500", "credit": "", "caption": ""}, "3": {"item_id": "2050563121", "image_id": "3", "src": "https://miro.medium.com/max/370/1*1ihhqrBr0M6C-zgHeR7I_Q.png", "width": "185", "height": "257", "credit": "", "caption": ""}, "4": {"item_id": "2050563121", "image_id": "4", "src": "https://miro.medium.com/max/972/1*NGAjqKmla8_N6c4tKmxkgA.png", "width": "486", "height": "233", "credit": "", "caption": "Our sample text corpus"}, "5": {"item_id": "2050563121", "image_id": "5", "src": "https://miro.medium.com/max/1046/1*hTzCB81C8Wi5VxMSGAzd-w.png", "width": "523", "height": "390", "credit": "", "caption": ""}, "6": {"item_id": "2050563121", "image_id": "6", "src": "https://miro.medium.com/max/1900/1*zMdHVQQ7HYv_mMZ5Ne-2yQ.png", "width": "950", "height": "236", "credit": "", "caption": "Our Bag of Words model based document feature vectors"}, "7": {"item_id": "2050563121", "image_id": "7", "src": "https://miro.medium.com/max/2008/1*TrMMDjpylFZQIU6EY8INPw.png", "width": "1004", "height": "287", "credit": "", "caption": "Bi-gram based feature vectors using the Bag of N-Grams Model"}, "8": {"item_id": "2050563121", "image_id": "8", "src": "https://miro.medium.com/max/848/1*PUtPh3Jj0sPiRuCGhzpxSg.png", "width": "424", "height": "71", "credit": "", "caption": ""}, "9": {"item_id": "2050563121", "image_id": "9", "src": "https://miro.medium.com/max/1904/1*VTI7EPLNqXECMM_48SZTww.png", "width": "952", "height": "235", "credit": "", "caption": "Our TF-IDF model based document feature vectors"}, "10": {"item_id": "2050563121", "image_id": "10", "src": "https://miro.medium.com/max/880/0*yqSGboQIoKYxkMh3.", "width": "440", "height": "333", "credit": "", "caption": "Are we similar?"}, "11": {"item_id": "2050563121", "image_id": "11", "src": "https://miro.medium.com/max/1076/1*1FT_YXdRC1hc7Ns18Non2Q.png", "width": "538", "height": "233", "credit": "cosine similarity", "caption": "Pairwise document similarity matrix"}, "12": {"item_id": "2050563121", "image_id": "12", "src": "https://miro.medium.com/max/1554/1*6kOlPsrmOvTFIuGGb0qBJw.png", "width": "777", "height": "242", "credit": "", "caption": "Cosine similarity depictions for text document feature vectors"}, "13": {"item_id": "2050563121", "image_id": "13", "src": "https://miro.medium.com/max/836/0*nkjubhFvynBLrXv7.png", "width": "418", "height": "333", "credit": "", "caption": "Agglomerative Hierarchical Clustering"}, "14": {"item_id": "2050563121", "image_id": "14", "src": "https://miro.medium.com/max/908/1*2dcWnQrb8ws3d8aBMu1irA.png", "width": "454", "height": "211", "credit": "", "caption": "Linkage Matrix for our Corpus"}, "15": {"item_id": "2050563121", "image_id": "15", "src": "https://miro.medium.com/max/1012/1*Be-eVWH7XbpQ0J04ixL4uQ.png", "width": "506", "height": "228", "credit": "", "caption": "Dendrogram visualizing our hierarchical clustering process"}, "16": {"item_id": "2050563121", "image_id": "16", "src": "https://miro.medium.com/max/1156/1*P-F02GgiCwIUndQXWRGqSg.png", "width": "578", "height": "239", "credit": "", "caption": "Clustering our documents into groups with hierarchical clustering"}, "17": {"item_id": "2050563121", "image_id": "17", "src": "https://miro.medium.com/max/1274/0*3YiGp_YuwcwPNfM8.png", "width": "637", "height": "353", "credit": "", "caption": "An example of topic models"}, "18": {"item_id": "2050563121", "image_id": "18", "src": "https://miro.medium.com/max/2800/0*qZAMpfL2XlHF2gCT.png", "width": "1400", "height": "736", "credit": "courtesy of C. Doig, Introduction to Topic  Modeling in Python", "caption": "End-to-end LDA framework"}, "19": {"item_id": "2050563121", "image_id": "19", "src": "https://miro.medium.com/max/1000/1*Wa5tvzIPAfcJj3bV6RW7xg.png", "width": "500", "height": "417", "credit": "", "caption": ""}, "20": {"item_id": "2050563121", "image_id": "20", "src": "https://miro.medium.com/max/438/1*JfwMR3Ye0WVXuSHWOp7DPQ.png", "width": "219", "height": "242", "credit": "", "caption": "Document-Topic Matrix from our LDA Model"}, "21": {"item_id": "2050563121", "image_id": "21", "src": "https://miro.medium.com/max/1150/1*WxRbRltR92LuQG5oZs08uA.png", "width": "575", "height": "231", "credit": "", "caption": "Clustering our documents into groups with K-means clustering"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1486}, "3678166295": {"item_id": "3678166295", "resolved_id": "3678166295", "given_url": "https://towardsdatascience.com/visualizing-part-of-speech-tags-with-nltk-and-spacy-42056fcd777e", "given_title": "Visualizing Part-of-Speech Tags with NLTK and SpaCy", "favorite": "0", "status": "1", "time_added": "1660260957", "time_updated": "1660935251", "time_read": "1660935251", "time_favorited": "0", "sort_id": 106, "resolved_title": "Visualizing Part-of-Speech Tags with NLTK and SpaCy", "resolved_url": "https://towardsdatascience.com/visualizing-part-of-speech-tags-with-nltk-and-spacy-42056fcd777e", "excerpt": "In this tutorial, we will develop a function to visualize part-of-speech (POS) tags with NLTK and SpaCy. POS tagging is a technique used in Natural Language Processing. It categorizes the tokens in a text as nouns, verbs, adjectives, and so on.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "988", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/max/940/1*m2qeNjOSiDZzTFhdHpORqw.png", "tags": {"nlp": {"item_id": "3678166295", "tag": "nlp"}, "nltk": {"item_id": "3678166295", "tag": "nltk"}, "python": {"item_id": "3678166295", "tag": "python"}, "spacy": {"item_id": "3678166295", "tag": "spacy"}}, "authors": {"169303828": {"item_id": "3678166295", "author_id": "169303828", "name": "Leonie Monigatti", "url": "https://medium.com/@iamleonie"}}, "image": {"item_id": "3678166295", "src": "https://miro.medium.com/max/1400/1*m2qeNjOSiDZzTFhdHpORqw.png", "width": "700", "height": "300"}, "images": {"1": {"item_id": "3678166295", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*m2qeNjOSiDZzTFhdHpORqw.png", "width": "700", "height": "300", "credit": "", "caption": "Image by the author."}, "2": {"item_id": "3678166295", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*vfFfxudYGgWvM_f-iihxIA.png", "width": "700", "height": "54", "credit": "Image by the author", "caption": "Input sentence"}, "3": {"item_id": "3678166295", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*VrXgMuotozPb7EUygvz0PA.png", "width": "700", "height": "54", "credit": "Image by the author", "caption": "Output sentence"}, "4": {"item_id": "3678166295", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*fyKIjNTz5SwnZvbQTf1y4A.png", "width": "700", "height": "258", "credit": "Image by the author", "caption": "POS-tagged example sentence"}, "5": {"item_id": "3678166295", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*h4-ttf5okQmoVHESOH22AA.png", "width": "700", "height": "266", "credit": "Image by the author", "caption": "Visualized dependencies of example sentence with displaCy"}, "6": {"item_id": "3678166295", "image_id": "6", "src": "https://miro.medium.com/max/1348/1*J5jgu1qSN_nJgsFhxhSi8w.png", "width": "674", "height": "70", "credit": "Image by the author", "caption": "Visualized entities of example sentence with displaCy"}, "7": {"item_id": "3678166295", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*I9nPaFDU7Sr5tdRlVwZKcA.png", "width": "700", "height": "44", "credit": "", "caption": ""}, "8": {"item_id": "3678166295", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*81t0J8JLp6iOBfsQ6gHMtw.png", "width": "700", "height": "76", "credit": "", "caption": ""}, "9": {"item_id": "3678166295", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*eh0vgx-SzrByHGscl8JwJA.png", "width": "700", "height": "44", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 382}, "3741252241": {"item_id": "3741252241", "resolved_id": "3741252241", "given_url": "https://towardsdatascience.com/what-do-countries-talk-about-at-the-un-general-debate-topic-modelings-using-lda-19873cf00fe0", "given_title": "", "favorite": "0", "status": "1", "time_added": "1669033583", "time_updated": "1669164828", "time_read": "1669164828", "time_favorited": "0", "sort_id": 107, "resolved_title": "What do countries talk about at the UN General Debate? Topic modelings using LDA", "resolved_url": "https://towardsdatascience.com/what-do-countries-talk-about-at-the-un-general-debate-topic-modelings-using-lda-19873cf00fe0", "excerpt": "By Lan Chu and Robert Jan Sokolewicz. Latent Dirichlet Allocation (LDA) is a popular model when it comes to analyzing large amounts of text. It is a generative probabilistic model that enables users to uncover hidden (“latent”) topics and themes from a collection of documents.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "3181", "lang": "en", "time_to_read": 14, "top_image_url": "https://miro.medium.com/max/1058/0*oU_X5rAYD80g0Tx5", "tags": {"lda": {"item_id": "3741252241", "tag": "lda"}, "nlp": {"item_id": "3741252241", "tag": "nlp"}, "topic-modeling": {"item_id": "3741252241", "tag": "topic-modeling"}}, "authors": {"174376312": {"item_id": "3741252241", "author_id": "174376312", "name": "Lan Chu", "url": "https://huonglanchu.medium.com"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1231}, "2728661613": {"item_id": "2728661613", "resolved_id": "2728661613", "given_url": "https://towardsml.com/2019/09/17/bert-explained-a-complete-guide-with-theory-and-tutorial/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1575403256", "time_updated": "1608317893", "time_read": "1575563583", "time_favorited": "0", "sort_id": 108, "resolved_title": "BERT Explained: A Complete Guide with Theory and Tutorial", "resolved_url": "https://towardsml.com/2019/09/17/bert-explained-a-complete-guide-with-theory-and-tutorial/", "excerpt": "Unless you have been out of touch with the Deep Learning world, chances are that you have heard about BERT —  it has been the talk of the town for the last one year.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3260", "lang": "en", "time_to_read": 15, "amp_url": "https://towardsml.com/2019/09/17/bert-explained-a-complete-guide-with-theory-and-tutorial/amp/", "top_image_url": "https://towardsml.files.wordpress.com/2019/09/bert.png?w=1200", "tags": {"bert": {"item_id": "2728661613", "tag": "bert"}, "nlp": {"item_id": "2728661613", "tag": "nlp"}}, "authors": {"85801090": {"item_id": "2728661613", "author_id": "85801090", "name": "Samia Khalid", "url": "https://towardsml.com/author/samiakhalid/"}}, "image": {"item_id": "2728661613", "src": "https://towardsml.files.wordpress.com/2019/09/input.png?w=810", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2728661613", "image_id": "1", "src": "https://towardsml.files.wordpress.com/2019/09/input.png?w=810", "width": "0", "height": "0", "credit": "", "caption": "The input representation for BERT: The input embeddings are the sum of the token embeddings, the segmentation embeddings and the position embeddings."}, "2": {"item_id": "2728661613", "image_id": "2", "src": "https://towardsml.files.wordpress.com/2019/09/nsp-1.png?w=810", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2728661613", "image_id": "3", "src": "https://towardsml.files.wordpress.com/2019/09/qa.png?w=810", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2728661613", "image_id": "4", "src": "https://towardsml.files.wordpress.com/2019/09/capture.png?w=810", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1262}, "3541365215": {"item_id": "3541365215", "resolved_id": "3541365215", "given_url": "https://transformersbook.com/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1646613788", "time_updated": "1648069449", "time_read": "1648069449", "time_favorited": "0", "sort_id": 109, "resolved_title": "Natural Language Processing with Transformers Book", "resolved_url": "https://transformersbook.com/", "excerpt": "“The preeminent book for the preeminent transformers library—a model of clarity!” —Jeremy Howard, cofounder of fast.ai and professor at University of Queensland “A wonderfully clear and incisive guide to modern NLP’s most essential library.", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "317", "lang": "en", "top_image_url": "https://transformersbook.com/images/logo.png", "tags": {"books": {"item_id": "3541365215", "tag": "books"}, "machine-learning": {"item_id": "3541365215", "tag": "machine-learning"}, "nlp": {"item_id": "3541365215", "tag": "nlp"}}, "image": {"item_id": "3541365215", "src": "https://transformersbook.com/images/book_cover.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3541365215", "image_id": "1", "src": "https://transformersbook.com/images/book_cover.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 123}, "3718988973": {"item_id": "3718988973", "resolved_id": "3718988973", "given_url": "https://undark.org/2022/10/07/interview-why-mastering-language-is-so-difficult-for-ai/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1665968804", "time_updated": "1665968863", "time_read": "1665968862", "time_favorited": "0", "sort_id": 110, "resolved_title": "Interview: Why Mastering Language Is So Difficult for AI", "resolved_url": "https://undark.org/2022/10/07/interview-why-mastering-language-is-so-difficult-for-ai/", "excerpt": "The field of artificial intelligence has never lacked for hype. Back in 1965, AI pioneer Herb Simon declared, “Machines will be capable, within 20 years, of doing any work a man can do.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1799", "lang": "en", "time_to_read": 8, "top_image_url": "https://undark.org/wp-content/uploads/2022/10/GettyImages-1355827275_edit.jpg", "tags": {"deep-learning": {"item_id": "3718988973", "tag": "deep-learning"}, "goodreads": {"item_id": "3718988973", "tag": "goodreads"}, "language-linguistics": {"item_id": "3718988973", "tag": "language-linguistics"}, "nlp": {"item_id": "3718988973", "tag": "nlp"}}, "authors": {"122246514": {"item_id": "3718988973", "author_id": "122246514", "name": "Dan Falk", "url": "https://undark.org/undark-author/dan-falk/"}}, "listen_duration_estimate": 696}, "3172042531": {"item_id": "3172042531", "resolved_id": "3172042531", "given_url": "https://venturebeat.com/2020/11/13/amazon-shifts-some-alexa-and-rekognition-computing-to-its-own-inferentia-chip/", "given_title": "Amazon shifts some Alexa and Rekognition computing to its own Inferentia ch", "favorite": "0", "status": "1", "time_added": "1605265165", "time_updated": "1605267806", "time_read": "1605267805", "time_favorited": "0", "sort_id": 111, "resolved_title": "Amazon shifts some Alexa and Rekognition computing to its own Inferentia chip", "resolved_url": "https://venturebeat.com/2020/11/13/amazon-shifts-some-alexa-and-rekognition-computing-to-its-own-inferentia-chip/", "excerpt": "Where does your enterprise stand on the AI adoption curve? Take our AI survey to find out. When users of devices such as Amazon’s Echo line of smart speakers ask the voice assistant a question, the query is sent to one of Amazon’s datacenters for several steps of processing.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "428", "lang": "en", "amp_url": "https://venturebeat.com/2020/11/13/amazon-shifts-some-alexa-and-rekognition-computing-to-its-own-inferentia-chip/amp/", "top_image_url": "https://venturebeat.com/wp-content/uploads/2018/05/alexa-on-book-e1595272380870.jpg?w=1200&strip=all", "tags": {"nlp": {"item_id": "3172042531", "tag": "nlp"}}, "authors": {"39087381": {"item_id": "3172042531", "author_id": "39087381", "name": "Reuters", "url": "https://venturebeat.com/author/reuters/"}}, "image": {"item_id": "3172042531", "src": "https://venturebeat.com/wp-content/uploads/2018/05/alexa-on-book-e1595272380870.jpg?resize=1200%2C600&strip=all", "width": "1200", "height": "600"}, "images": {"1": {"item_id": "3172042531", "image_id": "1", "src": "https://venturebeat.com/wp-content/uploads/2018/05/alexa-on-book-e1595272380870.jpg?resize=1200%2C600&strip=all", "width": "1200", "height": "600", "credit": "", "caption": "Amazon's Echo smart speaker with Alexa.Image Credit: Amazon"}}, "domain_metadata": {"name": "VentureBeat", "logo": "https://logo.clearbit.com/venturebeat.com?size=800", "greyscale_logo": "https://logo.clearbit.com/venturebeat.com?size=800&greyscale=true"}, "listen_duration_estimate": 166}, "3267911475": {"item_id": "3267911475", "resolved_id": "3267911475", "given_url": "https://venturebeat.com/2021/02/27/gpt-3-were-at-the-very-beginning-of-a-new-app-ecosystem/", "given_title": "GPT-3: We’re at the very beginning of a new app ecosystem", "favorite": "0", "status": "1", "time_added": "1614466688", "time_updated": "1671724937", "time_read": "1614468059", "time_favorited": "0", "sort_id": 112, "resolved_title": "GPT-3: We’re at the very beginning of a new app ecosystem", "resolved_url": "https://venturebeat.com/2021/02/27/gpt-3-were-at-the-very-beginning-of-a-new-app-ecosystem/", "excerpt": "Elevate your enterprise data technology and strategy at Transform 2021. The most impressive thing about OpenAI’s natural language processing (NLP) model, GPT-3, is its sheer size.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1215", "lang": "en", "time_to_read": 6, "amp_url": "https://venturebeat.com/2021/02/27/gpt-3-were-at-the-very-beginning-of-a-new-app-ecosystem/amp/", "top_image_url": "https://venturebeat.com/wp-content/uploads/2021/02/gpt-3.jpg?w=1200&strip=all", "tags": {"chatbots": {"item_id": "3267911475", "tag": "chatbots"}, "deep-learning": {"item_id": "3267911475", "tag": "deep-learning"}, "nlp": {"item_id": "3267911475", "tag": "nlp"}}, "authors": {"147418404": {"item_id": "3267911475", "author_id": "147418404", "name": "YouTuber Bakz T.", "url": ""}}, "image": {"item_id": "3267911475", "src": "https://venturebeat.com/wp-content/uploads/2021/02/gpt-3.jpg?resize=1200%2C600&strip=all", "width": "1200", "height": "600"}, "images": {"1": {"item_id": "3267911475", "image_id": "1", "src": "https://venturebeat.com/wp-content/uploads/2021/02/gpt-3.jpg?resize=1200%2C600&strip=all", "width": "1200", "height": "600", "credit": "", "caption": ""}}, "domain_metadata": {"name": "VentureBeat", "logo": "https://logo.clearbit.com/venturebeat.com?size=800", "greyscale_logo": "https://logo.clearbit.com/venturebeat.com?size=800&greyscale=true"}, "listen_duration_estimate": 470}, "987493974": {"item_id": "987493974", "resolved_id": "987493974", "given_url": "https://web.stanford.edu/~jurafsky/slp3/", "given_title": "Speech and Language Processing", "favorite": "0", "status": "1", "time_added": "1644102761", "time_updated": "1644176491", "time_read": "1644176491", "time_favorited": "0", "sort_id": 113, "resolved_title": "Speech and Language Processing", "resolved_url": "https://web.stanford.edu/~jurafsky/slp3/", "excerpt": "Here's our Feb 3, 2024 release! We also expect to release Chapter 12 soon in an updated release. Feel free to use the draft chapters and slides in your classes, the resulting feedback we get from you makes the book better! As always, typos and comments very welcome (just email slp3edbugs@gmail.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "328", "lang": "", "tags": {"machine-learning": {"item_id": "987493974", "tag": "machine-learning"}, "nlp": {"item_id": "987493974", "tag": "nlp"}}, "listen_duration_estimate": 127}, "3191240650": {"item_id": "3191240650", "resolved_id": "3191240650", "given_url": "https://www.amazon.science/blog/a-version-of-the-bert-language-model-thats-20-times-as-fast", "given_title": "", "favorite": "0", "status": "1", "time_added": "1607165245", "time_updated": "1638708525", "time_read": "1607639414", "time_favorited": "0", "sort_id": 114, "resolved_title": "A version of the BERT language model that’s 20 times as fast", "resolved_url": "https://www.amazon.science/blog/a-version-of-the-bert-language-model-thats-20-times-as-fast", "excerpt": "In natural-language understanding (NLU), the Transformer-based BERT language model is king. Its high performance on multiple tasks has strongly influenced contemporary NLU research. On the other hand, it is a relatively big and slow model, which makes it unsuitable for some applications.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1349", "lang": "en", "time_to_read": 6, "top_image_url": "https://assets.amazon.science/dims4/default/7d37b6f/2147483647/strip/true/crop/951x499+0+17/resize/1200x630!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F91%2Fc9%2F4aab043e4973805be90d1737bba1%2Fagora.png", "tags": {"bert": {"item_id": "3191240650", "tag": "bert"}, "deep-learning": {"item_id": "3191240650", "tag": "deep-learning"}, "nlp": {"item_id": "3191240650", "tag": "nlp"}}, "authors": {"143590884": {"item_id": "3191240650", "author_id": "143590884", "name": "Adrian de Wynter", "url": "https://www.amazon.science/author/adrian-de-wynter"}}, "image": {"item_id": "3191240650", "src": "https://assets.amazon.science/dims4/default/9898d05/2147483647/strip/true/crop/951x534+0+0/resize/1200x674!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F4a%2Fa5%2Fdd99dd5b4b5599ec3ab958a979bb%2Fbort-models.png", "width": "1200", "height": "674"}, "images": {"1": {"item_id": "3191240650", "image_id": "1", "src": "https://assets.amazon.science/dims4/default/9898d05/2147483647/strip/true/crop/951x534+0+0/resize/1200x674!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F4a%2Fa5%2Fdd99dd5b4b5599ec3ab958a979bb%2Fbort-models.png", "width": "1200", "height": "674", "credit": "", "caption": ""}, "2": {"item_id": "3191240650", "image_id": "2", "src": "https://assets.amazon.science/dims4/default/6d6d332/2147483647/strip/true/crop/951x534+0+0/resize/1200x674!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F91%2Fc9%2F4aab043e4973805be90d1737bba1%2Fagora.png", "width": "1200", "height": "674", "credit": "", "caption": ""}}, "listen_duration_estimate": 522}, "3765918890": {"item_id": "3765918890", "resolved_id": "3765918890", "given_url": "https://www.ben-evans.com/benedictevans/2022/12/14/ChatGPT-imagenet", "given_title": "", "favorite": "0", "status": "1", "time_added": "1671155259", "time_updated": "1671155598", "time_read": "1671155598", "time_favorited": "0", "sort_id": 115, "resolved_title": "ChatGPT and the Imagenet moment", "resolved_url": "https://www.ben-evans.com/benedictevans/2022/12/14/ChatGPT-imagenet", "excerpt": "A decade or so ago, systems based on something called ‘machine learning’ started producing really good results in Imagenet, a contest for computer vision researchers.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1920", "lang": "en", "time_to_read": 9, "top_image_url": "http://static1.squarespace.com/static/50363cf324ac8e905e7df861/t/639997a380800648445acf3f/1671010211384/B4AAC213-3764-4A49-A1F1-CA18B3368CF0.jpeg?format=1500w", "tags": {"chatgpt": {"item_id": "3765918890", "tag": "chatgpt"}, "deep-learning": {"item_id": "3765918890", "tag": "deep-learning"}, "generative": {"item_id": "3765918890", "tag": "generative"}, "ideas": {"item_id": "3765918890", "tag": "ideas"}, "machine-learning": {"item_id": "3765918890", "tag": "machine-learning"}, "nlp": {"item_id": "3765918890", "tag": "nlp"}}, "authors": {"116009647": {"item_id": "3765918890", "author_id": "116009647", "name": "Benedict Evans", "url": "https://www.ben-evans.com/benedictevans?author=50363cf324ac8e905e7df863"}}, "image": {"item_id": "3765918890", "src": "https://images.squarespace-cdn.com/content/v1/50363cf324ac8e905e7df861/18e369f9-d96f-4f12-a8ab-caa6943af902/B4AAC213-3764-4A49-A1F1-CA18B3368CF0.jpeg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3765918890", "image_id": "1", "src": "https://images.squarespace-cdn.com/content/v1/50363cf324ac8e905e7df861/18e369f9-d96f-4f12-a8ab-caa6943af902/B4AAC213-3764-4A49-A1F1-CA18B3368CF0.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Benedict Evans", "logo": "https://logo.clearbit.com/ben-evans.com?size=800", "greyscale_logo": "https://logo.clearbit.com/ben-evans.com?size=800&greyscale=true"}, "listen_duration_estimate": 743}, "2887966170": {"item_id": "2887966170", "resolved_id": "2887966170", "given_url": "https://www.datasciencecentral.com/profiles/blogs/10-common-nlp-terms-explained-for-the-text-analysis-novice?fbclid=IwAR01qshRiE0VLwiMAs79asUGuz3P940v1HO5ptMnAryVM_LYK2GdYr40Tjo", "given_title": "", "favorite": "0", "status": "1", "time_added": "1581969895", "time_updated": "1582142443", "time_read": "1582142443", "time_favorited": "0", "sort_id": 116, "resolved_title": "10 Common NLP Terms Explained for the Text Analysis Novice", "resolved_url": "https://www.datasciencecentral.com/profiles/blogs/10-common-nlp-terms-explained-for-the-text-analysis-novice?fbclid=IwAR01qshRiE0VLwiMAs79asUGuz3P940v1HO5ptMnAryVM_LYK2GdYr40Tjo", "excerpt": "If you’re relatively new to the NLP and Text Analysis world, you’ll more than likely have come across some pretty technical terms and acronyms, that are challenging to get your head around, especially, if you’re relying on scientific definitions for a plain and simple explanation.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "550", "lang": "en", "time_to_read": 3, "top_image_url": "http://storage.ning.com/topology/rest/1.0/file/get/2808320246?profile=RESIZE_1024x1024", "tags": {"nlp": {"item_id": "2887966170", "tag": "nlp"}}, "authors": {"78056766": {"item_id": "2887966170", "author_id": "78056766", "name": "Mike Waldron", "url": "https://www.datasciencecentral.com/profile/MikeWaldron"}}, "image": {"item_id": "2887966170", "src": "http://storage.ning.com/topology/rest/1.0/file/get/2808320246?profile=RESIZE_1024x1024", "width": "500", "height": "0"}, "images": {"1": {"item_id": "2887966170", "image_id": "1", "src": "http://storage.ning.com/topology/rest/1.0/file/get/2808320246?profile=RESIZE_1024x1024", "width": "500", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2887966170", "image_id": "2", "src": "http://storage.ning.com/topology/rest/1.0/file/get/2808320395?profile=RESIZE_1024x1024", "width": "500", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Data Science Central", "logo": "https://logo.clearbit.com/datasciencecentral.com?size=800", "greyscale_logo": "https://logo.clearbit.com/datasciencecentral.com?size=800&greyscale=true"}, "listen_duration_estimate": 213}, "2879449057": {"item_id": "2879449057", "resolved_id": "2879449057", "given_url": "https://www.datasciencecentral.com/profiles/blogs/top-nlp-algorithms-amp-concepts?fbclid=IwAR27H3vxeQfFx6jy6LlB3QqDdwTWdunPjusukToXy_9Q6-0wYDa2xvA7ImA", "given_title": "", "favorite": "0", "status": "1", "time_added": "1581263992", "time_updated": "1608262326", "time_read": "1582142455", "time_favorited": "0", "sort_id": 117, "resolved_title": "Top NLP Algorithms & Concepts", "resolved_url": "https://www.datasciencecentral.com/profiles/blogs/top-nlp-algorithms-amp-concepts?fbclid=IwAR27H3vxeQfFx6jy6LlB3QqDdwTWdunPjusukToXy_9Q6-0wYDa2xvA7ImA", "excerpt": "Today, one of the most popular tasks in Data Science is processing information presented in the text form.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2026", "lang": "en", "time_to_read": 9, "top_image_url": "https://storage.ning.com/topology/rest/1.0/file/get/3780583691?profile=RESIZE_710x", "tags": {"dictionary": {"item_id": "2879449057", "tag": "dictionary"}, "nlp": {"item_id": "2879449057", "tag": "nlp"}}, "authors": {"89353532": {"item_id": "2879449057", "author_id": "89353532", "name": "Igor Bobriakov", "url": "https://www.datasciencecentral.com/profile/IogrBobriakov"}}, "image": {"item_id": "2879449057", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780583691?profile=RESIZE_710x", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2879449057", "image_id": "1", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780583691?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2879449057", "image_id": "2", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780584426?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2879449057", "image_id": "3", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780585864?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2879449057", "image_id": "4", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780586526?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2879449057", "image_id": "5", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780587432?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2879449057", "image_id": "6", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780587886?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2879449057", "image_id": "7", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780588496?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2879449057", "image_id": "8", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780589634?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2879449057", "image_id": "9", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780590128?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2879449057", "image_id": "10", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780590625?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2879449057", "image_id": "11", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780591414?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2879449057", "image_id": "12", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780591744?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "2879449057", "image_id": "13", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780592986?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "2879449057", "image_id": "14", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780593498?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "2879449057", "image_id": "15", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780594023?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "2879449057", "image_id": "16", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780594470?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "2879449057", "image_id": "17", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780594929?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "2879449057", "image_id": "18", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3780595757?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Data Science Central", "logo": "https://logo.clearbit.com/datasciencecentral.com?size=800", "greyscale_logo": "https://logo.clearbit.com/datasciencecentral.com?size=800&greyscale=true"}, "listen_duration_estimate": 784}, "2652070861": {"item_id": "2652070861", "resolved_id": "2652070861", "given_url": "https://www.fast.ai/2019/07/08/fastai-nlp/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1622460950", "time_updated": "1622498973", "time_read": "1622498973", "time_favorited": "0", "sort_id": 118, "resolved_title": "A Code-First Introduction to Natural Language Processing · fast.ai", "resolved_url": "https://www.fast.ai/2019/07/08/fastai-nlp/", "excerpt": "Our newest course is a code-first introduction to NLP, following the fast.ai teaching philosophy of sharing practical code implementations and giving students a sense of the “whole game” before delving into lower-level details.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1058", "lang": "en", "time_to_read": 5, "top_image_url": "http://www.fast.ai/images/nlp-yt2.png", "tags": {"nlp": {"item_id": "2652070861", "tag": "nlp"}}, "authors": {"97374": {"item_id": "2652070861", "author_id": "97374", "name": "Rachel Thomas", "url": ""}}, "image": {"item_id": "2652070861", "src": "https://www.fast.ai/images/nlp-yt2.png", "width": "580", "height": "0"}, "images": {"1": {"item_id": "2652070861", "image_id": "1", "src": "https://www.fast.ai/images/nlp-yt2.png", "width": "580", "height": "0", "credit": "", "caption": "All videos for the course are on YouTube and all code is on GitHub"}, "2": {"item_id": "2652070861", "image_id": "2", "src": "https://www.fast.ai/images/disinfo-openai.png", "width": "680", "height": "0", "credit": "", "caption": "Risks raised by new language models such as GPT-2"}, "3": {"item_id": "2652070861", "image_id": "3", "src": "https://www.fast.ai/images/turkish-ulmfit.png", "width": "680", "height": "0", "credit": "", "caption": "Jeremy shares ULMFit implementations in Vietnamese and Turkish"}, "4": {"item_id": "2652070861", "image_id": "4", "src": "https://www.fast.ai/images/transformer2.png", "width": "680", "height": "0", "credit": "", "caption": "The Transformer for language translation"}, "5": {"item_id": "2652070861", "image_id": "5", "src": "https://www.fast.ai/images/garg2.png", "width": "680", "height": "0", "credit": "", "caption": "Nikhil Garg gave a guest lecture on his work showing how word embeddings quantify stereotypes over the last 100 years"}, "6": {"item_id": "2652070861", "image_id": "6", "src": "https://www.fast.ai/images/bias-matters.png", "width": "680", "height": "0", "credit": "", "caption": "On why algorithmic bias matters, different types, and steps towards addressing it"}}, "listen_duration_estimate": 410}, "2903801139": {"item_id": "2903801139", "resolved_id": "2903801139", "given_url": "https://www.intel.ai/bert-commercial-environments/", "given_title": "Why BERT Fails in Commercial Environments - Intel AI", "favorite": "0", "status": "1", "time_added": "1585059953", "time_updated": "1638708525", "time_read": "1585062107", "time_favorited": "0", "sort_id": 119, "resolved_title": "Why BERT Fails in Commercial Environments", "resolved_url": "https://www.intel.ai/bert-commercial-environments/", "excerpt": "Large transformer-based neural networks such as BERT, GPT and XLNET have recently achieved state-of-the-art results in many NLP tasks. The success of these models is based on transfer learning between a generic task (for example, language modeling) and a specific downstream task.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1275", "lang": "en", "time_to_read": 6, "top_image_url": "https://simplecore.intel.com/ai/wp-content/uploads/sites/69/AIDM-744_FI.jpg", "tags": {"deep-learning": {"item_id": "2903801139", "tag": "deep-learning"}, "nlp": {"item_id": "2903801139", "tag": "nlp"}}, "authors": {"110753942": {"item_id": "2903801139", "author_id": "110753942", "name": "Oren Pereg", "url": "https://www.intel.ai/bio/oren-pereg/"}}, "listen_duration_estimate": 494}, "2085438628": {"item_id": "2085438628", "resolved_id": "2085438628", "given_url": "https://www.kdnuggets.com/2018/02/5-fantastic-practical-natural-language-processing-resources.html", "given_title": "5 Fantastic Practical Natural Language Processing Resources", "favorite": "0", "status": "1", "time_added": "1519394509", "time_updated": "1611023404", "time_read": "1528501267", "time_favorited": "0", "sort_id": 120, "resolved_title": "5 Fantastic Practical Natural Language Processing Resources", "resolved_url": "https://www.kdnuggets.com/2018/02/5-fantastic-practical-natural-language-processing-resources.html", "excerpt": "Are you interested in some practical natural language processing resources?  There are so many NLP resources available online, especially those relying on deep learning approaches, that sifting through to find the quality can be quite a task.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "867", "lang": "en", "time_to_read": 4, "tags": {"nlp": {"item_id": "2085438628", "tag": "nlp"}}, "authors": {"77311567": {"item_id": "2085438628", "author_id": "77311567", "name": "Matthew Mayo", "url": "https://www.kdnuggets.com/author/matt-mayo"}}, "image": {"item_id": "2085438628", "src": "https://image.ibb.co/meseLx/nltk_word_len_dist.png", "width": "80", "height": "0"}, "images": {"1": {"item_id": "2085438628", "image_id": "1", "src": "https://image.ibb.co/meseLx/nltk_word_len_dist.png", "width": "80", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2085438628", "image_id": "2", "src": "https://cdn-images-1.medium.com/max/1600/1*uF146IBoRKACiq9J-HObHQ.png", "width": "90", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2085438628", "image_id": "3", "src": "https://cdn-images-1.medium.com/max/800/1*CdnxyA_fMXxEcEQ1kUTFRg.png", "width": "75", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2085438628", "image_id": "4", "src": "https://www.kdnuggets.com/wp-content/uploads/adventures-ml-rnn.png", "width": "90", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2085438628", "image_id": "5", "src": "https://www.kdnuggets.com/wp-content/uploads/lstm-cnn-konukoii.jpg", "width": "80", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 336}, "2301078505": {"item_id": "2301078505", "resolved_id": "2301078505", "given_url": "https://www.kdnuggets.com/2018/08/emotion-sentiment-analysis-practitioners-guide-nlp-5.html", "given_title": "Emotion and Sentiment Analysis: A Practitioner’s Guide to NLP", "favorite": "0", "status": "1", "time_added": "1535117410", "time_updated": "1609551491", "time_read": "1535594460", "time_favorited": "0", "sort_id": 121, "resolved_title": "Emotion and Sentiment Analysis: A Practitioner’s Guide to NLP", "resolved_url": "https://www.kdnuggets.com/2018/08/emotion-sentiment-analysis-practitioners-guide-nlp-5.html", "excerpt": "Sentiment analysis is perhaps one of the most popular applications of NLP, with a vast number of tutorials, courses, and applications that focus on analyzing sentiments of diverse datasets ranging from corporate surveys to movie reviews.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1252", "lang": "en", "time_to_read": 6, "tags": {"nlp": {"item_id": "2301078505", "tag": "nlp"}, "sentiment-analysis": {"item_id": "2301078505", "tag": "sentiment-analysis"}}, "authors": {"116893470": {"item_id": "2301078505", "author_id": "116893470", "name": "Dipanjan Sarkar", "url": "https://www.kdnuggets.com/author/dipanjan-sarkar"}}, "image": {"item_id": "2301078505", "src": "https://cdn-images-1.medium.com/max/800/0*ESoUKVXyWsss8WMA.png", "width": "99", "height": "0"}, "images": {"1": {"item_id": "2301078505", "image_id": "1", "src": "https://cdn-images-1.medium.com/max/800/0*ESoUKVXyWsss8WMA.png", "width": "99", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2301078505", "image_id": "2", "src": "https://cdn-images-1.medium.com/max/800/1*NF6AdPk6sOMNNbQE5glvEQ.png", "width": "99", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2301078505", "image_id": "3", "src": "https://cdn-images-1.medium.com/max/800/1*O4LrZi_BC-ugh483h9BlMw.png", "width": "70", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2301078505", "image_id": "4", "src": "https://cdn-images-1.medium.com/max/800/1*W4ixKiBwZcK_CFSBs8MkNA.png", "width": "99", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2301078505", "image_id": "5", "src": "https://cdn-images-1.medium.com/max/800/1*RovlmKOStJ6EnxCUhF4FcQ.png", "width": "50", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2301078505", "image_id": "6", "src": "https://cdn-images-1.medium.com/max/1000/1*ZZAEgQ8GUtUaYiFO9kzDjw.png", "width": "99", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2301078505", "image_id": "7", "src": "https://cdn-images-1.medium.com/max/1000/1*6BFwZOWdXXMCiJ7VbyBXog.png", "width": "99", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2301078505", "image_id": "8", "src": "https://cdn-images-1.medium.com/max/800/1*0V807lJ3_V7H3f-y9FlMUA.png", "width": "80", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2301078505", "image_id": "9", "src": "https://cdn-images-1.medium.com/max/800/1*2O24lGMJ78OEpDkk0LH5YQ.png", "width": "50", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2301078505", "image_id": "10", "src": "https://cdn-images-1.medium.com/max/1000/1*Z-GnfttYsvIsWVDF-tVTIA.png", "width": "99", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2301078505", "image_id": "11", "src": "https://cdn-images-1.medium.com/max/800/1*PjZ9TiqwvMDdr-imOrZ6Zw.png", "width": "50", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 485}, "2845513155": {"item_id": "2845513155", "resolved_id": "2845513195", "given_url": "https://www.kdnuggets.com/2020/01/guide-natural-language-generation.html", "given_title": "A Comprehensive Guide to Natural Language Generation", "favorite": "0", "status": "1", "time_added": "1578435462", "time_updated": "1608302666", "time_read": "1582143110", "time_favorited": "0", "sort_id": 122, "resolved_title": "A Comprehensive Guide to Natural Language Generation", "resolved_url": "https://www.kdnuggets.com/a-comprehensive-guide-to-natural-language-generation.html/", "excerpt": "By Sciforce. As long as Artificial Intelligence helps us to get more out of natural language, we see more tasks and fields mushrooming at the intersection of AI and linguistics.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2082", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/2000/0*CssYMxCpdhLWxISD", "tags": {"nlp": {"item_id": "2845513155", "tag": "nlp"}}, "image": {"item_id": "2845513155", "src": "https://miro.medium.com/max/2000/0*CssYMxCpdhLWxISD", "width": "90", "height": "0"}, "images": {"1": {"item_id": "2845513155", "image_id": "1", "src": "https://miro.medium.com/max/2000/0*CssYMxCpdhLWxISD", "width": "90", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2845513155", "image_id": "2", "src": "https://miro.medium.com/max/1770/0*Sp5KnAKQkD0e3loU", "width": "90", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2845513155", "image_id": "3", "src": "https://miro.medium.com/max/1784/0*S0Dcts6DSWikr3VG", "width": "90", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2845513155", "image_id": "4", "src": "https://miro.medium.com/max/1519/0*KBWlgfzRsseCOcS4", "width": "90", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2845513155", "image_id": "5", "src": "https://miro.medium.com/max/2000/0*_hAtI0EhNrFCechc", "width": "90", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 806}, "2847697347": {"item_id": "2847697347", "resolved_id": "2847697378", "given_url": "https://www.kdnuggets.com/2020/01/intro-guide-nlp-data-scientists.html", "given_title": "An Introductory Guide to NLP for Data Scientists with 7 Common Techniques", "favorite": "0", "status": "1", "time_added": "1578694065", "time_updated": "1586973436", "time_read": "1582142817", "time_favorited": "0", "sort_id": 123, "resolved_title": "An Introductory Guide to NLP for Data Scientists with 7 Common Techniques", "resolved_url": "https://www.kdnuggets.com/an-introductory-guide-to-nlp-for-data-scientists-with-7-common-techniques.html/", "excerpt": "Modern organizations work with huge amounts of data. That data can come in a variety of different forms including documents, spreadsheets, audio recordings, emails, JSON, and so many, many more. One of the most common ways that such data is recorded is via text.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1938", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/768/1*0UPaOO0wLTowafTrHtB0dA.png", "tags": {"nlp": {"item_id": "2847697347", "tag": "nlp"}}, "authors": {"113456808": {"item_id": "2847697347", "author_id": "113456808", "name": "George Seif", "url": "https://www.kdnuggets.com/author/george-seif"}}, "image": {"item_id": "2847697347", "src": "https://miro.medium.com/max/768/1*0UPaOO0wLTowafTrHtB0dA.png", "width": "90", "height": "0"}, "images": {"1": {"item_id": "2847697347", "image_id": "1", "src": "https://miro.medium.com/max/768/1*0UPaOO0wLTowafTrHtB0dA.png", "width": "90", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2847697347", "image_id": "2", "src": "https://miro.medium.com/max/790/1*QLJOwNimo83t2LptWd3msA.png", "width": "632", "height": "122", "credit": "", "caption": ""}, "3": {"item_id": "2847697347", "image_id": "3", "src": "https://miro.medium.com/max/469/1*Oj0mj73wnYonATCQMBidDQ.png", "width": "375", "height": "162", "credit": "", "caption": ""}, "4": {"item_id": "2847697347", "image_id": "4", "src": "https://miro.medium.com/max/556/1*LK1VgRt7Wz_nggDtNWYTPw.png", "width": "445", "height": "162", "credit": "", "caption": ""}, "5": {"item_id": "2847697347", "image_id": "5", "src": "https://miro.medium.com/max/1143/1*Fdx7sfVua0W8K7xCVTOiGQ.png", "width": "90", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2847697347", "image_id": "6", "src": "https://miro.medium.com/max/433/1*efBqPqQCpKDSyWWXImYsbQ.png", "width": "346", "height": "63", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 750}, "2899522125": {"item_id": "2899522125", "resolved_id": "2899522152", "given_url": "https://www.kdnuggets.com/2020/02/big-bad-nlp-database.html", "given_title": "The Big Bad NLP Database: Access Nearly 300 Datasets", "favorite": "0", "status": "1", "time_added": "1582915355", "time_updated": "1608336669", "time_read": "1583785007", "time_favorited": "0", "sort_id": 124, "resolved_title": "The Big Bad NLP Database : Access Nearly 300 Datasets", "resolved_url": "https://www.kdnuggets.com/the-big-bad-nlp-database-access-nearly-300-datasets.html/", "excerpt": "When looking to hone your natural language processing (NLP) skills, finding accessible and relevant datasets can be one of the biggest bottlenecks of the experience.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "293", "lang": "en", "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/big-bad-nlp.jpg", "tags": {"datasets": {"item_id": "2899522125", "tag": "datasets"}, "nlp": {"item_id": "2899522125", "tag": "nlp"}}, "authors": {"77311567": {"item_id": "2899522125", "author_id": "77311567", "name": "Matthew Mayo", "url": "https://www.kdnuggets.com/author/matt-mayo"}}, "image": {"item_id": "2899522125", "src": "https://www.kdnuggets.com/wp-content/uploads/big-bad-nlp.jpg", "width": "100", "height": "0"}, "images": {"1": {"item_id": "2899522125", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/uploads/big-bad-nlp.jpg", "width": "100", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 113}, "2968716993": {"item_id": "2968716993", "resolved_id": "2968717019", "given_url": "https://www.kdnuggets.com/2020/05/natural-language-processing-recipes-best-practices-examples.html", "given_title": "Natural Language Processing Recipes: Best Practices and Examples", "favorite": "0", "status": "1", "time_added": "1588333243", "time_updated": "1588808686", "time_read": "1588808686", "time_favorited": "0", "sort_id": 125, "resolved_title": "Natural Language Processing Recipes : Best Practices and Examples", "resolved_url": "https://www.kdnuggets.com/natural-language-processing-recipes-best-practices-and-examples.html/", "excerpt": "We at KDnuggets have been doing our best to highlight some quality natural language processing (NLP) resources in the recent past, most notably The Big Bad NLP Database and The Super Duper NLP Repo, a pair of initiatives managed by Quantum Stat.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "478", "lang": "en", "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/microsoft-nlp-logo.jpg", "tags": {"nlp": {"item_id": "2968716993", "tag": "nlp"}}, "authors": {"77311567": {"item_id": "2968716993", "author_id": "77311567", "name": "Matthew Mayo", "url": "https://www.kdnuggets.com/author/matt-mayo"}}, "image": {"item_id": "2968716993", "src": "https://i.ibb.co/S5vWyXk/microsoft-nlp-logo.jpg", "width": "80", "height": "0"}, "images": {"1": {"item_id": "2968716993", "image_id": "1", "src": "https://i.ibb.co/S5vWyXk/microsoft-nlp-logo.jpg", "width": "80", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2968716993", "image_id": "2", "src": "https://i.ibb.co/sVcg1xk/microsoft-nlp-repo-scenarios.jpg", "width": "100", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2968716993", "image_id": "3", "src": "https://i.ibb.co/94B0zm4/microsoft-nlp-text-classification.jpg", "width": "100", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 185}, "3097116292": {"item_id": "3097116292", "resolved_id": "3097116337", "given_url": "https://www.kdnuggets.com/2020/08/linguistic-fundamentals-natural-language-processing.html", "given_title": "Linguistic Fundamentals for Natural Language Processing: 100 Essentials fro", "favorite": "0", "status": "1", "time_added": "1598882849", "time_updated": "1613769990", "time_read": "1608290404", "time_favorited": "0", "sort_id": 126, "resolved_title": "Linguistic Fundamentals for Natural Language Processing: 100 Essentials from Semantics and Pragmatics", "resolved_url": "https://www.kdnuggets.com/linguistic-fundamentals-for-natural-language-processing-100-essentials-from-semantics-and-pragmatics.html/", "excerpt": "By Emily M. Bender, Professor of Linguistics at the University of Washington. Natural language processing (NLP), including text analytics, text as data, etc., involves the application of machine learning and other methods to text (and speech) in some natural language.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "415", "lang": "en", "top_image_url": "https://www.kdnuggets.comhttps//www.morganclaypoolpublishers.com/catalog_Orig/images/9781681730738.png", "tags": {"language-linguistics": {"item_id": "3097116292", "tag": "language-linguistics"}, "nlp": {"item_id": "3097116292", "tag": "nlp"}}, "image": {"item_id": "3097116292", "src": "https://www.kdnuggets.com/images/bender-syntax-tree-700.jpg", "width": "90", "height": "0"}, "images": {"1": {"item_id": "3097116292", "image_id": "1", "src": "https://www.kdnuggets.com/images/bender-syntax-tree-700.jpg", "width": "90", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3097116292", "image_id": "2", "src": "https://www.kdnuggets.com/images/bender-sandy-paris-700.jpg", "width": "90", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3097116292", "image_id": "3", "src": "https://www.kdnuggets.com/images/bender-dogs-carried-700.jpg", "width": "90", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 161}, "3727630668": {"item_id": "3727630668", "resolved_id": "3727630678", "given_url": "https://www.kdnuggets.com/2022/10/converting-text-documents-token-counts-countvectorizer.html", "given_title": "Converting Text Documents to Token Counts with CountVectorizer", "favorite": "0", "status": "1", "time_added": "1666188680", "time_updated": "1666197916", "time_read": "1666197915", "time_favorited": "0", "sort_id": 127, "resolved_title": "Converting Text Documents to Token Counts with CountVectorizer", "resolved_url": "https://www.kdnuggets.com/converting-text-documents-to-token-counts-with-countvectorizer.html", "excerpt": "We interact with machines on a daily basis – whether it's asking “OK Google, set the alarm for 6 AM” or “Alexa, play my favorite playlist”. But these machines do not understand natural language. So what happens when we talk to a device? It needs to convert the speech i.e.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "949", "lang": "en", "time_to_read": 4, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/chugh_converting_text_documents_token_counts_countvectorizer_6.jpg", "tags": {"nlp": {"item_id": "3727630668", "tag": "nlp"}, "python": {"item_id": "3727630668", "tag": "python"}, "scikit-learn": {"item_id": "3727630668", "tag": "scikit-learn"}}, "authors": {"164770597": {"item_id": "3727630668", "author_id": "164770597", "name": "Vidhi Chugh", "url": "https://www.kdnuggets.com/author/vidhi-chugh"}}, "image": {"item_id": "3727630668", "src": "https://www.kdnuggets.com/wp-content/uploads/chugh_converting_text_documents_token_counts_countvectorizer_6.jpg", "width": "70", "height": "0"}, "images": {"1": {"item_id": "3727630668", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/uploads/chugh_converting_text_documents_token_counts_countvectorizer_6.jpg", "width": "70", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3727630668", "image_id": "2", "src": "https://www.kdnuggets.com/wp-content/uploads/chugh_converting_text_documents_token_counts_countvectorizer_1.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3727630668", "image_id": "3", "src": "https://www.kdnuggets.com/wp-content/uploads/chugh_converting_text_documents_token_counts_countvectorizer_5.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3727630668", "image_id": "4", "src": "https://www.kdnuggets.com/wp-content/uploads/chugh_converting_text_documents_token_counts_countvectorizer_8.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3727630668", "image_id": "5", "src": "https://www.kdnuggets.com/wp-content/uploads/chugh_converting_text_documents_token_counts_countvectorizer_9.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3727630668", "image_id": "6", "src": "https://www.kdnuggets.com/wp-content/uploads/chugh_converting_text_documents_token_counts_countvectorizer_7.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3727630668", "image_id": "7", "src": "https://www.kdnuggets.com/wp-content/uploads/chugh_converting_text_documents_token_counts_countvectorizer_2.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3727630668", "image_id": "8", "src": "https://www.kdnuggets.com/wp-content/uploads/chugh_converting_text_documents_token_counts_countvectorizer_3.png", "width": "70", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3727630668", "image_id": "9", "src": "https://www.kdnuggets.com/wp-content/uploads/chugh_converting_text_documents_token_counts_countvectorizer_4.png", "width": "70", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 367}, "3745867008": {"item_id": "3745867008", "resolved_id": "3745856042", "given_url": "https://www.kdnuggets.com/2022/11/5-linguistics-courses-nlp-practitioners.html", "given_title": "5 Linguistics Courses for NLP Practitioners", "favorite": "0", "status": "1", "time_added": "1668553706", "time_updated": "1669013118", "time_read": "1669013117", "time_favorited": "0", "sort_id": 128, "resolved_title": "5 Linguistics Courses for NLP Practitioners", "resolved_url": "https://www.kdnuggets.com/5-linguistics-courses-for-nlp-practitioners.html", "excerpt": "This collection of 5 courses is intended to help NLP practitioners or hopefuls acquire some of their lacking linguistics knowledge.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "819", "lang": "en", "time_to_read": 4, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/sanskrit-stone-charl-folscher-unsplash.jpg", "tags": {"language-linguistics": {"item_id": "3745867008", "tag": "language-linguistics"}, "nlp": {"item_id": "3745867008", "tag": "nlp"}}, "authors": {"77311567": {"item_id": "3745867008", "author_id": "77311567", "name": "Matthew Mayo", "url": "https://www.kdnuggets.com/author/matt-mayo"}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 317}, "2900507056": {"item_id": "2900507056", "resolved_id": "2900210172", "given_url": "https://www.linkedin.com/posts/activity-6639302449037406208-LJJ1", "given_title": "", "favorite": "0", "status": "1", "time_added": "1582987336", "time_updated": "1638708525", "time_read": "1583785007", "time_favorited": "0", "sort_id": 129, "resolved_title": "Vincent Boucher’s Post", "resolved_url": "https://www.linkedin.com/posts/montrealai_transformer-bert-nlp-activity-6639302449037406208-iBsS", "excerpt": "See more comments To view or add a comment, sign in", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "11", "lang": "en", "top_image_url": "https://media.licdn.com/dms/image/C4E22AQERV7utC98QDw/feedshare-shrink_2048_1536/0/1582933055059?e=1694044800&v=beta&t=kk2G2MEitpRRs6TKobk3BwldWlFSPxmpGA3LrG3x6BU", "tags": {"bert": {"item_id": "2900507056", "tag": "bert"}, "deep-learning": {"item_id": "2900507056", "tag": "deep-learning"}, "nlp": {"item_id": "2900507056", "tag": "nlp"}}, "domain_metadata": {"name": "LinkedIn", "logo": "https://logo.clearbit.com/linkedin.com?size=800", "greyscale_logo": "https://logo.clearbit.com/linkedin.com?size=800&greyscale=true"}, "listen_duration_estimate": 4}, "2129700381": {"item_id": "2129700381", "resolved_id": "2129700381", "given_url": "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/", "given_title": "Topic Modeling with Gensim (Python) - A Practical Guide", "favorite": "0", "status": "1", "time_added": "1522190661", "time_updated": "1611022700", "time_read": "1526161389", "time_favorited": "0", "sort_id": 130, "resolved_title": "Topic Modeling with Gensim (Python)", "resolved_url": "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/", "excerpt": "Topic Modeling is a technique to extract the hidden topics from large volumes of text. Latent Dirichlet Allocation(LDA) is a popular algorithm for topic modeling with excellent implementations in the Python’s Gensim package.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "4041", "lang": "en", "time_to_read": 18, "top_image_url": "https://www.machinelearningplus.com/wp-content/uploads/2018/03/Gensim_Topic_Modeling_Feature.png", "tags": {"gensim": {"item_id": "2129700381", "tag": "gensim"}, "nlp": {"item_id": "2129700381", "tag": "nlp"}, "python": {"item_id": "2129700381", "tag": "python"}}, "authors": {"125980664": {"item_id": "2129700381", "author_id": "125980664", "name": "Selva Prabhakaran", "url": "https://www.machinelearningplus.com/author/selva86/"}}, "listen_duration_estimate": 1564}, "2880544412": {"item_id": "2880544412", "resolved_id": "2880544412", "given_url": "https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/", "given_title": "Turing-NLG: A 17-billion-parameter language model by Microsoft", "favorite": "0", "status": "1", "time_added": "1581361608", "time_updated": "1638708525", "time_read": "1582142562", "time_favorited": "0", "sort_id": 131, "resolved_title": "Turing-NLG: A 17-billion-parameter language model by Microsoft", "resolved_url": "https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/", "excerpt": "This figure was adapted from a similar image published in DistilBERT. Turing Natural Language Generation (T-NLG) is a 17 billion parameter language model by Microsoft that outperforms the state of the art on many downstream NLP tasks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1875", "lang": "en", "time_to_read": 9, "top_image_url": "https://www.microsoft.com/en-us/research/uploads/prod/2020/02/TurningNGL_Model__1400x788-5e418cff76a2a.png", "tags": {"deep-learning": {"item_id": "2880544412", "tag": "deep-learning"}, "nlp": {"item_id": "2880544412", "tag": "nlp"}}, "authors": {"152310267": {"item_id": "2880544412", "author_id": "152310267", "name": "View", "url": "https://www.microsoft.com/en-us/research/people/corosset/"}}, "image": {"item_id": "2880544412", "src": "https://www.microsoft.com/en-us/research/uploads/prod/2019/01/Ada-Lovelace-PhD-Fellowship_AD_Site_01_2019_1400x788.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2880544412", "image_id": "1", "src": "https://www.microsoft.com/en-us/research/uploads/prod/2019/01/Ada-Lovelace-PhD-Fellowship_AD_Site_01_2019_1400x788.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2880544412", "image_id": "2", "src": "https://www.microsoft.com/en-us/research/uploads/prod/2020/02/Turing-Table-4.jpg", "width": "859", "height": "148", "credit": "", "caption": ""}, "3": {"item_id": "2880544412", "image_id": "3", "src": "https://www.microsoft.com/en-us/research/uploads/prod/2020/02/Turing-Table-Update.jpg", "width": "1409", "height": "459", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Microsoft", "logo": "https://logo.clearbit.com/microsoft.com?size=800", "greyscale_logo": "https://logo.clearbit.com/microsoft.com?size=800&greyscale=true"}, "listen_duration_estimate": 726}, "3380222827": {"item_id": "3380222827", "resolved_id": "3380222827", "given_url": "https://www.packtpub.com/product/mastering-spacy/9781800563353", "given_title": "", "favorite": "0", "status": "1", "time_added": "1630199762", "time_updated": "1631052272", "time_read": "1631052272", "time_favorited": "0", "sort_id": 132, "resolved_title": "", "resolved_url": "https://www.packtpub.com/product/mastering-spacy/9781800563353", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"books": {"item_id": "3380222827", "tag": "books"}, "nlp": {"item_id": "3380222827", "tag": "nlp"}, "spacy": {"item_id": "3380222827", "tag": "spacy"}}, "listen_duration_estimate": 0}, "3454472044": {"item_id": "3454472044", "resolved_id": "3454472044", "given_url": "https://www.pinecone.io/learn/dense-vector-embeddings-nlp/", "given_title": "Dense Vectors | Pinecone", "favorite": "0", "status": "1", "time_added": "1671844950", "time_updated": "1678909325", "time_read": "1672242770", "time_favorited": "0", "sort_id": 133, "resolved_title": "Dense Vector Embeddings for NLP", "resolved_url": "https://www.pinecone.io/learn/dense-vector-embeddings-nlp/", "excerpt": "There is perhaps no greater contributor to the success of modern Natural Language Processing (NLP) technology than vector representations of language. The meteoric early-2010s rise of NLP was ignited with the introduction of word2vec by a team led by Tomáš Mikolov in 2013 [1].", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "2865", "lang": "en", "time_to_read": 13, "tags": {"databases": {"item_id": "3454472044", "tag": "databases"}, "machine-learning": {"item_id": "3454472044", "tag": "machine-learning"}, "nlp": {"item_id": "3454472044", "tag": "nlp"}, "word2vec": {"item_id": "3454472044", "tag": "word2vec"}}, "image": {"item_id": "3454472044", "src": "https://d33wubrfki0l68.cloudfront.net/edd29e3bab1b132c609d94afd8dea4cc305499b3/28eab/images/nlp-embedding-methods-1.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3454472044", "image_id": "1", "src": "https://d33wubrfki0l68.cloudfront.net/edd29e3bab1b132c609d94afd8dea4cc305499b3/28eab/images/nlp-embedding-methods-1.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3454472044", "image_id": "2", "src": "https://d33wubrfki0l68.cloudfront.net/43d0db23e9f1bfed7a3f34acbf1abacc7f831309/a72c9/images/nlp-embedding-methods-2.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3454472044", "image_id": "3", "src": "https://d33wubrfki0l68.cloudfront.net/429d58bc351cd28595d66b720acf07eb8f194af8/0ff77/images/nlp-embedding-methods-3.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3454472044", "image_id": "4", "src": "https://d33wubrfki0l68.cloudfront.net/ddfea44acb8542cb00084c5c61520a7553088ac9/a3bf2/images/nlp-embedding-methods-4.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3454472044", "image_id": "5", "src": "https://d33wubrfki0l68.cloudfront.net/ad9a7f3399a50ad7ace3b79752768a6075b34b80/be79f/images/nlp-embedding-methods-5.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3454472044", "image_id": "6", "src": "https://d33wubrfki0l68.cloudfront.net/380b027efede992d688069f96ce5fc6cc403be6e/f8abb/images/nlp-embedding-methods-6.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3454472044", "image_id": "7", "src": "https://d33wubrfki0l68.cloudfront.net/b2860727db71a1029adfb933f242f4f158044962/d08c7/images/nlp-embedding-methods-7.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3454472044", "image_id": "8", "src": "https://d33wubrfki0l68.cloudfront.net/ec6c90d7a0fd7d2c7fdaffd4a0957d7fbfcda982/6bb2e/images/nlp-embedding-methods-8.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3454472044", "image_id": "9", "src": "https://d33wubrfki0l68.cloudfront.net/af609dbb57152e5b2e4711f090bb107aa5fbbb67/bffde/images/nlp-embedding-methods-9.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3454472044", "image_id": "10", "src": "https://d33wubrfki0l68.cloudfront.net/cac505249b17a14b25c2ecfc6cfa6a473253a9cd/34299/images/nlp-embedding-methods-10.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "3454472044", "video_id": "1", "src": "https://www.youtube-nocookie.com/embed/bVZJ_O_-0RE", "width": "560", "height": "315", "type": "1", "vid": "bVZJ_O_-0RE", "length": "0"}}, "listen_duration_estimate": 1109}, "3369116070": {"item_id": "3369116070", "resolved_id": "3369116070", "given_url": "https://www.pinecone.io/learn/semantic-search/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1625269437", "time_updated": "1625351158", "time_read": "1625351158", "time_favorited": "0", "sort_id": 134, "resolved_title": "Semantic Search: Measuring Meaning From Jaccard to Bert", "resolved_url": "https://www.pinecone.io/learn/semantic-search/", "excerpt": "Similarity search is one of the fastest-growing domains in AI and machine learning. At its core, it is the process of matching relevant pieces of information together. There’s a strong chance that you found this article through a search engine — most likely Google.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "2504", "lang": "en", "time_to_read": 11, "tags": {"machine-learning": {"item_id": "3369116070", "tag": "machine-learning"}, "nlp": {"item_id": "3369116070", "tag": "nlp"}, "semantic-search": {"item_id": "3369116070", "tag": "semantic-search"}}, "image": {"item_id": "3369116070", "src": "https://www.pinecone.io/images/semantic-search-1.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3369116070", "image_id": "1", "src": "https://www.pinecone.io/images/semantic-search-1.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3369116070", "image_id": "2", "src": "https://www.pinecone.io/images/semantic-search-2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3369116070", "image_id": "3", "src": "https://www.pinecone.io/images/semantic-search-3.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3369116070", "image_id": "4", "src": "https://www.pinecone.io/images/semantic-search-30.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3369116070", "image_id": "5", "src": "https://www.pinecone.io/images/semantic-search-4.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3369116070", "image_id": "6", "src": "https://www.pinecone.io/images/semantic-search-5.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3369116070", "image_id": "7", "src": "https://www.pinecone.io/images/semantic-search-6.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3369116070", "image_id": "8", "src": "https://www.pinecone.io/images/semantic-search-7.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3369116070", "image_id": "9", "src": "https://www.pinecone.io/images/semantic-search-8.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3369116070", "image_id": "10", "src": "https://www.pinecone.io/images/semantic-search-9.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3369116070", "image_id": "11", "src": "https://www.pinecone.io/images/semantic-search-10.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3369116070", "image_id": "12", "src": "https://www.pinecone.io/images/semantic-search-11.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3369116070", "image_id": "13", "src": "https://www.pinecone.io/images/semantic-search-12.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "3369116070", "image_id": "14", "src": "https://www.pinecone.io/images/semantic-search-13.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "3369116070", "image_id": "15", "src": "https://www.pinecone.io/images/semantic-search-14.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "3369116070", "image_id": "16", "src": "https://www.pinecone.io/images/semantic-search-15.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "3369116070", "image_id": "17", "src": "https://www.pinecone.io/images/semantic-search-16.png", "width": "0", "height": "0", "credit": "left", "caption": "The IDF part of BM25"}, "18": {"item_id": "3369116070", "image_id": "18", "src": "https://www.pinecone.io/images/semantic-search-17.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "3369116070", "image_id": "19", "src": "https://www.pinecone.io/images/semantic-search-18.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "3369116070", "image_id": "20", "src": "https://www.pinecone.io/images/semantic-search-19.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "3369116070", "image_id": "21", "src": "https://www.pinecone.io/images/semantic-search-20.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "3369116070", "video_id": "1", "src": "https://www.youtube-nocookie.com/embed/AY62z7HrghY", "width": "560", "height": "315", "type": "1", "vid": "AY62z7HrghY", "length": "0"}, "2": {"item_id": "3369116070", "video_id": "2", "src": "https://www.youtube-nocookie.com/embed/ziiF1eFM3_4", "width": "560", "height": "315", "type": "1", "vid": "ziiF1eFM3_4", "length": "0"}}, "listen_duration_estimate": 969}, "3261141820": {"item_id": "3261141820", "resolved_id": "3260316757", "given_url": "https://www.protocol.com/china/i-built-bytedance-censorship-machine?utm_campaign=post-teaser&utm_content=8gi0rq1u", "given_title": "I helped build ByteDance's censorship machine - Protocol — The people, powe", "favorite": "0", "status": "1", "time_added": "1613838368", "time_updated": "1613840790", "time_read": "1613840790", "time_favorited": "0", "sort_id": 135, "resolved_title": "I helped build ByteDance's vast censorship machine", "resolved_url": "https://www.protocol.com/china/i-built-bytedance-censorship-machine", "excerpt": "“What we're really trying to do is to look at that end-to-end journey of data and to build really compelling, powerful capabilities and services at each stop in that data journey and then…knit all that together with strong concepts like governance,” Selipsky told Protocol in a recent interview", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3314", "lang": "en", "time_to_read": 15, "amp_url": "https://www.protocol.com/amp/i-built-bytedance-censorship-machine-2650611161", "top_image_url": "https://www.protocol.com/media-library/a-view-from-outside-bytedance-s-headquarters-in-beijing.jpg?id=25661542&width=1200&height=600&coordinates=0%2C250%2C0%2C250", "tags": {"censorship": {"item_id": "3261141820", "tag": "censorship"}, "nlp": {"item_id": "3261141820", "tag": "nlp"}}, "authors": {"29712919": {"item_id": "3261141820", "author_id": "29712919", "name": "Shen Lu", "url": ""}}, "image": {"item_id": "3261141820", "src": "https://www.protocol.com/media-library/a-view-from-outside-bytedance-s-headquarters-in-beijing.jpg?id=25661542&width=1245&height=700&quality=85&coordinates=0%2C156%2C0%2C156", "width": "1245", "height": "700"}, "images": {"1": {"item_id": "3261141820", "image_id": "1", "src": "https://www.protocol.com/media-library/a-view-from-outside-bytedance-s-headquarters-in-beijing.jpg?id=25661542&width=1245&height=700&quality=85&coordinates=0%2C156%2C0%2C156", "width": "1245", "height": "700", "credit": "Emmanuel Wong / Contributor via Getty Images", "caption": "A view from outside ByteDance's headquarters in Beijing."}, "2": {"item_id": "3261141820", "image_id": "2", "src": "https://www.protocol.com/media-library/image.jpg?id=32066661&width=600&height=600&coordinates=0%2C16%2C0%2C45", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3261141820", "image_id": "3", "src": "https://www.protocol.com/media-library/image.png?id=32061671&width=600&height=600&coordinates=0%2C0%2C0%2C0", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3261141820", "image_id": "4", "src": "https://www.protocol.com/media-library/image.png?id=32066580&width=600&height=600&coordinates=0%2C0%2C0%2C8", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3261141820", "image_id": "5", "src": "https://www.protocol.com/media-library/image.jpg?id=32061676&width=600&height=600&coordinates=0%2C0%2C0%2C0", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3261141820", "image_id": "6", "src": "https://www.protocol.com/media-library/image.jpg?id=32066584&width=600&height=600&coordinates=0%2C0%2C0%2C300", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3261141820", "image_id": "7", "src": "https://www.protocol.com/media-library/image.jpg?id=32066599&width=600&height=600&coordinates=0%2C412%2C0%2C830", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3261141820", "image_id": "8", "src": "https://www.protocol.com/media-library/image.jpg?id=32061677&width=600&height=600&coordinates=0%2C0%2C0%2C300", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3261141820", "image_id": "9", "src": "https://www.protocol.com/media-library/image.png?id=32066618&width=600&height=600&coordinates=23%2C0%2C43%2C0", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1283}, "2251873012": {"item_id": "2251873012", "resolved_id": "2251873012", "given_url": "https://www.reddit.com/r/MachineLearning/comments/8x9g4x/p_using_tsne_and_word2vec_embeddings_to_create/", "given_title": "[P] Using T-SNE and word2vec embeddings to create clusters in wordclouds", "favorite": "0", "status": "1", "time_added": "1531135929", "time_updated": "1609455260", "time_read": "1536189796", "time_favorited": "0", "sort_id": 136, "resolved_title": "[P] Using T-SNE and word2vec embeddings to create clusters in wordclouds", "resolved_url": "https://www.reddit.com/r/MachineLearning/comments/8x9g4x/p_using_tsne_and_word2vec_embeddings_to_create/", "excerpt": "1", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "amp_url": "https://amp.reddit.com/r/MachineLearning/comments/8x9g4x/p_using_tsne_and_word2vec_embeddings_to_create/", "top_image_url": "https://i.redditmedia.com/-jCrsPmQPdxEVp8Yuv-9qj6osF7ClY03WULTne892BM.jpg?s=bcd92e9bf9c81f7220fa6d5c16e37ae8", "tags": {"nlp": {"item_id": "2251873012", "tag": "nlp"}}, "authors": {"2490210": {"item_id": "2251873012", "author_id": "2490210", "name": "U", "url": ""}}, "domain_metadata": {"name": "Reddit", "logo": "https://logo.clearbit.com/reddit.com?size=800", "greyscale_logo": "https://logo.clearbit.com/reddit.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "2476178701": {"item_id": "2476178701", "resolved_id": "2476178701", "given_url": "https://www.reddit.com/r/MachineLearning/comments/amfinl/project_nlptutoral_repository_who_is_studying/", "given_title": "[Project] nlp-tutoral repository who is studying NLP(Natural Language Proce", "favorite": "0", "status": "1", "time_added": "1585048609", "time_updated": "1585072331", "time_read": "1585072331", "time_favorited": "0", "sort_id": 137, "resolved_title": "[Project] nlp-tutoral repository who is studying NLP(Natural Language Processing) using TensorFlow and Pytorch", "resolved_url": "https://www.reddit.com/r/MachineLearning/comments/amfinl/project_nlptutoral_repository_who_is_studying/", "excerpt": "You can see NNLM which is first language model, baseline model such as RNN, LSTM, TextCNN, Word2Vec in NLP. Also You can more easily learn NLP model, training steps as implemented Only ONE file (*.py) from seq2seq, attention, bi-LSTM attenton, Transformer(self-attention), to BERT model.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "90", "lang": "en", "amp_url": "https://amp.reddit.com/r/MachineLearning/comments/amfinl/project_nlptutoral_repository_who_is_studying/", "top_image_url": "https://external-preview.redd.it/cPJkpItCpKpgrfqdMjcWF3frcC8kyboULWKpOc2ad7s.jpg?auto=webp&s=c6523895ee60bf06441f9f89301f6f68f42fe361", "tags": {"nlp": {"item_id": "2476178701", "tag": "nlp"}}, "domain_metadata": {"name": "Reddit", "logo": "https://logo.clearbit.com/reddit.com?size=800", "greyscale_logo": "https://logo.clearbit.com/reddit.com?size=800&greyscale=true"}, "listen_duration_estimate": 35}, "2849970235": {"item_id": "2849970235", "resolved_id": "2849970235", "given_url": "https://www.reddit.com/r/MachineLearning/comments/enfsk1/n_huggingface_releases_ultrafast_tokenization/", "given_title": "[N] HuggingFace releases ultra-fast tokenization library for deep-learning ", "favorite": "0", "status": "1", "time_added": "1578832459", "time_updated": "1608302034", "time_read": "1582142817", "time_favorited": "0", "sort_id": 138, "resolved_title": "[N] HuggingFace releases ultra-fast tokenization library for deep-learning NLP pipelines", "resolved_url": "https://www.reddit.com/r/MachineLearning/comments/enfsk1/n_huggingface_releases_ultrafast_tokenization/", "excerpt": "Huggingface, the NLP research company known for its transformers library, has just released a new open-source library for ultra-fast & versatile tokenization for NLP neural net models (i.e. converting strings in model input tensors).", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "95", "lang": "en", "amp_url": "https://amp.reddit.com/r/MachineLearning/comments/enfsk1/n_huggingface_releases_ultrafast_tokenization/", "top_image_url": "https://external-preview.redd.it/QgX98dZxfvAvV3FA8JzgPuSvdZh8W7a0isiNwqMUAwE.jpg?auto=webp&s=2a644171267d3c8a6330ad56b0aac6fc4de1e07d", "tags": {"nlp": {"item_id": "2849970235", "tag": "nlp"}}, "domain_metadata": {"name": "Reddit", "logo": "https://logo.clearbit.com/reddit.com?size=800", "greyscale_logo": "https://logo.clearbit.com/reddit.com?size=800&greyscale=true"}, "listen_duration_estimate": 37}, "2177758428": {"item_id": "2177758428", "resolved_id": "2177758428", "given_url": "https://www.reddit.com/r/Python/comments/8hf37u/nltk_33_is_out/", "given_title": "NLTK 3.3 is out", "favorite": "0", "status": "1", "time_added": "1525619239", "time_updated": "1609553426", "time_read": "1528501039", "time_favorited": "0", "sort_id": 139, "resolved_title": "NLTK 3.3 is out", "resolved_url": "https://www.reddit.com/r/Python/comments/8hf37u/nltk_33_is_out/", "excerpt": "1NLTK 3.3 is outNLTK 3.3 has been releasedNLTK 3.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "11", "lang": "en", "amp_url": "https://amp.reddit.com/r/Python/comments/8hf37u/nltk_33_is_out/", "top_image_url": "https://www.reddit.com/r/Python/comments/8hf37u/nltk_33_is_out/self", "tags": {"nlp": {"item_id": "2177758428", "tag": "nlp"}, "nltk": {"item_id": "2177758428", "tag": "nltk"}}, "authors": {"2490210": {"item_id": "2177758428", "author_id": "2490210", "name": "U", "url": ""}}, "domain_metadata": {"name": "Reddit", "logo": "https://logo.clearbit.com/reddit.com?size=800", "greyscale_logo": "https://logo.clearbit.com/reddit.com?size=800&greyscale=true"}, "listen_duration_estimate": 4}, "3649931229": {"item_id": "3649931229", "resolved_id": "3649931229", "given_url": "https://www.surgehq.ai//blog/generating-childrens-stories-using-gpt-3-and-dall-e", "given_title": "", "favorite": "0", "status": "1", "time_added": "1656872143", "time_updated": "1671724937", "time_read": "1657051488", "time_favorited": "0", "sort_id": 140, "resolved_title": "Generating Children's Stories Using GPT-3 and DALL·E", "resolved_url": "https://www.surgehq.ai//blog/generating-childrens-stories-using-gpt-3-and-dall-e", "excerpt": "Imagine being 5 years old, dreaming of new adventures for Pikachu and Aladdin, and turning those tales into a cartoon right in front of your eyes… (Perhaps even with you as the main character!) What kinds of new storybook experiences could GPT-3 and DALL·E enable?", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "507", "lang": "en", "top_image_url": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb785bbd308083974abdae_d2.png", "tags": {"chatbots": {"item_id": "3649931229", "tag": "chatbots"}, "deep-learning": {"item_id": "3649931229", "tag": "deep-learning"}, "nlp": {"item_id": "3649931229", "tag": "nlp"}, "storytelling": {"item_id": "3649931229", "tag": "storytelling"}}, "authors": {"118701": {"item_id": "3649931229", "author_id": "118701", "name": "Edwin Chen", "url": ""}}, "image": {"item_id": "3649931229", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb785bbd308083974abdae_d2.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3649931229", "image_id": "1", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb785bbd308083974abdae_d2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3649931229", "image_id": "2", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb745889868a47c3f3bb3c_IlB-TYxtuvn3mfN4bam64yWLSW8NooJVjLkUanUMh5Dj-2xnnqo7eONzaRHQeuFmNgEusbrHZu4r00W1BPzm53CK4pRbyP4ehQy6_Jyjm7OSKkiRvi-n4N1gumpZR38fNOkmq9hZ233d0JeemQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3649931229", "image_id": "3", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb7459d3b3c89b945368c8_ApucvO2nLC93o55Nu5wtVn6AymcMoyj_nvNTLM9Qub2y1Y-rYQPwz0HWoWdC5g3IDYpWa3OOBoeutQ1wU9vC-7zGqQUCqdIBJpJ9n88PZdp9aT2UPgWR5PJsxPJn3huzTiB9z6imNPixc7vlOA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3649931229", "image_id": "4", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb7459e4b7d252016889ce_uO9fbdGXgNtjf8-YORknzMKbVUFJPGaDnbxGMzCRlT7RHqHjSpAwj7ePjuHtdI0EmXx4qiNJevpkDBMl253wWaxt9utQ63FUhh8cS9DisQpijXAbg4HHqmD_X77lqpHbDqQVbnfb6tIRJ3GPpQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3649931229", "image_id": "5", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb7459be9e0ace0e3c3eab_I1jXdeifi6lgxK0y5_9WSywzXRo_oeM29nsfMkxlkkczCHEcIj-J60dukXXT1YhubpEJOc9ljzk91TiJCanDjpX-TG-wd70GISHALDY3q3mj05pKB7iT6fnndtdi2QRinuYn1vkZ6PZb9EhoVw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3649931229", "image_id": "6", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb7459a1d2660228d6f88c_NayOvC8fA8tJhJdGDXQE5LAH2oBAApzOCDaPj-iVdr_Z1QucakYdndaJbZfBAL5iNd14wr-SMx2o2z6AfK0tuQBjTLHaA-nodE4UDsmnJPtslM-WdjPVwhXdrs5R5ORFi0C8oYiiKHFMuWv1Fg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3649931229", "image_id": "7", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb7459a0ee4638ba59b262_jkSo732BeGQNSf5YaN5O4WTX8v3-ZZJZPutn21HCcasAoHHB8sMBH5KDng1o9958FXYQyluxiveWzHQ_2amvpLVZCSDi0nVFxAY3_ovrk_vxQPDU22gsQ1FeNKC_-glWoLdUC6uMrKUS49-xNQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3649931229", "image_id": "8", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb745af1a69c24754d3367_lKb7G2r4jP40CUDCvwnZJGUKh80VqkYJYvcPLHhPxte3HP6aC8-lw-_nP_3VJcPMVi5-OZhcKe8jp8lkvxgqL9mNu0btVvLid6WU5xcMnZ_6FTtKOsvoNjCm3WONL5uwnS_QHTLb_Zwp9Dc1bA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3649931229", "image_id": "9", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb7ffb165404a2c4a62ffe_d5.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3649931229", "image_id": "10", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb745a76d06c4afba28af4_yOeYVb3uCbgRPU6bBaX_8Dn_m-fMXpE9KQ-8NHOVTuQTGAfvkgsbvVXQHwNBj5Ys1atLTuaoBPS4WPG8g0Dcb8Qqg3ZpY-ztBBsQItBAx8B1KR_tQJVHGQD0fDlX04tS6RMrgRUmZAp7IcylLw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3649931229", "image_id": "11", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb745ace9374f1fd7b93d9_vZxCg62SvefyQRMOQ87hrY4MnVxqiNKz4QOiHIKsUwnEhkix7by87r9efDbIxVVoibTCC__xg9ozx6X-4M_Cobh6REIeeKxxzOujLwJOWdP6OwnXudy65ZPY2DVdPQ8g34Q08iLd93U8oyRXvA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3649931229", "image_id": "12", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb745b0a345ac18bcd7ab8_JCvE8RcgEg1UCuCZ6zOWuvj1KhjTgvtLr-2bKXXahqZ6X0efEtQoZGUR2d2OcRfQxfi4ybgxcD5QGDUG8Z9EhyUeJoenSq5pgrlbde6Ne49Z3bYwdUj17clY5aQT-0fbOXG41CtL_oGcxgdV7Q.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3649931229", "image_id": "13", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb745ab1d2d8458633ccae_ydKIoYYX-tyYOhxeKrd7L8DikrlKqBDeyQYXk7F4NOTxUY4_yKmswSFu17wypzFN8cx786YOGskOj4VvUlQkm6XCOHdOHgIENgJGQy4fuXfckcgcBrZPDyvjJxG8KS6iZW6UrB8WzAiB6abWuw.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 196}, "3331734308": {"item_id": "3331734308", "resolved_id": "3331734308", "given_url": "https://www.technologyreview.com/2021/05/14/1024918/language-models-gpt3-search-engine-google/", "given_title": "Language models like GPT-3 could herald a new type of search engine", "favorite": "0", "status": "1", "time_added": "1621003862", "time_updated": "1671724937", "time_read": "1621357016", "time_favorited": "0", "sort_id": 141, "resolved_title": "Language models like GPT-3 could herald a new type of search engine", "resolved_url": "https://www.technologyreview.com/2021/05/14/1024918/language-models-gpt3-search-engine-google/", "excerpt": "In 1998 a couple of Stanford graduate students published a paper describing a new kind of search engine: “In this paper, we present Google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "858", "lang": "en", "time_to_read": 4, "amp_url": "https://www.technologyreview.com/2021/05/14/1024918/language-models-gpt3-search-engine-google/amp/", "top_image_url": "https://wp.technologyreview.com/wp-content/uploads/2021/05/files-1614223.jpg?resize=1200,600", "tags": {"chatbots": {"item_id": "3331734308", "tag": "chatbots"}, "nlp": {"item_id": "3331734308", "tag": "nlp"}}, "authors": {"25561932": {"item_id": "3331734308", "author_id": "25561932", "name": "Will Douglas Heaven", "url": ""}}, "image": {"item_id": "3331734308", "src": "https://wp.technologyreview.com/wp-content/uploads/2021/05/files-1614223.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3331734308", "image_id": "1", "src": "https://wp.technologyreview.com/wp-content/uploads/2021/05/files-1614223.jpg", "width": "0", "height": "0", "credit": "Pixabay", "caption": ""}, "2": {"item_id": "3331734308", "image_id": "2", "src": "https://wp.technologyreview.com/wp-content/uploads/2020/11/newsletter-preferences-sm.png", "width": "0", "height": "0", "credit": "Illustration  Rose Wong", "caption": "Illustration by Rose Wong"}}, "domain_metadata": {"name": "MIT Technology Review", "logo": "https://logo.clearbit.com/technologyreview.com?size=800", "greyscale_logo": "https://logo.clearbit.com/technologyreview.com?size=800&greyscale=true"}, "listen_duration_estimate": 332}, "3293130674": {"item_id": "3293130674", "resolved_id": "3293114192", "given_url": "https://www.theverge.com/2021/3/29/22356180/openai-gpt-3-text-generation-words-day?scrolla=5eb6d68b7fedc32c19ef33b4", "given_title": "OpenAI’s text-generating system GPT-3 is now spewing out 4.5 billion words ", "favorite": "0", "status": "1", "time_added": "1617111933", "time_updated": "1671724937", "time_read": "1617112056", "time_favorited": "0", "sort_id": 142, "resolved_title": "OpenAI’s text-generating system GPT-3 is now spewing out 4.5 billion words a day", "resolved_url": "https://www.theverge.com/2021/3/29/22356180/openai-gpt-3-text-generation-words-day", "excerpt": "One of the biggest trends in machine learning right now is text generation. AI systems learn by absorbing billions of words scraped from the internet and generate text in response to a variety of prompts.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "466", "lang": "en", "amp_url": "https://www.theverge.com/platform/amp/2021/3/29/22356180/openai-gpt-3-text-generation-words-day", "top_image_url": "https://cdn.vox-cdn.com/thumbor/r9dX7d8RVdEyoFEk548COf8z91Q=/0x146:2040x1214/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/20790706/acastro_200730_1777_ai_0001.jpg", "tags": {"chatbots": {"item_id": "3293130674", "tag": "chatbots"}, "nlp": {"item_id": "3293130674", "tag": "nlp"}}, "authors": {"97592195": {"item_id": "3293130674", "author_id": "97592195", "name": "James Vincent", "url": "https://www.theverge.com/authors/james-vincent"}}, "image": {"item_id": "3293130674", "src": "https://cdn.vox-cdn.com/uploads/chorus_image/image/69041641/acastro_200730_1777_ai_0001.0.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3293130674", "image_id": "1", "src": "https://cdn.vox-cdn.com/uploads/chorus_image/image/69041641/acastro_200730_1777_ai_0001.0.jpg", "width": "0", "height": "0", "credit": "Illustration  Alex Castro / The Verge", "caption": ""}}, "domain_metadata": {"name": "The Verge", "logo": "https://logo.clearbit.com/theverge.com?size=800", "greyscale_logo": "https://logo.clearbit.com/theverge.com?size=800&greyscale=true"}, "listen_duration_estimate": 180}, "2700405650": {"item_id": "2700405650", "resolved_id": "2700405650", "given_url": "https://www.topbots.com/ai-nlp-research-papers-acl2019/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1577212526", "time_updated": "1608304483", "time_read": "1582142883", "time_favorited": "0", "sort_id": 143, "resolved_title": "Top NLP Research Papers With Business Applications From ACL 2019", "resolved_url": "https://www.topbots.com/ai-nlp-research-papers-acl2019/", "excerpt": "This year’s annual meeting of the Association for Computational Linguistics (ACL 2019) was bigger than ever. Although the conference received 75% more submissions than last year, the quality of the research papers remained high, and so the acceptance rates are almost the same.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3173", "lang": "en", "time_to_read": 14, "amp_url": "https://www.topbots.com/ai-nlp-research-papers-acl2019/?amp", "top_image_url": "https://www.topbots.com/wp-content/uploads/2019/08/cover_ACL2019_1600px_web.jpg", "tags": {"nlp": {"item_id": "2700405650", "tag": "nlp"}}, "authors": {"114178771": {"item_id": "2700405650", "author_id": "114178771", "name": "Kate Koidan", "url": "https://www.topbots.com/author/kate-koidan/"}}, "image": {"item_id": "2700405650", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2019/08/cover_ACL2019_1600px_web.jpg", "width": "980", "height": "490"}, "images": {"1": {"item_id": "2700405650", "image_id": "1", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2019/08/cover_ACL2019_1600px_web.jpg", "width": "980", "height": "490", "credit": "", "caption": "ACL 2019 Research Papers"}, "2": {"item_id": "2700405650", "image_id": "2", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2019/08/1_Explain_yourself_examples_450px_web.jpg", "width": "450", "height": "377", "credit": "", "caption": ""}, "3": {"item_id": "2700405650", "image_id": "3", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2019/08/2_Detecting_concealed_information_700px_web.jpg", "width": "700", "height": "409", "credit": "", "caption": ""}, "4": {"item_id": "2700405650", "image_id": "4", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2019/08/3_Zero_shot_entity_linking_500px_web.jpg", "width": "500", "height": "574", "credit": "", "caption": ""}, "5": {"item_id": "2700405650", "image_id": "5", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2019/08/5_Emotion_cause_extraction_sample_700px_web.jpg", "width": "700", "height": "315", "credit": "", "caption": ""}, "6": {"item_id": "2700405650", "image_id": "6", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2019/08/5_Emotion_cause_extraction_model_700px_web.jpg", "width": "700", "height": "435", "credit": "", "caption": ""}, "7": {"item_id": "2700405650", "image_id": "7", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2019/08/6_Dialogue_history_600px_web.jpg", "width": "600", "height": "462", "credit": "", "caption": ""}}, "listen_duration_estimate": 1228}, "2896196828": {"item_id": "2896196828", "resolved_id": "2896196828", "given_url": "https://www.topbots.com/decoding-nlp-attention-mechanisms/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1582738930", "time_updated": "1608259628", "time_read": "1583785007", "time_favorited": "0", "sort_id": 144, "resolved_title": "Decoding NLP Attention Mechanisms", "resolved_url": "https://www.topbots.com/decoding-nlp-attention-mechanisms/", "excerpt": "Arguably more famous today than Michael Bay’s Transformers, the transformer architecture and transformer-based models have been breaking all kinds of state-of-the-art records.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1206", "lang": "en", "time_to_read": 5, "amp_url": "https://www.topbots.com/decoding-nlp-attention-mechanisms/?amp", "top_image_url": "https://www.topbots.com/wp-content/uploads/2020/02/1_pay_attention_1600px_web.jpg", "tags": {"nlp": {"item_id": "2896196828", "tag": "nlp"}}, "authors": {"129049937": {"item_id": "2896196828", "author_id": "129049937", "name": "Reda Affane", "url": "https://www.topbots.com/author/reda-affane/"}}, "image": {"item_id": "2896196828", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/1_pay_attention_1600px_web.jpg", "width": "980", "height": "490"}, "images": {"1": {"item_id": "2896196828", "image_id": "1", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/1_pay_attention_1600px_web.jpg", "width": "980", "height": "490", "credit": "", "caption": ""}, "2": {"item_id": "2896196828", "image_id": "2", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/2_encoder_decoder_800px_web.jpg", "width": "800", "height": "211", "credit": "", "caption": ""}, "3": {"item_id": "2896196828", "image_id": "3", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/3_LSTM_700px_web.jpg", "width": "700", "height": "309", "credit": "", "caption": ""}, "4": {"item_id": "2896196828", "image_id": "4", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/4_decoder_network_700px_web.jpg", "width": "700", "height": "297", "credit": "", "caption": ""}, "5": {"item_id": "2896196828", "image_id": "5", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/6_example_took_800px_web.jpg", "width": "800", "height": "590", "credit": "", "caption": ""}, "6": {"item_id": "2896196828", "image_id": "6", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/9_formula2_350px_web.jpg", "width": "350", "height": "142", "credit": "", "caption": ""}, "7": {"item_id": "2896196828", "image_id": "7", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/11_heatmap_600px_web.jpg", "width": "600", "height": "619", "credit": "", "caption": ""}}, "listen_duration_estimate": 467}, "3550235732": {"item_id": "3550235732", "resolved_id": "3549502534", "given_url": "https://www.toptal.com/python/topic-modeling-python?utm_campaign=%5BPubs%5D%20Engineering_Newsletter_2022&utm_medium=email&_hsmi=203516612&_hsenc=p2ANqtz-8ybqarqyXA4h4xlCYx-0A2xAVmpd7wIV0KTjaT5itQUz0hFZMYJBjj5DqlBz_BJnoqL5geXtZMXYuZ9dGU9kOtiIObDw&utm_content=203516612&utm_source=hs_email", "given_title": "Topic Modeling in Python | Toptal", "favorite": "0", "status": "1", "time_added": "1644591410", "time_updated": "1644607849", "time_read": "1644607849", "time_favorited": "0", "sort_id": 145, "resolved_title": "A Deeper Meaning: Topic Modeling in Python", "resolved_url": "https://www.toptal.com/python/topic-modeling-python", "excerpt": "Computers and the processors that power them are built to work with numbers. In contrast, the everyday language of emails and social media posts has a loose structure that doesn’t lend itself to computation. That’s where natural language processing (NLP) comes in.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1830", "lang": "en", "time_to_read": 8, "top_image_url": "https://bs-uploads.toptal.io/blackfish-uploads/components/seo/content/og_image_file/og_image/892817/OPEN_GRAPH-34c741d3173c84f2101c6fbf01ca0e3c.png", "tags": {"machine-learning": {"item_id": "3550235732", "tag": "machine-learning"}, "nlp": {"item_id": "3550235732", "tag": "nlp"}, "python": {"item_id": "3550235732", "tag": "python"}, "topic-modeling": {"item_id": "3550235732", "tag": "topic-modeling"}}, "authors": {"107255106": {"item_id": "3550235732", "author_id": "107255106", "name": "AllEngineeringDesignFinanceProjectsProductToptal Insights", "url": ""}}, "listen_duration_estimate": 708}, "3738519851": {"item_id": "3738519851", "resolved_id": "3738519851", "given_url": "https://zilliz.com/blog/vector-similarity-search", "given_title": "Introduction to Vector Similarity Search", "favorite": "0", "status": "1", "time_added": "1689249947", "time_updated": "1689349628", "time_read": "1689349628", "time_favorited": "0", "sort_id": 146, "resolved_title": "Introduction to Vector Similarity Search", "resolved_url": "https://zilliz.com/blog/vector-similarity-search", "excerpt": "In the previous tutorials, we took a look at unstructured data, vector databases, and Milvus - the world's most popular open-source vector database. We also briefly touched upon the idea of embeddings, high-dimensional vectors which serve as awesome semantic representations of unstructured data.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2969", "lang": "en", "time_to_read": 13, "top_image_url": "https://assets.zilliz.com/Zilliz_Blog_VDB_Series_4_7137f3aa6c.png", "tags": {"gensim": {"item_id": "3738519851", "tag": "gensim"}, "machine-learning": {"item_id": "3738519851", "tag": "machine-learning"}, "nlp": {"item_id": "3738519851", "tag": "nlp"}, "search": {"item_id": "3738519851", "tag": "search"}}, "authors": {"757106": {"item_id": "3738519851", "author_id": "757106", "name": "Use Case", "url": ""}}, "image": {"item_id": "3738519851", "src": "https://assets.zilliz.com/General_How_it_works_c1cd47cdd9.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3738519851", "image_id": "1", "src": "https://assets.zilliz.com/General_How_it_works_c1cd47cdd9.png", "width": "0", "height": "0", "credit": "", "caption": "General How it works.png"}, "2": {"item_id": "3738519851", "image_id": "2", "src": "https://assets.zilliz.com/hnsw_visualized_9bd0417e4d.png", "width": "0", "height": "0", "credit": "", "caption": "HNSW, visualized. Image source: https://arxiv.org/abs/1603.09320"}, "3": {"item_id": "3738519851", "image_id": "3", "src": "https://assets.zilliz.com/annoy_visualized_1adb042e7e.png", "width": "0", "height": "0", "credit": "", "caption": "ANNOY, visualized. Image source: https://github.com/spotify/annoy"}}, "listen_duration_estimate": 1149}}, "error": nil, "search_meta": {"search_type": "normal"}, "since": 1709419508}