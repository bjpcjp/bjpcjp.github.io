{"status": 1, "complete": 1, "list": {"2475249858": {"item_id": "2475249858", "resolved_id": "2475249858", "given_url": "https://paperswithcode.com/task/semantic-segmentation", "given_title": "Browse the State-of-the-Art in Machine Learning | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572371", "time_updated": "1638708525", "time_read": "1608572388", "time_favorited": "0", "sort_id": 0, "resolved_title": "Semantic Segmentation", "resolved_url": "https://paperswithcode.com/task/semantic-segmentation", "excerpt": "Semantic segmentation, or image segmentation, is the task of clustering parts of an image together which belong to the same object class. It is a form of pixel-level prediction because each pixel in an image is classified according to a category.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "71", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/Screenshot_2021-01-25_at_13.41.15_e92BZLz.png", "tags": {"deep-learning": {"item_id": "2475249858", "tag": "deep-learning"}, "semantic-segmentation": {"item_id": "2475249858", "tag": "semantic-segmentation"}}, "listen_duration_estimate": 27}, "3449750075": {"item_id": "3449750075", "resolved_id": "3449750096", "given_url": "https://towardsdatascience.com/hrnet-explained-human-pose-estimation-sematic-segmentation-and-object-detection-63f1ce79ef82?source=rss----7f60cf5620c9---4", "given_title": "HRNet explained: Human Pose Estimation, Semantic Segmentation and Object De", "favorite": "0", "status": "1", "time_added": "1633606526", "time_updated": "1633630869", "time_read": "1633630869", "time_favorited": "0", "sort_id": 1, "resolved_title": "HRNet explained: Human Pose Estimation, Sematic Segmentation and Object Detection", "resolved_url": "https://towardsdatascience.com/hrnet-explained-human-pose-estimation-sematic-segmentation-and-object-detection-63f1ce79ef82", "excerpt": "HRNet is a state-of-the-art algorithm in the field of semantic segmentation, facial landmark detection, and human pose estimation. It has shown superior results in semantic segmentation on datasets like PASCAL Context, LIP, Cityscapes, AFLW, COFW, and 300W.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1874", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/1200/1*rLhbwmHhjFF2u9NrO3iWpg.jpeg", "tags": {"deep-learning": {"item_id": "3449750075", "tag": "deep-learning"}, "machine-vision": {"item_id": "3449750075", "tag": "machine-vision"}, "pose-estimation": {"item_id": "3449750075", "tag": "pose-estimation"}, "semantic-segmentation": {"item_id": "3449750075", "tag": "semantic-segmentation"}}, "authors": {"129050273": {"item_id": "3449750075", "author_id": "129050273", "name": "Hucker Marius", "url": "https://medium.com/@hucker.marius"}}, "image": {"item_id": "3449750075", "src": "https://miro.medium.com/fit/c/56/56/2*7IaQcIIvxhB-crtlmJWGoA.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3449750075", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*7IaQcIIvxhB-crtlmJWGoA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3449750075", "image_id": "2", "src": "https://miro.medium.com/max/9036/1*rLhbwmHhjFF2u9NrO3iWpg.jpeg", "width": "4518", "height": "3011", "credit": "Christian Lue on Unsplash", "caption": ""}, "3": {"item_id": "3449750075", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*9ATXgoGvrOXukaOAgyWuCQ.png", "width": "700", "height": "317", "credit": "", "caption": "Source: http://host.robots.ox.ac.uk/pascal/VOC/voc2012/#devkit"}, "4": {"item_id": "3449750075", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*rekAeufx3gMVi3qUL3_UEw.png", "width": "700", "height": "307", "credit": "", "caption": "Source: https://learnopencv.com/face-swap-using-opencv-c-python/"}, "5": {"item_id": "3449750075", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*pcvyvpgNMuy4MCOG5ecKbw.png", "width": "700", "height": "603", "credit": "", "caption": "Source: https://arxiv.org/abs/2103.02440"}, "6": {"item_id": "3449750075", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*4U2mB9ZE46Uj2LQz989MHQ.png", "width": "700", "height": "158", "credit": "7", "caption": "Source: https://cs231n.github.io/convolutional-networks/"}, "7": {"item_id": "3449750075", "image_id": "7", "src": "https://miro.medium.com/max/1052/1*Z87z69ufkGnNolH6R_Ln_w.gif", "width": "526", "height": "384", "credit": "", "caption": "Source: https://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/"}, "8": {"item_id": "3449750075", "image_id": "8", "src": "https://miro.medium.com/max/1148/1*TCGAV3JvaWABGC34jaN4LQ.png", "width": "574", "height": "304", "credit": "7", "caption": "Source: https://cs231n.github.io/convolutional-networks/"}, "9": {"item_id": "3449750075", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*SGjMTghF8SQdD2l-DDD9vQ.png", "width": "700", "height": "115", "credit": "", "caption": "Source: https://arxiv.org/pdf/1904.04514.pdf"}, "10": {"item_id": "3449750075", "image_id": "10", "src": "https://miro.medium.com/max/928/1*BIYwJGwbm4VGQAOoazg5SQ.png", "width": "464", "height": "468", "credit": "", "caption": "Source: https://arxiv.org/pdf/1904.04514.pdf"}, "11": {"item_id": "3449750075", "image_id": "11", "src": "https://miro.medium.com/max/560/1*5lhntnXLH1YUTJKpX5-EqA.png", "width": "280", "height": "462", "credit": "", "caption": "Source: https://arxiv.org/pdf/1904.04514.pdf"}, "12": {"item_id": "3449750075", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*W2DJWlD--JgtgVLoz_03EA.png", "width": "700", "height": "65", "credit": "", "caption": "Previous CNN with serial convolution and not parallel. Source: https://arxiv.org/pdf/1904.04514.pdf"}, "13": {"item_id": "3449750075", "image_id": "13", "src": "https://miro.medium.com/max/952/1*vh1XNEWgUxn5vF0aP7BjCQ.png", "width": "476", "height": "298", "credit": "", "caption": "HRNetV1 illustration. Source: https://arxiv.org/pdf/1904.04514.pdf"}, "14": {"item_id": "3449750075", "image_id": "14", "src": "https://miro.medium.com/max/928/1*Fq-e4ExsbpZKAJxaN3sR8A.png", "width": "464", "height": "362", "credit": "", "caption": "HRNetV2 illustration. Source: https://arxiv.org/pdf/1904.04514.pdf"}, "15": {"item_id": "3449750075", "image_id": "15", "src": "https://miro.medium.com/max/960/1*keRNOE64DQXTthrITaGOOQ.png", "width": "480", "height": "360", "credit": "", "caption": "HRNetV2p illustration. Source: https://arxiv.org/pdf/1904.04514.pdf"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 725}, "3601370210": {"item_id": "3601370210", "resolved_id": "3601370210", "given_url": "https://www.engadget.com/mit-computer-vision-algorithm-identifies-images-down-to-the-pixel-130051112.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1672167095", "time_updated": "1672243463", "time_read": "1672243462", "time_favorited": "0", "sort_id": 2, "resolved_title": "MIT's newest computer vision algorithm identifies images down to the pixel", "resolved_url": "https://www.engadget.com/mit-computer-vision-algorithm-identifies-images-down-to-the-pixel-130051112.html", "excerpt": "For humans, identifying items in a scene — whether that’s an avocado or an Aventador, a pile of mashed potatoes or an alien mothership — is as simple as looking at them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "740", "lang": "en", "time_to_read": 3, "amp_url": "https://www.engadget.com/amp/mit-computer-vision-algorithm-identifies-images-down-to-the-pixel-130051112.html", "top_image_url": "https://s.yimg.com/os/creatr-uploaded-images/2022-04/bb03e290-c00b-11ec-9656-f63c96120141", "tags": {"machine-vision": {"item_id": "3601370210", "tag": "machine-vision"}, "semantic-segmentation": {"item_id": "3601370210", "tag": "semantic-segmentation"}}, "image": {"item_id": "3601370210", "src": "https://s.yimg.com/uu/api/res/1.2/5IMfhwrp_wRi.gTrlkg43g--~B/Zmk9ZmlsbDtoPTQ1Mjt3PTY3NTthcHBpZD15dGFjaHlvbg--/https://s.yimg.com/os/creatr-uploaded-images/2022-04/bb03e290-c00b-11ec-9656-f63c96120141.cf.jpg", "width": "6468", "height": "4329"}, "images": {"1": {"item_id": "3601370210", "image_id": "1", "src": "https://s.yimg.com/uu/api/res/1.2/5IMfhwrp_wRi.gTrlkg43g--~B/Zmk9ZmlsbDtoPTQ1Mjt3PTY3NTthcHBpZD15dGFjaHlvbg--/https://s.yimg.com/os/creatr-uploaded-images/2022-04/bb03e290-c00b-11ec-9656-f63c96120141.cf.jpg", "width": "6468", "height": "4329", "credit": "", "caption": ""}, "2": {"item_id": "3601370210", "image_id": "2", "src": "https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2022-04%2F70e22b90-c006-11ec-beef-b33cba4a592b&thumbnail=675%2C&client=49kdj93ncb8s938hkdo&signature=ce5886d973a1b5c29bd281b4772823028314ea49", "width": "0", "height": "0", "credit": "MIT CSAIL", "caption": ""}, "3": {"item_id": "3601370210", "image_id": "3", "src": "https://o.aolcdn.com/images/dims?image_uri=https%3A%2F%2Fs.yimg.com%2Fos%2Fcreatr-uploaded-images%2F2022-04%2F70e279b0-c006-11ec-9edf-f3fefbbab4cc&thumbnail=675%2C&client=49kdj93ncb8s938hkdo&signature=1797d347a92bb8cb8608984a27ba147b6e8703b6", "width": "0", "height": "0", "credit": "MIT CSAIL", "caption": ""}, "4": {"item_id": "3601370210", "image_id": "4", "src": "https://s.yimg.com/uu/api/res/1.2/K5N.2RVMY9tICnj06m36Ww--~B/Zmk9ZmlsbDtoPTE3MTtweW9mZj0wO3c9MjUwO2FwcGlkPXl0YWNoeW9u/https://s.yimg.com/os/creatr-uploaded-images/2022-04/05ad8340-c08a-11ec-b6dc-8a7add20239e.cf.jpg", "width": "640", "height": "421", "credit": "", "caption": ""}, "5": {"item_id": "3601370210", "image_id": "5", "src": "https://s.yimg.com/uu/api/res/1.2/sNMUpeDuXf_q6_Nl.Sk4zw--~B/Zmk9ZmlsbDtoPTE3MTtweW9mZj0wO3c9MjUwO2FwcGlkPXl0YWNoeW9u/https://s.yimg.com/os/creatr-uploaded-images/2022-03/ffd75390-9fed-11ec-b564-454e9eb7c931.cf.jpg", "width": "640", "height": "421", "credit": "", "caption": ""}, "6": {"item_id": "3601370210", "image_id": "6", "src": "https://s.yimg.com/uu/api/res/1.2/JxxE..q6AruNu4oes2kLJA--~B/Zmk9ZmlsbDtoPTE3MTtweW9mZj0wO3c9MjUwO2FwcGlkPXl0YWNoeW9u/https://s.yimg.com/os/creatr-images/2019-10/c18ed690-e6df-11e9-99ff-7080a87d6109.cf.jpg", "width": "640", "height": "421", "credit": "", "caption": ""}, "7": {"item_id": "3601370210", "image_id": "7", "src": "https://s.yimg.com/uu/api/res/1.2/AauNHVbLD3QWdW9X9NLpRQ--~B/Zmk9ZmlsbDtoPTE3MTtweW9mZj0wO3c9MjUwO2FwcGlkPXl0YWNoeW9u/https://s.yimg.com/os/creatr-uploaded-images/2022-04/68aec0e0-c16a-11ec-bfdd-3b04e2bab3dc.cf.jpg", "width": "640", "height": "421", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Engadget", "logo": "https://logo.clearbit.com/engadget.com?size=800", "greyscale_logo": "https://logo.clearbit.com/engadget.com?size=800&greyscale=true"}, "listen_duration_estimate": 286}}, "error": nil, "search_meta": {"search_type": "normal"}, "since": 1709419635}