{"status": 1, "complete": 1, "list": {"1618411073": {"item_id": "1618411073", "resolved_id": "1618411073", "given_url": "https://arxiv.org/abs/1605.09782v6", "given_title": "[1605.09782v6] Adversarial Feature Learning", "favorite": "0", "status": "1", "time_added": "1612436973", "time_updated": "1691366676", "time_read": "1612436988", "time_favorited": "0", "sort_id": 0, "resolved_title": "Title:Adversarial Feature Learning", "resolved_url": "https://arxiv.org/abs/1605.09782v6", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"adversarial": {"item_id": "1618411073", "tag": "adversarial"}, "deep-learning": {"item_id": "1618411073", "tag": "deep-learning"}, "feature-engineering": {"item_id": "1618411073", "tag": "feature-engineering"}}, "authors": {"63424573": {"item_id": "1618411073", "author_id": "63424573", "name": "cs cs.AI cs.CV", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "1834872066": {"item_id": "1834872066", "resolved_id": "1834872066", "given_url": "https://elitedatascience.com/feature-engineering-best-practices", "given_title": "Best Practices for Feature Engineering", "favorite": "0", "status": "1", "time_added": "1523290478", "time_updated": "1671277184", "time_read": "1526154049", "time_favorited": "0", "sort_id": 1, "resolved_title": "Best Practices for Feature Engineering", "resolved_url": "https://elitedatascience.com/feature-engineering-best-practices", "excerpt": "Feature engineering, the process creating new input features for machine learning, is one of the most effective ways to improve predictive models. Coming up with features is difficult, time-consuming, requires expert knowledge. “Applied machine learning” is basically feature engineering.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1547", "lang": "en", "time_to_read": 7, "top_image_url": "https://elitedatascience.com/wp-content/uploads/2017/07/Feature-Engineering-Best-Practices-Feature-No-Text.jpg", "tags": {"feature-engineering": {"item_id": "1834872066", "tag": "feature-engineering"}}, "listen_duration_estimate": 599}, "126146": {"item_id": "126146", "resolved_id": "126146", "given_url": "https://en.wikipedia.org/wiki/Planning_poker", "given_title": "Planning poker - Wikipedia", "favorite": "1", "status": "1", "time_added": "1697131758", "time_updated": "1697764390", "time_read": "1697764390", "time_favorited": "1677324476", "sort_id": 2, "resolved_title": "Planning poker", "resolved_url": "https://en.wikipedia.org/wiki/Planning_poker", "excerpt": "Planning poker, also called Scrum poker, is a consensus-based, gamified technique for estimating, mostly used to estimate effort or relative size of development goals in software development.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1059", "lang": "en", "time_to_read": 5, "top_image_url": "https://upload.wikimedia.org/wikipedia/commons/e/eb/CrispPlanningPokerDeck.jpg", "tags": {"agile": {"item_id": "126146", "tag": "agile"}, "feature-engineering": {"item_id": "126146", "tag": "feature-engineering"}, "features-benefits": {"item_id": "126146", "tag": "features-benefits"}, "prodmgmt": {"item_id": "126146", "tag": "prodmgmt"}, "projmgmt": {"item_id": "126146", "tag": "projmgmt"}}, "authors": {"7331684": {"item_id": "126146", "author_id": "7331684", "name": "From Wikipedia, the free", "url": ""}}, "image": {"item_id": "126146", "src": "https://upload.wikimedia.org/wikipedia/commons/thumb/e/eb/CrispPlanningPokerDeck.jpg/250px-CrispPlanningPokerDeck.jpg", "width": "250", "height": "183"}, "images": {"1": {"item_id": "126146", "image_id": "1", "src": "https://upload.wikimedia.org/wikipedia/commons/thumb/e/eb/CrispPlanningPokerDeck.jpg/250px-CrispPlanningPokerDeck.jpg", "width": "250", "height": "183", "credit": "", "caption": "Planning poker decks"}, "2": {"item_id": "126146", "image_id": "2", "src": "https://upload.wikimedia.org/wikipedia/commons/thumb/b/bb/Planning_poker_deck_Serpro.jpg/250px-Planning_poker_deck_Serpro.jpg", "width": "250", "height": "141", "credit": "", "caption": "Planning poker decks"}}, "domain_metadata": {"name": "Wikipedia", "logo": "https://logo.clearbit.com/wikipedia.org?size=800", "greyscale_logo": "https://logo.clearbit.com/wikipedia.org?size=800&greyscale=true"}, "listen_duration_estimate": 410}, "3493082076": {"item_id": "3493082076", "resolved_id": "3493082076", "given_url": "https://github.com/bjpcjp/python-data-science-handbook/blob/master/scikit/SciKit-Feature-Engineering.ipynb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638239964", "time_updated": "1671277184", "time_read": "1644193239", "time_favorited": "0", "sort_id": 3, "resolved_title": "", "resolved_url": "https://github.com/bjpcjp/python-data-science-handbook/blob/master/scikit/SciKit-Feature-Engineering.ipynb", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"feature-engineering": {"item_id": "3493082076", "tag": "feature-engineering"}, "github": {"item_id": "3493082076", "tag": "github"}, "scikit-learn": {"item_id": "3493082076", "tag": "scikit-learn"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3493082187": {"item_id": "3493082187", "resolved_id": "3493082187", "given_url": "https://github.com/bjpcjp/scikit-learn-0.24/blob/master/63_preprocessing.ipynb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638239964", "time_updated": "1671277184", "time_read": "1642373365", "time_favorited": "0", "sort_id": 4, "resolved_title": "", "resolved_url": "https://github.com/bjpcjp/scikit-learn-0.24/blob/master/63_preprocessing.ipynb", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"feature-engineering": {"item_id": "3493082187", "tag": "feature-engineering"}, "scikit-learn": {"item_id": "3493082187", "tag": "scikit-learn"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3767795540": {"item_id": "3767795540", "resolved_id": "3767795540", "given_url": "https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Second-Edition", "given_title": "PacktPublishing/Python-Feature-Engineering-Cookbook-Second-Edition: Python ", "favorite": "0", "status": "1", "time_added": "1671972474", "time_updated": "1673632403", "time_read": "1671995110", "time_favorited": "0", "sort_id": 5, "resolved_title": "PacktPublishing/Python-Feature-Engineering-Cookbook-Second-Edition", "resolved_url": "https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Second-Edition", "excerpt": "Packt is having its biggest sale of the year. Get this eBook or any other book, video, or course that you like just for $5 each This is the code repository for Python Feature Engineering Cookbook-Second Edition, published by Packt.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "594", "lang": "en", "time_to_read": 3, "top_image_url": "https://opengraph.githubassets.com/97a261559aad81e65388e3644227382e9d89dd8cec069db81401bb2262c90eca/PacktPublishing/Python-Feature-Engineering-Cookbook-Second-Edition", "tags": {"feature-engineering": {"item_id": "3767795540", "tag": "feature-engineering"}, "machine-learning": {"item_id": "3767795540", "tag": "machine-learning"}, "python": {"item_id": "3767795540", "tag": "python"}}, "authors": {"175911514": {"item_id": "3767795540", "author_id": "175911514", "name": "Packt-ITService", "url": "https://github.com/PacktPublishing/Python-Feature-Engineering-Cookbook-Second-Edition/commits?author=Packt-ITService"}}, "image": {"item_id": "3767795540", "src": "https://camo.githubusercontent.com/342f3fc6c42af65750bed6fc8a0c45556757e6c958592c370d8ec4f0bad3ebb8/68747470733a2f2f7374617469632e7061636b742d63646e2e636f6d2f70726f64756374732f393738313830343631313330322f636f7665722f736d616c6c6572", "width": "0", "height": "256"}, "images": {"1": {"item_id": "3767795540", "image_id": "1", "src": "https://camo.githubusercontent.com/342f3fc6c42af65750bed6fc8a0c45556757e6c958592c370d8ec4f0bad3ebb8/68747470733a2f2f7374617469632e7061636b742d63646e2e636f6d2f70726f64756374732f393738313830343631313330322f636f7665722f736d616c6c6572", "width": "0", "height": "256", "credit": "", "caption": ""}, "2": {"item_id": "3767795540", "image_id": "2", "src": "https://raw.githubusercontent.com/PacktPublishing/GitHub/master/GitHub.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 230}, "2994527545": {"item_id": "2994527545", "resolved_id": "2994527545", "given_url": "https://machinelearningmastery.com/rfe-feature-selection-in-python/", "given_title": "Recursive Feature Elimination (RFE) for Feature Selection in Python", "favorite": "0", "status": "1", "time_added": "1590348584", "time_updated": "1671277184", "time_read": "1591029811", "time_favorited": "0", "sort_id": 6, "resolved_title": "Recursive Feature Elimination (RFE) for Feature Selection in Python", "resolved_url": "https://machinelearningmastery.com/rfe-feature-selection-in-python/", "excerpt": "Recursive Feature Elimination, or RFE for short, is a popular feature selection algorithm. RFE is popular because it is easy to configure and use and because it is effective at selecting those features (columns) in a training dataset that are more or most relevant in predicting the target variable.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3900", "lang": "en", "time_to_read": 18, "top_image_url": "https://machinelearningmastery.com/wp-content/uploads/2020/02/Box-Plot-of-RFE-Number-of-Selected-Features-vs-Classification-Accuracy.png", "tags": {"feature-engineering": {"item_id": "2994527545", "tag": "feature-engineering"}, "machine-learning": {"item_id": "2994527545", "tag": "machine-learning"}, "python": {"item_id": "2994527545", "tag": "python"}}, "authors": {"26997241": {"item_id": "2994527545", "author_id": "26997241", "name": "Jason Brownlee", "url": "https://machinelearningmastery.com/author/jasonb/"}}, "image": {"item_id": "2994527545", "src": "https://machinelearningmastery.com/wp-content/uploads/2020/06/Cover-220.png", "width": "220", "height": "311"}, "images": {"1": {"item_id": "2994527545", "image_id": "1", "src": "https://machinelearningmastery.com/wp-content/uploads/2020/06/Cover-220.png", "width": "220", "height": "311", "credit": "", "caption": ""}}, "listen_duration_estimate": 1510}, "2020188159": {"item_id": "2020188159", "resolved_id": "2020188159", "given_url": "https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7", "given_title": "A Beginner’s Guide to Data Engineering — Part I – Robert Chang – Medium", "favorite": "0", "status": "1", "time_added": "1516369258", "time_updated": "1671277184", "time_read": "1517921516", "time_favorited": "0", "sort_id": 7, "resolved_title": "A Beginner’s Guide to Data Engineering", "resolved_url": "https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7", "excerpt": "The more experienced I become as a data scientist, the more convinced I am that data engineering is one of the most critical and foundational skills in any data scientist’s toolkit. I find this to be true for both evaluating project or job opportunities and scaling one’s work on the job.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3204", "lang": "en", "time_to_read": 15, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*gjgczPgeWlqWEVHtKYpJUg.png", "tags": {"feature-engineering": {"item_id": "2020188159", "tag": "feature-engineering"}}, "authors": {"169218115": {"item_id": "2020188159", "author_id": "169218115", "name": "here", "url": "http://cs.stanford.edu/people/widom/DB-mooc.html"}}, "image": {"item_id": "2020188159", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*EguVA0HsIGqUy0gaDS1VgA.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "2020188159", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*EguVA0HsIGqUy0gaDS1VgA.png", "width": "44", "height": "44", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 1240}, "2684592470": {"item_id": "2684592470", "resolved_id": "2684592470", "given_url": "https://mlwhiz.com/blog/2019/08/07/feature_selection/", "given_title": "The 5 Feature Selection Algorithms every Data Scientist should know", "favorite": "0", "status": "1", "time_added": "1565201576", "time_updated": "1671277184", "time_read": "1565212695", "time_favorited": "0", "sort_id": 8, "resolved_title": "The 5 Feature Selection Algorithms every Data Scientist should know", "resolved_url": "https://mlwhiz.com/blog/2019/08/07/feature_selection/", "excerpt": "Data Science is the study of algorithms. How many times it has happened when you create a lot of features and then you need to come up with ways to reduce the number of features.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1742", "lang": "en", "time_to_read": 8, "top_image_url": "https://mlwhiz.com/images/fs/1.png", "tags": {"feature-engineering": {"item_id": "2684592470", "tag": "feature-engineering"}}, "authors": {"8623619": {"item_id": "2684592470", "author_id": "8623619", "name": "Rahul Agarwal", "url": ""}}, "image": {"item_id": "2684592470", "src": "https://mlwhiz.com/images/fs/2.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2684592470", "image_id": "1", "src": "https://mlwhiz.com/images/fs/2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2684592470", "image_id": "2", "src": "https://mlwhiz.com/images/fs/3.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2684592470", "image_id": "3", "src": "https://mlwhiz.com/images/fs/12.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2684592470", "image_id": "4", "src": "https://mlwhiz.com/images/fs/4.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2684592470", "image_id": "5", "src": "https://mlwhiz.com/images/fs/5.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2684592470", "image_id": "6", "src": "https://mlwhiz.com/images/fs/6.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2684592470", "image_id": "7", "src": "https://mlwhiz.com/images/fs/7.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2684592470", "image_id": "8", "src": "https://mlwhiz.com/images/fs/8.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2684592470", "image_id": "9", "src": "https://mlwhiz.com/images/fs/9.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2684592470", "image_id": "10", "src": "https://mlwhiz.com/images/fs/10.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2684592470", "image_id": "11", "src": "https://mlwhiz.com/images/fs/11.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2684592470", "image_id": "12", "src": "https://mlwhiz.com/images/fs/13.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 674}, "2717574513": {"item_id": "2717574513", "resolved_id": "2684592470", "given_url": "https://mlwhiz.com/blog/2019/08/07/feature_selection/?utm_campaign=the-5-feature-selection-algorithms-every-data-scientist-should-know&utm_medium=social_link&utm_source=missinglettr", "given_title": "", "favorite": "0", "status": "1", "time_added": "1580743428", "time_updated": "1671277184", "time_read": "1582142562", "time_favorited": "0", "sort_id": 9, "resolved_title": "The 5 Feature Selection Algorithms every Data Scientist should know", "resolved_url": "https://mlwhiz.com/blog/2019/08/07/feature_selection/", "excerpt": "Data Science is the study of algorithms. How many times it has happened when you create a lot of features and then you need to come up with ways to reduce the number of features.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1742", "lang": "en", "time_to_read": 8, "top_image_url": "https://mlwhiz.com/images/fs/1.png", "tags": {"feature-engineering": {"item_id": "2717574513", "tag": "feature-engineering"}, "machine-learning": {"item_id": "2717574513", "tag": "machine-learning"}}, "authors": {"8623619": {"item_id": "2717574513", "author_id": "8623619", "name": "Rahul Agarwal", "url": ""}}, "image": {"item_id": "2717574513", "src": "https://mlwhiz.com/images/fs/2.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2717574513", "image_id": "1", "src": "https://mlwhiz.com/images/fs/2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2717574513", "image_id": "2", "src": "https://mlwhiz.com/images/fs/3.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2717574513", "image_id": "3", "src": "https://mlwhiz.com/images/fs/12.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2717574513", "image_id": "4", "src": "https://mlwhiz.com/images/fs/4.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2717574513", "image_id": "5", "src": "https://mlwhiz.com/images/fs/5.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2717574513", "image_id": "6", "src": "https://mlwhiz.com/images/fs/6.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2717574513", "image_id": "7", "src": "https://mlwhiz.com/images/fs/7.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2717574513", "image_id": "8", "src": "https://mlwhiz.com/images/fs/8.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2717574513", "image_id": "9", "src": "https://mlwhiz.com/images/fs/9.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2717574513", "image_id": "10", "src": "https://mlwhiz.com/images/fs/10.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2717574513", "image_id": "11", "src": "https://mlwhiz.com/images/fs/11.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2717574513", "image_id": "12", "src": "https://mlwhiz.com/images/fs/13.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 674}, "1828089404": {"item_id": "1828089404", "resolved_id": "1828089404", "given_url": "https://opendatascience.com/blog/feature-engineering-with-tidyverse/", "given_title": "Feature Engineering with Tidyverse", "favorite": "0", "status": "1", "time_added": "1500596502", "time_updated": "1671277184", "time_read": "1528501617", "time_favorited": "0", "sort_id": 10, "resolved_title": "Feature Engineering with Tidyverse", "resolved_url": "https://opendatascience.com/blog/feature-engineering-with-tidyverse/", "excerpt": "In this blog post, I will discuss feature engineering using the Tidyverse collection of libraries. Feature engineering is crucial for a variety of reasons, and it requires some care to produce any useful outcome.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "499", "lang": "en", "tags": {"feature-engineering": {"item_id": "1828089404", "tag": "feature-engineering"}, "machine-learning": {"item_id": "1828089404", "tag": "machine-learning"}}, "authors": {"69561356": {"item_id": "1828089404", "author_id": "69561356", "name": "Burak Himmetoglu", "url": "https://opendatascience.com/author/burak-himmetoglu/"}}, "image": {"item_id": "1828089404", "src": "https://burakhimmetoglu.files.wordpress.com/2017/04/rac.png?w=1140", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1828089404", "image_id": "1", "src": "https://burakhimmetoglu.files.wordpress.com/2017/04/rac.png?w=1140", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 193}, "2234221355": {"item_id": "2234221355", "resolved_id": "2234221355", "given_url": "https://towardsdatascience.com/a-feature-selection-tool-for-machine-learning-in-python-b64dd23710f0", "given_title": "", "favorite": "0", "status": "1", "time_added": "1534261287", "time_updated": "1671277184", "time_read": "1535630849", "time_favorited": "0", "sort_id": 11, "resolved_title": "A Feature Selection Tool for Machine Learning in Python", "resolved_url": "https://towardsdatascience.com/a-feature-selection-tool-for-machine-learning-in-python-b64dd23710f0", "excerpt": "Feature selection, the process of finding and selecting the most useful features in a dataset, is a crucial step of the machine learning pipeline.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2086", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/1200/1*rqeNwjiakRS-SqsW9wCgrA.jpeg", "tags": {"feature-engineering": {"item_id": "2234221355", "tag": "feature-engineering"}, "machine-learning": {"item_id": "2234221355", "tag": "machine-learning"}, "python": {"item_id": "2234221355", "tag": "python"}}, "authors": {"144033468": {"item_id": "2234221355", "author_id": "144033468", "name": "Will Koehrsen", "url": "https://williamkoehrsen.medium.com"}}, "image": {"item_id": "2234221355", "src": "https://miro.medium.com/max/2992/1*rqeNwjiakRS-SqsW9wCgrA.jpeg", "width": "1496", "height": "722"}, "images": {"1": {"item_id": "2234221355", "image_id": "1", "src": "https://miro.medium.com/max/2992/1*rqeNwjiakRS-SqsW9wCgrA.jpeg", "width": "1496", "height": "722", "credit": "", "caption": ""}, "2": {"item_id": "2234221355", "image_id": "2", "src": "https://miro.medium.com/fit/c/56/56/1*SckxdIFfjlR-cWXkL5ya-g.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "3": {"item_id": "2234221355", "image_id": "3", "src": "https://miro.medium.com/max/2180/1*W0qSMsheaWsXJBJ7i2pH4g.png", "width": "1090", "height": "173", "credit": "", "caption": "Example data. TARGET is the label for classification"}, "4": {"item_id": "2234221355", "image_id": "4", "src": "https://miro.medium.com/max/622/1*fpLJQBGZWhQXPFG5FyA1kg.png", "width": "311", "height": "198", "credit": "", "caption": ""}, "5": {"item_id": "2234221355", "image_id": "5", "src": "https://miro.medium.com/max/1212/1*0WBIKN83twXyWfyx9LG7Qg.png", "width": "606", "height": "462", "credit": "", "caption": ""}, "6": {"item_id": "2234221355", "image_id": "6", "src": "https://miro.medium.com/max/1816/1*_gK6g3YWylcgfL5Bz8JMUg.png", "width": "908", "height": "843", "credit": "", "caption": ""}, "7": {"item_id": "2234221355", "image_id": "7", "src": "https://miro.medium.com/max/802/1*unCzyN2BgucGodbioUz-Kw.png", "width": "401", "height": "176", "credit": "", "caption": ""}, "8": {"item_id": "2234221355", "image_id": "8", "src": "https://miro.medium.com/max/1516/1*fcLsRYskgzWxVoxj4npfvg.png", "width": "758", "height": "676", "credit": "", "caption": ""}, "9": {"item_id": "2234221355", "image_id": "9", "src": "https://miro.medium.com/max/2152/1*hWCOAEWkH4z5BKKqkFAd1g.png", "width": "1076", "height": "552", "credit": "", "caption": ""}, "10": {"item_id": "2234221355", "image_id": "10", "src": "https://miro.medium.com/max/1104/1*HJk89EkbcmriiWbxpV6Uew.png", "width": "552", "height": "396", "credit": "", "caption": ""}, "11": {"item_id": "2234221355", "image_id": "11", "src": "https://miro.medium.com/max/1256/1*d1uRrw212LAmpjlszj7CFg.png", "width": "628", "height": "306", "credit": "", "caption": ""}, "12": {"item_id": "2234221355", "image_id": "12", "src": "https://miro.medium.com/max/1228/1*F3BV5mUWG-GLP8gnS62Z6w.png", "width": "614", "height": "462", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 807}, "3807859383": {"item_id": "3807859383", "resolved_id": "3807859395", "given_url": "https://towardsdatascience.com/a-practical-introduction-to-sequential-feature-selection-a5444eb5b2fd?source=rss----7f60cf5620c9---4", "given_title": "A practical introduction to sequential feature selection", "favorite": "0", "status": "1", "time_added": "1676557760", "time_updated": "1676571770", "time_read": "1676571769", "time_favorited": "0", "sort_id": 12, "resolved_title": "A practical introduction to sequential feature selection", "resolved_url": "https://towardsdatascience.com/a-practical-introduction-to-sequential-feature-selection-a5444eb5b2fd", "excerpt": "Feature selection is always a challenging task for data scientists. Identifying the right set of features is crucial for the success of a model. There are several techniques that make use of the performance that a set of features gives to a model. One of them is the sequential feature selection.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "889", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/max/1024/0*Hhw0HNLZfX1zy6YO.jpg", "tags": {"feature-engineering": {"item_id": "3807859383", "tag": "feature-engineering"}, "machine-learning": {"item_id": "3807859383", "tag": "machine-learning"}}, "authors": {"153625615": {"item_id": "3807859383", "author_id": "153625615", "name": "Gianluca Malato", "url": "https://gianlucamalato.medium.com"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 344}, "2747237031": {"item_id": "2747237031", "resolved_id": "2747237031", "given_url": "https://towardsdatascience.com/how-to-find-feature-importances-for-blackbox-models-c418b694659d", "given_title": "How to find Feature importances for BlackBox Models?", "favorite": "0", "status": "1", "time_added": "1570215983", "time_updated": "1671277184", "time_read": "1576355368", "time_favorited": "0", "sort_id": 13, "resolved_title": "How to find Feature importances for BlackBox Models?", "resolved_url": "https://towardsdatascience.com/how-to-find-feature-importances-for-blackbox-models-c418b694659d", "excerpt": "Data Science is the study of algorithms. How many times it has happened when you create a lot of features and then you need to come up with ways to reduce the number of features?", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "903", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/max/1200/1*Ox8Cxbdvyhcxd7VGL49ERw.png", "tags": {"feature-engineering": {"item_id": "2747237031", "tag": "feature-engineering"}}, "authors": {"144145174": {"item_id": "2747237031", "author_id": "144145174", "name": "Rahul Agarwal", "url": "https://mlwhiz.medium.com"}}, "image": {"item_id": "2747237031", "src": "https://miro.medium.com/max/2000/1*Ox8Cxbdvyhcxd7VGL49ERw.png", "width": "1000", "height": "561"}, "images": {"1": {"item_id": "2747237031", "image_id": "1", "src": "https://miro.medium.com/max/2000/1*Ox8Cxbdvyhcxd7VGL49ERw.png", "width": "1000", "height": "561", "credit": "", "caption": "Source: DavidRockDesign, Randomness-the lifeblood of many algorithms"}, "2": {"item_id": "2747237031", "image_id": "2", "src": "https://miro.medium.com/fit/c/56/56/1*Ihl-t4w_lAH1zfqN-2THDw.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "3": {"item_id": "2747237031", "image_id": "3", "src": "https://miro.medium.com/max/1400/0*9krghn2aVDz9Y0wu.png", "width": "700", "height": "224", "credit": "", "caption": "Source: We permute a feature and predict using the updated dataset. Intuitively, if our accuracy or any evaluation metric doesn’t take a hit, we can say that the feature is not important. If our accuracy does take a hit, we consider this feature important."}, "4": {"item_id": "2747237031", "image_id": "4", "src": "https://miro.medium.com/max/1400/0*1qEzkD3R90N_sZFc.png", "width": "700", "height": "457", "credit": "", "caption": ""}, "5": {"item_id": "2747237031", "image_id": "5", "src": "https://miro.medium.com/max/1400/0*gA-rgdP_HIqvnY7s.png", "width": "700", "height": "99", "credit": "", "caption": "train Data X"}, "6": {"item_id": "2747237031", "image_id": "6", "src": "https://miro.medium.com/max/840/1*yBsyX6ioYf2kUrIQ-HDqGg.png", "width": "420", "height": "630", "credit": "", "caption": ""}, "7": {"item_id": "2747237031", "image_id": "7", "src": "https://miro.medium.com/max/1400/0*-5BpqwBny7KMBfAo.jpg", "width": "700", "height": "280", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 350}, "2672630781": {"item_id": "2672630781", "resolved_id": "2672630781", "given_url": "https://towardsdatascience.com/the-5-feature-selection-algorithms-every-data-scientist-need-to-know-3a6b566efd2", "given_title": "", "favorite": "0", "status": "1", "time_added": "1620229115", "time_updated": "1671277184", "time_read": "1620250162", "time_favorited": "0", "sort_id": 14, "resolved_title": "The 5 Feature Selection Algorithms every Data Scientist should know", "resolved_url": "https://towardsdatascience.com/the-5-feature-selection-algorithms-every-data-scientist-need-to-know-3a6b566efd2", "excerpt": "Data Science is the study of algorithms. How many times it has happened when you create a lot of features and then you need to come up with ways to reduce the number of features.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1274", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/1*Feid5O1I9KethU8WX45CTg.png", "tags": {"feature-engineering": {"item_id": "2672630781", "tag": "feature-engineering"}, "machine-learning": {"item_id": "2672630781", "tag": "machine-learning"}}, "authors": {"144145174": {"item_id": "2672630781", "author_id": "144145174", "name": "Rahul Agarwal", "url": "https://mlwhiz.medium.com"}}, "image": {"item_id": "2672630781", "src": "https://miro.medium.com/max/3840/1*Feid5O1I9KethU8WX45CTg.png", "width": "1920", "height": "1252"}, "images": {"1": {"item_id": "2672630781", "image_id": "1", "src": "https://miro.medium.com/max/3840/1*Feid5O1I9KethU8WX45CTg.png", "width": "1920", "height": "1252", "credit": "", "caption": "Source: Pixabay"}, "2": {"item_id": "2672630781", "image_id": "2", "src": "https://miro.medium.com/fit/c/56/56/1*Ihl-t4w_lAH1zfqN-2THDw.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "3": {"item_id": "2672630781", "image_id": "3", "src": "https://miro.medium.com/max/1154/1*tqjmErkEdzl2DrtjMg7GzQ.png", "width": "577", "height": "385", "credit": "", "caption": "Source"}, "4": {"item_id": "2672630781", "image_id": "4", "src": "https://miro.medium.com/max/5680/0*fFuXBJ5HZHIEV5n7", "width": "2840", "height": "2272", "credit": "", "caption": ""}, "5": {"item_id": "2672630781", "image_id": "5", "src": "https://miro.medium.com/max/756/0*EOpX0Ofh_zqAkLRk.png", "width": "378", "height": "133", "credit": "", "caption": ""}, "6": {"item_id": "2672630781", "image_id": "6", "src": "https://miro.medium.com/max/3604/0*l-qVhxRq6218__Qp.png", "width": "1802", "height": "1202", "credit": "", "caption": "Source"}, "7": {"item_id": "2672630781", "image_id": "7", "src": "https://miro.medium.com/max/610/1*qtDIt-7rlWqMVdwKAGJ4ww.png", "width": "305", "height": "65", "credit": "", "caption": ""}, "8": {"item_id": "2672630781", "image_id": "8", "src": "https://miro.medium.com/max/610/1*uQYw4RvEuyTpYU6F1H2rPw.png", "width": "305", "height": "65", "credit": "", "caption": "Observed and Expected Counts"}, "9": {"item_id": "2672630781", "image_id": "9", "src": "https://miro.medium.com/max/1536/0*_whJSrJbRUGnimXr.jpg", "width": "768", "height": "384", "credit": "", "caption": ""}, "10": {"item_id": "2672630781", "image_id": "10", "src": "https://miro.medium.com/max/1920/0*lkkVBAfy18P-ktY8.jpg", "width": "960", "height": "630", "credit": "", "caption": ""}, "11": {"item_id": "2672630781", "image_id": "11", "src": "https://miro.medium.com/max/1154/1*c515Qbsy4xujVcOsLWza8Q.png", "width": "577", "height": "385", "credit": "", "caption": "Source"}, "12": {"item_id": "2672630781", "image_id": "12", "src": "https://miro.medium.com/max/6528/0*rRkjb0kikflReKQH", "width": "3264", "height": "2447", "credit": "", "caption": ""}, "13": {"item_id": "2672630781", "image_id": "13", "src": "https://miro.medium.com/max/12000/0*Wn1mNHThCdAKL8q4", "width": "6000", "height": "4000", "credit": "", "caption": ""}, "14": {"item_id": "2672630781", "image_id": "14", "src": "https://miro.medium.com/max/2340/1*bmTyZgeMNUx1fQHD_f5Hqg.png", "width": "1170", "height": "1136", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 493}, "2014173782": {"item_id": "2014173782", "resolved_id": "2014173782", "given_url": "https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b", "given_title": "Understanding Feature Engineering (Part 1) — Continuous Numeric Data", "favorite": "0", "status": "1", "time_added": "1523218314", "time_updated": "1671277184", "time_read": "1523289826", "time_favorited": "0", "sort_id": 15, "resolved_title": "Continuous Numeric Data", "resolved_url": "https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b", "excerpt": "“Money makes the world go round” is something which you cannot ignore whether to choose to agree or disagree with it. A more apt saying in today’s digital revolutionary age would be “Data makes the world go round”.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4265", "lang": "en", "time_to_read": 19, "top_image_url": "https://miro.medium.com/max/1200/1*_ARjrrFLdgNf-vodDI6PDQ.jpeg", "tags": {"feature-engineering": {"item_id": "2014173782", "tag": "feature-engineering"}}, "authors": {"142369656": {"item_id": "2014173782", "author_id": "142369656", "name": "Dipanjan (DJ) Sarkar", "url": "https://djsarkar.medium.com"}}, "image": {"item_id": "2014173782", "src": "https://miro.medium.com/fit/c/56/56/1*Wy0cxXZpX-FrMWeXsqOOpg.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2014173782", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*Wy0cxXZpX-FrMWeXsqOOpg.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2014173782", "image_id": "2", "src": "https://miro.medium.com/max/2560/1*_ARjrrFLdgNf-vodDI6PDQ.jpeg", "width": "1280", "height": "570", "credit": "", "caption": "Source: https://pixabay.com"}, "3": {"item_id": "2014173782", "image_id": "3", "src": "https://miro.medium.com/max/1668/1*2T5rbjOBGVFdSvtlhCqlNg.png", "width": "834", "height": "339", "credit": "source: Practical Machine Learning with Python, Apress/Springer", "caption": "A standard machine learning pipeline"}, "4": {"item_id": "2014173782", "image_id": "4", "src": "https://miro.medium.com/max/680/1*OvvWVA31p5OE3z8CEwVrxA.png", "width": "340", "height": "203", "credit": "", "caption": "A generic dataset snapshot"}, "5": {"item_id": "2014173782", "image_id": "5", "src": "https://miro.medium.com/max/1628/1*UEVbo3a2WWK2sY1CH5RI9g.png", "width": "814", "height": "166", "credit": "", "caption": "Snapshot of our Pokemon dataset"}, "6": {"item_id": "2014173782", "image_id": "6", "src": "https://miro.medium.com/max/360/1*wN2EpH0MhOeF3HFVawzSfg.png", "width": "180", "height": "162", "credit": "continuous", "caption": "Features with"}, "7": {"item_id": "2014173782", "image_id": "7", "src": "https://miro.medium.com/max/570/1*aWMAGdYezTJPaVtkuvv3bA.png", "width": "285", "height": "236", "credit": "", "caption": "Basic descriptive statistics on numeric features"}, "8": {"item_id": "2014173782", "image_id": "8", "src": "https://miro.medium.com/max/1292/1*u8poCsS-SGl8jTkbV-MbCg.png", "width": "646", "height": "279", "credit": "", "caption": "Song listen counts as a numeric feature"}, "9": {"item_id": "2014173782", "image_id": "9", "src": "https://miro.medium.com/max/1600/1*7rPKhSdT9s8bc_nqfPKKcQ.png", "width": "800", "height": "314", "credit": "", "caption": "Binarizing song counts"}, "10": {"item_id": "2014173782", "image_id": "10", "src": "https://miro.medium.com/max/892/1*o4Y35xo-01zui0TBe40CeQ.png", "width": "446", "height": "211", "credit": "", "caption": "Rounding popularity to different scales"}, "11": {"item_id": "2014173782", "image_id": "11", "src": "https://miro.medium.com/max/310/1*Jq8qpv6zhOEDL8ozxgpmGw.png", "width": "155", "height": "19", "credit": "", "caption": ""}, "12": {"item_id": "2014173782", "image_id": "12", "src": "https://miro.medium.com/max/152/1*cFqSK0nMRhq8CEEdTQr4WA.png", "width": "76", "height": "24", "credit": "", "caption": ""}, "13": {"item_id": "2014173782", "image_id": "13", "src": "https://miro.medium.com/max/140/1*7F3HR9uxHmEqdJbeoy2WVQ.png", "width": "70", "height": "19", "credit": "", "caption": ""}, "14": {"item_id": "2014173782", "image_id": "14", "src": "https://miro.medium.com/max/652/1*y7WTSKnFg1RG5-CVPoccOg.png", "width": "326", "height": "19", "credit": "", "caption": ""}, "15": {"item_id": "2014173782", "image_id": "15", "src": "https://miro.medium.com/max/138/1*I12zyebq9bL7uTLgT8CwBQ.png", "width": "69", "height": "19", "credit": "", "caption": ""}, "16": {"item_id": "2014173782", "image_id": "16", "src": "https://miro.medium.com/max/298/1*Qyb6YD_LbXtBe8ZXOarPJg.png", "width": "149", "height": "165", "credit": "", "caption": ""}, "17": {"item_id": "2014173782", "image_id": "17", "src": "https://miro.medium.com/max/484/1*A3skXIYAF6nij6LQ6tgpNg.png", "width": "242", "height": "162", "credit": "", "caption": ""}, "18": {"item_id": "2014173782", "image_id": "18", "src": "https://miro.medium.com/max/798/1*K7cvymgrj7zUecDw0H2bHQ.png", "width": "399", "height": "161", "credit": "", "caption": "Numeric features with their interactions"}, "19": {"item_id": "2014173782", "image_id": "19", "src": "https://miro.medium.com/max/1130/1*jkv52GnJQ7tFkygkmI97yg.png", "width": "565", "height": "155", "credit": "", "caption": "Sample attributes from the FCC coder survey dataset"}, "20": {"item_id": "2014173782", "image_id": "20", "src": "https://miro.medium.com/max/832/1*R6ajYFdrsCZ6b3CVj_ZH4Q.png", "width": "416", "height": "281", "credit": "", "caption": "Histogram depicting developer age distribution"}, "21": {"item_id": "2014173782", "image_id": "21", "src": "https://miro.medium.com/max/826/1*31fhDxmXoGrfxbk64gg4Cw.png", "width": "413", "height": "161", "credit": "", "caption": "Binning by rounding"}, "22": {"item_id": "2014173782", "image_id": "22", "src": "https://miro.medium.com/max/1420/1*j7Wp0PxjYdvFmdf415jVWQ.png", "width": "710", "height": "157", "credit": "", "caption": "Custom binning scheme for developer ages"}, "23": {"item_id": "2014173782", "image_id": "23", "src": "https://miro.medium.com/max/818/1*ZICx_7zQc_QefDORO4HXKA.png", "width": "409", "height": "271", "credit": "", "caption": "Histogram depicting developer income distribution"}, "24": {"item_id": "2014173782", "image_id": "24", "src": "https://miro.medium.com/max/798/1*SFKE_AVc2SZEeV5xPanAXg.png", "width": "399", "height": "274", "credit": "", "caption": "Histogram depicting developer income distribution with quartile values"}, "25": {"item_id": "2014173782", "image_id": "25", "src": "https://miro.medium.com/max/1296/1*dHU2YSkyw_pOBHcRUb7T3g.png", "width": "648", "height": "157", "credit": "", "caption": "Quantile based bin ranges and labels for developer incomes"}, "26": {"item_id": "2014173782", "image_id": "26", "src": "https://miro.medium.com/max/138/1*wYFBF-DGcDTQlxukVhZRTg.png", "width": "69", "height": "20", "credit": "", "caption": ""}, "27": {"item_id": "2014173782", "image_id": "27", "src": "https://miro.medium.com/max/82/1*lPpz9UPNyCcrLcZyBCk1kA.png", "width": "41", "height": "22", "credit": "", "caption": ""}, "28": {"item_id": "2014173782", "image_id": "28", "src": "https://miro.medium.com/max/866/1*o4JmVum7d9QPjn9hevYXuA.png", "width": "433", "height": "164", "credit": "", "caption": "Log transform on developer income"}, "29": {"item_id": "2014173782", "image_id": "29", "src": "https://miro.medium.com/max/806/1*NV2JXvMfqfVQwUPUkh0Y9A.png", "width": "403", "height": "284", "credit": "", "caption": "Histogram depicting developer income distribution after log transform"}, "30": {"item_id": "2014173782", "image_id": "30", "src": "https://miro.medium.com/max/584/1*FSamGcAXuEWvvFkHQ8McFQ.png", "width": "292", "height": "70", "credit": "", "caption": ""}, "31": {"item_id": "2014173782", "image_id": "31", "src": "https://miro.medium.com/max/1566/1*VLYNEYrgmDc1Z78FhOaa0w.png", "width": "783", "height": "160", "credit": "", "caption": "Developer income distribution after Box-Cox transform"}, "32": {"item_id": "2014173782", "image_id": "32", "src": "https://miro.medium.com/max/800/1*b93f6b8rQfRdPRpvk5aXYA.png", "width": "400", "height": "282", "credit": "", "caption": "Histogram depicting developer income distribution after Box-Cox transform"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1651}, "2017217135": {"item_id": "2017217135", "resolved_id": "2017217135", "given_url": "https://towardsdatascience.com/understanding-feature-engineering-part-2-categorical-data-f54324193e63", "given_title": "Understanding Feature Engineering (Part 2) — Categorical Data", "favorite": "0", "status": "1", "time_added": "1523218303", "time_updated": "1671277184", "time_read": "1523289924", "time_favorited": "0", "sort_id": 16, "resolved_title": "Categorical Data", "resolved_url": "https://towardsdatascience.com/understanding-feature-engineering-part-2-categorical-data-f54324193e63", "excerpt": "We covered various feature engineering strategies for dealing with structured continuous numeric data in the previous article in this series. In this article, we will look at another type of structured data, which is discrete in nature and is popularly termed as categorical data.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3288", "lang": "en", "time_to_read": 15, "top_image_url": "https://miro.medium.com/max/1200/1*FgMeHrpzkMgDc1RCrl8JNw.jpeg", "tags": {"feature-engineering": {"item_id": "2017217135", "tag": "feature-engineering"}}, "authors": {"142369656": {"item_id": "2017217135", "author_id": "142369656", "name": "Dipanjan (DJ) Sarkar", "url": "https://djsarkar.medium.com"}}, "image": {"item_id": "2017217135", "src": "https://miro.medium.com/fit/c/56/56/1*Wy0cxXZpX-FrMWeXsqOOpg.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2017217135", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*Wy0cxXZpX-FrMWeXsqOOpg.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2017217135", "image_id": "2", "src": "https://miro.medium.com/max/2560/1*FgMeHrpzkMgDc1RCrl8JNw.jpeg", "width": "1280", "height": "520", "credit": "", "caption": "Source: https://pixabay.com"}, "3": {"item_id": "2017217135", "image_id": "3", "src": "https://miro.medium.com/max/1580/0*iKsDex5fUBQoYTju.png", "width": "790", "height": "502", "credit": "", "caption": "Weather as a categorical attribute"}, "4": {"item_id": "2017217135", "image_id": "4", "src": "https://miro.medium.com/max/1384/1*ychLO4DAe5cvD1UwUuvjZw.png", "width": "692", "height": "173", "credit": "", "caption": "Shirt size as an ordinal categorical attribute"}, "5": {"item_id": "2017217135", "image_id": "5", "src": "https://miro.medium.com/max/932/1*XlsFdg01yZh1IMPhmhw3Wg.png", "width": "466", "height": "181", "credit": "", "caption": "Dataset for video game sales"}, "6": {"item_id": "2017217135", "image_id": "6", "src": "https://miro.medium.com/max/964/1*_dhZ4-lsPVUzRdHUWbtBNQ.png", "width": "482", "height": "176", "credit": "", "caption": "Video game genres with their encoded labels"}, "7": {"item_id": "2017217135", "image_id": "7", "src": "https://miro.medium.com/max/2048/0*zQCDjMFdx-4uo3ec.png", "width": "1024", "height": "405", "credit": "source: https://www.reddit.com/r/pokemon/comments/2s2upx/heres_my_favorite_pokemon_by_type_and_gen_chart", "caption": "Popular Pokémon based on generation and type"}, "8": {"item_id": "2017217135", "image_id": "8", "src": "https://miro.medium.com/max/718/1*IKqNF9wJ11xdlIT5-EQ50Q.png", "width": "359", "height": "183", "credit": "", "caption": "Pokémon generation encoding"}, "9": {"item_id": "2017217135", "image_id": "9", "src": "https://miro.medium.com/max/640/1*keUxOv3nOszfDf8BmD4iyQ.png", "width": "320", "height": "180", "credit": "", "caption": "Subset of our Pokémon dataset"}, "10": {"item_id": "2017217135", "image_id": "10", "src": "https://miro.medium.com/max/956/1*vMZDgwJ1Fvzj-zOfGN21ug.png", "width": "478", "height": "185", "credit": "numeric", "caption": "Attributes with transformed"}, "11": {"item_id": "2017217135", "image_id": "11", "src": "https://miro.medium.com/max/1974/1*WiBsYgBy-GGRZzvNUBvQFQ.png", "width": "987", "height": "183", "credit": "", "caption": "One-hot encoded features for Pokémon generation and legendary status"}, "12": {"item_id": "2017217135", "image_id": "12", "src": "https://miro.medium.com/max/532/1*MKqRnwOdBfD33tgLmWM7lw.png", "width": "266", "height": "81", "credit": "", "caption": "Sample new data"}, "13": {"item_id": "2017217135", "image_id": "13", "src": "https://miro.medium.com/max/850/1*j-RLI_vxx-MA7pexi3G5QQ.png", "width": "425", "height": "80", "credit": "", "caption": "Categorical attributes after transformation"}, "14": {"item_id": "2017217135", "image_id": "14", "src": "https://miro.medium.com/max/1880/1*za1jYH-6ooFfccLxdggpKg.png", "width": "940", "height": "82", "credit": "", "caption": "Categorical attributes after one-hot encoding"}, "15": {"item_id": "2017217135", "image_id": "15", "src": "https://miro.medium.com/max/1062/1*wRIkttjEX1Udy4pZaPSZeg.png", "width": "531", "height": "184", "credit": "", "caption": "One-hot encoded features by leveraging pandas"}, "16": {"item_id": "2017217135", "image_id": "16", "src": "https://miro.medium.com/max/964/1*RrtvTvnqAYtI__CVRsqB8Q.png", "width": "482", "height": "185", "credit": "", "caption": "Dummy coded features for Pokémon generation"}, "17": {"item_id": "2017217135", "image_id": "17", "src": "https://miro.medium.com/max/964/1*pCnqiKj-Hrdn7FajO0sh1Q.png", "width": "482", "height": "188", "credit": "", "caption": "Dummy coded features for Pokémon generation"}, "18": {"item_id": "2017217135", "image_id": "18", "src": "https://miro.medium.com/max/972/1*ClxVY4HgIWzwL3zxdqOhQg.png", "width": "486", "height": "182", "credit": "", "caption": "Effect coded features for Pokémon generation"}, "19": {"item_id": "2017217135", "image_id": "19", "src": "https://miro.medium.com/max/1500/0*FwubnnoNlt6Coo9j.png", "width": "750", "height": "220", "credit": "", "caption": ""}, "20": {"item_id": "2017217135", "image_id": "20", "src": "https://miro.medium.com/max/954/1*-EbaK-Nn5L7pNulJzx39YQ.png", "width": "477", "height": "183", "credit": "", "caption": "Feature Hashing on the Genre attribute"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1273}, "2050563121": {"item_id": "2050563121", "resolved_id": "2050563121", "given_url": "https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41", "given_title": "Understanding Feature Engineering (Part 3) — Traditional Methods for Text D", "favorite": "0", "status": "1", "time_added": "1523218293", "time_updated": "1671277184", "time_read": "1523289982", "time_favorited": "0", "sort_id": 17, "resolved_title": "Traditional Methods for Text Data", "resolved_url": "https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41", "excerpt": "We have covered various feature engineering strategies for dealing with structured data in the first two parts of this series. Check out Part-I: Continuous, numeric data and Part-II: Discrete, categorical data for a refresher.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3839", "lang": "en", "time_to_read": 17, "top_image_url": "https://miro.medium.com/max/1024/1*vXKKe3J-lfi1YQ7HC6onxQ.jpeg", "tags": {"feature-engineering": {"item_id": "2050563121", "tag": "feature-engineering"}, "machine-learning": {"item_id": "2050563121", "tag": "machine-learning"}, "nlp": {"item_id": "2050563121", "tag": "nlp"}, "text": {"item_id": "2050563121", "tag": "text"}}, "authors": {"142369656": {"item_id": "2050563121", "author_id": "142369656", "name": "Dipanjan (DJ) Sarkar", "url": "https://djsarkar.medium.com"}}, "image": {"item_id": "2050563121", "src": "https://miro.medium.com/fit/c/56/56/1*Wy0cxXZpX-FrMWeXsqOOpg.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2050563121", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*Wy0cxXZpX-FrMWeXsqOOpg.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2050563121", "image_id": "2", "src": "https://miro.medium.com/max/2048/1*vXKKe3J-lfi1YQ7HC6onxQ.jpeg", "width": "1024", "height": "500", "credit": "", "caption": ""}, "3": {"item_id": "2050563121", "image_id": "3", "src": "https://miro.medium.com/max/370/1*1ihhqrBr0M6C-zgHeR7I_Q.png", "width": "185", "height": "257", "credit": "", "caption": ""}, "4": {"item_id": "2050563121", "image_id": "4", "src": "https://miro.medium.com/max/972/1*NGAjqKmla8_N6c4tKmxkgA.png", "width": "486", "height": "233", "credit": "", "caption": "Our sample text corpus"}, "5": {"item_id": "2050563121", "image_id": "5", "src": "https://miro.medium.com/max/1046/1*hTzCB81C8Wi5VxMSGAzd-w.png", "width": "523", "height": "390", "credit": "", "caption": ""}, "6": {"item_id": "2050563121", "image_id": "6", "src": "https://miro.medium.com/max/1900/1*zMdHVQQ7HYv_mMZ5Ne-2yQ.png", "width": "950", "height": "236", "credit": "", "caption": "Our Bag of Words model based document feature vectors"}, "7": {"item_id": "2050563121", "image_id": "7", "src": "https://miro.medium.com/max/2008/1*TrMMDjpylFZQIU6EY8INPw.png", "width": "1004", "height": "287", "credit": "", "caption": "Bi-gram based feature vectors using the Bag of N-Grams Model"}, "8": {"item_id": "2050563121", "image_id": "8", "src": "https://miro.medium.com/max/848/1*PUtPh3Jj0sPiRuCGhzpxSg.png", "width": "424", "height": "71", "credit": "", "caption": ""}, "9": {"item_id": "2050563121", "image_id": "9", "src": "https://miro.medium.com/max/1904/1*VTI7EPLNqXECMM_48SZTww.png", "width": "952", "height": "235", "credit": "", "caption": "Our TF-IDF model based document feature vectors"}, "10": {"item_id": "2050563121", "image_id": "10", "src": "https://miro.medium.com/max/880/0*yqSGboQIoKYxkMh3.", "width": "440", "height": "333", "credit": "", "caption": "Are we similar?"}, "11": {"item_id": "2050563121", "image_id": "11", "src": "https://miro.medium.com/max/1076/1*1FT_YXdRC1hc7Ns18Non2Q.png", "width": "538", "height": "233", "credit": "cosine similarity", "caption": "Pairwise document similarity matrix"}, "12": {"item_id": "2050563121", "image_id": "12", "src": "https://miro.medium.com/max/1554/1*6kOlPsrmOvTFIuGGb0qBJw.png", "width": "777", "height": "242", "credit": "", "caption": "Cosine similarity depictions for text document feature vectors"}, "13": {"item_id": "2050563121", "image_id": "13", "src": "https://miro.medium.com/max/836/0*nkjubhFvynBLrXv7.png", "width": "418", "height": "333", "credit": "", "caption": "Agglomerative Hierarchical Clustering"}, "14": {"item_id": "2050563121", "image_id": "14", "src": "https://miro.medium.com/max/908/1*2dcWnQrb8ws3d8aBMu1irA.png", "width": "454", "height": "211", "credit": "", "caption": "Linkage Matrix for our Corpus"}, "15": {"item_id": "2050563121", "image_id": "15", "src": "https://miro.medium.com/max/1012/1*Be-eVWH7XbpQ0J04ixL4uQ.png", "width": "506", "height": "228", "credit": "", "caption": "Dendrogram visualizing our hierarchical clustering process"}, "16": {"item_id": "2050563121", "image_id": "16", "src": "https://miro.medium.com/max/1156/1*P-F02GgiCwIUndQXWRGqSg.png", "width": "578", "height": "239", "credit": "", "caption": "Clustering our documents into groups with hierarchical clustering"}, "17": {"item_id": "2050563121", "image_id": "17", "src": "https://miro.medium.com/max/1274/0*3YiGp_YuwcwPNfM8.png", "width": "637", "height": "353", "credit": "", "caption": "An example of topic models"}, "18": {"item_id": "2050563121", "image_id": "18", "src": "https://miro.medium.com/max/2800/0*qZAMpfL2XlHF2gCT.png", "width": "1400", "height": "736", "credit": "courtesy of C. Doig, Introduction to Topic  Modeling in Python", "caption": "End-to-end LDA framework"}, "19": {"item_id": "2050563121", "image_id": "19", "src": "https://miro.medium.com/max/1000/1*Wa5tvzIPAfcJj3bV6RW7xg.png", "width": "500", "height": "417", "credit": "", "caption": ""}, "20": {"item_id": "2050563121", "image_id": "20", "src": "https://miro.medium.com/max/438/1*JfwMR3Ye0WVXuSHWOp7DPQ.png", "width": "219", "height": "242", "credit": "", "caption": "Document-Topic Matrix from our LDA Model"}, "21": {"item_id": "2050563121", "image_id": "21", "src": "https://miro.medium.com/max/1150/1*WxRbRltR92LuQG5oZs08uA.png", "width": "575", "height": "231", "credit": "", "caption": "Clustering our documents into groups with K-means clustering"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1486}, "3920095917": {"item_id": "3920095917", "resolved_id": "3920095933", "given_url": "https://towardsdatascience.com/why-is-feature-scaling-important-in-machine-learning-discussing-6-feature-scaling-techniques-2773bda5be30?source=rss----7f60cf5620c9---4", "given_title": "Why is Feature Scaling Important in Machine Learning? Discussing 6 Feature ", "favorite": "0", "status": "1", "time_added": "1692131778", "time_updated": "1692452179", "time_read": "1692452179", "time_favorited": "0", "sort_id": 18, "resolved_title": "Why Is Feature Scaling Important in Machine Learning? Discussing 6 Feature Scaling Techniques", "resolved_url": "https://towardsdatascience.com/why-is-feature-scaling-important-in-machine-learning-discussing-6-feature-scaling-techniques-2773bda5be30", "excerpt": "Many machine-learning algorithms need to have features on the same scale. There are diffident types of feature scaling methods that we can choose in various scenarios. They have different (technical) names. The term Feature Scaling simply refers to any of those methods.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "325", "lang": "en", "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*ap73KM7JcxuNTRp7PzXleA.jpeg", "tags": {"feature-engineering": {"item_id": "3920095917", "tag": "feature-engineering"}, "machine-learning": {"item_id": "3920095917", "tag": "machine-learning"}}, "authors": {"141882522": {"item_id": "3920095917", "author_id": "141882522", "name": "Rukshan Pramoditha", "url": "https://rukshanpramoditha.medium.com"}}, "image": {"item_id": "3920095917", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*K8IMVMBW8l0RVR-1oHoxwg.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3920095917", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*K8IMVMBW8l0RVR-1oHoxwg.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3920095917", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 126}, "3253928608": {"item_id": "3253928608", "resolved_id": "3253928629", "given_url": "https://towardsdatascience.com/why-you-should-always-use-feature-embeddings-with-structured-datasets-7f280b40e716?source=rss----7f60cf5620c9---4", "given_title": "Why you should always use feature embeddings with structured datasets", "favorite": "0", "status": "1", "time_added": "1613035669", "time_updated": "1671277184", "time_read": "1613042608", "time_favorited": "0", "sort_id": 19, "resolved_title": "Why You Should Always Use Feature Embeddings With Structured Datasets", "resolved_url": "https://towardsdatascience.com/why-you-should-always-use-feature-embeddings-with-structured-datasets-7f280b40e716", "excerpt": "Feature embeddings are one of the most important steps when training neural networks on tabular data tables. Unfortunately, this technique is seldom taught outside of natural language processing (NLP) settings and is consequently almost completely ignored for structured datasets.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1472", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/1200/1*XJw2acJVl-1XzQ3jB0Vdiw.jpeg", "tags": {"deep-learning": {"item_id": "3253928608", "tag": "deep-learning"}, "feature-engineering": {"item_id": "3253928608", "tag": "feature-engineering"}, "machine-learning": {"item_id": "3253928608", "tag": "machine-learning"}}, "authors": {"146630385": {"item_id": "3253928608", "author_id": "146630385", "name": "Michael Malin", "url": "https://michael-malin.medium.com"}}, "image": {"item_id": "3253928608", "src": "https://miro.medium.com/max/11230/1*XJw2acJVl-1XzQ3jB0Vdiw.jpeg", "width": "5615", "height": "3476"}, "images": {"1": {"item_id": "3253928608", "image_id": "1", "src": "https://miro.medium.com/max/11230/1*XJw2acJVl-1XzQ3jB0Vdiw.jpeg", "width": "5615", "height": "3476", "credit": "", "caption": "Image via iStock under license to Michael Malin"}, "2": {"item_id": "3253928608", "image_id": "2", "src": "https://miro.medium.com/fit/c/56/56/1*mncZFPtiYh1N60tLSrJ_cQ.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "3": {"item_id": "3253928608", "image_id": "3", "src": "https://miro.medium.com/max/794/1*lWExKUMZ8P8XPFyudgSXcw.jpeg", "width": "397", "height": "434", "credit": "the author, created  TensorFlow Embedding Projector", "caption": ""}, "4": {"item_id": "3253928608", "image_id": "4", "src": "https://miro.medium.com/max/1212/1*AjgSGbiszVJ6zBnfvd-3oQ.jpeg", "width": "606", "height": "280", "credit": "", "caption": "Example data frame by author"}, "5": {"item_id": "3253928608", "image_id": "5", "src": "https://miro.medium.com/max/1844/1*3V8VgHllhEHoY302cuxzSg.jpeg", "width": "922", "height": "601", "credit": "", "caption": "Example embedding diagram by author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 570}, "1566304962": {"item_id": "1566304962", "resolved_id": "1566304962", "given_url": "https://www.amazon.com/Mastering-Feature-Engineering-Principles-Techniques/dp/1491953241", "given_title": "", "favorite": "0", "status": "1", "time_added": "1521679645", "time_updated": "1671277184", "time_read": "1528501238", "time_favorited": "0", "sort_id": 20, "resolved_title": "Mastering Feature Engineering: Principles and Techniques for Data Scientists 1st Edition", "resolved_url": "https://www.amazon.com/Mastering-Feature-Engineering-Principles-Techniques/dp/1491953241", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "0", "lang": "en", "tags": {"feature-engineering": {"item_id": "1566304962", "tag": "feature-engineering"}}, "authors": {"64627657": {"item_id": "1566304962", "author_id": "64627657", "name": "Alice Zheng", "url": "https://www.amazon.com/s/ref=dp_byline_sr_book_1?ie=UTF8&field-author=Alice+Zheng&search-alias=books&text=Alice+Zheng&sort=relevancerank"}}, "image": {"item_id": "1566304962", "src": "https://images-na.ssl-images-amazon.com/images/G/01/gno/sprites/nav-sprite-global_bluebeacon-1x_optimized._CB281044790_.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1566304962", "image_id": "1", "src": "https://images-na.ssl-images-amazon.com/images/G/01/gno/sprites/nav-sprite-global_bluebeacon-1x_optimized._CB281044790_.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Amazon.com", "logo": "https://logo.clearbit.com/amazon.com?size=800", "greyscale_logo": "https://logo.clearbit.com/amazon.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "2871477705": {"item_id": "2871477705", "resolved_id": "1043805670", "given_url": "https://www.datasciencecentral.com/profiles/blogs/10-tools-and-platforms-for-data-preparation?fbclid=IwAR1bXhUiqDxKM54jWHMS4Naz1wffmOGpeCoSZkjjgNueuFmDA0ug1qNWCS8", "given_title": "10 tools and platforms for data preparation - Data Science Central", "favorite": "1", "status": "1", "time_added": "1580592586", "time_updated": "1706833159", "time_read": "1581282457", "time_favorited": "1581282401", "sort_id": 21, "resolved_title": "10 tools and platforms for data preparation", "resolved_url": "https://www.datasciencecentral.com/profiles/blogs/10-tools-and-platforms-for-data-preparation", "excerpt": "Traditional approaches to enterprise reporting, analysis and Business Intelligence such as Data Warehousing, upfront modelling and ETL have given way to new, more agile tools and ideas. Within this landscape Data Preparation tools have become very popular for good reason.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "783", "lang": "en", "time_to_read": 4, "top_image_url": "http://storage.ning.com/topology/rest/1.0/file/get/1327966?profile=RESIZE_1024x1024", "tags": {"feature-engineering": {"item_id": "2871477705", "tag": "feature-engineering"}, "machine-learning": {"item_id": "2871477705", "tag": "machine-learning"}, "programming": {"item_id": "2871477705", "tag": "programming"}}, "authors": {"78659038": {"item_id": "2871477705", "author_id": "78659038", "name": "Zygimantas Jacikevicius", "url": "https://www.datasciencecentral.com/profile/ZygimantasJacikevicius"}}, "image": {"item_id": "2871477705", "src": "http://datatovalue.co.uk/WP/wp-content/uploads/2015/09/paxata.png", "width": "613", "height": "341"}, "images": {"1": {"item_id": "2871477705", "image_id": "1", "src": "http://datatovalue.co.uk/WP/wp-content/uploads/2015/09/paxata.png", "width": "613", "height": "341", "credit": "", "caption": ""}, "2": {"item_id": "2871477705", "image_id": "2", "src": "http://datatovalue.co.uk/WP/wp-content/uploads/2015/09/alteryx.png", "width": "619", "height": "332", "credit": "", "caption": ""}, "3": {"item_id": "2871477705", "image_id": "3", "src": "http://datatovalue.co.uk/WP/wp-content/uploads/2015/09/lavastorm.png", "width": "616", "height": "400", "credit": "", "caption": ""}, "4": {"item_id": "2871477705", "image_id": "4", "src": "http://datatovalue.co.uk/WP/wp-content/uploads/2015/09/sap-lumira.png", "width": "633", "height": "467", "credit": "", "caption": ""}, "5": {"item_id": "2871477705", "image_id": "5", "src": "http://datatovalue.co.uk/WP/wp-content/uploads/2015/09/platfora.png", "width": "634", "height": "305", "credit": "", "caption": ""}, "6": {"item_id": "2871477705", "image_id": "6", "src": "http://datatovalue.co.uk/WP/wp-content/uploads/2015/09/teradata-loom.png", "width": "637", "height": "342", "credit": "", "caption": ""}, "7": {"item_id": "2871477705", "image_id": "7", "src": "http://datatovalue.co.uk/WP/wp-content/uploads/2015/09/datawatch.png", "width": "635", "height": "329", "credit": "", "caption": ""}, "8": {"item_id": "2871477705", "image_id": "8", "src": "http://datatovalue.co.uk/WP/wp-content/uploads/2015/09/datameer.png", "width": "642", "height": "365", "credit": "", "caption": ""}, "9": {"item_id": "2871477705", "image_id": "9", "src": "http://datatovalue.co.uk/WP/wp-content/uploads/2015/09/tamr.png", "width": "656", "height": "372", "credit": "", "caption": ""}, "10": {"item_id": "2871477705", "image_id": "10", "src": "http://datatovalue.co.uk/WP/wp-content/uploads/2015/09/rapidminer-studio.png", "width": "668", "height": "371", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Data Science Central", "logo": "https://logo.clearbit.com/datasciencecentral.com?size=800", "greyscale_logo": "https://logo.clearbit.com/datasciencecentral.com?size=800&greyscale=true"}, "listen_duration_estimate": 303}, "2975927254": {"item_id": "2975927254", "resolved_id": "2975927254", "given_url": "https://www.datasciencecentral.com/profiles/blogs/feature-engineering-data-scientist-s-secret-sauce-1?fbclid=IwAR30CuRTYhY9qxf9StfBl_J7GXHsFcg6gPDaZHvcGFNfAV6KOv6srP3gxn0", "given_title": "", "favorite": "0", "status": "1", "time_added": "1588876512", "time_updated": "1671277184", "time_read": "1589542025", "time_favorited": "0", "sort_id": 22, "resolved_title": "Feature Engineering: Data scientist's Secret Sauce !", "resolved_url": "https://www.datasciencecentral.com/profiles/blogs/feature-engineering-data-scientist-s-secret-sauce-1?fbclid=IwAR30CuRTYhY9qxf9StfBl_J7GXHsFcg6gPDaZHvcGFNfAV6KOv6srP3gxn0", "excerpt": "It is very tempting for  data science practitioners to opt for the best known  algorithms for a given problem.However It’s not the algorithm alone , which can provide the best solution  ; Model built on carefully engineered and selected features can provide far better results.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "907", "lang": "en", "time_to_read": 4, "top_image_url": "http://storage.ning.com/topology/rest/1.0/file/get/2808313467?profile=RESIZE_1024x1024", "tags": {"feature-engineering": {"item_id": "2975927254", "tag": "feature-engineering"}, "machine-learning": {"item_id": "2975927254", "tag": "machine-learning"}}, "authors": {"92639473": {"item_id": "2975927254", "author_id": "92639473", "name": "Ashish", "url": "https://www.datasciencecentral.com/profile/KumarAshish"}}, "image": {"item_id": "2975927254", "src": "https://storage.ning.com/topology/rest/1.0/file/get/2808313467?profile=RESIZE_1024x1024", "width": "750", "height": "0"}, "images": {"1": {"item_id": "2975927254", "image_id": "1", "src": "https://storage.ning.com/topology/rest/1.0/file/get/2808313467?profile=RESIZE_1024x1024", "width": "750", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Data Science Central", "logo": "https://logo.clearbit.com/datasciencecentral.com?size=800", "greyscale_logo": "https://logo.clearbit.com/datasciencecentral.com?size=800&greyscale=true"}, "listen_duration_estimate": 351}, "1961055653": {"item_id": "1961055653", "resolved_id": "1961055653", "given_url": "https://www.kdnuggets.com/2017/11/rapidminer-basic-concepts-feature-selection.html", "given_title": "Basic Concepts of Feature Selection", "favorite": "0", "status": "1", "time_added": "1510774177", "time_updated": "1671277184", "time_read": "1511384141", "time_favorited": "0", "sort_id": 23, "resolved_title": "Basic Concepts of Feature Selection", "resolved_url": "https://www.kdnuggets.com/2017/11/rapidminer-basic-concepts-feature-selection.html", "excerpt": "By RapidMiner Sponsored Post.  There is a consensus that feature engineering often has a bigger impact on the quality of a model than the model type or its parameters.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1574", "lang": "en", "time_to_read": 7, "tags": {"feature-engineering": {"item_id": "1961055653", "tag": "feature-engineering"}}, "image": {"item_id": "1961055653", "src": "https://www.kdnuggets.com/images/rapidminer-feature-selection1-605.jpg", "width": "90", "height": "0"}, "images": {"1": {"item_id": "1961055653", "image_id": "1", "src": "https://www.kdnuggets.com/images/rapidminer-feature-selection1-605.jpg", "width": "90", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1961055653", "image_id": "2", "src": "https://www.kdnuggets.com/images/rapidminer-feature-selection2-605.jpg", "width": "90", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "1961055653", "image_id": "3", "src": "https://www.kdnuggets.com/images/rapidminer-feature-selection3-605.jpg", "width": "90", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "1961055653", "image_id": "4", "src": "https://www.kdnuggets.com/images/rapidminer-feature-selection4-605.jpg", "width": "90", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "1961055653", "image_id": "5", "src": "https://www.kdnuggets.com/images/rapidminer-feature-selection5-605.jpg", "width": "90", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "1961055653", "image_id": "6", "src": "https://www.kdnuggets.com/images/rapidminer-feature-selection-3d-471.jpg", "width": "80", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 609}, "2742567331": {"item_id": "2742567331", "resolved_id": "2742567361", "given_url": "https://www.kdnuggets.com/2019/09/know-data-part-1.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1570733212", "time_updated": "1671277184", "time_read": "1577120468", "time_favorited": "0", "sort_id": 24, "resolved_title": "KDnuggets", "resolved_url": "https://www.kdnuggets.com/know-your-data-part-1.html/", "excerpt": "In my previous article, we discussed about the chemistry between Big Data and Machine Learning. We also reach to the fact that for making a good learning model we need to first understand our data well. Below picture represents the machine learning & data mining process in general.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "497", "lang": "en", "top_image_url": "https://miro.medium.com/max/1280/1*y5iOXWzUaA78akU7dbf3cw.jpeg", "tags": {"feature-engineering": {"item_id": "2742567331", "tag": "feature-engineering"}}, "image": {"item_id": "2742567331", "src": "https://miro.medium.com/max/1280/1*y5iOXWzUaA78akU7dbf3cw.jpeg", "width": "100", "height": "0"}, "images": {"1": {"item_id": "2742567331", "image_id": "1", "src": "https://miro.medium.com/max/1280/1*y5iOXWzUaA78akU7dbf3cw.jpeg", "width": "100", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2742567331", "image_id": "2", "src": "https://miro.medium.com/max/992/1*mqQ2L-cMgYimJFerKs7HxA.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2742567331", "image_id": "3", "src": "https://miro.medium.com/max/926/1*EicnE9GwBewgzLxFx27h_g.png", "width": "100", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 192}, "2692734624": {"item_id": "2692734624", "resolved_id": "2692734624", "given_url": "https://www.oreilly.com/ideas/labeling-transforming-and-structuring-training-data-sets-for-machine-learning", "given_title": "Labeling, transforming, and structuring training data sets for machine lear", "favorite": "0", "status": "1", "time_added": "1565869191", "time_updated": "1671277184", "time_read": "1566518235", "time_favorited": "0", "sort_id": 25, "resolved_title": "Labeling, transforming, and structuring training data sets for machine learning", "resolved_url": "https://www.oreilly.com/ideas/labeling-transforming-and-structuring-training-data-sets-for-machine-learning", "excerpt": "Alex Ratner’s talk, \"Building and managing training data sets for ML with Snorkel,\" is part of strong slate of sessions on \"Data, Data Networks, Data Quality\" at the O'Reilly Artificial Intelligence Conference in San Jose, September 9-12, 2019.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "362", "lang": "en", "top_image_url": "https://d3ucjech6zwjp8.cloudfront.net/1400x933/detected-with-yolo--schreibtisch-mit-objekten_crop-0b41e56b6733ed84ef9f163c4e04a908.jpg", "tags": {"feature-engineering": {"item_id": "2692734624", "tag": "feature-engineering"}}, "authors": {"114293952": {"item_id": "2692734624", "author_id": "114293952", "name": "Ben Lorica", "url": "https://www.oreilly.com/talent/4e7ad-ben-lorica"}}, "image": {"item_id": "2692734624", "src": "https://d3ucjech6zwjp8.cloudfront.net/360x240/Newcastle_University_College_graduation_Doctor_of_Philosophy_of_the_School_of_Mechanical_Engineering-62398eb83904fccc86436291c87eec55.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2692734624", "image_id": "1", "src": "https://d3ucjech6zwjp8.cloudfront.net/360x240/Newcastle_University_College_graduation_Doctor_of_Philosophy_of_the_School_of_Mechanical_Engineering-62398eb83904fccc86436291c87eec55.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2692734624", "image_id": "2", "src": "https://d3ucjech6zwjp8.cloudfront.net/360x240/dominoeffect_crop-e71ecc945d830bd7e7a571c2740b01da.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2692734624", "image_id": "3", "src": "https://d3ucjech6zwjp8.cloudfront.net/360x240/bridge-city-monument-statue-blue-sculpture-1181263-pxhere_crop-e1dd744d277f7d82bb1749115e2a4008.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2692734624", "image_id": "4", "src": "https://d3ucjech6zwjp8.cloudfront.net/360x240/julia_set_of_a_hyperbolic_exponential_map-crop-14ddc66a7eb8dbd95eaa73de276a857c.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "O'Reilly Media", "logo": "https://logo.clearbit.com/oreilly.com?size=800", "greyscale_logo": "https://logo.clearbit.com/oreilly.com?size=800&greyscale=true"}, "listen_duration_estimate": 140}, "2597733517": {"item_id": "2597733517", "resolved_id": "2597727450", "given_url": "https://www.reddit.com/r/datascience/comments/bqezb9/the_hitchhikers_guide_to_feature_extraction/?utm_source=share&utm_medium=ios_app", "given_title": "", "favorite": "1", "status": "1", "time_added": "1558298894", "time_updated": "1671277184", "time_read": "1558455465", "time_favorited": "1558455459", "sort_id": 26, "resolved_title": "The Hitchhiker’s Guide to Feature Extraction", "resolved_url": "https://www.reddit.com/r/datascience/comments/bqezb9/the_hitchhikers_guide_to_feature_extraction/", "excerpt": "168Posted by4 years ago mlwhiz.com/blog/2...", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "9", "lang": "en", "top_image_url": "https://external-preview.redd.it/BsG6gnzvwst8Vvtlfk1B-je7ydaQAGOj7dCzubYloro.jpg?auto=webp&s=6afd36e8f9809a8450845704878580178cf6584c", "tags": {"feature-engineering": {"item_id": "2597733517", "tag": "feature-engineering"}, "machine-learning": {"item_id": "2597733517", "tag": "machine-learning"}}, "domain_metadata": {"name": "Reddit", "logo": "https://logo.clearbit.com/reddit.com?size=800", "greyscale_logo": "https://logo.clearbit.com/reddit.com?size=800&greyscale=true"}, "listen_duration_estimate": 3}, "1861906783": {"item_id": "1861906783", "resolved_id": "1861906783", "given_url": "https://www.reddit.com/r/MachineLearning/comments/6uqkku/d_a_comparison_of_six_methods_for_missing_data/", "given_title": "[D] A Comparison of Six Methods for Missing Data Imputation", "favorite": "0", "status": "1", "time_added": "1503166780", "time_updated": "1671277184", "time_read": "1514398099", "time_favorited": "0", "sort_id": 27, "resolved_title": "[D] A Comparison of Six Methods for Missing Data Imputation", "resolved_url": "https://www.reddit.com/r/MachineLearning/comments/6uqkku/d_a_comparison_of_six_methods_for_missing_data/", "excerpt": "7Posted by5 years ago omicsonline.org/open-a...", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "9", "lang": "en", "tags": {"feature-engineering": {"item_id": "1861906783", "tag": "feature-engineering"}}, "authors": {"2490210": {"item_id": "1861906783", "author_id": "2490210", "name": "U", "url": ""}}, "domain_metadata": {"name": "Reddit", "logo": "https://logo.clearbit.com/reddit.com?size=800", "greyscale_logo": "https://logo.clearbit.com/reddit.com?size=800&greyscale=true"}, "listen_duration_estimate": 3}, "2670560038": {"item_id": "2670560038", "resolved_id": "2670560038", "given_url": "https://www.samueltaylor.org/articles/feature-importance-for-any-model.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1571600351", "time_updated": "1671277184", "time_read": "1577120358", "time_favorited": "0", "sort_id": 28, "resolved_title": "Model-agnostic feature importance through ablation", "resolved_url": "https://www.samueltaylor.org/articles/feature-importance-for-any-model.html", "excerpt": "Feature importances are, well, important. We can use them to provide a rudimentary level of interpretability; if a feature has higher importance, it has greater impact on the target variable.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "770", "lang": "", "tags": {"feature-engineering": {"item_id": "2670560038", "tag": "feature-engineering"}}, "image": {"item_id": "2670560038", "src": "https://www.samueltaylor.org/static/img/selecting_a_record_grande.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2670560038", "image_id": "1", "src": "https://www.samueltaylor.org/static/img/selecting_a_record_grande.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 298}, "3832648729": {"item_id": "3832648729", "resolved_id": "3832648759", "given_url": "https://www.uber.com/blog/research/maximum-relevance-and-minimum-redundancy-feature-selection-methods-for-a-marketing-machine-learning-platform", "given_title": "", "favorite": "0", "status": "1", "time_added": "1679752495", "time_updated": "1679780617", "time_read": "1679780617", "time_favorited": "0", "sort_id": 29, "resolved_title": "Page Not Found", "resolved_url": "https://www.uber.com/blog/maximum-relevance-and-minimum-redundancy-feature-selection-methods-for-a-marketing-machine-learning-platform/", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"feature-engineering": {"item_id": "3832648729", "tag": "feature-engineering"}, "machine-learning": {"item_id": "3832648729", "tag": "machine-learning"}}, "listen_duration_estimate": 0}}, "error": nil, "search_meta": {"search_type": "normal"}, "since": 1709173811}