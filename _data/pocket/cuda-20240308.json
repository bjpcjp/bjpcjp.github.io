{"status": 1, "complete": 1, "list": {"3945875967": {"item_id": "3945875967", "resolved_id": "3945875967", "given_url": "https://www.hpcwire.com/2023/10/05/how-amd-may-get-across-the-cuda-moat/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1696636049", "time_updated": "1696674512", "time_read": "1696674512", "time_favorited": "0", "sort_id": 0, "resolved_title": "", "resolved_url": "https://www.hpcwire.com/2023/10/05/how-amd-may-get-across-the-cuda-moat/", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"cuda": {"item_id": "3945875967", "tag": "cuda"}, "gpus": {"item_id": "3945875967", "tag": "gpus"}, "pytorch": {"item_id": "3945875967", "tag": "pytorch"}, "tensorflow": {"item_id": "3945875967", "tag": "tensorflow"}}, "listen_duration_estimate": 0}, "4006755995": {"item_id": "4006755995", "resolved_id": "4006755995", "given_url": "https://www.phoronix.com/review/radeon-cuda-zluda", "given_title": "AMD Quietly Funded A Drop-In CUDA Implementation Built On ROCm: It's Now Op", "favorite": "0", "status": "1", "time_added": "1707763701", "time_updated": "1707795923", "time_read": "1707795923", "time_favorited": "0", "sort_id": 1, "resolved_title": "AMD Quietly Funded A Drop-In CUDA Implementation Built On ROCm: It's Now Open-Source", "resolved_url": "https://www.phoronix.com/review/radeon-cuda-zluda", "excerpt": "While there have been efforts by AMD over the years to make it easier to port codebases targeting NVIDIA's CUDA API to run atop HIP/ROCm, it still requires work on the part of developers.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2565", "lang": "en", "time_to_read": 12, "top_image_url": "https://www.phoronix.net/image.php?id=radeon-cuda-zluda&image=radeon_cuda_4", "tags": {"amd": {"item_id": "4006755995", "tag": "amd"}, "cuda": {"item_id": "4006755995", "tag": "cuda"}, "gpus": {"item_id": "4006755995", "tag": "gpus"}}, "authors": {"159666303": {"item_id": "4006755995", "author_id": "159666303", "name": "Michael Larabel", "url": "https://www.michaellarabel.com/"}}, "image": {"item_id": "4006755995", "src": "https://phoronix.com/benchmark/result/zluda-radeon-benchmarks/result.svgz", "width": "100", "height": "0"}, "images": {"1": {"item_id": "4006755995", "image_id": "1", "src": "https://phoronix.com/benchmark/result/zluda-radeon-benchmarks/result.svgz", "width": "100", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "4006755995", "image_id": "2", "src": "https://phoronix.com/benchmark/result/zluda-radeon-benchmarks/namd-cuda-atpase-simulation-327506-atoms.svgz", "width": "100", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "4006755995", "image_id": "3", "src": "https://phoronix.com/benchmark/result/zluda-radeon-benchmarks/blender-bmw27-nvidia-cuda.svgz", "width": "100", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "4006755995", "image_id": "4", "src": "https://phoronix.com/benchmark/result/zluda-radeon-benchmarks/blender-bmw27-radeon-hip.svgz", "width": "100", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "4006755995", "image_id": "5", "src": "https://phoronix.com/benchmark/result/zluda-radeon-benchmarks/blender-classroom-nvidia-cuda.svgz", "width": "100", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "4006755995", "image_id": "6", "src": "https://phoronix.com/benchmark/result/zluda-radeon-benchmarks/blender-classroom-radeon-hip.svgz", "width": "100", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "4006755995", "image_id": "7", "src": "https://phoronix.com/benchmark/result/zluda-radeon-benchmarks/blender-fishy-cat-nvidia-cuda.svgz", "width": "100", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "4006755995", "image_id": "8", "src": "https://phoronix.com/benchmark/result/zluda-radeon-benchmarks/blender-pabellon-barcelona-nvidia-cuda.svgz", "width": "100", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Phoronix", "logo": "https://logo.clearbit.com/phoronix.com?size=800", "greyscale_logo": "https://logo.clearbit.com/phoronix.com?size=800&greyscale=true"}, "listen_duration_estimate": 993}, "2983448475": {"item_id": "2983448475", "resolved_id": "2983448475", "given_url": "https://devblogs.nvidia.com/cuda-11-features-revealed/", "given_title": "CUDA 11 Features Revealed | NVIDIA Developer Blog", "favorite": "0", "status": "1", "time_added": "1589463291", "time_updated": "1638708872", "time_read": "1589463302", "time_favorited": "0", "sort_id": 2, "resolved_title": "CUDA 11 Features Revealed", "resolved_url": "https://devblogs.nvidia.com/cuda-11-features-revealed/", "excerpt": "The new NVIDIA A100 GPU based on the NVIDIA Ampere GPU architecture delivers the greatest generational leap in accelerated computing. The A100 GPU has revolutionary hardware capabilities and we’re excited to announce CUDA 11 in conjunction with A100.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3933", "lang": "en", "time_to_read": 18, "top_image_url": "https://devblogs.nvidia.com/wp-content/uploads/2020/05/cuda-11-2.jpg", "tags": {"cuda": {"item_id": "2983448475", "tag": "cuda"}, "gpus": {"item_id": "2983448475", "tag": "gpus"}}, "authors": {"96355509": {"item_id": "2983448475", "author_id": "96355509", "name": "Pramod Ramarao", "url": "https://devblogs.nvidia.com/author/pramarao/"}}, "image": {"item_id": "2983448475", "src": "https://devblogs.nvidia.com/wp-content/uploads/2020/05/cuda-11-1.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2983448475", "image_id": "1", "src": "https://devblogs.nvidia.com/wp-content/uploads/2020/05/cuda-11-1.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2983448475", "image_id": "2", "src": "https://devblogs.nvidia.com/wp-content/uploads/2020/05/mig-in-a100.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2983448475", "image_id": "3", "src": "https://devblogs.nvidia.com/wp-content/uploads/2020/05/supported-data-types-matrix-operations-625x350.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2983448475", "image_id": "4", "src": "https://lh4.googleusercontent.com/7DexKCLBo00FKWr3GvmJ6cTyVXLxcXFcLr4RKcRqT7E0oAO3YECu8TA7ts2Iyfh9WV4iKcPLkL5TxkT3gTXq4ZXOhuIAZ1vy4EnLgAwx0K3U0mMG88wbjaPiH_6FoIJDbxsWty5D", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2983448475", "image_id": "5", "src": "https://devblogs.nvidia.com/wp-content/uploads/2020/05/platform-support-cuda-11-2-625x221.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2983448475", "image_id": "6", "src": "https://lh3.googleusercontent.com/IcfapaR1cGFxH0HxDL9JU2nWNE092Cg-IxO9TkvDNWVABF-pDoh0BhoJ0_G_jpQDK45hrIqYR1bCMJ-dnzPFlWGCXw3nsVv-P5Eu_7E5uSNYlCUhUxpw4tnFYsW8o_uJonpc3fNd", "width": "747", "height": "397", "credit": "", "caption": ""}, "7": {"item_id": "2983448475", "image_id": "7", "src": "https://lh3.googleusercontent.com/aMHu3SfbPmdurx8I1lYDfu7Avvvds0Fs4O3gGDyDhEdiVsMfOn1UQ_yjFo18cZMtPWYXJgQpzWXj6sZhrOuthhnfl5SaAfgLvN0tAouqyKJOti_vKrvZtz2s8upRnGs8gOH0H0JY", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2983448475", "image_id": "8", "src": "https://lh6.googleusercontent.com/yvPocpyURNFkglzR_cxxH66LCOvCV3nNH0bFAWxpwqoIEIOccI4NVR9472l1XRyHN1JFVDBD25HjWIn4RrCMfVM7zNO-TvUQLA_UWSgyrAmpXNc7mgVR_PA_SWVHCOJWvslb3kTD", "width": "800", "height": "364", "credit": "", "caption": ""}, "9": {"item_id": "2983448475", "image_id": "9", "src": "https://lh3.googleusercontent.com/_Q82XN6odXKJ2XF4BGANBRkU2PXIG7yS381AUG-gAQikDvTJcs2HR33d--w3s3ObtrmhygAAwXMDdiZQvN7s4PzpaDHkP5L_9RqCHVtk0oWriV1LqSuWQi8ScXUw5957L1xF9n0y", "width": "689", "height": "319", "credit": "", "caption": ""}, "10": {"item_id": "2983448475", "image_id": "10", "src": "https://devblogs.nvidia.com/wp-content/uploads/2020/05/nvjpeg-speedup-vs-cpu.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2983448475", "image_id": "11", "src": "https://lh4.googleusercontent.com/7-3pqthv4FNncPaQGw1jYCmq9VDmAV6PQPNmoh1ykba3jlXtxBqB05uaQxSEk2dgPFUC3k29ENIjIlawGJdsBHozGncApfNZWgvWjhX2Jn4nzLjVrrlea43X4Hn7Dcz97wYuAcnr", "width": "674", "height": "249", "credit": "", "caption": ""}, "12": {"item_id": "2983448475", "image_id": "12", "src": "https://devblogs.nvidia.com/wp-content/uploads/2020/05/roofline-model-1-625x208.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "2983448475", "image_id": "13", "src": "https://devblogs.nvidia.com/wp-content/uploads/2020/05/cuda-11-access-1-625x213.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1522}, "3713013281": {"item_id": "3713013281", "resolved_id": "3713013281", "given_url": "https://towardsdatascience.com/cuda-by-numba-examples-c583474124b0", "given_title": "CUDA by Numba Examples", "favorite": "0", "status": "1", "time_added": "1664393314", "time_updated": "1665774179", "time_read": "1665774179", "time_favorited": "0", "sort_id": 3, "resolved_title": "CUDA by Numba Examples: Atomics and Mutexes", "resolved_url": "https://towardsdatascience.com/cuda-by-numba-examples-c583474124b0", "excerpt": "Part 4 in the series concludes the journey of learning CUDA programming from scratch with PythonIntroductionIn the first three installments of this series (part 1 here, part 2 here, and part 3 here), we’ve gone through most of the basics of CUDA development such as launching kernels to perform emb", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2655", "lang": "en", "time_to_read": 12, "top_image_url": "https://miro.medium.com/max/1024/1*ZKaQL6AiJxOPe9Cgmt6-gg.png", "tags": {"cuda": {"item_id": "3713013281", "tag": "cuda"}, "numba": {"item_id": "3713013281", "tag": "numba"}, "python": {"item_id": "3713013281", "tag": "python"}}, "authors": {"172077559": {"item_id": "3713013281", "author_id": "172077559", "name": "Carlos Costa", "url": "https://medium.com/@cdacostaf"}}, "image": {"item_id": "3713013281", "src": "https://miro.medium.com/max/1400/1*ZKaQL6AiJxOPe9Cgmt6-gg.png", "width": "700", "height": "350"}, "images": {"1": {"item_id": "3713013281", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*ZKaQL6AiJxOPe9Cgmt6-gg.png", "width": "700", "height": "350", "credit": "", "caption": "Figure 3.0. Running Stable Diffusion with “atom heart mother album cover in the style of dali”. Credits: Own work under the CreativeML Open RAIL-M license."}, "2": {"item_id": "3713013281", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*lhgO-McHWkorkrDGELHF0g.png", "width": "700", "height": "325", "credit": "", "caption": "Figure 4.1. Several threads trying to read and write from the same global memory may result in a race condition. Credit: own work."}, "3": {"item_id": "3713013281", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*vkE70sAHWKKcX08zc41c-g.png", "width": "700", "height": "262", "credit": "", "caption": "Figure 4.2. When the resource is locked from read/write while the thread is operating on the contents, we ensure that each thread gets an updated value upon read, and its write are seen by the other threads. Atomic operations are generally slower. Credits: own work."}, "4": {"item_id": "3713013281", "image_id": "4", "src": "https://miro.medium.com/max/1198/1*19HwTlYrspUELml37MJeSw.png", "width": "599", "height": "210", "credit": "", "caption": "Histogram of CUDA by “Numba Examples”. Credit: own work."}, "5": {"item_id": "3713013281", "image_id": "5", "src": "https://miro.medium.com/max/802/1*4wRZhluoKZkO6aF_HTNtXg.png", "width": "401", "height": "264", "credit": "own work", "caption": ""}, "6": {"item_id": "3713013281", "image_id": "6", "src": "https://miro.medium.com/max/788/1*oLjKcCCFejnBCXB6LIjl2Q.png", "width": "394", "height": "264", "credit": "own work", "caption": ""}, "7": {"item_id": "3713013281", "image_id": "7", "src": "https://miro.medium.com/max/846/1*96CZMHi53R-EPsKk8S1ZOw.png", "width": "423", "height": "248", "credit": "own work", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1028}, "1257328725": {"item_id": "1257328725", "resolved_id": "1257328725", "given_url": "https://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html", "given_title": "CUDA Quick Start Guide", "favorite": "0", "status": "1", "time_added": "1690124404", "time_updated": "1690156749", "time_read": "1690156749", "time_favorited": "0", "sort_id": 4, "resolved_title": "Quick Start Guide", "resolved_url": "https://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html", "excerpt": "This document is provided for information purposes only and shall not be regarded as a warranty of a certain functionality, condition, or quality of a product.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "739", "lang": "en", "time_to_read": 3, "tags": {"cuda": {"item_id": "1257328725", "tag": "cuda"}}, "listen_duration_estimate": 286}, "3764847985": {"item_id": "3764847985", "resolved_id": "3764847985", "given_url": "https://developer.nvidia.com/blog/cuda-toolkit-12-0-released-for-general-availability/", "given_title": "CUDA Toolkit 12.0 Released for General Availability", "favorite": "0", "status": "1", "time_added": "1670876962", "time_updated": "1706833159", "time_read": "1670941056", "time_favorited": "0", "sort_id": 5, "resolved_title": "CUDA Toolkit 12.0 Released for General Availability", "resolved_url": "https://developer.nvidia.com/blog/cuda-toolkit-12-0-released-for-general-availability/", "excerpt": "NVIDIA announces the newest CUDA Toolkit software release, 12.0. This release is the first major release in many years and it focuses on new programming models and CUDA application acceleration through new hardware capabilities.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2155", "lang": "en", "time_to_read": 10, "top_image_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2022/01/cuda-image-16x9-1.jpg", "tags": {"cuda": {"item_id": "3764847985", "tag": "cuda"}, "gpus": {"item_id": "3764847985", "tag": "gpus"}, "programming": {"item_id": "3764847985", "tag": "programming"}}, "authors": {"158808428": {"item_id": "3764847985", "author_id": "158808428", "name": "Rob Armstrong", "url": "https://developer.nvidia.com/blog/author/roarmstrong/"}}, "image": {"item_id": "3764847985", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2022/12/InfiniBand-Switch-metrics-in-Nsight-Systems.png", "width": "784", "height": "148"}, "images": {"1": {"item_id": "3764847985", "image_id": "1", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2022/12/InfiniBand-Switch-metrics-in-Nsight-Systems.png", "width": "784", "height": "148", "credit": "", "caption": ""}, "2": {"item_id": "3764847985", "image_id": "2", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2022/12/Nsight-Systems-integration-in-Nsight-Compute.png", "width": "1000", "height": "312", "credit": "", "caption": ""}, "3": {"item_id": "3764847985", "image_id": "3", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2022/12/Inline-function-table-in-Nsight-Compute.png", "width": "815", "height": "234", "credit": "", "caption": ""}}, "listen_duration_estimate": 834}, "2186373608": {"item_id": "2186373608", "resolved_id": "2186373608", "given_url": "https://pytorch.org/tutorials/advanced/cpp_extension.html", "given_title": "Custom C   and CUDA Extensions — PyTorch Tutorials 1.7.0 documentation", "favorite": "0", "status": "1", "time_added": "1606677106", "time_updated": "1608290484", "time_read": "1608290484", "time_favorited": "0", "sort_id": 6, "resolved_title": "Custom C++ and CUDA Extensions — PyTorch Tutorials 1.10.0+cu102 documentation", "resolved_url": "https://pytorch.org/tutorials/advanced/cpp_extension.html", "excerpt": "PyTorch provides a plethora of operations related to neural networks, arbitrary tensor algebra, data wrangling and other purposes. However, you may still find yourself in need of a more customized operation.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "6897", "lang": "en", "time_to_read": 31, "tags": {"cuda": {"item_id": "2186373608", "tag": "cuda"}, "pytorch": {"item_id": "2186373608", "tag": "pytorch"}}, "listen_duration_estimate": 2670}, "3199191722": {"item_id": "3199191722", "resolved_id": "3199191722", "given_url": "https://askubuntu.com/questions/1288672/how-do-you-install-cuda-11-on-ubuntu-20-10-and-verify-the-installation", "given_title": "drivers - How do you install CUDA 11 on Ubuntu 20.10 and verify the install", "favorite": "0", "status": "1", "time_added": "1607738067", "time_updated": "1607740403", "time_read": "1607740403", "time_favorited": "0", "sort_id": 7, "resolved_title": "How do you install CUDA 11 on Ubuntu 20.10 and verify the installation", "resolved_url": "https://askubuntu.com/questions/1288672/how-do-you-install-cuda-11-on-ubuntu-20-10-and-verify-the-installation", "excerpt": "There seem be be several options to install CUDA on Ubuntu 20.10: It is pre-bundled with 20.10, there are various installers at the official NVIDIA page, etc. Question: What is a recommended way to install CUDA 11.X on Ubuntu 20.10, and how do I verify the installation?", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "630", "lang": "en", "time_to_read": 3, "top_image_url": "https://cdn.sstatic.net/Sites/askubuntu/Img/apple-touch-icon@2.png?v=c492c9229955", "tags": {"cuda": {"item_id": "3199191722", "tag": "cuda"}, "linux": {"item_id": "3199191722", "tag": "linux"}}, "domain_metadata": {"name": "Ask Ubuntu", "logo": "https://logo.clearbit.com/askubuntu.com?size=800", "greyscale_logo": "https://logo.clearbit.com/askubuntu.com?size=800&greyscale=true"}, "listen_duration_estimate": 244}, "3868952012": {"item_id": "3868952012", "resolved_id": "3868952012", "given_url": "https://www.linuxcapable.com/how-to-install-cuda-on-ubuntu-linux/", "given_title": "How to Install CUDA on Ubuntu 22.04 | 20.04 - LinuxCapable", "favorite": "0", "status": "1", "time_added": "1690125516", "time_updated": "1690156748", "time_read": "1690156748", "time_favorited": "0", "sort_id": 8, "resolved_title": "", "resolved_url": "https://www.linuxcapable.com/how-to-install-cuda-on-ubuntu-linux/", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"cuda": {"item_id": "3868952012", "tag": "cuda"}}, "listen_duration_estimate": 0}, "3919154906": {"item_id": "3919154906", "resolved_id": "3919154906", "given_url": "https://www.reddit.com/r/CUDA/comments/157jzum/idiotproof_checklist_for_installation_on_ubuntu/", "given_title": "Idiot-proof checklist for installation on Ubuntu 22.10? : CUDA", "favorite": "0", "status": "1", "time_added": "1691965763", "time_updated": "1692018288", "time_read": "1692018288", "time_favorited": "0", "sort_id": 9, "resolved_title": "Reddit - Dive into anything", "resolved_url": "https://www.reddit.com/r/CUDA/comments/157jzum/idiotproof_checklist_for_installation_on_ubuntu/", "excerpt": "Scan this QR code to download the app now Or check it out in the app stores", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "17", "lang": "en", "tags": {"cuda": {"item_id": "3919154906", "tag": "cuda"}}, "authors": {"179489877": {"item_id": "3919154906", "author_id": "179489877", "name": "PullThisFinger", "url": "https://www.reddit.com/user/PullThisFinger/"}}, "domain_metadata": {"name": "Reddit", "logo": "https://logo.clearbit.com/reddit.com?size=800", "greyscale_logo": "https://logo.clearbit.com/reddit.com?size=800&greyscale=true"}, "listen_duration_estimate": 7}, "1896680617": {"item_id": "1896680617", "resolved_id": "1896680617", "given_url": "https://devblogs.nvidia.com/parallelforall/numba-python-cuda-acceleration/", "given_title": "Numba: High-Performance Python with CUDA Acceleration", "favorite": "0", "status": "1", "time_added": "1506023720", "time_updated": "1611280489", "time_read": "1514398033", "time_favorited": "0", "sort_id": 10, "resolved_title": "Numba: High-Performance Python with CUDA Acceleration", "resolved_url": "https://devblogs.nvidia.com/parallelforall/numba-python-cuda-acceleration/", "excerpt": "Python is a high-productivity dynamic programming language that is widely used in science, engineering, and data analytics applications.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1419", "lang": "en", "time_to_read": 6, "top_image_url": "https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2013/09/numba_blue_icon_rgb-300x300.png", "tags": {"cuda": {"item_id": "1896680617", "tag": "cuda"}, "numba": {"item_id": "1896680617", "tag": "numba"}, "python": {"item_id": "1896680617", "tag": "python"}}, "authors": {"16771545": {"item_id": "1896680617", "author_id": "16771545", "name": "Mark Harris", "url": "https://devblogs.nvidia.com/parallelforall/author/mharris/"}}, "image": {"item_id": "1896680617", "src": "https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2013/09/numba_blue_icon_rgb-300x300.png", "width": "300", "height": "300"}, "images": {"1": {"item_id": "1896680617", "image_id": "1", "src": "https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2013/09/numba_blue_icon_rgb-300x300.png", "width": "300", "height": "300", "credit": "", "caption": ""}, "2": {"item_id": "1896680617", "image_id": "2", "src": "https://devblogs.nvidia.com/wp-content/uploads/2013/09/Python_Mandelbrot.png", "width": "391", "height": "268", "credit": "", "caption": ""}}, "listen_duration_estimate": 549}, "2334152708": {"item_id": "2334152708", "resolved_id": "2334152708", "given_url": "https://pytorch.org/get-started/locally/", "given_title": "Start Locally | PyTorch", "favorite": "0", "status": "1", "time_added": "1607701386", "time_updated": "1607701395", "time_read": "1607701395", "time_favorited": "0", "sort_id": 11, "resolved_title": "PyTorch", "resolved_url": "https://pytorch.org/get-started/locally/", "excerpt": "Select your preferences and run the install command. Stable represents the most currently tested and supported version of PyTorch. This should be suitable for many users. Preview is available if you want the latest, not fully tested and supported, 1.10 builds that are generated nightly.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "2071", "lang": "en", "time_to_read": 9, "top_image_url": "https://pytorch.org/assets/images/pytorch-logo.png", "tags": {"cuda": {"item_id": "2334152708", "tag": "cuda"}, "pytorch": {"item_id": "2334152708", "tag": "pytorch"}}, "listen_duration_estimate": 802}, "4000693070": {"item_id": "4000693070", "resolved_id": "4000693070", "given_url": "https://forums.developer.nvidia.com/t/ubuntu-nvidia-driver-installed-but-not-running/166619/2", "given_title": "Ubuntu - nvidia driver installed but not running - Graphics / Linux / Linux", "favorite": "0", "status": "1", "time_added": "1706547819", "time_updated": "1709249536", "time_read": "1709249536", "time_favorited": "0", "sort_id": 12, "resolved_title": "Ubuntu - nvidia driver installed but not running", "resolved_url": "https://forums.developer.nvidia.com/t/ubuntu-nvidia-driver-installed-but-not-running/166619/2", "excerpt": "NVIDIA tools indicate that the driver is not running, though. And nvidia-settings gets a glib error. $ nvidia-smi NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "811", "lang": "en", "time_to_read": 4, "top_image_url": "https://global.discourse-cdn.com/nvidia/original/3X/e/4/e41d27491ee72562cf68c340597ca95f587879bd.png", "tags": {"cuda": {"item_id": "4000693070", "tag": "cuda"}, "linux": {"item_id": "4000693070", "tag": "linux"}}, "listen_duration_estimate": 314}}, "error": nil, "search_meta": {"search_type": "normal"}, "since": 1709934546}