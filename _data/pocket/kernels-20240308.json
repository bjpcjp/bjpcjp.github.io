{"status": 1, "complete": 1, "list": {"1940513959": {"item_id": "1940513959", "resolved_id": "1940513959", "given_url": "https://rmarcus.info/blog/2017/10/04/rfk.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1509381475", "time_updated": "1611283609", "time_read": "1514397961", "time_favorited": "0", "sort_id": 0, "resolved_title": "The often-overlooked random forest kernel · Ryan Marcus", "resolved_url": "https://rmarcus.info/blog/2017/10/04/rfk.html", "excerpt": "Machine learning problems often require a kernel function that measures the similarity between two different input vectors, and . Such kernel functions can enable linear algorithms (like SVM, PCA, and k-means) to find non-linear solutions to classification, regression, or clustering problems.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1322", "lang": "en", "time_to_read": 6, "tags": {"kernels": {"item_id": "1940513959", "tag": "kernels"}}, "image": {"item_id": "1940513959", "src": "https://rmarcus.info/blog/assets/rfk/mnist.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1940513959", "image_id": "1", "src": "https://rmarcus.info/blog/assets/rfk/mnist.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 512}, "3493082078": {"item_id": "3493082078", "resolved_id": "3493082078", "given_url": "https://github.com/bjpcjp/python-data-science-handbook/blob/master/scikit/SciKit-Kernel-Density-Estimation.ipynb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638239964", "time_updated": "1642439944", "time_read": "1642439944", "time_favorited": "0", "sort_id": 1, "resolved_title": "", "resolved_url": "https://github.com/bjpcjp/python-data-science-handbook/blob/master/scikit/SciKit-Kernel-Density-Estimation.ipynb", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"kernels": {"item_id": "3493082078", "tag": "kernels"}, "machine-learning": {"item_id": "3493082078", "tag": "machine-learning"}, "scikit-learn": {"item_id": "3493082078", "tag": "scikit-learn"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "262662498": {"item_id": "262662498", "resolved_id": "262662498", "given_url": "https://wiki.postgresql.org/wiki/Apt", "given_title": "Apt - PostgreSQL wiki", "favorite": "0", "status": "1", "time_added": "1653510128", "time_updated": "1673901697", "time_read": "1653859164", "time_favorited": "0", "sort_id": 2, "resolved_title": "Apt", "resolved_url": "https://wiki.postgresql.org/wiki/Apt", "excerpt": "The PostgreSQL Global Development Group (PGDG) maintains an APT repository of PostgreSQL packages for Debian and Ubuntu located at http://apt.postgresql.org/pub/repos/apt/.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "959", "lang": "en", "time_to_read": 4, "tags": {"command-line": {"item_id": "262662498", "tag": "command-line"}, "databases": {"item_id": "262662498", "tag": "databases"}, "jupyter": {"item_id": "262662498", "tag": "jupyter"}, "kernels": {"item_id": "262662498", "tag": "kernels"}, "postgres": {"item_id": "262662498", "tag": "postgres"}, "ubuntu": {"item_id": "262662498", "tag": "ubuntu"}, "_r_": {"item_id": "262662498", "tag": "_r_"}}, "listen_duration_estimate": 371}, "4015079045": {"item_id": "4015079045", "resolved_id": "4015079053", "given_url": "https://towardsdatascience.com/bounded-kernel-density-estimation-2082dff3f47f?source=rss----7f60cf5620c9---4", "given_title": "Bounded Kernel Density Estimation", "favorite": "0", "status": "1", "time_added": "1709144785", "time_updated": "1709182097", "time_read": "1709182097", "time_favorited": "0", "sort_id": 3, "resolved_title": "Bounded Kernel Density Estimation", "resolved_url": "https://towardsdatascience.com/bounded-kernel-density-estimation-2082dff3f47f", "excerpt": "Histograms are widely used and easily grasped, but when it comes to estimating continuous densities, people often resort to treating it as a mysterious black box.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1715", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/v2/da:true/resize:fit:1200/0*6hwwlhkfyMF1T1LF", "tags": {"kernels": {"item_id": "4015079045", "tag": "kernels"}}, "authors": {"162328075": {"item_id": "4015079045", "author_id": "162328075", "name": "Thomas Rouch", "url": "https://medium.com/@thom01.rouch"}}, "image": {"item_id": "4015079045", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*bzXmGPw5ErdKoJZ6gYLBsw.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "4015079045", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*bzXmGPw5ErdKoJZ6gYLBsw.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "4015079045", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 664}, "829494372": {"item_id": "829494372", "resolved_id": "829494372", "given_url": "http://setosa.io/ev/image-kernels/", "given_title": "Image Kernels explained visually", "favorite": "0", "status": "1", "time_added": "1638891846", "time_updated": "1638993149", "time_read": "1638993149", "time_favorited": "0", "sort_id": 4, "resolved_title": "Image Kernels", "resolved_url": "http://setosa.io/ev/image-kernels/", "excerpt": "An image kernel is a small matrix used to apply effects like the ones you might find in Photoshop or Gimp, such as blurring, sharpening, outlining or embossing. They're also used in machine learning for 'feature extraction', a technique for determining the most important portions of an image.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "428", "lang": "en", "top_image_url": "https://setosa.io/ev/image-kernels/fb-thumb.png", "tags": {"images": {"item_id": "829494372", "tag": "images"}, "kernels": {"item_id": "829494372", "tag": "kernels"}, "machine-learning": {"item_id": "829494372", "tag": "machine-learning"}}, "listen_duration_estimate": 166}, "885337026": {"item_id": "885337026", "resolved_id": "885337026", "given_url": "https://github.com/IRkernel/IRkernel", "given_title": "IRkernel/IRkernel: R kernel for Jupyter", "favorite": "0", "status": "1", "time_added": "1642475600", "time_updated": "1673901427", "time_read": "1642531439", "time_favorited": "0", "sort_id": 5, "resolved_title": "Native R kernel for Jupyter", "resolved_url": "https://github.com/IRkernel/IRkernel", "excerpt": "Per default IRkernel::installspec() will install a kernel with the name “ir” and a display name of “R”. Multiple calls will overwrite the kernel with a kernel spec pointing to the last R interpreter you called that commands from.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "508", "lang": "en", "top_image_url": "https://opengraph.githubassets.com/a15d7ae5bc0375bb8017210d53169bf503e37369f92e2f1e95afd0476153f87f/IRkernel/IRkernel", "tags": {"jupyter": {"item_id": "885337026", "tag": "jupyter"}, "kernels": {"item_id": "885337026", "tag": "kernels"}, "_r_": {"item_id": "885337026", "tag": "_r_"}}, "image": {"item_id": "885337026", "src": "https://camo.githubusercontent.com/c2bab196413bada22bb7a9fc059d4fb0f1c376f90b5f51c8fdcb11540d17bc1c/68747470733a2f2f7472617669732d63692e636f6d2f49526b65726e656c2f49526b65726e656c2e7376673f6272616e63683d6d6173746572", "width": "0", "height": "0"}, "images": {"1": {"item_id": "885337026", "image_id": "1", "src": "https://camo.githubusercontent.com/c2bab196413bada22bb7a9fc059d4fb0f1c376f90b5f51c8fdcb11540d17bc1c/68747470733a2f2f7472617669732d63692e636f6d2f49526b65726e656c2f49526b65726e656c2e7376673f6272616e63683d6d6173746572", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "885337026", "image_id": "2", "src": "https://camo.githubusercontent.com/510f6b765253e19545caabfda590030659bcdacfd919c480196109bba5783eb7/68747470733a2f2f7777772e722d706b672e6f72672f6261646765732f76657273696f6e2f49526b65726e656c", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 197}, "1316722733": {"item_id": "1316722733", "resolved_id": "1316722733", "given_url": "http://www.cs.toronto.edu/~duvenaud/cookbook/index.html", "given_title": "Kernel Cookbook", "favorite": "0", "status": "1", "time_added": "1526671476", "time_updated": "1612385105", "time_read": "1528132059", "time_favorited": "0", "sort_id": 6, "resolved_title": "The Kernel Cookbook:", "resolved_url": "https://www.cs.toronto.edu/~duvenaud/cookbook/", "excerpt": "If you've ever asked yourself: \"How do I choose the covariance function for a Gaussian process?\" this is the page for you. Here you'll find concrete advice on how to choose a covariance function for your problem, or better yet, make your own.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "2501", "lang": "en", "time_to_read": 11, "tags": {"kernels": {"item_id": "1316722733", "tag": "kernels"}, "machine-learning": {"item_id": "1316722733", "tag": "machine-learning"}}, "authors": {"90118833": {"item_id": "1316722733", "author_id": "90118833", "name": "David Duvenaud", "url": "https://www.cs.toronto.edu/~duvenaud/"}}, "image": {"item_id": "1316722733", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/structure_examples/se_kernel.png", "width": "125", "height": "0"}, "images": {"1": {"item_id": "1316722733", "image_id": "1", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/structure_examples/se_kernel.png", "width": "125", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1316722733", "image_id": "2", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/structure_examples/se_kernel_draws_s1.png", "width": "125", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "1316722733", "image_id": "3", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/structure_examples/rq_kernel.png", "width": "125", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "1316722733", "image_id": "4", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/structure_examples/rq_kernel_draws.png", "width": "125", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "1316722733", "image_id": "5", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/structure_examples/per_kernel.png", "width": "125", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "1316722733", "image_id": "6", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/structure_examples/per_kernel_draws_s2.png", "width": "125", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "1316722733", "image_id": "7", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/structure_examples/longse_times_per.png", "width": "125", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "1316722733", "image_id": "8", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/structure_examples/longse_times_per_draws_s1.png", "width": "125", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "1316722733", "image_id": "9", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/structure_examples/lin_kernel.png", "width": "125", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "1316722733", "image_id": "10", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/structure_examples/lin_kernel_draws_s2.png", "width": "125", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "1316722733", "image_id": "11", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/structure_examples/lin_times_per.png", "width": "125", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "1316722733", "image_id": "12", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/structure_examples/lin_times_per_draws_s2.png", "width": "125", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "1316722733", "image_id": "13", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/structure_examples/lin_times_lin.png", "width": "125", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "1316722733", "image_id": "14", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/structure_examples/lin_times_lin_draws_s7.png", "width": "125", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "1316722733", "image_id": "15", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/multidimensional_kernels/Sqaured-exp%20kernel%20in%202d.png", "width": "600", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "1316722733", "image_id": "16", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/structure_examples/lin_plus_per.png", "width": "125", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "1316722733", "image_id": "17", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/structure_examples/lin_plus_per_draws_s2.png", "width": "125", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "1316722733", "image_id": "18", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/multidimensional_kernels/Additive%20kernel.png", "width": "600", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "1316722733", "image_id": "19", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/symmetry/symmetry_2d.png", "width": "400", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "1316722733", "image_id": "20", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/multidimensional_kernels/1d%20Function%20in%202d.png", "width": "600", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "1316722733", "image_id": "21", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/multidimensional_kernels/1d%20Function%20plus%20low-variance%202d%20function.png", "width": "600", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "1316722733", "image_id": "22", "src": "https://www.cs.toronto.edu/~duvenaud/cookbook/multidimensional_kernels/Factor%20analysis%20kernel.png", "width": "600", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 968}, "3920139311": {"item_id": "3920139311", "resolved_id": "3920139329", "given_url": "https://towardsdatascience.com/kernel-density-estimation-explained-step-by-step-7cc5b5bc4517?source=rss----7f60cf5620c9---4", "given_title": "Kernel Density Estimation explained step by step", "favorite": "0", "status": "1", "time_added": "1692142790", "time_updated": "1692452179", "time_read": "1692452179", "time_favorited": "0", "sort_id": 7, "resolved_title": "Kernel Density Estimation explained step by step", "resolved_url": "https://towardsdatascience.com/kernel-density-estimation-explained-step-by-step-7cc5b5bc4517", "excerpt": "To get a sense of the data distribution, we draw probability density functions (PDF). We are pleased when data fit well to a common density function, such as normal, Poisson, geometrical, etc. Then, the maximum likelihood approach can be used to fit the density function to the data.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1309", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/0*2tFCbispFUn767CB", "tags": {"kernels": {"item_id": "3920139311", "tag": "kernels"}, "machine-learning": {"item_id": "3920139311", "tag": "machine-learning"}}, "authors": {"184449846": {"item_id": "3920139311", "author_id": "184449846", "name": "Jaroslaw Drapala", "url": "https://medium.com/@jaroslaw.drapala"}}, "image": {"item_id": "3920139311", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*UOcQjVU5X3yqZH0NoxpOpA.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3920139311", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*UOcQjVU5X3yqZH0NoxpOpA.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3920139311", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 507}, "3456202237": {"item_id": "3456202237", "resolved_id": "3456202257", "given_url": "https://towardsdatascience.com/kernel-methods-a-simple-introduction-4a26dcbe4ebd?source=rss----7f60cf5620c9---4", "given_title": "Kernel Methods: A Simple Introduction", "favorite": "0", "status": "1", "time_added": "1634254323", "time_updated": "1634337568", "time_read": "1634337568", "time_favorited": "0", "sort_id": 8, "resolved_title": "Kernel Methods: A Simple Introduction", "resolved_url": "https://towardsdatascience.com/kernel-methods-a-simple-introduction-4a26dcbe4ebd", "excerpt": "The bias-variance dilemma dominates machine learning methods. If a model is too simple, the model will struggle to find appropriate relationships between inputs and outputs.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1233", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/0*V2XbjEqNCaQsV1p_", "tags": {"kernels": {"item_id": "3456202237", "tag": "kernels"}, "machine-learning": {"item_id": "3456202237", "tag": "machine-learning"}}, "authors": {"157002256": {"item_id": "3456202237", "author_id": "157002256", "name": "Diego Unzueta", "url": "https://diegounzuetaruedas.medium.com"}}, "image": {"item_id": "3456202237", "src": "https://miro.medium.com/fit/c/56/56/1*WWYuBKM8R-KY5VrIjZQzkw.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3456202237", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*WWYuBKM8R-KY5VrIjZQzkw.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3456202237", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*V2XbjEqNCaQsV1p_", "width": "700", "height": "467", "credit": "Markus Winkler on Unsplash", "caption": ""}, "3": {"item_id": "3456202237", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*fMGKzXH_cGbJrqizCGf80w.png", "width": "700", "height": "135", "credit": "", "caption": ""}, "4": {"item_id": "3456202237", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*mEZ-DY5hARqnsemBqrYhkg.png", "width": "700", "height": "273", "credit": "", "caption": ""}, "5": {"item_id": "3456202237", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*pN1_SkHeq9H7m7y6m5Td3w.png", "width": "700", "height": "208", "credit": "", "caption": ""}, "6": {"item_id": "3456202237", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*WJ8yhXLRNQywb1VK3N3J_g.png", "width": "700", "height": "170", "credit": "", "caption": ""}, "7": {"item_id": "3456202237", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*LZHT1o2JwCbpC21hBEhuJQ.png", "width": "700", "height": "175", "credit": "", "caption": ""}, "8": {"item_id": "3456202237", "image_id": "8", "src": "https://miro.medium.com/max/1188/1*55R-kAprR0ubbjoZErezlQ.png", "width": "594", "height": "303", "credit": "", "caption": "Image by Author"}, "9": {"item_id": "3456202237", "image_id": "9", "src": "https://miro.medium.com/max/1188/1*hIR5RJ1DeejozgFiSmnJsQ.png", "width": "594", "height": "303", "credit": "", "caption": "Image by Author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 477}, "1987049766": {"item_id": "1987049766", "resolved_id": "1940513959", "given_url": "https://rmarcus.info/blog/2017/10/04/rfk.html?utm_content=buffera57e2&utm_medium=social&utm_source=linkedin.com&utm_campaign=buffer", "given_title": "The often-overlooked random forest kernel · RMarcus", "favorite": "0", "status": "1", "time_added": "1512790987", "time_updated": "1612385105", "time_read": "1512840667", "time_favorited": "0", "sort_id": 9, "resolved_title": "The often-overlooked random forest kernel · Ryan Marcus", "resolved_url": "https://rmarcus.info/blog/2017/10/04/rfk.html", "excerpt": "Machine learning problems often require a kernel function that measures the similarity between two different input vectors, and . Such kernel functions can enable linear algorithms (like SVM, PCA, and k-means) to find non-linear solutions to classification, regression, or clustering problems.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1322", "lang": "en", "time_to_read": 6, "tags": {"kernels": {"item_id": "1987049766", "tag": "kernels"}, "machine-learning": {"item_id": "1987049766", "tag": "machine-learning"}}, "image": {"item_id": "1987049766", "src": "https://rmarcus.info/blog/assets/rfk/mnist.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1987049766", "image_id": "1", "src": "https://rmarcus.info/blog/assets/rfk/mnist.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 512}}, "error": nil, "search_meta": {"search_type": "normal"}, "since": 1709934709}