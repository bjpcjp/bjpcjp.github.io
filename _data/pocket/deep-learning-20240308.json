{"status": 1, "complete": 1, "list": {"3843525269": {"item_id": "3843525269", "resolved_id": "3843525269", "given_url": "https://thesequence.substack.com/p/guest-post-caching-llm-queries-for", "given_title": "", "favorite": "0", "status": "1", "time_added": "1681173913", "time_updated": "1681265771", "time_read": "1681265771", "time_favorited": "0", "sort_id": 0, "resolved_title": "üìù Guest Post: Caching LLM Queries for Improved Performance and Cost Savings*", "resolved_url": "https://thesequence.substack.com/p/guest-post-caching-llm-queries-for", "excerpt": "If you're looking for a way to improve the performance of your large language model (LLM) application while reducing costs, consider utilizing a semantic cache to store LLM responses.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "773", "lang": "en", "time_to_read": 4, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1763eb47-236b-4dfd-851c-2a388c7a5671_3200x1454.png", "tags": {"caching": {"item_id": "3843525269", "tag": "caching"}, "deep-learning": {"item_id": "3843525269", "tag": "deep-learning"}, "llms": {"item_id": "3843525269", "tag": "llms"}}, "authors": {"173331956": {"item_id": "3843525269", "author_id": "173331956", "name": "Ksenia Se", "url": ""}}, "listen_duration_estimate": 299}, "3786259503": {"item_id": "3786259503", "resolved_id": "3786259506", "given_url": "https://arxiv.org/abs/2301.04655", "given_title": "", "favorite": "0", "status": "1", "time_added": "1674301730", "time_updated": "1674531019", "time_read": "1674531019", "time_favorited": "0", "sort_id": 1, "resolved_title": "Title:ChatGPT is not all you need. A State of the Art Review of large Generative AI models", "resolved_url": "https://arxiv.org/abs/2301.04655v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"chatgpt": {"item_id": "3786259503", "tag": "chatgpt"}, "deep-learning": {"item_id": "3786259503", "tag": "deep-learning"}, "generative": {"item_id": "3786259503", "tag": "generative"}}, "authors": {"63228634": {"item_id": "3786259503", "author_id": "63228634", "name": "cs cs.AI", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3332682830": {"item_id": "3332682830", "resolved_id": "3331395178", "given_url": "https://towardsdatascience.com/causal-ml-for-data-science-deep-learning-with-instrumental-variables-96e5b7cc0482?gi=5889f08cd8e2", "given_title": "", "favorite": "0", "status": "1", "time_added": "1621107721", "time_updated": "1670682426", "time_read": "1621356931", "time_favorited": "0", "sort_id": 2, "resolved_title": "Causal ML for Data Science: Deep Learning with Instrumental Variables", "resolved_url": "https://towardsdatascience.com/causal-ml-for-data-science-deep-learning-with-instrumental-variables-96e5b7cc0482", "excerpt": "Historically, both economists and philosophers have been preoccupied with extracting an understanding of cause and effect from empirical evidence.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4526", "lang": "en", "time_to_read": 21, "top_image_url": "https://miro.medium.com/max/475/1*WvCaYm8PeaKaKdHb0MTFPw.png", "tags": {"deep-learning": {"item_id": "3332682830", "tag": "deep-learning"}, "machine-learning": {"item_id": "3332682830", "tag": "machine-learning"}}, "authors": {"141909850": {"item_id": "3332682830", "author_id": "141909850", "name": "Haaya Naushan", "url": "https://haaya-naushan.medium.com"}}, "image": {"item_id": "3332682830", "src": "https://miro.medium.com/fit/c/56/56/1*d5MTDlkEur_UZxybpnmTXQ.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3332682830", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*d5MTDlkEur_UZxybpnmTXQ.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3332682830", "image_id": "2", "src": "https://miro.medium.com/max/1678/1*tofM7kMO_TiB3Gmlklg38g.png", "width": "839", "height": "813", "credit": "Abrahams, 2021", "caption": "Satellite image of the West Bank, Palestine circa December, 2007 from ‚ÄúHard traveling: unemployment and road infrastructure in the shadow of political conflict‚Äù"}, "3": {"item_id": "3332682830", "image_id": "3", "src": "https://miro.medium.com/max/1392/1*TwQ8utMTXrVtlwdsvU3A9A.png", "width": "696", "height": "700", "credit": "", "caption": "Spatial histogram showing the main results of ‚ÄúHard traveling‚Äù. The obstruction effects are higher in the peripheral rural areas and the protection effects are higher in the commercial centers. Source: Abrahams, 2021"}, "4": {"item_id": "3332682830", "image_id": "4", "src": "https://miro.medium.com/max/836/1*wIbrMTxtkzlIYuq91vEYbQ.png", "width": "418", "height": "201", "credit": "CATE", "caption": "Causal diagram of the conditional average treatment effect"}, "5": {"item_id": "3332682830", "image_id": "5", "src": "https://miro.medium.com/max/950/1*WvCaYm8PeaKaKdHb0MTFPw.png", "width": "475", "height": "780", "credit": "red", "caption": "Map of the West Bank, Palestine showing the small peripheral neighbourhoods"}, "6": {"item_id": "3332682830", "image_id": "6", "src": "https://miro.medium.com/max/1272/1*OeBlm0yPg1LvS72UUmFhEQ.png", "width": "636", "height": "305", "credit": "", "caption": "Causal graph of the DGP under the IV specification. Source: Hartford et al., 2017"}, "7": {"item_id": "3332682830", "image_id": "7", "src": "https://miro.medium.com/max/394/1*RoUCIFTZ9nXbOt2_7zCU-w.png", "width": "197", "height": "54", "credit": "", "caption": "Structural form of outcome variable y. Source: Hartford et al., 2017"}, "8": {"item_id": "3332682830", "image_id": "8", "src": "https://miro.medium.com/max/618/1*dfrB_dYduWuyv8Ka6jtlxA.png", "width": "309", "height": "63", "credit": "", "caption": "The counterfactual prediction function. Source: Hartford et al., 2017"}, "9": {"item_id": "3332682830", "image_id": "9", "src": "https://miro.medium.com/max/858/1*BtniRmpPuPOoEN0WjQNw2w.png", "width": "429", "height": "134", "credit": "", "caption": "Conditional expectations of the structural form of outcome variable y, conditioned on covariates x, and instruments z. Source: Hartford et al., 2017"}, "10": {"item_id": "3332682830", "image_id": "10", "src": "https://miro.medium.com/max/1084/1*EdzLMsCaIIo9KPntsF-5hQ.png", "width": "542", "height": "145", "credit": "", "caption": "Loss function used to optimize the estimate of the structural equation h_hat. Source: Hartford et al., 2017"}, "11": {"item_id": "3332682830", "image_id": "11", "src": "https://miro.medium.com/max/1740/1*01fBB16LeeR1Qpz6urTW-g.png", "width": "870", "height": "573", "credit": "blue", "caption": "The CATE for the peripheral neighbourhoods"}, "12": {"item_id": "3332682830", "image_id": "12", "src": "https://miro.medium.com/max/1814/1*dY8Aa2j_2vEi81N2pQEpKA.png", "width": "907", "height": "591", "credit": "blue", "caption": "The CATE for the peripheral neighbourhoods"}, "13": {"item_id": "3332682830", "image_id": "13", "src": "https://miro.medium.com/max/1798/1*U8V7-Pf-My1wfKg9By7CbQ.png", "width": "899", "height": "588", "credit": "blue", "caption": "The CATE for peripheral neighbourhoods"}, "14": {"item_id": "3332682830", "image_id": "14", "src": "https://miro.medium.com/max/1926/1*RzU733lZc_4BKj6D2sDPEA.png", "width": "963", "height": "595", "credit": "purple", "caption": "The CATE for central neighbourhoods"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1752}, "2270883351": {"item_id": "2270883351", "resolved_id": "2270883351", "given_url": "https://github.com/matsui528/nanopq", "given_title": "", "favorite": "0", "status": "1", "time_added": "1664843487", "time_updated": "1670681126", "time_read": "1665774186", "time_favorited": "0", "sort_id": 3, "resolved_title": "nanopq", "resolved_url": "https://github.com/matsui528/nanopq", "excerpt": "Nano Product Quantization (nanopq): a vanilla implementation of Product Quantization (PQ) and Optimized Product Quantization (OPQ) written in pure python without any third party dependencies. You can install the package via pip. This library works with Python 3.5+ on linux.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "249", "lang": "en", "top_image_url": "https://opengraph.githubassets.com/e750ea18977718d5d85a67bbf961a847dd63131c8ed5a2aa083ca64bd0d5e1f2/matsui528/nanopq", "tags": {"deep-learning": {"item_id": "2270883351", "tag": "deep-learning"}, "python": {"item_id": "2270883351", "tag": "python"}, "search": {"item_id": "2270883351", "tag": "search"}}, "image": {"item_id": "2270883351", "src": "https://github.com/matsui528/nanopq/actions/workflows/build.yml/badge.svg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2270883351", "image_id": "1", "src": "https://github.com/matsui528/nanopq/actions/workflows/build.yml/badge.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2270883351", "image_id": "2", "src": "https://camo.githubusercontent.com/1451b6a52f907fc4207fe75238a47de604c802743f9a6b7d2a30034a548249b3/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f6e616e6f70712f62616467652f3f76657273696f6e3d6c6174657374", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2270883351", "image_id": "3", "src": "https://camo.githubusercontent.com/589a037271a1500601b758f3304910554e1b8c99e708b388bc25ea0db0c15011/68747470733a2f2f62616467652e667572792e696f2f70792f6e616e6f70712e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2270883351", "image_id": "4", "src": "https://camo.githubusercontent.com/671b93ea07c0cda39740e07f238367752395206b861e8f64cb2b165055e776b5/68747470733a2f2f706570792e746563682f62616467652f6e616e6f7071", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 96}, "3878343531": {"item_id": "3878343531", "resolved_id": "3878343531", "given_url": "https://spectrum.ieee.org/ai-cpu", "given_title": "", "favorite": "0", "status": "1", "time_added": "1685635267", "time_updated": "1685664105", "time_read": "1685664105", "time_favorited": "0", "sort_id": 4, "resolved_title": "The Case for Running AI on CPUs Isn't Dead Yet", "resolved_url": "https://spectrum.ieee.org/ai-cpu", "excerpt": "It‚Äôs time to give the humble CPU another crack at AI. That‚Äôs the conclusion reached by a small but increasingly vocal group of AI researchers.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "935", "lang": "en", "time_to_read": 4, "amp_url": "https://spectrum.ieee.org/amp/ai-cpu-2660616835", "top_image_url": "https://spectrum.ieee.org/media-library/an-intel-xeon-processor-on-a-black-backdrop-the-processor-is-shown-from-both-above-and-below-displaying-the-thousands-of-conta.jpg?id=33743986&width=1200&height=600&coordinates=0%2C698%2C0%2C698", "tags": {"cpus": {"item_id": "3878343531", "tag": "cpus"}, "deep-learning": {"item_id": "3878343531", "tag": "deep-learning"}, "gpus": {"item_id": "3878343531", "tag": "gpus"}, "llms": {"item_id": "3878343531", "tag": "llms"}, "semiconductors": {"item_id": "3878343531", "tag": "semiconductors"}}, "domain_metadata": {"name": "IEEE", "logo": "https://logo.clearbit.com/ieee.org?size=800", "greyscale_logo": "https://logo.clearbit.com/ieee.org?size=800&greyscale=true"}, "listen_duration_estimate": 362}, "3859904981": {"item_id": "3859904981", "resolved_id": "3859904981", "given_url": "https://spectrum.ieee.org/backpropagation-optical-ai", "given_title": "", "favorite": "0", "status": "1", "time_added": "1684710266", "time_updated": "1684777690", "time_read": "1684777689", "time_favorited": "0", "sort_id": 5, "resolved_title": "Photonic Chips Curb AI Training‚Äôs Energy Appetite", "resolved_url": "https://spectrum.ieee.org/backpropagation-optical-ai", "excerpt": "Processors that use light instead of electricity show promise as a faster and more energy-efficient way to implement AI. So far they‚Äôve only been used to run models that have already been trained, but new research has demonstrated the ability to train AI on an optical chip for the first time.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "916", "lang": "en", "time_to_read": 4, "amp_url": "https://spectrum.ieee.org/amp/backpropagation-optical-ai-2659949547", "top_image_url": "https://spectrum.ieee.org/media-library/two-colorful-microscope-images.jpg?id=33603527&width=1200&height=600&coordinates=0%2C7%2C0%2C7", "tags": {"deep-learning": {"item_id": "3859904981", "tag": "deep-learning"}, "optics-photonics": {"item_id": "3859904981", "tag": "optics-photonics"}, "semiconductors": {"item_id": "3859904981", "tag": "semiconductors"}}, "domain_metadata": {"name": "IEEE", "logo": "https://logo.clearbit.com/ieee.org?size=800", "greyscale_logo": "https://logo.clearbit.com/ieee.org?size=800&greyscale=true"}, "listen_duration_estimate": 355}, "3844746192": {"item_id": "3844746192", "resolved_id": "3844707196", "given_url": "https://thesequence.substack.com/p/the-sequence-chat-salesforce-researchs?utm_medium=email", "given_title": "", "favorite": "0", "status": "1", "time_added": "1681303073", "time_updated": "1681304570", "time_read": "1681304569", "time_favorited": "0", "sort_id": 6, "resolved_title": "The Sequence Chat: Salesforce Research's Junnan Li on Multimodal Generative AI", "resolved_url": "https://thesequence.substack.com/p/the-sequence-chat-salesforce-researchs", "excerpt": "Tell us a bit about yourself. Your background, current role and how did you get started in machine learning (ML)? I¬†‚Äòm a research scientist at Salesforce Research focusing on multimodal AI research. I did my PhD at National University of Singapore in Computer Vision.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "534", "lang": "en", "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F814feca2-f68a-4ec4-8beb-ea2de67381ce_1278x720.jpeg", "tags": {"deep-learning": {"item_id": "3844746192", "tag": "deep-learning"}, "generative": {"item_id": "3844746192", "tag": "generative"}}, "authors": {"86252": {"item_id": "3844746192", "author_id": "86252", "name": "Jesus Rodriguez", "url": ""}}, "listen_duration_estimate": 207}, "3243583333": {"item_id": "3243583333", "resolved_id": "3243150021", "given_url": "https://arxiv.org/abs/2101.11714?fbclid=IwAR1M4kpl679ATOb9klbcx04ts3hdMhxMmJd2FJEUbLNzIxhwJ2zXMKVN7tY", "given_title": "", "favorite": "0", "status": "1", "time_added": "1612003298", "time_updated": "1678841985", "time_read": "1612005764", "time_favorited": "0", "sort_id": 7, "resolved_title": "Title:TT-Rec: Tensor Train Compression for Deep Learning Recommendation Models", "resolved_url": "https://arxiv.org/abs/2101.11714v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"deep-learning": {"item_id": "3243583333", "tag": "deep-learning"}, "recommenders": {"item_id": "3243583333", "tag": "recommenders"}}, "authors": {"146135519": {"item_id": "3243583333", "author_id": "146135519", "name": "cs", "url": "https://arxiv.org/abs/2101.11714?context=cs"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3661315241": {"item_id": "3661315241", "resolved_id": "3661315241", "given_url": "https://towardsdatascience.com/rethinking-thinking-how-do-attention-mechanisms-actually-work-a6f67d313f99", "given_title": "", "favorite": "0", "status": "1", "time_added": "1659015292", "time_updated": "1706235144", "time_read": "1659214994", "time_favorited": "0", "sort_id": 8, "resolved_title": "Rethinking Thinking: How Do Attention Mechanisms Actually Work?", "resolved_url": "https://towardsdatascience.com/rethinking-thinking-how-do-attention-mechanisms-actually-work-a6f67d313f99", "excerpt": "2. Attention mechanisms in deep learning 2.1. RNNSearch 2.2. What exactly are keys, queries, and values in attention mechanisms? 3. Categorization of attention mechanisms 3.1. The softness of attention 3.2. Forms of input feature 3.3. Input representation 3.4. Output representation", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4110", "lang": "en", "time_to_read": 19, "top_image_url": "https://miro.medium.com/v2/resize:fit:712/1*rn3dKuGlyCljldvE94KrnA.png", "tags": {"deep-learning": {"item_id": "3661315241", "tag": "deep-learning"}}, "authors": {"169881463": {"item_id": "3661315241", "author_id": "169881463", "name": "Soran Ghaderi", "url": "https://soran-ghaderi.medium.com"}}, "image": {"item_id": "3661315241", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*oF0Ju0wFYlAgPv1IZvJP_w.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3661315241", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*oF0Ju0wFYlAgPv1IZvJP_w.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3661315241", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1591}, "3838345443": {"item_id": "3838345443", "resolved_id": "3838332429", "given_url": "https://arxiv.org/abs/2303.18223#", "given_title": "", "favorite": "0", "status": "1", "time_added": "1680575326", "time_updated": "1681439192", "time_read": "1681439192", "time_favorited": "0", "sort_id": 9, "resolved_title": "Title:A Survey of Large Language Models", "resolved_url": "https://arxiv.org/abs/2303.18223v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "72", "lang": "en", "top_image_url": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png", "tags": {"arxiv": {"item_id": "3838345443", "tag": "arxiv"}, "deep-learning": {"item_id": "3838345443", "tag": "deep-learning"}, "llms": {"item_id": "3838345443", "tag": "llms"}}, "authors": {"180127060": {"item_id": "3838345443", "author_id": "180127060", "name": "Wayne Xin Zhao", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 28}, "3835064556": {"item_id": "3835064556", "resolved_id": "3830004280", "given_url": "https://medium.com/towards-data-science/hands-on-generative-ai-with-gans-using-python-autoencoders-c77232b402fc", "given_title": "", "favorite": "0", "status": "1", "time_added": "1680049787", "time_updated": "1680284008", "time_read": "1680284008", "time_favorited": "0", "sort_id": 10, "resolved_title": "Hands-on Generative AI with GANs using Python: Autoencoders", "resolved_url": "https://towardsdatascience.com/hands-on-generative-ai-with-gans-using-python-autoencoders-c77232b402fc", "excerpt": "In recent years, generative models have gained popularity due to Artificial Intelligent‚Äôs ability to produce synthetic instances that are almost indistinguishable from real data.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1433", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/0*1Sd8PSZCmbPTizb8", "tags": {"autoencoders": {"item_id": "3835064556", "tag": "autoencoders"}, "deep-learning": {"item_id": "3835064556", "tag": "deep-learning"}}, "authors": {"156659042": {"item_id": "3835064556", "author_id": "156659042", "name": "Marcello Politi", "url": "https://medium.com/@marcellopoliti"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 555}, "1024078227": {"item_id": "1024078227", "resolved_id": "1024078227", "given_url": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1622248091", "time_updated": "1638708525", "time_read": "1622249133", "time_favorited": "0", "sort_id": 11, "resolved_title": "Understanding LSTM Networks", "resolved_url": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/", "excerpt": "Humans don‚Äôt start their thinking from scratch every second. As you read this essay, you understand each word based on your understanding of previous words. You don‚Äôt throw everything away and start thinking from scratch again. Your thoughts have persistence.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2193", "lang": "en", "time_to_read": 10, "tags": {"deep-learning": {"item_id": "1024078227", "tag": "deep-learning"}, "lstms": {"item_id": "1024078227", "tag": "lstms"}}, "authors": {"38227226": {"item_id": "1024078227", "author_id": "38227226", "name": "Luke Vilnis", "url": "http://people.cs.umass.edu/~luke/"}}, "image": {"item_id": "1024078227", "src": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-rolled.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1024078227", "image_id": "1", "src": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-rolled.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1024078227", "image_id": "2", "src": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "1024078227", "image_id": "3", "src": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-shorttermdepdencies.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "1024078227", "image_id": "4", "src": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-longtermdependencies.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "1024078227", "image_id": "5", "src": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png", "width": "0", "height": "0", "credit": "", "caption": "The repeating module in a standard RNN contains a single layer."}, "6": {"item_id": "1024078227", "image_id": "6", "src": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png", "width": "0", "height": "0", "credit": "", "caption": "The repeating module in an LSTM contains four interacting layers."}, "7": {"item_id": "1024078227", "image_id": "7", "src": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM2-notation.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "1024078227", "image_id": "8", "src": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-C-line.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "1024078227", "image_id": "9", "src": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-gate.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "1024078227", "image_id": "10", "src": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-f.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "1024078227", "image_id": "11", "src": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-i.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "1024078227", "image_id": "12", "src": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-C.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "1024078227", "image_id": "13", "src": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-o.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "1024078227", "image_id": "14", "src": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-peepholes.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "1024078227", "image_id": "15", "src": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-tied.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "1024078227", "image_id": "16", "src": "http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-GRU.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 849}, "1096569162": {"item_id": "1096569162", "resolved_id": "1096569162", "given_url": "http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1622248019", "time_updated": "1638708525", "time_read": "1622249139", "time_favorited": "0", "sort_id": 12, "resolved_title": "", "resolved_url": "http://wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"convolutions": {"item_id": "1096569162", "tag": "convolutions"}, "deep-learning": {"item_id": "1096569162", "tag": "deep-learning"}, "nlp": {"item_id": "1096569162", "tag": "nlp"}}, "listen_duration_estimate": 0}, "1182061259": {"item_id": "1182061259", "resolved_id": "1182061259", "given_url": "https://www.slideshare.net/dominodatalab/gpu-computing-for-data-science", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638241035", "time_updated": "1638561346", "time_read": "1638561345", "time_favorited": "0", "sort_id": 13, "resolved_title": "GPU Computing for Data Science", "resolved_url": "https://www.slideshare.net/dominodatalab/gpu-computing-for-data-science", "excerpt": "SlideShare uses cookies to improve functionality and performance, and to provide you with relevant advertising. If you continue browsing the site, you agree to the use of cookies on this website. See our User Agreement and Privacy Policy.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "78", "lang": "", "top_image_url": "https://cdn.slidesharecdn.com/ss_thumbnails/dominogpuwebinarslides1-160202162602-thumbnail-4.jpg?cb=1454599050", "tags": {"deep-learning": {"item_id": "1182061259", "tag": "deep-learning"}, "gpus": {"item_id": "1182061259", "tag": "gpus"}}, "authors": {"157719669": {"item_id": "1182061259", "author_id": "157719669", "name": "Domino Data Lab", "url": "https://www.slideshare.net/dominodatalab?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideview"}}, "domain_metadata": {"name": "LinkedIn SlideShare", "logo": "https://logo.clearbit.com/slideshare.net?size=800", "greyscale_logo": "https://logo.clearbit.com/slideshare.net?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "1235655690": {"item_id": "1235655690", "resolved_id": "1235655690", "given_url": "https://github.com/vdumoulin/conv_arithmetic", "given_title": "", "favorite": "0", "status": "1", "time_added": "1541510530", "time_updated": "1706648249", "time_read": "1541515398", "time_favorited": "0", "sort_id": 14, "resolved_title": "Convolution arithmetic", "resolved_url": "https://github.com/vdumoulin/conv_arithmetic", "excerpt": "N.B.: Blue maps are inputs, and cyan maps are outputs. N.B.: Blue maps are inputs, and cyan maps are outputs.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "211", "lang": "en", "top_image_url": "https://opengraph.githubassets.com/bb8b17aab7c685e76e3b3ba18fab28c706dbb8cf6c2d9656e44534b83ff43ac3/vdumoulin/conv_arithmetic", "tags": {"algorithms-math": {"item_id": "1235655690", "tag": "algorithms-math"}, "deep-learning": {"item_id": "1235655690", "tag": "deep-learning"}}, "image": {"item_id": "1235655690", "src": "https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides.gif", "width": "150", "height": "0"}, "images": {"1": {"item_id": "1235655690", "image_id": "1", "src": "https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides.gif", "width": "150", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1235655690", "image_id": "2", "src": "https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/arbitrary_padding_no_strides.gif", "width": "150", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "1235655690", "image_id": "3", "src": "https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/same_padding_no_strides.gif", "width": "150", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "1235655690", "image_id": "4", "src": "https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/full_padding_no_strides.gif", "width": "150", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "1235655690", "image_id": "5", "src": "https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_strides.gif", "width": "150", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "1235655690", "image_id": "6", "src": "https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/padding_strides.gif", "width": "150", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "1235655690", "image_id": "7", "src": "https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/padding_strides_odd.gif", "width": "150", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "1235655690", "image_id": "8", "src": "https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_no_strides_transposed.gif", "width": "150", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "1235655690", "image_id": "9", "src": "https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/arbitrary_padding_no_strides_transposed.gif", "width": "150", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "1235655690", "image_id": "10", "src": "https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/same_padding_no_strides_transposed.gif", "width": "150", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "1235655690", "image_id": "11", "src": "https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/full_padding_no_strides_transposed.gif", "width": "150", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "1235655690", "image_id": "12", "src": "https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/no_padding_strides_transposed.gif", "width": "150", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "1235655690", "image_id": "13", "src": "https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/padding_strides_transposed.gif", "width": "150", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "1235655690", "image_id": "14", "src": "https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/padding_strides_odd_transposed.gif", "width": "150", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "1235655690", "image_id": "15", "src": "https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/dilation.gif", "width": "150", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 82}, "1302148495": {"item_id": "1302148495", "resolved_id": "1302148495", "given_url": "http://veredshwartz.blogspot.com/2015/09/language-models.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1622248044", "time_updated": "1638708525", "time_read": "1622249137", "time_favorited": "0", "sort_id": 15, "resolved_title": "Language Models", "resolved_url": "http://veredshwartz.blogspot.com/2015/09/language-models.html", "excerpt": "And as always, there are more complex smoothing techniques (Back-off, Kneser-Ney, etc.), that I will not discuss in this post. Choosing the corpus from which you learn the language model greatly affects the final outcome. Needless to say, choosing the language of the corpus is crucial.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1597", "lang": "en", "time_to_read": 7, "top_image_url": "http://2.bp.blogspot.com/-8I8Dz-ksgok/VfCcGOxpr5I/AAAAAAAADBo/FwNtiy9jzr0/w1200-h630-p-k-no-nu/5flmIpp.png", "tags": {"deep-learning": {"item_id": "1302148495", "tag": "deep-learning"}, "language-linguistics": {"item_id": "1302148495", "tag": "language-linguistics"}}, "authors": {"118393217": {"item_id": "1302148495", "author_id": "118393217", "name": "Vered Shwartz", "url": "https://www.blogger.com/profile/17531957962535846245"}}, "image": {"item_id": "1302148495", "src": "http://2.bp.blogspot.com/-8I8Dz-ksgok/VfCcGOxpr5I/AAAAAAAADBo/FwNtiy9jzr0/s1600/5flmIpp.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1302148495", "image_id": "1", "src": "http://2.bp.blogspot.com/-8I8Dz-ksgok/VfCcGOxpr5I/AAAAAAAADBo/FwNtiy9jzr0/s1600/5flmIpp.png", "width": "0", "height": "0", "credit": "", "caption": "Google suggests words that are likely to complete the query. From here."}}, "listen_duration_estimate": 618}, "1590985594": {"item_id": "1590985594", "resolved_id": "1590985594", "given_url": "https://www.nextplatform.com/2017/02/02/memory-core-new-deep-learning-research-chip/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638241035", "time_updated": "1638671748", "time_read": "1638369874", "time_favorited": "0", "sort_id": 16, "resolved_title": "Memory at the Core of New Deep Learning Research Chip", "resolved_url": "https://www.nextplatform.com/2017/02/02/memory-core-new-deep-learning-research-chip/", "excerpt": "Over the last two years, there has been a push for novel architectures to feed the needs of machine learning and more specifically, deep neural networks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "871", "lang": "en", "time_to_read": 4, "amp_url": "https://www.nextplatform.com/2017/02/02/memory-core-new-deep-learning-research-chip/amp/", "top_image_url": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2016/06/ab_53434447820.jpe", "tags": {"deep-learning": {"item_id": "1590985594", "tag": "deep-learning"}, "semiconductor-memory": {"item_id": "1590985594", "tag": "semiconductor-memory"}, "semiconductors": {"item_id": "1590985594", "tag": "semiconductors"}}, "authors": {"58691955": {"item_id": "1590985594", "author_id": "58691955", "name": "Nicole Hemsoth", "url": "https://www.nextplatform.com/author/nicole/"}}, "image": {"item_id": "1590985594", "src": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2016/06/ab_53434447820.jpe", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1590985594", "image_id": "1", "src": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2016/06/ab_53434447820.jpe", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1590985594", "image_id": "2", "src": "http://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/02/Neurostream1.png", "width": "516", "height": "716", "credit": "", "caption": ""}}, "listen_duration_estimate": 337}, "1620401292": {"item_id": "1620401292", "resolved_id": "1620401292", "given_url": "http://research.baidu.com/bringing-hpc-techniques-deep-learning/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638241035", "time_updated": "1638708525", "time_read": "1638369919", "time_favorited": "0", "sort_id": 17, "resolved_title": "", "resolved_url": "http://research.baidu.com/bringing-hpc-techniques-deep-learning/", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"deep-learning": {"item_id": "1620401292", "tag": "deep-learning"}, "gpus": {"item_id": "1620401292", "tag": "gpus"}}, "listen_duration_estimate": 0}, "1620533951": {"item_id": "1620533951", "resolved_id": "1620533951", "given_url": "https://www.hpcwire.com/2017/02/21/hpc-technique-benefits-deep-learning", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638241035", "time_updated": "1639002036", "time_read": "1639002036", "time_favorited": "0", "sort_id": 18, "resolved_title": "HPC Technique Propels Deep Learning at Scale", "resolved_url": "https://www.hpcwire.com/2017/02/21/hpc-technique-benefits-deep-learning/", "excerpt": "Researchers from Baidu‚Äôs Silicon Valley AI Lab (SVAIL) have adapted a well-known HPC communication technique to boost the speed and scale of their neural network training and now they are sharing their implementation¬†with the larger deep learning community.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1124", "lang": "en", "time_to_read": 5, "top_image_url": "https://6lli539m39y3hpkelqsm3c2fg-wpengine.netdna-ssl.com/wp-content/uploads/2017/02/shutterstock_abstract_tech-1.jpg", "tags": {"deep-learning": {"item_id": "1620533951", "tag": "deep-learning"}}, "authors": {"1831386": {"item_id": "1620533951", "author_id": "1831386", "name": "Tiffany Trader", "url": ""}}, "image": {"item_id": "1620533951", "src": "https://6lli539m39y3hpkelqsm3c2fg-wpengine.netdna-ssl.com/wp-content/uploads/2017/02/BaiduRingAllreduce-480x.png", "width": "280", "height": "300"}, "images": {"1": {"item_id": "1620533951", "image_id": "1", "src": "https://6lli539m39y3hpkelqsm3c2fg-wpengine.netdna-ssl.com/wp-content/uploads/2017/02/BaiduRingAllreduce-480x.png", "width": "280", "height": "300", "credit": "", "caption": "Ring all-reduce ‚Äì all GPUs send data simultaneously"}}, "listen_duration_estimate": 435}, "1652373239": {"item_id": "1652373239", "resolved_id": "1652373239", "given_url": "https://www.nextplatform.com/2017/03/14/3d-stacking-boost-gpu-machine-learning/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638241035", "time_updated": "1639002104", "time_read": "1639002103", "time_favorited": "0", "sort_id": 19, "resolved_title": "3D Stacking Could Boost GPU Machine Learning", "resolved_url": "https://www.nextplatform.com/2017/03/14/3d-stacking-boost-gpu-machine-learning/", "excerpt": "Nvidia has staked its growth in the datacenter on machine learning.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "816", "lang": "en", "time_to_read": 4, "amp_url": "https://www.nextplatform.com/2017/03/14/3d-stacking-boost-gpu-machine-learning/amp/", "top_image_url": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2015/11/TeslaGPU2.jpg", "tags": {"deep-learning": {"item_id": "1652373239", "tag": "deep-learning"}, "gpus": {"item_id": "1652373239", "tag": "gpus"}, "interconnects": {"item_id": "1652373239", "tag": "interconnects"}, "semiconductor-memory": {"item_id": "1652373239", "tag": "semiconductor-memory"}, "semiconductors": {"item_id": "1652373239", "tag": "semiconductors"}}, "authors": {"63639129": {"item_id": "1652373239", "author_id": "63639129", "name": "Jeffrey Burt", "url": "https://www.nextplatform.com/author/jeffrey/"}}, "image": {"item_id": "1652373239", "src": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2015/11/TeslaGPU2.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1652373239", "image_id": "1", "src": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2015/11/TeslaGPU2.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 316}, "1685729181": {"item_id": "1685729181", "resolved_id": "1685729181", "given_url": "https://www.nextplatform.com/2017/04/05/first-depth-look-googles-tpu-architecture/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638241035", "time_updated": "1638839085", "time_read": "1638839085", "time_favorited": "0", "sort_id": 20, "resolved_title": "First In-Depth Look at Google‚Äôs TPU Architecture", "resolved_url": "https://www.nextplatform.com/2017/04/05/first-depth-look-googles-tpu-architecture/", "excerpt": "Four years ago, Google started to see the real potential for deploying neural networks to support a large number of new services.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1532", "lang": "en", "time_to_read": 7, "amp_url": "https://www.nextplatform.com/2017/04/05/first-depth-look-googles-tpu-architecture/amp/", "top_image_url": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/04/Google_TPU_2.jpg", "tags": {"deep-learning": {"item_id": "1685729181", "tag": "deep-learning"}, "semiconductors": {"item_id": "1685729181", "tag": "semiconductors"}, "tpu": {"item_id": "1685729181", "tag": "tpu"}}, "authors": {"58691955": {"item_id": "1685729181", "author_id": "58691955", "name": "Nicole Hemsoth", "url": "https://www.nextplatform.com/author/nicole/"}}, "image": {"item_id": "1685729181", "src": "http://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/04/Jouppi1.jpg", "width": "501", "height": "377"}, "images": {"1": {"item_id": "1685729181", "image_id": "1", "src": "http://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/04/Jouppi1.jpg", "width": "501", "height": "377", "credit": "there is no looping", "caption": "This shows everything on a TPU except for the DDR3 memory that hangs outside, you‚Äôll see the host interface on the left. Instructions are sent from that host in a queue"}, "2": {"item_id": "1685729181", "image_id": "2", "src": "http://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/04/JouppiTable2.jpg", "width": "1018", "height": "315", "credit": "", "caption": ""}, "3": {"item_id": "1685729181", "image_id": "3", "src": "http://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/04/JouppiTable4.png", "width": "300", "height": "117", "credit": "", "caption": ""}}, "listen_duration_estimate": 593}, "1754138891": {"item_id": "1754138891", "resolved_id": "1754138891", "given_url": "https://www.nextplatform.com/2017/05/22/hood-googles-tpu2-machine-learning-clusters/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638241035", "time_updated": "1639221794", "time_read": "1639221794", "time_favorited": "0", "sort_id": 21, "resolved_title": "Under The Hood Of Google‚Äôs TPU2 Machine Learning Clusters", "resolved_url": "https://www.nextplatform.com/2017/05/22/hood-googles-tpu2-machine-learning-clusters/", "excerpt": "As we previously reported, Google unveiled its second-generation TensorFlow Processing Unit (TPU2) at Google I/O last week.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2884", "lang": "en", "time_to_read": 13, "amp_url": "https://www.nextplatform.com/2017/05/22/hood-googles-tpu2-machine-learning-clusters/amp/", "top_image_url": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/05/tpu2.jpg", "tags": {"deep-learning": {"item_id": "1754138891", "tag": "deep-learning"}, "semiconductors": {"item_id": "1754138891", "tag": "semiconductors"}, "tpu": {"item_id": "1754138891", "tag": "tpu"}}, "authors": {"80709507": {"item_id": "1754138891", "author_id": "80709507", "name": "Timothy Prickett Morgan", "url": "https://www.nextplatform.com/author/tpmn/"}}, "image": {"item_id": "1754138891", "src": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/05/tpu2-870x438.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1754138891", "image_id": "1", "src": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/05/tpu2-870x438.jpg", "width": "0", "height": "0", "credit": "", "caption": "Google‚Äôs first-generation TPU card: A, Without heat sink and B, with heat sink"}, "2": {"item_id": "1754138891", "image_id": "2", "src": "http://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/05/image002.jpg", "width": "624", "height": "239", "credit": "blue", "caption": "Google‚Äôs TPU2 stamp: A is a CPU rack, B is a TPU2 rack, C is a TPU2 rack, and D is a CPU rack; the solid box"}, "3": {"item_id": "1754138891", "image_id": "3", "src": "http://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/05/image003.jpg", "width": "624", "height": "414", "credit": "", "caption": "Three Google TPU2 stamps"}, "4": {"item_id": "1754138891", "image_id": "4", "src": "http://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/05/image004.jpg", "width": "624", "height": "275", "credit": "OPA", "caption": "Top view of TPU2 board: A is four TPU2 chips with heat sinks; B is two BlueLink 25GB/s cables per TPU2; C is two Omni-Path Architecture"}, "5": {"item_id": "1754138891", "image_id": "5", "src": "http://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/05/image005.jpg", "width": "624", "height": "322", "credit": "", "caption": "TPU2 front panel connections"}, "6": {"item_id": "1754138891", "image_id": "6", "src": "http://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/05/image006.jpg", "width": "623", "height": "477", "credit": "", "caption": "Comparing the two CPU racks with rack D flipped"}, "7": {"item_id": "1754138891", "image_id": "7", "src": "http://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/05/image007.jpg", "width": "623", "height": "486", "credit": "", "caption": "Comparing the two TPU2 racks with rack C flipped"}, "8": {"item_id": "1754138891", "image_id": "8", "src": "http://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/05/image009.jpg", "width": "623", "height": "407", "credit": "", "caption": "Heat sinks on parade: A is quad TPU2 motherboard side view, B is dual IBM Power9 ‚ÄúZaius‚Äù motherboard, C is dual IBM Power8 ‚ÄúMinsky‚Äù motherboard, D is Dual Intel Xeon Facebook ‚ÄúYosemite‚Äù motherboard, and E is Nvidia P100 SMX2 module with heat sink and Facebook ‚ÄúBig Basin‚Äù motherboard"}}, "listen_duration_estimate": 1116}, "1817158629": {"item_id": "1817158629", "resolved_id": "1817158629", "given_url": "https://becominghuman.ai/neural-networks-for-algorithmic-trading-multimodal-and-multitask-deep-learning-5498e0098caf", "given_title": "", "favorite": "0", "status": "1", "time_added": "1500834965", "time_updated": "1638708525", "time_read": "1528501620", "time_favorited": "0", "sort_id": 22, "resolved_title": "Neural networks for algorithmic trading. Multimodal and multitask deep learning", "resolved_url": "https://becominghuman.ai/neural-networks-for-algorithmic-trading-multimodal-and-multitask-deep-learning-5498e0098caf", "excerpt": "Here we are again! We already have four tutorials on financial forecasting with artificial neural networks where we compared different architectures for financial time series forecasting, realized how to do this forecasting adequately with correct data preprocessing and regularization, performed our", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2225", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/max/396/0*WhJwmSlP08C5CM1B.png", "tags": {"deep-learning": {"item_id": "1817158629", "tag": "deep-learning"}}, "authors": {"173069025": {"item_id": "1817158629", "author_id": "173069025", "name": "Alex Honchar", "url": "https://alexrachnog.medium.com"}}, "image": {"item_id": "1817158629", "src": "https://miro.medium.com/max/792/0*WhJwmSlP08C5CM1B.png", "width": "396", "height": "496"}, "images": {"1": {"item_id": "1817158629", "image_id": "1", "src": "https://miro.medium.com/max/792/0*WhJwmSlP08C5CM1B.png", "width": "396", "height": "496", "credit": "", "caption": "Almost multimodal learning model"}, "2": {"item_id": "1817158629", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*hGWuBm7Ni-gqdQJRMQTOaQ.png", "width": "700", "height": "127", "credit": "", "caption": ""}, "3": {"item_id": "1817158629", "image_id": "3", "src": "https://miro.medium.com/max/1400/0*nMcDt4d8EYI1BpU_.png", "width": "700", "height": "269", "credit": "", "caption": "Illustration from http://ruder.io/"}, "4": {"item_id": "1817158629", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*QkvTxpd-CUkmatGdpCweJA.png", "width": "700", "height": "482", "credit": "", "caption": "Loss function for 2-layer RNN volatility forecast"}, "5": {"item_id": "1817158629", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*0gv8be-TjeHpQjEfunjMqw.png", "width": "700", "height": "386", "credit": "", "caption": "Prediction of volatility of 2-layer RNN"}, "6": {"item_id": "1817158629", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*aZWavb4by9_sIw7L-opxTA.png", "width": "700", "height": "482", "credit": "", "caption": "Multitask network loss"}, "7": {"item_id": "1817158629", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*42WGGNyz3KOjCsZRZh4o9Q.png", "width": "700", "height": "482", "credit": "", "caption": "Multitask network result"}, "8": {"item_id": "1817158629", "image_id": "8", "src": "https://miro.medium.com/max/1400/0*h-1v3vOHpzh29mpb.", "width": "700", "height": "525", "credit": "", "caption": "Another illustration showing what multimodal learning is about"}, "9": {"item_id": "1817158629", "image_id": "9", "src": "https://miro.medium.com/max/900/0*2sJN-4AZ6BEbafds.jpg", "width": "450", "height": "439", "credit": "", "caption": "How a network with several heads and legs really looks like"}, "10": {"item_id": "1817158629", "image_id": "10", "src": "https://miro.medium.com/max/1600/1*Lfjuo3p0lyXJVhzcZYrWzw.png", "width": "500", "height": "550", "credit": "", "caption": ""}, "11": {"item_id": "1817158629", "image_id": "11", "src": "https://miro.medium.com/max/1600/1*QGO2b7rtWl0XbRcsdSzkmw.png", "width": "500", "height": "550", "credit": "", "caption": "Results plot and loss plot for multimodal-multitask network"}, "12": {"item_id": "1817158629", "image_id": "12", "src": "https://miro.medium.com/max/510/1*2f7OqE2AJK1KSrhkmD9ZMw.png", "width": "255", "height": "170", "credit": "", "caption": ""}, "13": {"item_id": "1817158629", "image_id": "13", "src": "https://miro.medium.com/max/510/1*v-PpfkSWHbvlWWamSVHHWg.png", "width": "255", "height": "170", "credit": "", "caption": ""}, "14": {"item_id": "1817158629", "image_id": "14", "src": "https://miro.medium.com/max/510/1*Wt2auqISiEAOZxJ-I7brDQ.png", "width": "255", "height": "170", "credit": "", "caption": ""}}, "listen_duration_estimate": 861}, "1818967899": {"item_id": "1818967899", "resolved_id": "1818967899", "given_url": "http://www.mensxp.com/work-life/career-growth/38139-6-deep-learning-techniques-they-never-taught-you-in-school.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1501211525", "time_updated": "1638708525", "time_read": "1514398117", "time_favorited": "0", "sort_id": 23, "resolved_title": "6 Deep Learning Techniques They Never Taught You In School", "resolved_url": "https://www.mensxp.com/work-life/career-growth/38139-6-deep-learning-techniques-they-never-taught-you-in-school.html", "excerpt": "We all remember Maxim Gorky, Rabindranath Tagore, Ernest Hemingway, James Watt, Thomas Alva Edison, Leonardo da Vinci, and the Wright Brothers as some of the few people who left their mark in the world but do you also know that all of them were partially or wholly self-taught.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "886", "lang": "en", "time_to_read": 4, "amp_url": "https://www.mensxp.com/amp/work-life/career-growth/38139-6-deep-learning-techniques-they-never-taught-you-in-school.html", "top_image_url": "https://img.mensxp.com/media/content/2017/Jul/learning-techniques-they-never-taught-you-in-schools-800x420-1499930856.jpg", "tags": {"deep-learning": {"item_id": "1818967899", "tag": "deep-learning"}}, "authors": {"77765216": {"item_id": "1818967899", "author_id": "77765216", "name": "Piyush Sharma", "url": "https://www.mensxp.com/author/378-piyush-sharma.html"}}, "image": {"item_id": "1818967899", "src": "https://img.mensxp.com/media/content/2017/Jul/learning-techniques-they-never-taught-you-in-schools-740x400-4-1499930733.gif?w=635&h=356", "width": "635", "height": "356"}, "images": {"1": {"item_id": "1818967899", "image_id": "1", "src": "https://img.mensxp.com/media/content/2017/Jul/learning-techniques-they-never-taught-you-in-schools-740x400-4-1499930733.gif?w=635&h=356", "width": "635", "height": "356", "credit": "", "caption": ""}, "2": {"item_id": "1818967899", "image_id": "2", "src": "https://img.mensxp.com/media/content/2017/Jul/learning-techniques-they-never-taught-you-in-schools-740x400-6-1499930781.jpg?w=500&h=487", "width": "500", "height": "487", "credit": "", "caption": "¬©¬†Central Coffee"}}, "listen_duration_estimate": 343}, "1827545612": {"item_id": "1827545612", "resolved_id": "1827545612", "given_url": "https://blog.statsbot.co/data-structures-related-to-machine-learning-algorithms-5edf77c8bbf4", "given_title": "", "favorite": "0", "status": "1", "time_added": "1500913604", "time_updated": "1638708525", "time_read": "1528501626", "time_favorited": "0", "sort_id": 24, "resolved_title": "Data Structures Related to Machine Learning Algorithms", "resolved_url": "https://blog.statsbot.co/data-structures-related-to-machine-learning-algorithms-5edf77c8bbf4", "excerpt": "If you want to solve some real-world problems and design a cool product or algorithm, then having machine learning skills is not enough. You would need good working knowledge of data structures.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2368", "lang": "en", "time_to_read": 11, "top_image_url": "https://miro.medium.com/freeze/max/660/1*-LPWHNpRrRKcQAoqHRqmKQ.gif", "tags": {"deep-learning": {"item_id": "1827545612", "tag": "deep-learning"}}, "authors": {"112067592": {"item_id": "1827545612", "author_id": "112067592", "name": "Peter Mills", "url": "https://medium.com/@peteymills"}}, "image": {"item_id": "1827545612", "src": "https://miro.medium.com/max/1320/1*-LPWHNpRrRKcQAoqHRqmKQ.gif", "width": "660", "height": "495"}, "images": {"1": {"item_id": "1827545612", "image_id": "1", "src": "https://miro.medium.com/max/1320/1*-LPWHNpRrRKcQAoqHRqmKQ.gif", "width": "660", "height": "495", "credit": "", "caption": "Illustration source"}, "2": {"item_id": "1827545612", "image_id": "2", "src": "https://miro.medium.com/max/700/1*0L1wdZtDkvb96E2Lq8MRAA.png", "width": "350", "height": "202", "credit": "", "caption": ""}, "3": {"item_id": "1827545612", "image_id": "3", "src": "https://miro.medium.com/max/2800/0*I8aevS6mp9CC5axo.", "width": "1400", "height": "463", "credit": "", "caption": ""}, "4": {"item_id": "1827545612", "image_id": "4", "src": "https://miro.medium.com/max/2800/0*MNyPE09SLovaEXLy.", "width": "1400", "height": "363", "credit": "", "caption": ""}, "5": {"item_id": "1827545612", "image_id": "5", "src": "https://miro.medium.com/max/2800/0*jVACzdZjPQMP0ZYK.", "width": "1400", "height": "963", "credit": "", "caption": ""}, "6": {"item_id": "1827545612", "image_id": "6", "src": "https://miro.medium.com/max/2800/0*lxY5ElUH4_v63r6V.", "width": "1400", "height": "875", "credit": "", "caption": ""}, "7": {"item_id": "1827545612", "image_id": "7", "src": "https://miro.medium.com/max/2800/0*8t99vi34DxThN92s.", "width": "1400", "height": "719", "credit": "", "caption": ""}, "8": {"item_id": "1827545612", "image_id": "8", "src": "https://miro.medium.com/max/2536/0*dsfzSACqUcjmklKF.", "width": "1268", "height": "424", "credit": "", "caption": ""}}, "listen_duration_estimate": 917}, "1827655168": {"item_id": "1827655168", "resolved_id": "1827655168", "given_url": "https://blog.openai.com/openai-baselines-ppo/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1501336407", "time_updated": "1638708525", "time_read": "1514398115", "time_favorited": "0", "sort_id": 25, "resolved_title": "Proximal Policy Optimization", "resolved_url": "https://blog.openai.com/openai-baselines-ppo/", "excerpt": "PPO lets us train AI policies in challenging environments, like the Roboschool one shown above where an agent tries to reach a target (the pink sphere), learning to walk, run, turn, use its momentum to recover from minor hits, and how to stand up from the ground when it is knocked over.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "717", "lang": "en", "time_to_read": 3, "top_image_url": "https://blog.openai.com/content/images/2017/07/Screenshot-2017-07-20-08.45.19.png", "tags": {"deep-learning": {"item_id": "1827655168", "tag": "deep-learning"}}, "authors": {"72464972": {"item_id": "1827655168", "author_id": "72464972", "name": "John Schulman", "url": "https://blog.openai.com/tag/john-schulman/"}}, "image": {"item_id": "1827655168", "src": "https://blog.openai.com/content/images/2017/07/math_PPO_5-1.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1827655168", "image_id": "1", "src": "https://blog.openai.com/content/images/2017/07/math_PPO_5-1.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "1827655168", "video_id": "1", "src": "https://d4mucfpksywv.cloudfront.net/openai-baselines-ppo/knocked-over-stand-up.mp4", "width": "0", "height": "0", "type": "5", "vid": "", "length": "0"}, "2": {"item_id": "1827655168", "video_id": "2", "src": "https://d4mucfpksywv.cloudfront.net/openai-baselines-ppo/flagrun-no-bombardment-awesome-camera-work.mp4", "width": "0", "height": "0", "type": "5", "vid": "", "length": "0"}, "3": {"item_id": "1827655168", "video_id": "3", "src": "https://d4mucfpksywv.cloudfront.net/openai-baselines-ppo/flagrun-keyboard-control.mp4", "width": "0", "height": "0", "type": "5", "vid": "", "length": "0"}, "4": {"item_id": "1827655168", "video_id": "4", "src": "https://d4mucfpksywv.cloudfront.net/openai-baselines-ppo/atlas.mp4", "width": "0", "height": "0", "type": "5", "vid": "", "length": "0"}}, "listen_duration_estimate": 278}, "1867629806": {"item_id": "1867629806", "resolved_id": "1867629806", "given_url": "https://machinelearningmastery.com/gentle-introduction-generative-long-short-term-memory-networks/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1503969113", "time_updated": "1638708525", "time_read": "1514398065", "time_favorited": "0", "sort_id": 26, "resolved_title": "Gentle Introduction to Generative Long Short-Term Memory Networks", "resolved_url": "https://machinelearningmastery.com/gentle-introduction-generative-long-short-term-memory-networks/", "excerpt": "The Long Short-Term Memory recurrent neural network was developed for sequence prediction. In addition to sequence prediction problems. LSTMs can also be used as a generative model", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "922", "lang": "en", "time_to_read": 4, "top_image_url": "https://machinelearningmastery.com/wp-content/uploads/2017/07/Example-of-LSTMs-used-in-Automatic-Handwriting-Generation.png", "tags": {"deep-learning": {"item_id": "1867629806", "tag": "deep-learning"}}, "authors": {"26997241": {"item_id": "1867629806", "author_id": "26997241", "name": "Jason Brownlee", "url": "https://machinelearningmastery.com/author/jasonb/"}}, "image": {"item_id": "1867629806", "src": "https://machinelearningmastery.com/wp-content/uploads/2017/08/Gentle-Introduction-to-Generative-Long-Short-Term-Memory-Networks.jpg", "width": "640", "height": "480"}, "images": {"1": {"item_id": "1867629806", "image_id": "1", "src": "https://machinelearningmastery.com/wp-content/uploads/2017/08/Gentle-Introduction-to-Generative-Long-Short-Term-Memory-Networks.jpg", "width": "640", "height": "480", "credit": "", "caption": "Gentle Introduction to Generative Long Short-Term Memory Networks   \nPhoto by Fraser Mummery, some rights reserved."}, "2": {"item_id": "1867629806", "image_id": "2", "src": "https://machinelearningmastery.com/wp-content/uploads/2017/07/Vanilla-LSTM-Architecture-for-Generative-Models.png", "width": "113", "height": "295", "credit": "", "caption": "Vanilla LSTM Architecture for Generative Models"}, "3": {"item_id": "1867629806", "image_id": "3", "src": "https://machinelearningmastery.com/wp-content/uploads/2017/07/Cover-220.png", "width": "220", "height": "311", "credit": "", "caption": ""}}, "listen_duration_estimate": 357}, "1880817729": {"item_id": "1880817729", "resolved_id": "1880817729", "given_url": "https://machinelearningmastery.com/rnn-unrolling/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1505357650", "time_updated": "1638708525", "time_read": "1528501393", "time_favorited": "0", "sort_id": 27, "resolved_title": "A Gentle Introduction to RNN Unrolling", "resolved_url": "https://machinelearningmastery.com/rnn-unrolling/", "excerpt": "Recurrent neural networks are a type of neural network where the outputs from previous time steps are fed as input to the current time step. This creates a network graph or circuit diagram with cycles, which can make it difficult to understand how information moves through the network.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "992", "lang": "en", "time_to_read": 5, "top_image_url": "https://machinelearningmastery.com/wp-content/uploads/2017/08/Example-of-Unrolled-RNN-on-the-forward-pass.png", "tags": {"deep-learning": {"item_id": "1880817729", "tag": "deep-learning"}, "rnns": {"item_id": "1880817729", "tag": "rnns"}}, "authors": {"26997241": {"item_id": "1880817729", "author_id": "26997241", "name": "Jason Brownlee", "url": "https://machinelearningmastery.com/author/jasonb/"}}, "image": {"item_id": "1880817729", "src": "https://machinelearningmastery.com/wp-content/uploads/2017/08/Example-of-an-RNN-with-a-cycle.png", "width": "147", "height": "323"}, "images": {"1": {"item_id": "1880817729", "image_id": "1", "src": "https://machinelearningmastery.com/wp-content/uploads/2017/08/Example-of-an-RNN-with-a-cycle.png", "width": "147", "height": "323", "credit": "", "caption": "Example of an RNN with a cycle"}, "2": {"item_id": "1880817729", "image_id": "2", "src": "https://machinelearningmastery.com/wp-content/uploads/2017/08/Example-of-Unrolled-RNN-on-the-forward-pass.png", "width": "350", "height": "317", "credit": "", "caption": "Example of Unrolled RNN on the forward pass"}, "3": {"item_id": "1880817729", "image_id": "3", "src": "https://machinelearningmastery.com/wp-content/uploads/2017/08/Example-of-Unrolled-RNN-with-each-copy-of-the-network-as-a-layer.png", "width": "190", "height": "235", "credit": "", "caption": "Example of Unrolled RNN with each copy of the network as a layer"}, "4": {"item_id": "1880817729", "image_id": "4", "src": "https://machinelearningmastery.com/wp-content/uploads/2017/07/Cover-220.png", "width": "220", "height": "311", "credit": "", "caption": ""}}, "listen_duration_estimate": 384}, "1932612961": {"item_id": "1932612961", "resolved_id": "1932612961", "given_url": "https://lilianweng.github.io/lil-log/2017/06/21/an-overview-of-deep-learning.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1622248123", "time_updated": "1638708525", "time_read": "1622249128", "time_favorited": "0", "sort_id": 28, "resolved_title": "An Overview of Deep Learning for Curious People", "resolved_url": "https://lilianweng.github.io/lil-log/2017/06/21/an-overview-of-deep-learning.html", "excerpt": "Starting earlier this year, I grew a strong curiosity of deep learning and spent some time reading about this field. To document what I‚Äôve learned and to provide some interesting pointers to people with similar interests, I wrote this overview of deep learning models and their applications.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2451", "lang": "en", "time_to_read": 11, "top_image_url": "https://lilianweng.github.io/lil-log/assets/images/data_size_vs_model_performance.png", "tags": {"deep-learning": {"item_id": "1932612961", "tag": "deep-learning"}}, "authors": {"76470090": {"item_id": "1932612961", "author_id": "76470090", "name": "Lilian Weng", "url": ""}}, "image": {"item_id": "1932612961", "src": "https://lilianweng.github.io/lil-log/assets/images/ANN.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1932612961", "image_id": "1", "src": "https://lilianweng.github.io/lil-log/assets/images/ANN.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1932612961", "image_id": "2", "src": "https://lilianweng.github.io/lil-log/assets/images/data_size_vs_model_performance.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "1932612961", "image_id": "3", "src": "https://lilianweng.github.io/lil-log/assets/images/visual_cortex_system.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "1932612961", "image_id": "4", "src": "https://lilianweng.github.io/lil-log/assets/images/lenet.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "1932612961", "image_id": "5", "src": "https://lilianweng.github.io/lil-log/assets/images/RNN.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "1932612961", "image_id": "6", "src": "https://lilianweng.github.io/lil-log/assets/images/LSTM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "1932612961", "image_id": "7", "src": "https://lilianweng.github.io/lil-log/assets/images/rnn_shakespeare.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "1932612961", "image_id": "8", "src": "https://lilianweng.github.io/lil-log/assets/images/seq2seq_gmail.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "1932612961", "image_id": "9", "src": "https://lilianweng.github.io/lil-log/assets/images/autoencoder.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "1932612961", "image_id": "10", "src": "https://lilianweng.github.io/lil-log/assets/images/autoencoder_experiment.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "1932612961", "image_id": "11", "src": "https://lilianweng.github.io/lil-log/assets/images/alphago_paper.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "1932612961", "image_id": "12", "src": "https://lilianweng.github.io/lil-log/assets/images/alphago_model.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "1932612961", "image_id": "13", "src": "https://lilianweng.github.io/lil-log/assets/images/GAN.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "1932612961", "image_id": "14", "src": "https://lilianweng.github.io/lil-log/assets/images/deep_learning_toolkits.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 949}, "1940888604": {"item_id": "1940888604", "resolved_id": "1940888604", "given_url": "https://medium.com/applied-data-science/alphago-zero-explained-in-one-diagram-365f5abf67e0", "given_title": "", "favorite": "0", "status": "1", "time_added": "1600564934", "time_updated": "1638708525", "time_read": "1604362491", "time_favorited": "0", "sort_id": 29, "resolved_title": "AlphaGo Zero Explained In One Diagram", "resolved_url": "https://medium.com/applied-data-science/alphago-zero-explained-in-one-diagram-365f5abf67e0", "excerpt": "I‚Äôve just released a series on MuZero ‚Äî AlphaZero‚Äôs younger and cooler brother. Check it out üëá I‚Äôve just released a post on how you can build AlphaZero using Python and Keras. Check it out üëá", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "315", "lang": "en", "top_image_url": "https://miro.medium.com/max/1200/1*0pn33bETjYOimWjlqDLLNw.png", "tags": {"deep-learning": {"item_id": "1940888604", "tag": "deep-learning"}}, "authors": {"66774605": {"item_id": "1940888604", "author_id": "66774605", "name": "David Foster", "url": "https://medium.com/@dtfoster"}}, "image": {"item_id": "1940888604", "src": "https://miro.medium.com/max/4000/1*0pn33bETjYOimWjlqDLLNw.png", "width": "2000", "height": "1800"}, "images": {"1": {"item_id": "1940888604", "image_id": "1", "src": "https://miro.medium.com/max/4000/1*0pn33bETjYOimWjlqDLLNw.png", "width": "2000", "height": "1800", "credit": "high-res link below", "caption": "The AlphaGo Zero Cheat Sheet"}, "2": {"item_id": "1940888604", "image_id": "2", "src": "https://miro.medium.com/fit/c/56/56/1*QqMD1rth7ahcS7Gc415R9w.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "3": {"item_id": "1940888604", "image_id": "3", "src": "https://miro.medium.com/max/2388/1*eDhCRrmRljKt6DegLuwgUg.png", "width": "1194", "height": "332", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 122}, "2050986739": {"item_id": "2050986739", "resolved_id": "2050986739", "given_url": "http://parrt.cs.usfca.edu/doc/matrix-calculus/index.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1517363533", "time_updated": "1671277463", "time_read": "1528501335", "time_favorited": "0", "sort_id": 30, "resolved_title": "The Matrix Calculus You Need For Deep Learning", "resolved_url": "http://parrt.cs.usfca.edu/doc/matrix-calculus/index.html", "excerpt": "(We teach in University of San Francisco's MS in Data Science program and have other nefarious projects underway. You might know Terence as the creator of the ANTLR parser generator. For more material, see Jeremy's fast.", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "8224", "lang": "en", "time_to_read": 37, "tags": {"deep-learning": {"item_id": "2050986739", "tag": "deep-learning"}, "linear-algebra": {"item_id": "2050986739", "tag": "linear-algebra"}}, "image": {"item_id": "2050986739", "src": "http://parrt.cs.usfca.edu/doc/matrix-calculus/images/neuron.png", "width": "250", "height": "0"}, "images": {"1": {"item_id": "2050986739", "image_id": "1", "src": "http://parrt.cs.usfca.edu/doc/matrix-calculus/images/neuron.png", "width": "250", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 3183}, "2085972723": {"item_id": "2085972723", "resolved_id": "2085972723", "given_url": "https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807", "given_title": "", "favorite": "0", "status": "1", "time_added": "1528044500", "time_updated": "1638708525", "time_read": "1528127325", "time_favorited": "0", "sort_id": 31, "resolved_title": "A guide to receptive field arithmetic for Convolutional Neural Networks", "resolved_url": "https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807", "excerpt": "The receptive field is perhaps one of the most important concepts in Convolutional Neural Networks (CNNs) that deserves more attention from the literature. All of the state-of-the-art object recognition methods design their model architectures around this idea.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1210", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/1*mModSYik9cD9XJNemdTraw.png", "tags": {"deep-learning": {"item_id": "2085972723", "tag": "deep-learning"}}, "authors": {"76973619": {"item_id": "2085972723", "author_id": "76973619", "name": "Dang Ha The Hien", "url": "https://medium.com/@nikasa1889"}}, "image": {"item_id": "2085972723", "src": "https://miro.medium.com/fit/c/96/96/0*dQni5LNP41bPKJmX.", "width": "48", "height": "48"}, "images": {"1": {"item_id": "2085972723", "image_id": "1", "src": "https://miro.medium.com/fit/c/96/96/0*dQni5LNP41bPKJmX.", "width": "48", "height": "48", "credit": "", "caption": ""}, "2": {"item_id": "2085972723", "image_id": "2", "src": "https://miro.medium.com/max/1600/1*D47ER7IArwPv69k3O_1nqQ.png", "width": "330", "height": "230", "credit": "", "caption": ""}, "3": {"item_id": "2085972723", "image_id": "3", "src": "https://miro.medium.com/max/4146/1*mModSYik9cD9XJNemdTraw.png", "width": "2073", "height": "1059", "credit": "Top row", "caption": "Figure 1: Two ways to visualize CNN feature maps. In all cases, we uses the convolution C with kernel size k = 3x3, padding size p = 1x1, stride s = 2x2."}, "4": {"item_id": "2085972723", "image_id": "4", "src": "https://miro.medium.com/max/3854/1*KFX5mWoRMfMme2jngak8wg.png", "width": "1927", "height": "1036", "credit": "Left", "caption": "Figure 2: Another fixed-sized CNN feature map representation. The same convolution C is applied on a bigger input map with i = 7x7. I drew the receptive field bounding box around the center feature and removed the padding grid for a clearer view. The fixed-sized CNN feature map can be presented in 3D"}, "5": {"item_id": "2085972723", "image_id": "5", "src": "https://miro.medium.com/max/1600/1*gtEtvAQqaAubgvfQycgnyQ.png", "width": "372", "height": "171", "credit": "", "caption": ""}, "6": {"item_id": "2085972723", "image_id": "6", "src": "https://miro.medium.com/max/4388/1*5IjtUJiHN9oUfNXLWgkh4w.png", "width": "2194", "height": "1821", "credit": "", "caption": "Figure 3: Applying the receptive field calculation on the example given in Figure 1. The first row shows the notations and general equations, while the second and the last row shows the process of applying it to calculate the receptive field of the output layer given the input layer information."}, "7": {"item_id": "2085972723", "image_id": "7", "src": "https://miro.medium.com/max/1600/1*APXSo8yysuc446vuIyddMw.png", "width": "477", "height": "1023", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 468}, "2086961578": {"item_id": "2086961578", "resolved_id": "1935137906", "given_url": "https://t.co/icegCCI05B", "given_title": "", "favorite": "0", "status": "1", "time_added": "1519392487", "time_updated": "1638708525", "time_read": "1528501269", "time_favorited": "0", "sort_id": 32, "resolved_title": "Title: Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning", "resolved_url": "https://arxiv.org/abs/1710.07654", "excerpt": "Authors: Wei Ping, Kainan Peng, Andrew Gibiansky, Sercan O. Arik, Ajay Kannan, Sharan Narang, Jonathan Raiman, John Miller v1), last revised 22 Feb 2018 (this version, v3)) Abstract: We present Deep Voice 3, a fully-convolutional attention-based neural text-to-speech (TTS) system.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "130", "lang": "en", "tags": {"audio": {"item_id": "2086961578", "tag": "audio"}, "deep-learning": {"item_id": "2086961578", "tag": "deep-learning"}}, "authors": {"63858755": {"item_id": "2086961578", "author_id": "63858755", "name": "cs cs.AI cs.CL", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 50}, "2117559580": {"item_id": "2117559580", "resolved_id": "2117559580", "given_url": "https://medium.com/@Synced/baidu-apollo-releases-massive-self-driving-dataset-teams-up-with-berkeley-deepdrive-5e785ab4053b", "given_title": "", "favorite": "0", "status": "1", "time_added": "1521299691", "time_updated": "1638708525", "time_read": "1521336163", "time_favorited": "0", "sort_id": 33, "resolved_title": "Baidu Apollo Releases Massive Self-driving Dataset; Teams Up With Berkeley DeepDrive", "resolved_url": "https://medium.com/@Synced/baidu-apollo-releases-massive-self-driving-dataset-teams-up-with-berkeley-deepdrive-5e785ab4053b", "excerpt": "Baidu this Thursday announced the release of Apollo Scape, billed as the world‚Äôs largest open-source dataset for autonomous driving technology.  Apollo Scape was released under Baidu‚Äôs autonomous driving platform Apollo, which Baidu hopes will become ‚Äúthe Android of the auto industry.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "398", "lang": "en", "top_image_url": "https://cdn-images-1.medium.com/max/1200/1*WrmkbovvgQlRLPKV2lXUYg.png", "tags": {"datasets": {"item_id": "2117559580", "tag": "datasets"}, "deep-learning": {"item_id": "2117559580", "tag": "deep-learning"}}, "authors": {"43477116": {"item_id": "2117559580", "author_id": "43477116", "name": "Synced", "url": "https://medium.com/@Synced"}}, "image": {"item_id": "2117559580", "src": "https://cdn-images-1.medium.com/max/1600/1*WrmkbovvgQlRLPKV2lXUYg.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2117559580", "image_id": "1", "src": "https://cdn-images-1.medium.com/max/1600/1*WrmkbovvgQlRLPKV2lXUYg.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 154}, "2121453683": {"item_id": "2121453683", "resolved_id": "2121453683", "given_url": "https://github.com/agnusmaximus/Word2Bits", "given_title": "", "favorite": "0", "status": "1", "time_added": "1521546858", "time_updated": "1638708525", "time_read": "1528501274", "time_favorited": "0", "sort_id": 34, "resolved_title": "Word2Bits - Quantized Word Vectors", "resolved_url": "https://github.com/agnusmaximus/Word2Bits", "excerpt": "Word2Bits extends the Word2Vec algorithm to output high quality quantized word vectors that take 8x-16x less storage than regular word vectors. Read the details at https://arxiv.org/abs/1803.05651. Quantized word vectors are word vectors where each parameter is one of 2^bitlevel values.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "679", "lang": "en", "time_to_read": 3, "top_image_url": "https://opengraph.githubassets.com/079027bdad6cc62d253bff6742b0931818e9351ad5957aadd02fd75882233c6d/agnusmaximus/Word2Bits", "tags": {"deep-learning": {"item_id": "2121453683", "tag": "deep-learning"}, "nlp": {"item_id": "2121453683", "tag": "nlp"}, "text": {"item_id": "2121453683", "tag": "text"}}, "image": {"item_id": "2121453683", "src": "https://github.com/agnusmaximus/Word2Bits/blob/master/images/visualize_nearest_man.png?raw=true", "width": "400", "height": "300"}, "images": {"1": {"item_id": "2121453683", "image_id": "1", "src": "https://github.com/agnusmaximus/Word2Bits/blob/master/images/visualize_nearest_man.png?raw=true", "width": "400", "height": "300", "credit": "", "caption": ""}, "2": {"item_id": "2121453683", "image_id": "2", "src": "https://github.com/agnusmaximus/Word2Bits/blob/master/images/visualize_nearest_science.png?raw=true", "width": "400", "height": "300", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 263}, "2130262921": {"item_id": "2130262921", "resolved_id": "2130262921", "given_url": "https://deepmind.com/blog/learning-to-generate-images/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1522174137", "time_updated": "1638708525", "time_read": "1528501230", "time_favorited": "0", "sort_id": 35, "resolved_title": "Learning to write programs that generate images", "resolved_url": "https://deepmind.com/blog/learning-to-generate-images/", "excerpt": "Through a human‚Äôs eyes, the world is much more than just the images reflected in our corneas. For example, when we look at a building and admire the intricacies of its design, we can appreciate the craftsmanship it requires.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "729", "lang": "en", "time_to_read": 3, "top_image_url": "https://lh3.googleusercontent.com/FhVFQi0vU4ChnmSidjJFjAYJ1uguGjvM699QhzHnN2LB9_jvebxYGAFXqFKiLx9jMmHceHZXgioPr_hFbEHYilmcYq31hyUgsbTF", "tags": {"deep-learning": {"item_id": "2130262921", "tag": "deep-learning"}, "image-generation": {"item_id": "2130262921", "tag": "image-generation"}, "vision": {"item_id": "2130262921", "tag": "vision"}}, "image": {"item_id": "2130262921", "src": "https://lh3.googleusercontent.com/FhVFQi0vU4ChnmSidjJFjAYJ1uguGjvM699QhzHnN2LB9_jvebxYGAFXqFKiLx9jMmHceHZXgioPr_hFbEHYilmcYq31hyUgsbTF=w1440", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2130262921", "image_id": "1", "src": "https://lh3.googleusercontent.com/FhVFQi0vU4ChnmSidjJFjAYJ1uguGjvM699QhzHnN2LB9_jvebxYGAFXqFKiLx9jMmHceHZXgioPr_hFbEHYilmcYq31hyUgsbTF=w1440", "width": "0", "height": "0", "credit": "", "caption": "Blog post"}, "2": {"item_id": "2130262921", "image_id": "2", "src": "https://lh3.googleusercontent.com/892tLzmH606L6BsDLDdhUUnK6dEoUFHPaU9BVWMqTBkW_4cW_b4D364aeOY8UbVTPFmHAHAqEpCwwXkMCKKQwad-CC5Il-Xx6Tcx0A=w1440", "width": "0", "height": "0", "credit": "Shutterstock", "caption": ""}, "3": {"item_id": "2130262921", "image_id": "3", "src": "https://lh3.googleusercontent.com/YgQyDVc33nRcETixZAqQm3qUdoDR0-_6D48cktlXYuWvCJPdF21mquS8n-9vDkREVuU_ck4bwEdGz7MZvNM_Agw6zUyb7uIi8XQE=w1440", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2130262921", "image_id": "4", "src": "https://lh3.googleusercontent.com/U0qP8uUeL9fizBeHFbYEohk93OrbX_yE0jwt91xwO3P1CqvvRS4Pz-gZnX8Gn6sZjiJev1Te7MYid6H-jT3CpsRrGA-C8sdSWhuZpQ=w1440", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2130262921", "image_id": "5", "src": "https://lh3.googleusercontent.com/kG1U-2HgvhO0JW4u80vv6wGVsvs_Li4NwUIuIt7IkEa45lGmNrN7cp-GUnlszl1U80nbj_GnaAM2MitVqwBTP87sndRV-i3m1AN-qw=w1440", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 282}, "2167308623": {"item_id": "2167308623", "resolved_id": "2167308623", "given_url": "https://blog.riseml.com/comparing-google-tpuv2-against-nvidia-v100-on-resnet-50-c2bbb6a51e5e", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638241035", "time_updated": "1638708872", "time_read": "1638409356", "time_favorited": "0", "sort_id": 36, "resolved_title": "", "resolved_url": "https://blog.riseml.com/comparing-google-tpuv2-against-nvidia-v100-on-resnet-50-c2bbb6a51e5e", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"deep-learning": {"item_id": "2167308623", "tag": "deep-learning"}, "gpus": {"item_id": "2167308623", "tag": "gpus"}, "semiconductors": {"item_id": "2167308623", "tag": "semiconductors"}}, "listen_duration_estimate": 0}, "2173719204": {"item_id": "2173719204", "resolved_id": "2173719204", "given_url": "https://mlperf.org/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1585320856", "time_updated": "1638708525", "time_read": "1585580018", "time_favorited": "0", "sort_id": 37, "resolved_title": "MLPerf", "resolved_url": "https://mlperf.org/", "excerpt": "Dataset:¬†Russakovsky, O.; Deng, J.; Su, H.; Krause, J.; Satheesh, S.; Ma, S.; Huang, Z.; Karpathy, A.; Khosla, A.; Bernstein, M. S.; Berg, A. C. & Li, F.-F. (2014), 'ImageNet Large Scale Visual Recognition Challenge', CoRR abs/1409.0575.  Model:¬†He, K.; Zhang, X.; Ren, S. & Sun, J.", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "420", "lang": "en", "tags": {"benchmarks": {"item_id": "2173719204", "tag": "benchmarks"}, "deep-learning": {"item_id": "2173719204", "tag": "deep-learning"}}, "listen_duration_estimate": 163}, "2183015234": {"item_id": "2183015234", "resolved_id": "2183015234", "given_url": "https://www-nextplatform-com.cdn.ampproject.org/c/s/www.nextplatform.com/2018/05/10/tearing-apart-googles-tpu-3-0-ai-coprocessor/amp/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1526007164", "time_updated": "1638708525", "time_read": "1526093345", "time_favorited": "0", "sort_id": 38, "resolved_title": "Tearing Apart Google‚Äôs TPU 3.0 AI Coprocessor", "resolved_url": "https://www-nextplatform-com.cdn.ampproject.org/c/s/www.nextplatform.com/2018/05/10/tearing-apart-googles-tpu-3-0-ai-coprocessor/amp/", "excerpt": "Google did its best to impress this week at its annual IO conference. While Google rolled out a bunch of benchmarks that were run on its current Cloud TPU instances, based on TPUv2 chips, the company divulged a few skimpy details about its next generation TPU chip and its systems architecture.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2136", "lang": "en", "time_to_read": 10, "top_image_url": "https://www.nextplatform.com/wp-content/uploads/2017/05/tpu2.jpg", "tags": {"deep-learning": {"item_id": "2183015234", "tag": "deep-learning"}, "semiconductors": {"item_id": "2183015234", "tag": "semiconductors"}}, "image": {"item_id": "2183015234", "src": "https://www-nextplatform-com.cdn.ampproject.org/i/s/www.nextplatform.com/wp-content/uploads/2017/05/tpu2.jpg", "width": "678", "height": "351"}, "images": {"1": {"item_id": "2183015234", "image_id": "1", "src": "https://www-nextplatform-com.cdn.ampproject.org/i/s/www.nextplatform.com/wp-content/uploads/2017/05/tpu2.jpg", "width": "678", "height": "351", "credit": "", "caption": ""}, "2": {"item_id": "2183015234", "image_id": "2", "src": "https://www.nextplatform.com/wp-content/uploads/2018/05/image017.jpg", "width": "500", "height": "262", "credit": "left", "caption": "Toroidal mesh interconnect diagrams: 2D"}, "3": {"item_id": "2183015234", "image_id": "3", "src": "https://www.nextplatform.com/wp-content/uploads/2018/05/bfloat.jpg", "width": "1088", "height": "610", "credit": "", "caption": ""}, "4": {"item_id": "2183015234", "image_id": "4", "src": "https://www.nextplatform.com/wp-content/uploads/2018/05/image019.jpg", "width": "650", "height": "262", "credit": "left", "caption": "Block diagrams: TPUv2"}, "5": {"item_id": "2183015234", "image_id": "5", "src": "https://www.nextplatform.com/wp-content/uploads/2018/05/image021.png", "width": "550", "height": "268", "credit": "", "caption": ""}}, "listen_duration_estimate": 827}, "2233172833": {"item_id": "2233172833", "resolved_id": "2233172833", "given_url": "https://www.ayasdi.com/blog/artificial-intelligence/using-topological-data-analysis-understand-behavior-convolutional-neural-networks/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1530713436", "time_updated": "1638708525", "time_read": "1540698936", "time_favorited": "0", "sort_id": 39, "resolved_title": "Exposing Financial Crime", "resolved_url": "https://www.ayasdi.com/blog/artificial-intelligence/using-topological-data-analysis-understand-behavior-convolutional-neural-networks/", "excerpt": "Transform financial crime team productivity by driving out pointless investigations and finding true malignancies hidden from your existing rules and machine learning techniques.", "is_article": "0", "is_index": "1", "has_video": "1", "has_image": "1", "word_count": "714", "lang": "en", "time_to_read": 3, "top_image_url": "https://www.ayasdi.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-22-at-9.54.13-AM-1024x459.png", "tags": {"deep-learning": {"item_id": "2233172833", "tag": "deep-learning"}, "topology": {"item_id": "2233172833", "tag": "topology"}}, "image": {"item_id": "2233172833", "src": "https://www.ayasdi.com/wp-content/uploads/2021/01/graphic-real-results-from-ayasdi-aml.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2233172833", "image_id": "1", "src": "https://www.ayasdi.com/wp-content/uploads/2021/01/graphic-real-results-from-ayasdi-aml.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2233172833", "image_id": "2", "src": "https://www.ayasdi.com/wp-content/uploads/2021/01/graphic-real-results-from-ayasdi-alm.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2233172833", "image_id": "3", "src": "https://www.ayasdi.com/wp-content/uploads/2021/01/graphic-real-results-from-ayasdi-churn-prediction.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2233172833", "image_id": "4", "src": "https://www.ayasdi.com/wp-content/uploads/2020/06/1.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2233172833", "image_id": "5", "src": "https://www.ayasdi.com/wp-content/uploads/2020/06/2.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2233172833", "image_id": "6", "src": "https://www.ayasdi.com/wp-content/uploads/2020/06/3.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2233172833", "image_id": "7", "src": "https://www.ayasdi.com/wp-content/uploads/2020/06/4.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2233172833", "image_id": "8", "src": "https://www.ayasdi.com/wp-content/uploads/2020/06/5.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2233172833", "image_id": "9", "src": "https://www.ayasdi.com/wp-content/uploads/2020/06/6.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "2233172833", "video_id": "1", "src": "https://player.vimeo.com/video/536458357", "width": "878", "height": "504", "type": "4", "vid": "536458357", "length": "0"}}, "listen_duration_estimate": 276}, "2271167341": {"item_id": "2271167341", "resolved_id": "2271167341", "given_url": "https://medium.com/@srnghn/deep-learning-which-loss-and-activation-functions-should-i-use-ac02f1c56aa8", "given_title": "", "favorite": "0", "status": "1", "time_added": "1537635896", "time_updated": "1673901884", "time_read": "1567127412", "time_favorited": "0", "sort_id": 40, "resolved_title": "Deep Learning: Which Loss and Activation Functions should I¬†use?", "resolved_url": "https://medium.com/@srnghn/deep-learning-which-loss-and-activation-functions-should-i-use-ac02f1c56aa8", "excerpt": "The purpose of this post is to provide guidance on which combination of final-layer activation function and loss function should be used in a neural network depending on the business goal.  This post assumes that the reader has knowledge of activation functions.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "851", "lang": "en", "time_to_read": 4, "top_image_url": "https://cdn-images-1.medium.com/max/1200/1*85yYbdUgMBXpcKw1uHgqNg.png", "tags": {"activations": {"item_id": "2271167341", "tag": "activations"}, "deep-learning": {"item_id": "2271167341", "tag": "deep-learning"}, "loss-functions": {"item_id": "2271167341", "tag": "loss-functions"}}, "authors": {"88105425": {"item_id": "2271167341", "author_id": "88105425", "name": "srnghn", "url": "https://medium.com/@srnghn"}}, "image": {"item_id": "2271167341", "src": "https://cdn-images-1.medium.com/max/1600/1*85yYbdUgMBXpcKw1uHgqNg.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2271167341", "image_id": "1", "src": "https://cdn-images-1.medium.com/max/1600/1*85yYbdUgMBXpcKw1uHgqNg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2271167341", "image_id": "2", "src": "https://cdn-images-1.medium.com/max/1600/1*v83Le0f8ONiOSjywUTgemg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2271167341", "image_id": "3", "src": "https://cdn-images-1.medium.com/max/1600/1*sOsKmP59FYCLAIKkzxkAXA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2271167341", "image_id": "4", "src": "https://cdn-images-1.medium.com/max/1600/1*nZzH-sr4agNgICvRsoJ8hA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2271167341", "image_id": "5", "src": "https://cdn-images-1.medium.com/max/1600/1*B0CoTaPsLxUbYcakSdQ8iw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2271167341", "image_id": "6", "src": "https://cdn-images-1.medium.com/max/1600/1*GyTBLJqNPbk8s5W4U-uTNA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2271167341", "image_id": "7", "src": "https://cdn-images-1.medium.com/max/1600/1*NVpGlUvNjE8Tq3KrNBDqMg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2271167341", "image_id": "8", "src": "https://cdn-images-1.medium.com/max/1600/1*4SlLLYAdwMJ6OB90q51PlQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2271167341", "image_id": "9", "src": "https://cdn-images-1.medium.com/max/1600/1*ruKvFqd7i2dYIq8DoG5MQA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2271167341", "image_id": "10", "src": "https://cdn-images-1.medium.com/max/1600/1*gcIhjRGUPHbh0iQr81xVUA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2271167341", "image_id": "11", "src": "https://cdn-images-1.medium.com/max/1600/1*kineGv8kBE0MbOG67yRCcg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2271167341", "image_id": "12", "src": "https://cdn-images-1.medium.com/max/1600/1*C2sWPDEYdLV5wm7dNAmBOQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "2271167341", "image_id": "13", "src": "https://cdn-images-1.medium.com/max/1600/1*IhP8BdoUpAbssltq0VBafg.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 329}, "2361292242": {"item_id": "2361292242", "resolved_id": "2361292242", "given_url": "https://github.com/jsbroks/coco-annotator", "given_title": "", "favorite": "0", "status": "1", "time_added": "1619946297", "time_updated": "1638708525", "time_read": "1619975157", "time_favorited": "0", "sort_id": 41, "resolved_title": "Features", "resolved_url": "https://github.com/jsbroks/coco-annotator", "excerpt": "COCO Annotator is a web-based image annotation tool designed for versatility and efficiently label images to create training data for image localization and object detection.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "360", "lang": "en", "top_image_url": "https://opengraph.githubassets.com/7b8d5e5054445da9a446c0875b1aefecd6051bb7e6e58c5396f80f96a40ac8b5/jsbroks/coco-annotator", "tags": {"deep-learning": {"item_id": "2361292242", "tag": "deep-learning"}, "machine-vision": {"item_id": "2361292242", "tag": "machine-vision"}}, "image": {"item_id": "2361292242", "src": "https://camo.githubusercontent.com/69ce7a40db8bdee3e2a292950b5d84cd3f60cc8ac32bdce3316e40ca4130a71d/68747470733a2f2f692e696d6775722e636f6d2f414137496462512e706e67", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2361292242", "image_id": "1", "src": "https://camo.githubusercontent.com/69ce7a40db8bdee3e2a292950b5d84cd3f60cc8ac32bdce3316e40ca4130a71d/68747470733a2f2f692e696d6775722e636f6d2f414137496462512e706e67", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2361292242", "image_id": "2", "src": "https://camo.githubusercontent.com/27beb08a24fa9cdcaa34922076d06036b413c919d0e05950909f03a943e49de0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6a7362726f6b732f636f636f2d616e6e6f7461746f722e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2361292242", "image_id": "3", "src": "https://camo.githubusercontent.com/30926cd756b4cbb535f573c9eef48cbd9c99c03cd1fb45bcf0c17e5baa4a9234/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f6a7362726f6b732f636f636f2d616e6e6f7461746f722e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2361292242", "image_id": "4", "src": "https://camo.githubusercontent.com/2ff6a06f2f6e08b17783133ca7ebc23ce1f8ac4415eee8e835647b57048a8f0d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d6173686170652f6170697374617475732e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2361292242", "image_id": "5", "src": "https://camo.githubusercontent.com/467c76f1dba5284c5b3498c5c050546b6372d029f4e295e323f8e24abe474ae7/68747470733a2f2f696d672e736869656c64732e696f2f6c67746d2f67726164652f6a6176617363726970742f672f6a7362726f6b732f636f636f2d616e6e6f7461746f722e7376673f6c6162656c3d636f64652532307175616c697479", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2361292242", "image_id": "6", "src": "https://camo.githubusercontent.com/4a28be9123410257788f557f35fa0952906e882eee2289501b163226e6f82422/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f64656d6f2d6f6e6c696e652d677265656e2e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2361292242", "image_id": "7", "src": "https://camo.githubusercontent.com/2c664b37ca079051d4393da800f4c0d4676ed6eea0d069e3381a9b92a49c196d/68747470733a2f2f7472617669732d63692e6f72672f6a7362726f6b732f636f636f2d616e6e6f7461746f722e7376673f6272616e63683d6d6173746572", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2361292242", "image_id": "8", "src": "https://camo.githubusercontent.com/5bfb3d72aba7e089bc55547611e0eb7b0793b7954498bb443c10728842afdb46/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f70756c6c732f6a7362726f6b732f636f636f2d616e6e6f7461746f722e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2361292242", "image_id": "9", "src": "https://camo.githubusercontent.com/93247a2ccf90df2b8077980a18025a0c361c7351fe1cef6d69fa0b8c5bec20a5/68747470733a2f2f646973636f72642e636f6d2f6173736574732f65343932333539346536393461323135343261343839343731656366666135302e737667", "width": "120", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2361292242", "image_id": "10", "src": "https://camo.githubusercontent.com/7fe796df96bd5b9036ac5934f390c8d46f68bd1c8e6c5ab1811da5426da843ad/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f4f4d4a52636a6e4d4d6f6b2f6d617872657364656661756c742e6a7067", "width": "600", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2361292242", "image_id": "11", "src": "https://camo.githubusercontent.com/5f495baf75cafc48aff2d39594a44e5d47a983b33c7b275aa608410a12f898cf/68747470733a2f2f692e696d6775722e636f6d2f6d34526d6a43702e676966", "width": "600", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2361292242", "image_id": "12", "src": "https://camo.githubusercontent.com/ca317983c1ee436cd8c1157c5d2769c641372ee441af705dc0a32e3654fcbc9f/68747470733a2f2f63352e70617472656f6e2e636f6d2f65787465726e616c2f6c6f676f2f6265636f6d655f615f706174726f6e5f627574746f6e4032782e706e67", "width": "120", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "2361292242", "image_id": "13", "src": "https://camo.githubusercontent.com/fe25c35204cc9a688bfd1113a85f4c40a1b825fcf8ea461bbb2e7e487ad90452/68747470733a2f2f692e696d6775722e636f6d2f734f51317335462e706e67", "width": "250", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 139}, "2445194052": {"item_id": "2445194052", "resolved_id": "2445194052", "given_url": "https://github.com/d2l-ai/d2l-en", "given_title": "", "favorite": "0", "status": "1", "time_added": "1658077622", "time_updated": "1658187806", "time_read": "1658187806", "time_favorited": "0", "sort_id": 42, "resolved_title": "d2l-ai/d2l-en", "resolved_url": "https://github.com/d2l-ai/d2l-en", "excerpt": "This open-source book represents our attempt to make deep learning approachable, teaching you the concepts, the context, and the code. The entire book is drafted in Jupyter notebooks, seamlessly integrating exposition figures, math, and interactive examples with self-contained code.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "690", "lang": "en", "time_to_read": 3, "top_image_url": "https://opengraph.githubassets.com/4823764fe1cc24f795736adededbda2bd2312c4f3825c9de387573ecdba7e046/d2l-ai/d2l-en", "tags": {"books": {"item_id": "2445194052", "tag": "books"}, "deep-learning": {"item_id": "2445194052", "tag": "deep-learning"}}, "authors": {"171235375": {"item_id": "2445194052", "author_id": "171235375", "name": "astonzhang", "url": "https://github.com/d2l-ai/d2l-en/commits?author=astonzhang"}}, "image": {"item_id": "2445194052", "src": "https://raw.githubusercontent.com/d2l-ai/d2l-en/master/static/logo-with-text.png", "width": "350", "height": "0"}, "images": {"1": {"item_id": "2445194052", "image_id": "1", "src": "https://raw.githubusercontent.com/d2l-ai/d2l-en/master/static/logo-with-text.png", "width": "350", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2445194052", "image_id": "2", "src": "https://camo.githubusercontent.com/90e48a7541af1afa4bf545a3a4bf8cc02976b1379aeffc800e8e25d93cce78ea/687474703a2f2f63692e64326c2e61692f6a6f622f64326c2d656e2f6a6f622f6d61737465722f62616467652f69636f6e", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2445194052", "image_id": "3", "src": "https://github.com/d2l-ai/d2l-en/blob/master/static/frontpage/_images/eq.jpg", "width": "200", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2445194052", "image_id": "4", "src": "https://github.com/d2l-ai/d2l-en/blob/master/static/frontpage/_images/figure.jpg", "width": "200", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2445194052", "image_id": "5", "src": "https://github.com/d2l-ai/d2l-en/blob/master/static/frontpage/_images/code.jpg", "width": "200", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2445194052", "image_id": "6", "src": "https://github.com/d2l-ai/d2l-en/raw/master/static/frontpage/_images/notebook.gif", "width": "200", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2445194052", "image_id": "7", "src": "https://github.com/d2l-ai/d2l-en/blob/master/static/frontpage/_images/map.png", "width": "600", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 267}, "2482593775": {"item_id": "2482593775", "resolved_id": "2482593775", "given_url": "https://blog.acolyer.org/2019/02/08/graph-neural-networks-a-review-of-methods-and-applications/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1550105306", "time_updated": "1638708525", "time_read": "1552423429", "time_favorited": "0", "sort_id": 43, "resolved_title": "Graph neural networks: a review of methods and applications", "resolved_url": "https://blog.acolyer.org/2019/02/08/graph-neural-networks-a-review-of-methods-and-applications/", "excerpt": "It‚Äôs another graph neural networks survey paper today! Cue the obligatory bus joke.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "927", "lang": "en", "time_to_read": 4, "tags": {"deep-learning": {"item_id": "2482593775", "tag": "deep-learning"}, "graphs": {"item_id": "2482593775", "tag": "graphs"}}, "authors": {"136059453": {"item_id": "2482593775", "author_id": "136059453", "name": "Adrian Colyer", "url": "https://blog.acolyer.org/author/adriancolyer/"}}, "image": {"item_id": "2482593775", "src": "https://blog.acolyer.org/wp-content/uploads/2019/02/gnn-review-fig-2a.jpeg?w=480", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2482593775", "image_id": "1", "src": "https://blog.acolyer.org/wp-content/uploads/2019/02/gnn-review-fig-2a.jpeg?w=480", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2482593775", "image_id": "2", "src": "https://blog.acolyer.org/wp-content/uploads/2019/02/gnn-review-fig-2c.jpeg?w=640", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2482593775", "image_id": "3", "src": "https://blog.acolyer.org/wp-content/uploads/2019/02/gnn-review-table-2.jpeg?w=640", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2482593775", "image_id": "4", "src": "https://blog.acolyer.org/wp-content/uploads/2019/02/gnn-review-fig-2b.jpeg?w=480", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2482593775", "image_id": "5", "src": "https://blog.acolyer.org/wp-content/uploads/2019/02/gnn-review-table-3.jpeg?w=640", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"logo": "https://logo.clearbit.com/acolyer.org?size=800", "greyscale_logo": "https://logo.clearbit.com/acolyer.org?size=800&greyscale=true"}, "listen_duration_estimate": 359}, "2514631034": {"item_id": "2514631034", "resolved_id": "2514631034", "given_url": "https://www.reddit.com/r/dataisbeautiful/comments/aydqig/is_it_a_duck_or_a_rabbit_for_google_cloud_vision/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1552043956", "time_updated": "1638708525", "time_read": "1552240116", "time_favorited": "0", "sort_id": 44, "resolved_title": "Is it a Duck or a Rabbit? For Google Cloud Vision, it depends how the image is rotated. [OC]", "resolved_url": "https://www.reddit.com/r/dataisbeautiful/comments/aydqig/is_it_a_duck_or_a_rabbit_for_google_cloud_vision/", "excerpt": "27.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "11", "lang": "en", "amp_url": "https://amp.reddit.com/r/dataisbeautiful/comments/aydqig/is_it_a_duck_or_a_rabbit_for_google_cloud_vision/", "top_image_url": "https://external-preview.redd.it/YIWtpSvWAKzvbb-Z4Y4uFyPpgPUgDOY0I8liyEISqpY.png?format=pjpg&auto=webp&s=42046b62747a1f2841159cba7b6eb6e15e66ba7d", "tags": {"deep-learning": {"item_id": "2514631034", "tag": "deep-learning"}, "images": {"item_id": "2514631034", "tag": "images"}}, "authors": {"126697172": {"item_id": "2514631034", "author_id": "126697172", "name": "Viz Practitioner", "url": ""}}, "image": {"item_id": "2514631034", "src": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2514631034", "image_id": "1", "src": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Reddit", "logo": "https://logo.clearbit.com/reddit.com?size=800", "greyscale_logo": "https://logo.clearbit.com/reddit.com?size=800&greyscale=true"}, "listen_duration_estimate": 4}, "2520745010": {"item_id": "2520745010", "resolved_id": "2520745010", "given_url": "https://towardsdatascience.com/transformers-141e32e69591", "given_title": "", "favorite": "0", "status": "1", "time_added": "1578222370", "time_updated": "1638708525", "time_read": "1582143110", "time_favorited": "0", "sort_id": 45, "resolved_title": "Transformers", "resolved_url": "https://towardsdatascience.com/transformers-141e32e69591", "excerpt": "Transformers are a type of neural network architecture that have been gaining popularity. Transformers were recently used by OpenAI in their language , and also used recently by DeepMind for ‚Äî their program to defeat a top professional Starcraft player.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "2880", "lang": "en", "time_to_read": 13, "top_image_url": "https://miro.medium.com/v2/resize:fit:1127/1*Aqcm4iX3AQNWx9Zb-z7o1Q.png", "tags": {"deep-learning": {"item_id": "2520745010", "tag": "deep-learning"}}, "authors": {"45100425": {"item_id": "2520745010", "author_id": "45100425", "name": "Giuliano Giacaglia", "url": "https://medium.com/@giacaglia"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1115}, "2532354906": {"item_id": "2532354906", "resolved_id": "2532354906", "given_url": "https://monkeylearn.com/blog/aspect-based-sentiment-analysis/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1553293264", "time_updated": "1638708525", "time_read": "1567115034", "time_favorited": "0", "sort_id": 46, "resolved_title": "Guide to Aspect-Based Sentiment Analysis", "resolved_url": "https://monkeylearn.com/blog/aspect-based-sentiment-analysis/", "excerpt": "If you thought sentiment analysis was pretty neat, then prepare to be blown away by an even more advanced text analysis technique: aspect-based sentiment analysis.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2605", "lang": "en", "time_to_read": 12, "top_image_url": "https://monkeylearn.com/static/4688cdc9da9b930344235a2b7bddee91/Aspect-based-Sentiment-Analysis-Social-2.png", "tags": {"deep-learning": {"item_id": "2532354906", "tag": "deep-learning"}, "nlp": {"item_id": "2532354906", "tag": "nlp"}, "sentiment-analysis": {"item_id": "2532354906", "tag": "sentiment-analysis"}}, "image": {"item_id": "2532354906", "src": "https://d33wubrfki0l68.cloudfront.net/a0a5c4df5927c34145ea7d3e1cf300e6f9bd514a/e4e45/static/b8a7bff833a6c47d89d6d2d7e38a162d/28bdc/opinion_unit-ex.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2532354906", "image_id": "1", "src": "https://d33wubrfki0l68.cloudfront.net/a0a5c4df5927c34145ea7d3e1cf300e6f9bd514a/e4e45/static/b8a7bff833a6c47d89d6d2d7e38a162d/28bdc/opinion_unit-ex.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2532354906", "image_id": "2", "src": "https://d33wubrfki0l68.cloudfront.net/bc9678968ad4312215b45f083cf92df9546c980e/f10af/static/8169d032170501bd0382eb263a3b6d9c/ca7fb/choose-model.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2532354906", "image_id": "3", "src": "https://d33wubrfki0l68.cloudfront.net/9a451c0030099ce793b6dab7ed5879d8ee05583e/f9022/static/f36fed41a39dc01c3f5b692ca95e7d1d/04dd0/choose-classification.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2532354906", "image_id": "4", "src": "https://d33wubrfki0l68.cloudfront.net/6aaf42c9bd34b8136386db31f3ce9116b725ae50/1e642/static/acda0e37460c38fe24e23fee942766ca/ca7fb/import-data.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2532354906", "image_id": "5", "src": "https://d33wubrfki0l68.cloudfront.net/a9875a6a41cb28a078c9b03f7ee9dad23e11fc28/9c73b/static/fa738dc0169d5e94f9d46ebb0ae818ac/52c6a/e0738a3a91694929969f652f7115adfd.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2532354906", "image_id": "6", "src": "https://d33wubrfki0l68.cloudfront.net/2c9bf2f815f0d3f128c02bacbf13d50c6cab0f58/9860e/static/568bc978ee522ab5ccd3c5b8bf64fc8f/42cbc/d65c65dbd3e74fef89cbe6eb5b8918cb.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2532354906", "image_id": "7", "src": "https://d33wubrfki0l68.cloudfront.net/33fc3edc0d5b00288db9973a9a969d6dec8b2229/2e79a/static/d34feee0f45961e3fc6acc0a63627533/5f864/define-tags.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2532354906", "image_id": "8", "src": "https://d33wubrfki0l68.cloudfront.net/2c9bf2f815f0d3f128c02bacbf13d50c6cab0f58/ba80b/static/568bc978ee522ab5ccd3c5b8bf64fc8f/42cbc/61c7bb0b5dd24c4caaf420dd5b5dbeab.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2532354906", "image_id": "9", "src": "https://d33wubrfki0l68.cloudfront.net/def9be6edbd19b5d2e02c84c33fe13adce9132bf/0fa5c/static/5899e3902d303d7239fca4b930e0b77f/ac7a9/ml-studio.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1008}, "2539683507": {"item_id": "2539683507", "resolved_id": "2539683515", "given_url": "https://towardsdatascience.com/semantic-segmentation-popular-architectures-dff0a75f39d0?source=rss----7f60cf5620c9---4", "given_title": "", "favorite": "0", "status": "1", "time_added": "1576411286", "time_updated": "1638708525", "time_read": "1577120201", "time_favorited": "0", "sort_id": 47, "resolved_title": "Semantic Segmentation‚Ää‚Äî‚ÄäPopular Architectures", "resolved_url": "https://towardsdatascience.com/semantic-segmentation-popular-architectures-dff0a75f39d0", "excerpt": "Semantic segmentation is the task of classifying each and very pixel in an image into a class as shown in the image below. Here you can see that all persons are red, the road is purple, the vehicles are blue, street signs are yellow etc.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "874", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/freeze/max/500/1*wbaUQkYzRhvmd7IjKJjjCg.gif", "tags": {"deep-learning": {"item_id": "2539683507", "tag": "deep-learning"}}, "authors": {"142229466": {"item_id": "2539683507", "author_id": "142229466", "name": "Priya Dwivedi", "url": "https://priya-dwivedi.medium.com"}}, "image": {"item_id": "2539683507", "src": "https://miro.medium.com/max/1000/1*wbaUQkYzRhvmd7IjKJjjCg.gif", "width": "500", "height": "250"}, "images": {"1": {"item_id": "2539683507", "image_id": "1", "src": "https://miro.medium.com/max/1000/1*wbaUQkYzRhvmd7IjKJjjCg.gif", "width": "500", "height": "250", "credit": "", "caption": "Semantic Segmentation"}, "2": {"item_id": "2539683507", "image_id": "2", "src": "https://miro.medium.com/max/1096/1*OnuIJiFVpy7m83LSCUgi6w.png", "width": "548", "height": "423", "credit": "", "caption": "Different tasks in computer vision"}, "3": {"item_id": "2539683507", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*qH9KLGfNCBdx0GgihpHw2Q.png", "width": "700", "height": "357", "credit": "", "caption": "Fully Convolutional Network"}, "4": {"item_id": "2539683507", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*S6CBjXOyTkXOzVGiQaMZ8A.png", "width": "700", "height": "584", "credit": "", "caption": "U-net model"}, "5": {"item_id": "2539683507", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*iX5V_ANafXMvyaNeoStjRg.png", "width": "700", "height": "326", "credit": "", "caption": "Mask RCNN Model"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 338}, "2583575658": {"item_id": "2583575658", "resolved_id": "2583575658", "given_url": "https://www.pyimagesearch.com/2019/05/06/getting-started-with-the-nvidia-jetson-nano/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1583862570", "time_updated": "1638708872", "time_read": "1583928172", "time_favorited": "0", "sort_id": 48, "resolved_title": "Getting started with the NVIDIA Jetson Nano", "resolved_url": "https://www.pyimagesearch.com/2019/05/06/getting-started-with-the-nvidia-jetson-nano/", "excerpt": "I‚Äôll also provide my commentary along the way, including what tripped me up when I set up my Jetson Nano, ensuring you avoid the same mistakes I made. By the time you‚Äôre done with this tutorial, your NVIDIA Jetson Nano will be configured and ready for deep learning!", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "3177", "lang": "en", "time_to_read": 14, "top_image_url": "https://pyimagesearch.com/wp-content/uploads/2019/05/jetson_nano_geting_started_header.jpg", "tags": {"deep-learning": {"item_id": "2583575658", "tag": "deep-learning"}, "gpus": {"item_id": "2583575658", "tag": "gpus"}, "semiconductors": {"item_id": "2583575658", "tag": "semiconductors"}}, "authors": {"163714234": {"item_id": "2583575658", "author_id": "163714234", "name": "Adrian Rosebrock", "url": "https://pyimagesearch.com/author/adrian/"}}, "image": {"item_id": "2583575658", "src": "https://pyimagesearch.com/wp-content/uploads/2019/05/jetson_nano_geting_started_header.jpg", "width": "600", "height": "436"}, "images": {"1": {"item_id": "2583575658", "image_id": "1", "src": "https://pyimagesearch.com/wp-content/uploads/2019/05/jetson_nano_geting_started_header.jpg", "width": "600", "height": "436", "credit": "", "caption": ""}, "2": {"item_id": "2583575658", "image_id": "2", "src": "https://pyimagesearch.com/wp-content/uploads/2019/05/jetson_nano_getting_started_board.jpg", "width": "600", "height": "490", "credit": "image source", "caption": "Figure 1: In this blog post, we‚Äôll get started with the NVIDIA Jetson Nano, an AI edge device capable of 472 GFLOPS of computation. At around $100 USD, the device is packed with capability including a Maxwell architecture 128 CUDA core GPU covered up by the massive heatsink shown in the image."}, "3": {"item_id": "2583575658", "image_id": "3", "src": "https://pyimagesearch.com/wp-content/uploads/2019/05/jetson_nano_getting_started_sd_slot.jpg", "width": "450", "height": "600", "credit": "", "caption": "Figure 2: Where is the microSD card slot on the NVIDIA Jetson Nano? The microSD receptacle is hidden under the heatsink as shown in the image."}, "4": {"item_id": "2583575658", "image_id": "4", "src": "https://pyimagesearch.com/wp-content/uploads/2019/05/jetson_nano_getting_started_boot_up.jpg", "width": "600", "height": "450", "credit": "preconfigured with Jetpack", "caption": "Figure 3: To get started with the NVIDIA Jetson Nano AI device, just flash the .img"}}, "videos": {"1": {"item_id": "2583575658", "video_id": "1", "src": "https://www.youtube.com/embed/vnpUmI0xy0g?feature=oembed", "width": "630", "height": "354", "type": "1", "vid": "vnpUmI0xy0g", "length": "0"}, "2": {"item_id": "2583575658", "video_id": "2", "src": "https://www.youtube.com/embed/wHoZC2qQE3A?feature=oembed", "width": "630", "height": "354", "type": "1", "vid": "wHoZC2qQE3A", "length": "0"}}, "listen_duration_estimate": 1230}, "2625108754": {"item_id": "2625108754", "resolved_id": "2625108754", "given_url": "https://deepai.org/machine-learning-glossary-and-terms/error-backpropagation-learning-algorithm", "given_title": "", "favorite": "0", "status": "1", "time_added": "1612959137", "time_updated": "1638708525", "time_read": "1613045852", "time_favorited": "0", "sort_id": 49, "resolved_title": "Error Backpropagation Learning Algorithm", "resolved_url": "https://deepai.org/machine-learning-glossary-and-terms/error-backpropagation-learning-algorithm", "excerpt": "The error backpropagation learning algorithm is a supervised learning technique for neural networks that calculates the gradient of descent for weighting different variables.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "0", "lang": "", "top_image_url": "https://images.deepai.org/glossary-terms/da1846ea0aac46ff83e820ccf1f2578e/errorback.png", "tags": {"deep-learning": {"item_id": "2625108754", "tag": "deep-learning"}, "machine-learning": {"item_id": "2625108754", "tag": "machine-learning"}}, "image": {"item_id": "2625108754", "src": "https://deepai.org/static/images/glossary-icon.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2625108754", "image_id": "1", "src": "https://deepai.org/static/images/glossary-icon.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 0}, "2626623484": {"item_id": "2626623484", "resolved_id": "2626623484", "given_url": "https://deepai.org/machine-learning-glossary-and-terms/spatial-transformer-network", "given_title": "", "favorite": "0", "status": "1", "time_added": "1585433742", "time_updated": "1638708525", "time_read": "1585579970", "time_favorited": "0", "sort_id": 50, "resolved_title": "Spatial Transformer Network", "resolved_url": "https://deepai.org/machine-learning-glossary-and-terms/spatial-transformer-network", "excerpt": "A spatial transformer network is a specialized type of convoluted neural network, or CNN, used to improve the clarity of an object in an image.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "0", "lang": "", "top_image_url": "https://images.deepai.org/glossary-terms/65fd589a8bf0448daafb29131b5b5990/epoch_evolution.gif", "tags": {"deep-learning": {"item_id": "2626623484", "tag": "deep-learning"}}, "authors": {"152366328": {"item_id": "2626623484", "author_id": "152366328", "name": "Agisilaos Chartsias", "url": "https://deepai.org/profile/agisilaos-chartsias"}}, "image": {"item_id": "2626623484", "src": "https://deepai.org/static/images/glossary-icon.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2626623484", "image_id": "1", "src": "https://deepai.org/static/images/glossary-icon.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 0}, "2644506040": {"item_id": "2644506040", "resolved_id": "2644506040", "given_url": "https://www.quantamagazine.org/where-we-see-shapes-ai-sees-textures-20190701/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1595176572", "time_updated": "1638708525", "time_read": "1597023109", "time_favorited": "0", "sort_id": 51, "resolved_title": "Where We See Shapes, AI Sees Textures", "resolved_url": "https://www.quantamagazine.org/where-we-see-shapes-ai-sees-textures-20190701/", "excerpt": "To researchers‚Äô surprise, deep learning vision algorithms often fail at classifying images because they mostly take cues from textures, not shapes.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1921", "lang": "en", "time_to_read": 9, "top_image_url": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/07/AI_Textures_1200_social.jpg", "tags": {"deep-learning": {"item_id": "2644506040", "tag": "deep-learning"}, "vision": {"item_id": "2644506040", "tag": "vision"}}, "authors": {"71944334": {"item_id": "2644506040", "author_id": "71944334", "name": "Jordana Cepelewicz", "url": "https://www.quantamagazine.org/authors/jordana-cepelewicz/"}}, "image": {"item_id": "2644506040", "src": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/07/AI_Textures_2880x1220_LHPA.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2644506040", "image_id": "1", "src": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2019/07/AI_Textures_2880x1220_LHPA.jpg", "width": "0", "height": "0", "credit": "", "caption": "To make deep learning algorithms use shapes to identify objects, as humans do, researchers trained the systems with images that had been ‚Äúpainted‚Äù with irrelevant textures. The systems‚Äô performance improved, a result that may hold clues about the evolution of our own vision.\n\n\nCourtesy of Robert Geirhos"}}, "domain_metadata": {"name": "Quanta Magazine", "logo": "https://logo.clearbit.com/quantamagazine.org?size=800", "greyscale_logo": "https://logo.clearbit.com/quantamagazine.org?size=800&greyscale=true"}, "listen_duration_estimate": 744}, "2666169603": {"item_id": "2666169603", "resolved_id": "2629321017", "given_url": "https://mlwhiz.com/blog/2019/06/17/gans/?utm_campaign=an-end-to-end-introduction-to-gans&utm_medium=social_link&utm_source=missinglettr", "given_title": "", "favorite": "0", "status": "1", "time_added": "1570390973", "time_updated": "1691366676", "time_read": "1577120468", "time_favorited": "0", "sort_id": 52, "resolved_title": "An End to End Introduction to GANs using Keras", "resolved_url": "https://mlwhiz.com/blog/2019/06/17/gans/", "excerpt": "I bet most of us have seen a lot of AI-generated people faces in recent times, be it in papers or blogs. We have reached a stage where it is becoming increasingly difficult to distinguish between actual human faces and faces that are generated by Artificial Intelligence.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3476", "lang": "", "top_image_url": "https://mlwhiz.com/images/gans/faces.png", "tags": {"adversarial": {"item_id": "2666169603", "tag": "adversarial"}, "deep-learning": {"item_id": "2666169603", "tag": "deep-learning"}, "gans": {"item_id": "2666169603", "tag": "gans"}}, "authors": {"8623619": {"item_id": "2666169603", "author_id": "8623619", "name": "Rahul Agarwal", "url": ""}}, "image": {"item_id": "2666169603", "src": "https://mlwhiz.com/images/gans/duel.jpeg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2666169603", "image_id": "1", "src": "https://mlwhiz.com/images/gans/duel.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2666169603", "image_id": "2", "src": "https://mlwhiz.com/images/gans/noise.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2666169603", "image_id": "3", "src": "https://cdn-images-1.medium.com/max/3720/0*MQspqgJbMj2BnO22.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2666169603", "image_id": "4", "src": "https://mlwhiz.com/images/gans/genarch.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2666169603", "image_id": "5", "src": "https://mlwhiz.com/images/gans/disarch.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2666169603", "image_id": "6", "src": "https://cdn-images-1.medium.com/max/10368/0*OjIw7GFIkonGjfcc", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2666169603", "image_id": "7", "src": "https://cdn-images-1.medium.com/max/2000/0*Qn0oyAYAK67oawZl.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2666169603", "image_id": "8", "src": "https://cdn-images-1.medium.com/max/2000/0*gB21j4tJpkIzMxnc.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2666169603", "image_id": "9", "src": "https://cdn-images-1.medium.com/max/2270/0*rfKbSQzG8IRliFSM.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1346}, "2683716889": {"item_id": "2683716889", "resolved_id": "2683716889", "given_url": "https://github.com/Machine-Learning-Tokyo/Interactive_Tools", "given_title": "", "favorite": "0", "status": "1", "time_added": "1639316125", "time_updated": "1706833159", "time_read": "1639439146", "time_favorited": "0", "sort_id": 53, "resolved_title": "Interactive Tools for machine learning, deep learning, and math", "resolved_url": "https://github.com/Machine-Learning-Tokyo/Interactive_Tools", "excerpt": "\"BertViz is a tool for visualizing attention in the Transformer model, supporting most models from the transformers library (BERT, GPT-2, XLNet, RoBERTa, XLM, CTRL, MarianMT, etc.). It extends the Tensor2Tensor visualization tool by Llion Jones and the transformers library from HuggingFace.\"", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "806", "lang": "en", "time_to_read": 4, "top_image_url": "https://opengraph.githubassets.com/38705592f5de9cafb7341baffc6822c27d06a57bbb9fd7bfa6cdcbef6430bb84/Machine-Learning-Tokyo/Interactive_Tools", "tags": {"deep-learning": {"item_id": "2683716889", "tag": "deep-learning"}, "machine-learning": {"item_id": "2683716889", "tag": "machine-learning"}, "programming": {"item_id": "2683716889", "tag": "programming"}, "visualization": {"item_id": "2683716889", "tag": "visualization"}}, "authors": {"135431136": {"item_id": "2683716889", "author_id": "135431136", "name": "Simon Ward-Jones. A", "url": ""}}, "image": {"item_id": "2683716889", "src": "https://github.com/Machine-Learning-Tokyo/DL_study_group/raw/master/images/bert_vis.gif", "width": "600", "height": "0"}, "images": {"1": {"item_id": "2683716889", "image_id": "1", "src": "https://github.com/Machine-Learning-Tokyo/DL_study_group/raw/master/images/bert_vis.gif", "width": "600", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2683716889", "image_id": "2", "src": "https://github.com/Machine-Learning-Tokyo/DL_study_group/raw/master/images/cnn_explainer.gif", "width": "400", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2683716889", "image_id": "3", "src": "https://github.com/Machine-Learning-Tokyo/DL_study_group/raw/master/images/gans.png", "width": "1000", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2683716889", "image_id": "4", "src": "https://github.com/Machine-Learning-Tokyo/DL_study_group/raw/master/images/convnetplaygroud.png", "width": "1000", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2683716889", "image_id": "5", "src": "https://github.com/Machine-Learning-Tokyo/DL_study_group/raw/master/images/activation_atlas.png", "width": "1000", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2683716889", "image_id": "6", "src": "https://github.com/Machine-Learning-Tokyo/DL_study_group/raw/master/images/intro_ML.png", "width": "1000", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2683716889", "image_id": "7", "src": "https://github.com/Machine-Learning-Tokyo/DL_study_group/raw/master/images/dl_playground.png", "width": "1000", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2683716889", "image_id": "8", "src": "https://github.com/Machine-Learning-Tokyo/DL_study_group/raw/master/images/weight_init.png", "width": "1000", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2683716889", "image_id": "9", "src": "https://github.com/Machine-Learning-Tokyo/DL_study_group/raw/master/images/embedding-mnist.gif", "width": "1000", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2683716889", "image_id": "10", "src": "https://github.com/Machine-Learning-Tokyo/DL_study_group/raw/master/images/openai_microscope.png", "width": "1000", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2683716889", "image_id": "11", "src": "https://github.com/Machine-Learning-Tokyo/Interactive_Tools/raw/master/images/lit.gif", "width": "1000", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2683716889", "image_id": "12", "src": "https://user-images.githubusercontent.com/27798583/118443855-b3cc9b80-b6ec-11eb-9c28-849d7e755cd4.gif", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "2683716889", "image_id": "13", "src": "https://github.com/Machine-Learning-Tokyo/DL_study_group/raw/master/images/mdiv.png", "width": "1000", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "2683716889", "image_id": "14", "src": "https://github.com/Machine-Learning-Tokyo/DL_study_group/raw/master/images/sage.png", "width": "1000", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "2683716889", "image_id": "15", "src": "https://github.com/Machine-Learning-Tokyo/DL_study_group/raw/master/images/prob.png", "width": "1000", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "2683716889", "image_id": "16", "src": "https://github.com/Machine-Learning-Tokyo/DL_study_group/raw/master/images/bayes.png", "width": "1000", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "2683716889", "image_id": "17", "src": "https://github.com/Machine-Learning-Tokyo/DL_study_group/raw/master/images/seeing_theory.png", "width": "1000", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "2683716889", "image_id": "18", "src": "https://github.com/Machine-Learning-Tokyo/DL_study_group/raw/master/images/gaussian_vis.png", "width": "1000", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 312}, "2729547760": {"item_id": "2729547760", "resolved_id": "2729547760", "given_url": "https://towardsdatascience.com/how-to-make-your-own-deep-learning-accelerator-chip-1ff69b78ece4", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638241035", "time_updated": "1638561365", "time_read": "1638561364", "time_favorited": "0", "sort_id": 54, "resolved_title": "How to make your own deep learning accelerator chip!", "resolved_url": "https://towardsdatascience.com/how-to-make-your-own-deep-learning-accelerator-chip-1ff69b78ece4", "excerpt": "Currently, there are more than 100 companies all over the world building ASICs (Application Specific Integrated Circuit) or SOC‚Äôs (System on Chip) targeted towards deep learning applications. There is a long list of companies here.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2246", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/max/1200/1*Y6fXBUTKqlDcoGxOPpHz_A.png", "tags": {"deep-learning": {"item_id": "2729547760", "tag": "deep-learning"}, "semiconductors": {"item_id": "2729547760", "tag": "semiconductors"}}, "authors": {"152411918": {"item_id": "2729547760", "author_id": "152411918", "name": "Manu Suryavansh", "url": "https://msuryavanshi.medium.com"}}, "image": {"item_id": "2729547760", "src": "https://miro.medium.com/fit/c/56/56/1*E-JBVkwtscyIJC71f25qlw.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2729547760", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*E-JBVkwtscyIJC71f25qlw.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2729547760", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*Y6fXBUTKqlDcoGxOPpHz_A.png", "width": "700", "height": "407", "credit": "", "caption": "AI Landscape by Shan Tang : Source"}, "3": {"item_id": "2729547760", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*ww2YM3cy-I53xLe-S4X1KA.jpeg", "width": "700", "height": "528", "credit": "", "caption": "Habana Goya High-Level Architecture: Source"}, "4": {"item_id": "2729547760", "image_id": "4", "src": "https://miro.medium.com/max/1376/1*B0cbZ090-385BMCYB-eUuQ.png", "width": "688", "height": "502", "credit": "", "caption": "Eyeriss V2 top-level architecture: Source"}, "5": {"item_id": "2729547760", "image_id": "5", "src": "https://miro.medium.com/max/1082/1*e8b7fNeYtbbz0s3A1v1OCA.jpeg", "width": "541", "height": "448", "credit": "", "caption": "NVDLA : Source"}, "6": {"item_id": "2729547760", "image_id": "6", "src": "https://miro.medium.com/max/1262/1*7Njs6sntpB_xkKuMWFTEYw.jpeg", "width": "631", "height": "357", "credit": "", "caption": "Hailo ‚Äî Embedded Vision Summit ‚Äî Source"}, "7": {"item_id": "2729547760", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*RY0P6wAZWhmVcsfLLzIPeg.jpeg", "width": "700", "height": "586", "credit": "MPE", "caption": "Matrix Processing Engine"}, "8": {"item_id": "2729547760", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*l4AtQE8zmxX_f85DoddoDA.png", "width": "700", "height": "518", "credit": "", "caption": "Matrix Multiplier on TPU ‚Äî Source"}, "9": {"item_id": "2729547760", "image_id": "9", "src": "https://miro.medium.com/max/894/1*yAl85NvKgwKEqhU5MhexIQ.jpeg", "width": "447", "height": "397", "credit": "", "caption": "TPU Floor plan ‚Äî Source"}, "10": {"item_id": "2729547760", "image_id": "10", "src": "https://miro.medium.com/max/1356/1*vrwxsVxqF6iZi25_zZipZA.png", "width": "678", "height": "415", "credit": "", "caption": "Data movement Energy Vs Compute ‚Äî Source ‚Äî Efficient Processing of Deep Neural Networks: A Tutorial and Survey"}, "11": {"item_id": "2729547760", "image_id": "11", "src": "https://miro.medium.com/max/1092/1*ZV4poPG977D20rQN3DOHLA.jpeg", "width": "546", "height": "551", "credit": "", "caption": "AlexNet Layers and Parameter ‚Äî Source"}, "12": {"item_id": "2729547760", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*f57O6E5hQ61JmSJIemGZzg.png", "width": "700", "height": "549", "credit": "", "caption": "Accuracy Vs Model Size ‚Äî Source"}, "13": {"item_id": "2729547760", "image_id": "13", "src": "https://miro.medium.com/max/1096/1*Kv0Jr5UMvCzt_Ko90Hx8Og.png", "width": "548", "height": "614", "credit": "", "caption": "AMR Ethos NPU ‚Äî Source"}, "14": {"item_id": "2729547760", "image_id": "14", "src": "https://miro.medium.com/max/660/1*gcFCfBIy2i56ka9Ogb2CKg.png", "width": "330", "height": "316", "credit": "", "caption": "ASIC Flow from Wikipedia ‚Äî Source"}, "15": {"item_id": "2729547760", "image_id": "15", "src": "https://miro.medium.com/max/1000/0*bOQf7QcKkzL4b3Ql.PNG", "width": "500", "height": "208", "credit": "", "caption": "Cross-section of two transistors in a CMOS gate, in an N-well CMOS process"}, "16": {"item_id": "2729547760", "image_id": "16", "src": "https://miro.medium.com/max/1114/1*G-4gGeg5WpE05hNGsjJGtw.jpeg", "width": "557", "height": "454", "credit": "", "caption": "CMOS Wafer ‚Äî Source"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 869}, "2746847510": {"item_id": "2746847510", "resolved_id": "2746847510", "given_url": "https://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1622248108", "time_updated": "1638708525", "time_read": "1622249131", "time_favorited": "0", "sort_id": 55, "resolved_title": "Deep Learning: Our Miraculous Year 1990-1991", "resolved_url": "http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html", "excerpt": "The Deep Learning Artificial Neural Networks (NNs) of our team have revolutionized Machine Learning and Artificial Intelligence, and are now heavily used in academia and industry.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "13973", "lang": "en", "time_to_read": 64, "top_image_url": "https://people.idsia.ch/~juergen/miraculous-year754x395.png", "tags": {"deep-learning": {"item_id": "2746847510", "tag": "deep-learning"}}, "authors": {"132518843": {"item_id": "2746847510", "author_id": "132518843", "name": "PDF", "url": "ftp://ftp.idsia.ch/pub/juergen/bioadit2004.pdf"}}, "image": {"item_id": "2746847510", "src": "https://people.idsia.ch//~juergen/lstmagfa288.gif", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2746847510", "image_id": "1", "src": "https://people.idsia.ch//~juergen/lstmagfa288.gif", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2746847510", "image_id": "2", "src": "https://people.idsia.ch//~juergen/deepoverview754x288.gif", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2746847510", "image_id": "3", "src": "https://people.idsia.ch//~juergen/backprop754x466seppo.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2746847510", "image_id": "4", "src": "https://people.idsia.ch//~juergen/chunker754x288.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2746847510", "image_id": "5", "src": "https://people.idsia.ch//~juergen/cancer754x466.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2746847510", "image_id": "6", "src": "https://people.idsia.ch//~juergen/firstdeep754x466b.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2746847510", "image_id": "7", "src": "https://people.idsia.ch//~juergen/seppdeep754x466.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2746847510", "image_id": "8", "src": "https://people.idsia.ch//~juergen/lstm754x466.gif", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2746847510", "image_id": "9", "src": "https://people.idsia.ch//~juergen/lstmagfa754x288circles.gif", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2746847510", "image_id": "10", "src": "https://people.idsia.ch//~juergen/handwriting466x288.gif", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2746847510", "image_id": "11", "src": "https://people.idsia.ch//~juergen/highway-networks754x466.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2746847510", "image_id": "12", "src": "https://people.idsia.ch//~juergen/lstm-policy-gradient754x288.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "2746847510", "image_id": "13", "src": "https://people.idsia.ch//~juergen/robot-slap754x466.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "2746847510", "image_id": "14", "src": "https://people.idsia.ch//~juergen/pmfaust754x466.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "2746847510", "image_id": "15", "src": "https://people.idsia.ch//~juergen/deep-decade754x466.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "2746847510", "image_id": "16", "src": "https://people.idsia.ch//~juergen/curiosity754x288.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "2746847510", "image_id": "17", "src": "https://people.idsia.ch//~juergen/pm288x288.gif", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "2746847510", "image_id": "18", "src": "https://people.idsia.ch//~juergen/fastweights754x288.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "2746847510", "image_id": "19", "src": "https://people.idsia.ch//~juergen/metalearning754x288.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "2746847510", "image_id": "20", "src": "https://people.idsia.ch//~juergen/compressnet754x288.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "2746847510", "image_id": "21", "src": "https://people.idsia.ch//~juergen/first-learn-deep754x178.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "2746847510", "image_id": "22", "src": "https://people.idsia.ch//~juergen/deep1990attention754x288.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "23": {"item_id": "2746847510", "image_id": "23", "src": "https://people.idsia.ch//~juergen/hrl466x288.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "2746847510", "image_id": "24", "src": "https://people.idsia.ch//~juergen/controller-model754x288.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "2746847510", "image_id": "25", "src": "https://people.idsia.ch//~juergen/powerplay754x288.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "26": {"item_id": "2746847510", "image_id": "26", "src": "https://people.idsia.ch//~juergen/gphelix6rot754x288.gif", "width": "0", "height": "0", "credit": "", "caption": ""}, "27": {"item_id": "2746847510", "image_id": "27", "src": "https://people.idsia.ch//~juergen/neural-heat-exchanger466x288.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "28": {"item_id": "2746847510", "image_id": "28", "src": "https://people.idsia.ch//~juergen/neural-economy754x466.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "29": {"item_id": "2746847510", "image_id": "29", "src": "https://people.idsia.ch//~juergen/gmlogo288.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "30": {"item_id": "2746847510", "image_id": "30", "src": "https://people.idsia.ch//~juergen/deep2010nn754x288.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "31": {"item_id": "2746847510", "image_id": "31", "src": "https://people.idsia.ch//~juergen/dannet754x288.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "32": {"item_id": "2746847510", "image_id": "32", "src": "https://people.idsia.ch//~juergen/gpu-cnn-contests754x288.gif", "width": "0", "height": "0", "credit": "", "caption": ""}, "33": {"item_id": "2746847510", "image_id": "33", "src": "https://people.idsia.ch//~juergen/trafficsigns754x288.gif", "width": "0", "height": "0", "credit": "", "caption": ""}, "34": {"item_id": "2746847510", "image_id": "34", "src": "https://people.idsia.ch//~juergen/fki466.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "35": {"item_id": "2746847510", "image_id": "35", "src": "https://people.idsia.ch//~juergen/juergen-schmidhuber-vangogh754x754.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "36": {"item_id": "2746847510", "image_id": "36", "src": "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "37": {"item_id": "2746847510", "image_id": "37", "src": "https://people.idsia.ch//~juergen/lstmagfa754x466circles.gif", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 5409}, "2752523899": {"item_id": "2752523899", "resolved_id": "2752523899", "given_url": "https://heartbeat.fritz.ai/the-5-algorithms-for-efficient-deep-learning-inference-on-small-devices-bcc2d18aa806", "given_title": "", "favorite": "1", "status": "1", "time_added": "1571154391", "time_updated": "1638708525", "time_read": "1576355472", "time_favorited": "1571235696", "sort_id": 56, "resolved_title": "The 5 Algorithms for Efficient Deep Learning Inference on Small Devices", "resolved_url": "https://heartbeat.fritz.ai/the-5-algorithms-for-efficient-deep-learning-inference-on-small-devices-bcc2d18aa806", "excerpt": "With recent developments in deep learning, neural networks are getting larger and larger. For example, in the ImageNet recognition challenge, the winning model, from 2012 to 2015, increased in size by 16 times.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1845", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1080/1*XcBZJ1JuAi9qfnIy-IpEgg.jpeg", "tags": {"deep-learning": {"item_id": "2752523899", "tag": "deep-learning"}, "mobile": {"item_id": "2752523899", "tag": "mobile"}}, "authors": {"143561470": {"item_id": "2752523899", "author_id": "143561470", "name": "James Le", "url": "https://le-james94.medium.com"}}, "image": {"item_id": "2752523899", "src": "https://miro.medium.com/fit/c/96/96/1*kbXSc2-EEtk9ekKq36woIQ.jpeg", "width": "48", "height": "48"}, "images": {"1": {"item_id": "2752523899", "image_id": "1", "src": "https://miro.medium.com/fit/c/96/96/1*kbXSc2-EEtk9ekKq36woIQ.jpeg", "width": "48", "height": "48", "credit": "", "caption": ""}, "2": {"item_id": "2752523899", "image_id": "2", "src": "https://miro.medium.com/max/2160/1*XcBZJ1JuAi9qfnIy-IpEgg.jpeg", "width": "1080", "height": "720", "credit": "", "caption": ""}, "3": {"item_id": "2752523899", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*xThsIw0l96ydLh_YCqqgGw.png", "width": "700", "height": "452", "credit": "", "caption": ""}, "4": {"item_id": "2752523899", "image_id": "4", "src": "https://miro.medium.com/max/2000/1*GUPk6z6ANtJfPhxKVbb-8g.png", "width": "1000", "height": "287", "credit": "", "caption": "Image Source"}, "5": {"item_id": "2752523899", "image_id": "5", "src": "https://miro.medium.com/max/2000/1*P9I4rroXRNZz1MppWrJf2A.png", "width": "1000", "height": "366", "credit": "", "caption": ""}, "6": {"item_id": "2752523899", "image_id": "6", "src": "https://miro.medium.com/max/1000/1*Y5tl-VePuokiotEofCMUpw.png", "width": "500", "height": "589", "credit": "", "caption": ""}, "7": {"item_id": "2752523899", "image_id": "7", "src": "https://miro.medium.com/max/1000/1*xr2HNvyXa-rqwRAaP52GJw.png", "width": "500", "height": "352", "credit": "", "caption": ""}, "8": {"item_id": "2752523899", "image_id": "8", "src": "https://miro.medium.com/max/2000/1*CP7pdm65I9UQ56M1lmEGtg.png", "width": "1000", "height": "226", "credit": "", "caption": ""}}, "listen_duration_estimate": 714}, "2754888520": {"item_id": "2754888520", "resolved_id": "2754888520", "given_url": "https://www.technologyreview.com/f/614551/ai-computer-vision-algorithms-on-your-phone-mit-ibm/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1574511240", "time_updated": "1638708525", "time_read": "1574616600", "time_favorited": "0", "sort_id": 57, "resolved_title": "Powerful computer vision algorithms are now small enough to run on your phone", "resolved_url": "https://www.technologyreview.com/f/614551/ai-computer-vision-algorithms-on-your-phone-mit-ibm/", "excerpt": "Researchers have shrunk state-of-the-art computer vision models to run on low-power devices. Growing pains: Visual recognition is deep learning‚Äôs strongest skill. Computer vision algorithms are analyzing medical images, enabling self-driving cars, and powering face recognition.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "359", "lang": "en", "top_image_url": "https://cdn.technologyreview.com/i/images/tinymachinevision-01-01.png?sw=1200&cx=0&cy=0&cw=3200&ch=1800", "tags": {"deep-learning": {"item_id": "2754888520", "tag": "deep-learning"}, "mobile": {"item_id": "2754888520", "tag": "mobile"}, "vision": {"item_id": "2754888520", "tag": "vision"}}, "authors": {"96772099": {"item_id": "2754888520", "author_id": "96772099", "name": "Karen Hao", "url": "https://www.technologyreview.com/profile/karen-hao/"}}, "domain_metadata": {"name": "MIT Technology Review", "logo": "https://logo.clearbit.com/technologyreview.com?size=800", "greyscale_logo": "https://logo.clearbit.com/technologyreview.com?size=800&greyscale=true"}, "listen_duration_estimate": 139}, "2754998011": {"item_id": "2754998011", "resolved_id": "2754888520", "given_url": "https://www.technologyreview.com/f/614551/ai-computer-vision-algorithms-on-your-phone-mit-ibm/?utm_medium=tr_social&utm_campaign=site_visitor.unpaid.engagement&utm_source=LinkedIn#Echobox=1586193065", "given_title": "", "favorite": "0", "status": "1", "time_added": "1586216092", "time_updated": "1638708525", "time_read": "1589542127", "time_favorited": "0", "sort_id": 58, "resolved_title": "Powerful computer vision algorithms are now small enough to run on your phone", "resolved_url": "https://www.technologyreview.com/f/614551/ai-computer-vision-algorithms-on-your-phone-mit-ibm/", "excerpt": "Researchers have shrunk state-of-the-art computer vision models to run on low-power devices. Growing pains: Visual recognition is deep learning‚Äôs strongest skill. Computer vision algorithms are analyzing medical images, enabling self-driving cars, and powering face recognition.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "359", "lang": "en", "top_image_url": "https://cdn.technologyreview.com/i/images/tinymachinevision-01-01.png?sw=1200&cx=0&cy=0&cw=3200&ch=1800", "tags": {"deep-learning": {"item_id": "2754998011", "tag": "deep-learning"}, "semiconductors": {"item_id": "2754998011", "tag": "semiconductors"}, "vision": {"item_id": "2754998011", "tag": "vision"}}, "authors": {"96772099": {"item_id": "2754998011", "author_id": "96772099", "name": "Karen Hao", "url": "https://www.technologyreview.com/profile/karen-hao/"}}, "domain_metadata": {"name": "MIT Technology Review", "logo": "https://logo.clearbit.com/technologyreview.com?size=800", "greyscale_logo": "https://logo.clearbit.com/technologyreview.com?size=800&greyscale=true"}, "listen_duration_estimate": 139}, "2771046155": {"item_id": "2771046155", "resolved_id": "2771046155", "given_url": "https://www.technologyreview.com/s/614597/a-neural-net-solves-the-three-body-problem-100-million-times-faster/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1578659463", "time_updated": "1638708525", "time_read": "1582142817", "time_favorited": "0", "sort_id": 59, "resolved_title": "A neural net solves the three-body problem 100 million times faster", "resolved_url": "https://www.technologyreview.com/s/614597/a-neural-net-solves-the-three-body-problem-100-million-times-faster/", "excerpt": "In the 18th century, the great scientific challenge of the age was to find a way for mariners to determine their position at sea. One of the most successful solutions was to measure the position of the moon in the sky relative to the fixed background of stars.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "705", "lang": "en", "time_to_read": 3, "amp_url": "https://www.technologyreview.com/s/614597/a-neural-net-solves-the-three-body-problem-100-million-times-faster/amp/", "top_image_url": "https://cdn.technologyreview.com/i/images/threebodies.jpg?cx=0&cy=3&cw=3000&ch=1686&sw1200", "tags": {"deep-learning": {"item_id": "2771046155", "tag": "deep-learning"}}, "authors": {"28381895": {"item_id": "2771046155", "author_id": "28381895", "name": "Emerging Technology From the arXiv", "url": ""}}, "image": {"item_id": "2771046155", "src": "https://cdn.technologyreview.com/i/images/threebodies.jpg?sw=1272&cx=0&cy=0&cw=3000&ch=1687", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2771046155", "image_id": "1", "src": "https://cdn.technologyreview.com/i/images/threebodies.jpg?sw=1272&cx=0&cy=0&cw=3000&ch=1687", "width": "0", "height": "0", "credit": "Getty Images/Ms. Tech", "caption": "Getty Images/Ms. Tech"}, "2": {"item_id": "2771046155", "image_id": "2", "src": "https://cdn.technologyreview.com/i/images/three-body-sims.png?sw=616&cx=0&cy=0&cw=1421&ch=1117", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2771046155", "image_id": "3", "src": "https://cdn.technologyreview.com/i/images/threebodies.jpg?sw=959&cx=0&cy=0&cw=3000&ch=1687", "width": "0", "height": "0", "credit": "Getty Images/Ms. Tech", "caption": "Getty Images/Ms. Tech"}}, "domain_metadata": {"name": "MIT Technology Review", "logo": "https://logo.clearbit.com/technologyreview.com?size=800", "greyscale_logo": "https://logo.clearbit.com/technologyreview.com?size=800&greyscale=true"}, "listen_duration_estimate": 273}, "2782966156": {"item_id": "2782966156", "resolved_id": "2782966208", "given_url": "https://www.kdnuggets.com/2019/11/research-guide-advanced-loss-functions-machine-learning-models.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1573071363", "time_updated": "1638708525", "time_read": "1573087501", "time_favorited": "0", "sort_id": 60, "resolved_title": "Research Guide: Advanced Loss Functions for Machine Learning Models", "resolved_url": "https://www.kdnuggets.com/research-guide-advanced-loss-functions-for-machine-learning-models.html/", "excerpt": "This guide explores research centered on a variety of advanced loss functions for machine learning models. In addition to good training data and the right model architecture, loss functions are one of the most important parts of training an accurate machine learning model.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1419", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1063/1*NsAYvcskssR5Gw9Jb9mTmA.png", "tags": {"deep-learning": {"item_id": "2782966156", "tag": "deep-learning"}, "machine-learning": {"item_id": "2782966156", "tag": "machine-learning"}}, "authors": {"101570162": {"item_id": "2782966156", "author_id": "101570162", "name": "Derrick Mwiti", "url": "https://www.kdnuggets.com/author/derrick-mwiti"}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 549}, "2788284304": {"item_id": "2788284304", "resolved_id": "2788284304", "given_url": "https://towardsdatascience.com/workflow-tools-for-model-pipelines-45030a93e9e0", "given_title": "", "favorite": "0", "status": "1", "time_added": "1573602296", "time_updated": "1706833159", "time_read": "1576355626", "time_favorited": "0", "sort_id": 61, "resolved_title": "Workflow Tools for Model Pipelines", "resolved_url": "https://towardsdatascience.com/workflow-tools-for-model-pipelines-45030a93e9e0", "excerpt": "Airflow is becoming the industry standard for authoring data engineering and model pipeline workflows. This chapter of my book explores the process of taking a simple pipeline that runs on a single EC2 instance to a fully-managed Kubernetes ecosystem responsible for scheduling tasks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3620", "lang": "en", "time_to_read": 16, "top_image_url": "https://miro.medium.com/max/1200/1*BMf9Y9wV7U9sXVEo_9yigg.png", "tags": {"deep-learning": {"item_id": "2788284304", "tag": "deep-learning"}, "machine-learning": {"item_id": "2788284304", "tag": "machine-learning"}, "programming": {"item_id": "2788284304", "tag": "programming"}}, "authors": {"144674312": {"item_id": "2788284304", "author_id": "144674312", "name": "Ben Weber", "url": "https://bgweber.medium.com"}}, "image": {"item_id": "2788284304", "src": "https://miro.medium.com/max/1400/1*BMf9Y9wV7U9sXVEo_9yigg.png", "width": "700", "height": "381"}, "images": {"1": {"item_id": "2788284304", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*BMf9Y9wV7U9sXVEo_9yigg.png", "width": "700", "height": "381", "credit": "", "caption": "Source: https://www.flickr.com/photos/rauckhaus/8638556209"}, "2": {"item_id": "2788284304", "image_id": "2", "src": "https://miro.medium.com/fit/c/56/56/0*k5U0JTbKUqtoJBMU.", "width": "28", "height": "28", "credit": "", "caption": ""}, "3": {"item_id": "2788284304", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*ydFRQ_f2OauuinRCvVXgEw.png", "width": "700", "height": "366", "credit": "", "caption": "FIGURE 5.1: Querying the uploaded predictions in BigQuery."}, "4": {"item_id": "2788284304", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*iWqdUjkY_LOdWsxd3nxWpA.png", "width": "700", "height": "250", "credit": "", "caption": "FIGURE 5.3: The Airflow web app running on an EC2 instance."}, "5": {"item_id": "2788284304", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*UR5cfIZTo7IK2iXiDBnETQ.png", "width": "700", "height": "198", "credit": "", "caption": "FIGURE 5.4: The sklearn DAG scheduled on Airflow."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1401}, "2818360536": {"item_id": "2818360536", "resolved_id": "2885287535", "given_url": "https://slideslive.com/38921492/efficient-processing-of-deep-neural-network-from-algorithms-to-hardware-architectures", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638241035", "time_updated": "1638708525", "time_read": "1638561300", "time_favorited": "0", "sort_id": 62, "resolved_title": "Efficient Processing of Deep Neural Network: from Algorithms to Hardware Architectures", "resolved_url": "https://slideslive.com/38922815", "excerpt": "This tutorial describes methods to enable efficient processing for deep neural networks (DNNs), which are used in many AI applications including computer vision, speech recognition, robotics, etc.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "184", "lang": "en", "top_image_url": "https://d2ygwrecguqg66.cloudfront.net/data/presentations/38922815/slideslive_vivienne-sze_efficient-processing-of-deep-neural-network-from-algorithms-to-hardware-architectures__medium.jpg?1618919424", "tags": {"deep-learning": {"item_id": "2818360536", "tag": "deep-learning"}, "semiconductors": {"item_id": "2818360536", "tag": "semiconductors"}}, "authors": {"114197379": {"item_id": "2818360536", "author_id": "114197379", "name": "Vivienne Sze", "url": "https://slideslive.com/s/vivienne-sze-18791"}}, "listen_duration_estimate": 71}, "2826804311": {"item_id": "2826804311", "resolved_id": "2826804329", "given_url": "https://www.kdnuggets.com/2019/12/automatic-text-summarization-nutshell.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1576760939", "time_updated": "1638708525", "time_read": "1577120201", "time_favorited": "0", "sort_id": 63, "resolved_title": "Automatic Text Summarization in a Nutshell", "resolved_url": "https://www.kdnuggets.com/automatic-text-summarization-in-a-nutshell.html/", "excerpt": "Kevin Gray: What is¬†automatic text summarization? Anna Farzindar: Text summarization is one of the complex tasks in Natural Language Processing (NLP). It should produce a shorter version of a text and preserve the meaning and key ideas of the original text.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1293", "lang": "en", "time_to_read": 6, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/anna-farzindar.jpg", "tags": {"deep-learning": {"item_id": "2826804311", "tag": "deep-learning"}, "text": {"item_id": "2826804311", "tag": "text"}}, "authors": {"77389387": {"item_id": "2826804311", "author_id": "77389387", "name": "Kevin Gray", "url": "https://www.kdnuggets.com/author/kevin-gray"}}, "image": {"item_id": "2826804311", "src": "https://www.kdnuggets.com/wp-content/uploads/anna-farzindar.jpg", "width": "80", "height": "0"}, "images": {"1": {"item_id": "2826804311", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/uploads/anna-farzindar.jpg", "width": "80", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2826804311", "image_id": "2", "src": "https://www.kdnuggets.com/wp-content/uploads/text-summarization.jpg", "width": "100", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 501}, "2838901686": {"item_id": "2838901686", "resolved_id": "2838288110", "given_url": "https://www.reddit.com/r/learnmachinelearning/comments/ehv5r6/dive_really_deep_into_yolo_v3_a_beginners_guide/?utm_source=share&utm_medium=ios_app&utm_name=iossmf", "given_title": "", "favorite": "0", "status": "1", "time_added": "1577813552", "time_updated": "1638708525", "time_read": "1582143051", "time_favorited": "0", "sort_id": 64, "resolved_title": "Dive Really Deep into YOLO v3: A Beginner‚Äôs Guide", "resolved_url": "https://www.reddit.com/r/learnmachinelearning/comments/ehv5r6/dive_really_deep_into_yolo_v3_a_beginners_guide/", "excerpt": "I wrote this article recently when I implement YOLO v3 in TF2. My english is not good, though. And I just start to work on object detection this year.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "122", "lang": "en", "amp_url": "https://amp.reddit.com/r/learnmachinelearning/comments/ehv5r6/dive_really_deep_into_yolo_v3_a_beginners_guide/", "top_image_url": "https://external-preview.redd.it/5s3C0SFUxDRlhO68uPtlE26U-uq7RcsLkMEo-KDrDG0.jpg?auto=webp&s=90cb8583e26e487743385c1818e009be1c38bced", "tags": {"deep-learning": {"item_id": "2838901686", "tag": "deep-learning"}, "vision": {"item_id": "2838901686", "tag": "vision"}}, "domain_metadata": {"name": "Reddit", "logo": "https://logo.clearbit.com/reddit.com?size=800", "greyscale_logo": "https://logo.clearbit.com/reddit.com?size=800&greyscale=true"}, "listen_duration_estimate": 47}, "2854958340": {"item_id": "2854958340", "resolved_id": "2854958340", "given_url": "https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1579521706", "time_updated": "1638708525", "time_read": "1582142974", "time_favorited": "0", "sort_id": 65, "resolved_title": "Reformer: The Efficient Transformer", "resolved_url": "https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html", "excerpt": "Understanding sequential data ‚Äî such as language, music or videos ‚Äî is a challenging task, especially when there is dependence on extensive surrounding context.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1149", "lang": "en", "time_to_read": 5, "top_image_url": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png", "tags": {"deep-learning": {"item_id": "2854958340", "tag": "deep-learning"}}, "authors": {"125412132": {"item_id": "2854958340", "author_id": "125412132", "name": "Nikita Kitaev", "url": ""}}, "image": {"item_id": "2854958340", "src": "https://1.bp.blogspot.com/-27SvVUMvl3I/Xh-9qWcjyDI/AAAAAAAAFNQ/tlaQwWkJUSAxacT47COYlb7s_8eaLerdACLcBGAsYHQ/s1600/image3.png", "width": "640", "height": "409"}, "images": {"1": {"item_id": "2854958340", "image_id": "1", "src": "https://1.bp.blogspot.com/-27SvVUMvl3I/Xh-9qWcjyDI/AAAAAAAAFNQ/tlaQwWkJUSAxacT47COYlb7s_8eaLerdACLcBGAsYHQ/s1600/image3.png", "width": "640", "height": "409", "credit": "or pixels, in the case of images", "caption": "Locality-sensitive-hashing: Reformer takes in an input sequence of keys, where each key is a vector representing individual words"}, "2": {"item_id": "2854958340", "image_id": "2", "src": "https://1.bp.blogspot.com/-l3GO6OKfPPQ/Xh-9qQA6HvI/AAAAAAAAFNM/ioxl9LL_GoghLIjTVGLu2Pm8ghclT22egCEwYBhgL/s1600/image4.png", "width": "640", "height": "441", "credit": "A", "caption": "Reversible layers:"}}, "listen_duration_estimate": 445}, "2883671853": {"item_id": "2883671853", "resolved_id": "2883671871", "given_url": "https://www.kdnuggets.com/2020/02/easy-image-dataset-augmentation-tensorflow.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1582723709", "time_updated": "1638708525", "time_read": "1583785007", "time_favorited": "0", "sort_id": 66, "resolved_title": "Easy Image Dataset Augmentation with TensorFlow", "resolved_url": "https://www.kdnuggets.com/easy-image-dataset-augmentation-with-tensorflow.html/", "excerpt": "The success of image classification is driven, at least significantly, by large amounts of available training data. Putting aside concerns such as overfitting for a moment, the more image data you train with, the better chances you have of building an effective model.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "855", "lang": "en", "time_to_read": 4, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/cats-data-augmentation.jpg", "tags": {"deep-learning": {"item_id": "2883671853", "tag": "deep-learning"}, "images": {"item_id": "2883671853", "tag": "images"}, "tensorflow": {"item_id": "2883671853", "tag": "tensorflow"}}, "authors": {"77311567": {"item_id": "2883671853", "author_id": "77311567", "name": "Matthew Mayo", "url": "https://www.kdnuggets.com/author/matt-mayo"}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 331}, "2883948346": {"item_id": "2883948346", "resolved_id": "2883948346", "given_url": "https://spectrum.ieee.org/tech-talk/semiconductors/processors/lowpower-ai-startup-eta-compute-delivers-first-commercial-chips", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638241035", "time_updated": "1639520075", "time_read": "1639520075", "time_favorited": "0", "sort_id": 67, "resolved_title": "Full Page Reload", "resolved_url": "https://spectrum.ieee.org/tech-talk/semiconductors/processors/lowpower-ai-startup-eta-compute-delivers-first-commercial-chips", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"deep-learning": {"item_id": "2883948346", "tag": "deep-learning"}, "semiconductors": {"item_id": "2883948346", "tag": "semiconductors"}}, "domain_metadata": {"name": "IEEE", "logo": "https://logo.clearbit.com/ieee.org?size=800", "greyscale_logo": "https://logo.clearbit.com/ieee.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "2884922097": {"item_id": "2884922097", "resolved_id": "2884922097", "given_url": "https://medium.com/@lukas_1583/serving-gpt-2-in-google-cloud-platform-9ea07a69c87d", "given_title": "", "favorite": "0", "status": "1", "time_added": "1581818862", "time_updated": "1638708525", "time_read": "1581818879", "time_favorited": "0", "sort_id": 68, "resolved_title": "Serving GPT-2 in Google Cloud Platform", "resolved_url": "https://medium.com/@lukas_1583/serving-gpt-2-in-google-cloud-platform-9ea07a69c87d", "excerpt": "Our mission at Deepdesk is to unburden contact centers by applying AI. We provide real time response recommendations (think Smart Compose), and automation of repetitive dialogs. We do this by training Machine Learning models with actual conversations.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "743", "lang": "en", "time_to_read": 3, "top_image_url": "https://miro.medium.com/max/1080/1*tI33WFWKB6VyEj__mmolkw.jpeg", "tags": {"deep-learning": {"item_id": "2884922097", "tag": "deep-learning"}, "nlp": {"item_id": "2884922097", "tag": "nlp"}}, "authors": {"128425585": {"item_id": "2884922097", "author_id": "128425585", "name": "Lukas Batteau", "url": "https://medium.com/@lukas_1583"}}, "image": {"item_id": "2884922097", "src": "https://miro.medium.com/max/2160/1*tI33WFWKB6VyEj__mmolkw.jpeg", "width": "1080", "height": "675"}, "images": {"1": {"item_id": "2884922097", "image_id": "1", "src": "https://miro.medium.com/max/2160/1*tI33WFWKB6VyEj__mmolkw.jpeg", "width": "1080", "height": "675", "credit": "", "caption": ""}, "2": {"item_id": "2884922097", "image_id": "2", "src": "https://miro.medium.com/max/4982/1*k9k9vHSTMbq05zLvLDfy5Q.jpeg", "width": "2491", "height": "780", "credit": "", "caption": ""}, "3": {"item_id": "2884922097", "image_id": "3", "src": "https://miro.medium.com/max/1600/1*cgA9c-1cZylUderYmjCHjw.png", "width": "400", "height": "226", "credit": "", "caption": ""}, "4": {"item_id": "2884922097", "image_id": "4", "src": "https://miro.medium.com/max/3608/1*8QQXaOCYMbDv5gpu5sZWaA.png", "width": "1804", "height": "272", "credit": "", "caption": ""}, "5": {"item_id": "2884922097", "image_id": "5", "src": "https://miro.medium.com/max/2692/1*RMihOIP0_GPSreMYvAmjgg.jpeg", "width": "1346", "height": "427", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 288}, "2885117488": {"item_id": "2885117488", "resolved_id": "2885117488", "given_url": "https://huggingface.co/blog/how-to-train", "given_title": "", "favorite": "0", "status": "1", "time_added": "1581772106", "time_updated": "1638708525", "time_read": "1582142974", "time_favorited": "0", "sort_id": 69, "resolved_title": "How to train a new language model from scratch using Transformers and Tokenizers", "resolved_url": "https://huggingface.co/blog/how-to-train", "excerpt": "Over the past few months, we made several improvements to our transformers and tokenizers libraries, with the goal of making it easier than ever to train a new language model from scratch.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1690", "lang": "en", "time_to_read": 8, "top_image_url": "https://huggingface.co/blog/assets/01_how-to-train/how-to-train_blogpost.png", "tags": {"deep-learning": {"item_id": "2885117488", "tag": "deep-learning"}, "nlp": {"item_id": "2885117488", "tag": "nlp"}}, "image": {"item_id": "2885117488", "src": "https://colab.research.google.com/assets/colab-badge.svg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2885117488", "image_id": "1", "src": "https://colab.research.google.com/assets/colab-badge.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2885117488", "image_id": "2", "src": "https://huggingface.co/blog/assets/01_how-to-train/eo.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2885117488", "image_id": "3", "src": "https://huggingface.co/blog/assets/01_how-to-train/oscar.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2885117488", "image_id": "4", "src": "https://huggingface.co/blog/assets/01_how-to-train/tensorboard.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2885117488", "image_id": "5", "src": "https://huggingface.co/blog/assets/01_how-to-train/conll-2003.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2885117488", "image_id": "6", "src": "https://huggingface.co/blog/assets/01_how-to-train/model_page.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 654}, "2896167496": {"item_id": "2896167496", "resolved_id": "2896167496", "given_url": "https://www.linkedin.com/posts/mit-technology-review_a-little-known-ai-method-can-train-on-your-activity-6638048662511501312-N-fD", "given_title": "", "favorite": "0", "status": "1", "time_added": "1582644733", "time_updated": "1706624319", "time_read": "1583785007", "time_favorited": "0", "sort_id": 70, "resolved_title": "MIT Technology Review‚Äôs Post", "resolved_url": "https://www.linkedin.com/posts/mit-technology-review_a-little-known-ai-method-can-train-on-your-activity-6638048662511501312-N-fD", "excerpt": "To view or add a comment, sign in", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "8", "lang": "en", "top_image_url": "https://static.licdn.com/aero-v1/sc/h/c45fy346jw096z9pbphyyhdz7", "tags": {"deep-learning": {"item_id": "2896167496", "tag": "deep-learning"}, "federated-learning": {"item_id": "2896167496", "tag": "federated-learning"}}, "domain_metadata": {"name": "LinkedIn", "logo": "https://logo.clearbit.com/linkedin.com?size=800", "greyscale_logo": "https://logo.clearbit.com/linkedin.com?size=800&greyscale=true"}, "listen_duration_estimate": 3}, "2896196841": {"item_id": "2896196841", "resolved_id": "2896196841", "given_url": "https://www.topbots.com/dissecting-the-transformer/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1582738941", "time_updated": "1638708525", "time_read": "1583785007", "time_favorited": "0", "sort_id": 71, "resolved_title": "Dissecting The Transformer", "resolved_url": "https://www.topbots.com/dissecting-the-transformer/", "excerpt": "We saw how attention works and how it improved neural machine translation systems (see the previous blogpost), we are going to unveil the secrets behind the power of the most famous NLP models nowadays (a.k.a BERT and friends), the transformer.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1763", "lang": "en", "time_to_read": 8, "amp_url": "https://www.topbots.com/dissecting-the-transformer/?amp", "top_image_url": "https://www.topbots.com/wp-content/uploads/2020/02/cover_Self-attention_layer_1600px_web.jpg", "tags": {"deep-learning": {"item_id": "2896196841", "tag": "deep-learning"}}, "authors": {"129049937": {"item_id": "2896196841", "author_id": "129049937", "name": "Reda Affane", "url": "https://www.topbots.com/author/reda-affane/"}}, "image": {"item_id": "2896196841", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/cover_Self-attention_layer_1600px_web.jpg", "width": "980", "height": "490"}, "images": {"1": {"item_id": "2896196841", "image_id": "1", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/cover_Self-attention_layer_1600px_web.jpg", "width": "980", "height": "490", "credit": "", "caption": ""}, "2": {"item_id": "2896196841", "image_id": "2", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/1_Monster_450px_web.jpg", "width": "450", "height": "617", "credit": "", "caption": ""}, "3": {"item_id": "2896196841", "image_id": "3", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/2_Architecture_overview_500px_web.jpg", "width": "500", "height": "656", "credit": "", "caption": ""}, "4": {"item_id": "2896196841", "image_id": "4", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/3_Self-attention_layer_800px_web.jpg", "width": "800", "height": "484", "credit": "", "caption": ""}, "5": {"item_id": "2896196841", "image_id": "5", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/4_Attention_figure_800px_web.jpg", "width": "800", "height": "631", "credit": "", "caption": ""}, "6": {"item_id": "2896196841", "image_id": "6", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/5_Softmax_step_800px_web.jpg", "width": "800", "height": "623", "credit": "", "caption": ""}, "7": {"item_id": "2896196841", "image_id": "7", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/6_Self_attention_vectorized_400px_web.jpg", "width": "400", "height": "81", "credit": "", "caption": ""}, "8": {"item_id": "2896196841", "image_id": "8", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/7_Multi-head_attention_400px_web.jpg", "width": "400", "height": "470", "credit": "", "caption": ""}, "9": {"item_id": "2896196841", "image_id": "9", "src": "https://qjjnh3a9hpo1nukrg1fwoh71-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/8_Positional_encoding_600px_web.jpg", "width": "600", "height": "143", "credit": "", "caption": ""}}, "listen_duration_estimate": 682}, "2899763458": {"item_id": "2899763458", "resolved_id": "2899763458", "given_url": "https://github.com/fastai/fastbook", "given_title": "", "favorite": "0", "status": "1", "time_added": "1658673596", "time_updated": "1658676478", "time_read": "1658676478", "time_favorited": "0", "sort_id": 72, "resolved_title": "fastai/fastbook", "resolved_url": "https://github.com/fastai/fastbook", "excerpt": "These notebooks cover an introduction to deep learning, fastai, and PyTorch. fastai is a layered API for deep learning; for more information, see the fastai paper. Everything in this repo is copyright Jeremy Howard and Sylvain Gugger, 2020 onwards.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "480", "lang": "en", "top_image_url": "https://opengraph.githubassets.com/8e454e433f543cf8e8d56503e19cd03d7101e1354e0ccdceaca39abacf678ce1/fastai/fastbook", "tags": {"books": {"item_id": "2899763458", "tag": "books"}, "deep-learning": {"item_id": "2899763458", "tag": "deep-learning"}, "pytorch": {"item_id": "2899763458", "tag": "pytorch"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 186}, "2900507056": {"item_id": "2900507056", "resolved_id": "2900210172", "given_url": "https://www.linkedin.com/posts/activity-6639302449037406208-LJJ1", "given_title": "", "favorite": "0", "status": "1", "time_added": "1582987336", "time_updated": "1638708525", "time_read": "1583785007", "time_favorited": "0", "sort_id": 73, "resolved_title": "Vincent Boucher‚Äôs Post", "resolved_url": "https://www.linkedin.com/posts/montrealai_transformer-bert-nlp-activity-6639302449037406208-iBsS", "excerpt": "See more comments To view or add a comment, sign in", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "11", "lang": "en", "top_image_url": "https://media.licdn.com/dms/image/C4E22AQERV7utC98QDw/feedshare-shrink_2048_1536/0/1582933055059?e=1694044800&v=beta&t=kk2G2MEitpRRs6TKobk3BwldWlFSPxmpGA3LrG3x6BU", "tags": {"bert": {"item_id": "2900507056", "tag": "bert"}, "deep-learning": {"item_id": "2900507056", "tag": "deep-learning"}, "nlp": {"item_id": "2900507056", "tag": "nlp"}}, "domain_metadata": {"name": "LinkedIn", "logo": "https://logo.clearbit.com/linkedin.com?size=800", "greyscale_logo": "https://logo.clearbit.com/linkedin.com?size=800&greyscale=true"}, "listen_duration_estimate": 4}, "2913864649": {"item_id": "2913864649", "resolved_id": "2913864656", "given_url": "https://arxiv.org/abs/2003.05689", "given_title": "", "favorite": "0", "status": "1", "time_added": "1584292458", "time_updated": "1706233547", "time_read": "1584377645", "time_favorited": "0", "sort_id": 74, "resolved_title": "Title:Hyper-Parameter Optimization: A Review of Algorithms and Applications", "resolved_url": "https://arxiv.org/abs/2003.05689v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"algorithms-math": {"item_id": "2913864649", "tag": "algorithms-math"}, "deep-learning": {"item_id": "2913864649", "tag": "deep-learning"}, "machine-learning": {"item_id": "2913864649", "tag": "machine-learning"}}, "authors": {"101783936": {"item_id": "2913864649", "author_id": "101783936", "name": "cs   stat   stat.ML", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "2916170851": {"item_id": "2916170851", "resolved_id": "2916170851", "given_url": "https://tldrthis.com/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1584276641", "time_updated": "1638708525", "time_read": "1585739737", "time_favorited": "0", "sort_id": 75, "resolved_title": "Summarize any in a click.", "resolved_url": "https://tldrthis.com/", "excerpt": "TLDR This helps you summarize any piece of text into concise, easy to digest content so you can free yourself from information overload. INTRODUCING OUR ‚ú® NEW ‚ú® PARAPHRASING TOOL We know how hard it is to find the right voice for your audience.", "is_article": "0", "is_index": "1", "has_video": "1", "has_image": "1", "word_count": "433", "lang": "en", "top_image_url": "https://tldrthis.com/static/images/tldrthis-krishna.jpg", "tags": {"deep-learning": {"item_id": "2916170851", "tag": "deep-learning"}, "nlp": {"item_id": "2916170851", "tag": "nlp"}}, "image": {"item_id": "2916170851", "src": "https://tldrthis.com/static/images/landing/harvard.svg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2916170851", "image_id": "1", "src": "https://tldrthis.com/static/images/landing/harvard.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2916170851", "image_id": "2", "src": "https://tldrthis.com/static/images/landing/stanford.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2916170851", "image_id": "3", "src": "https://tldrthis.com/static/images/landing/mit.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2916170851", "image_id": "4", "src": "https://tldrthis.com/static/images/landing/ucl.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2916170851", "image_id": "5", "src": "https://tldrthis.com/static/images/landing/cambridge.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2916170851", "image_id": "6", "src": "https://tldrthis.com/static/images/landing/toronto.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2916170851", "image_id": "7", "src": "https://tldrthis.com/static/images/landing/auckland.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2916170851", "image_id": "8", "src": "https://tldrthis.com/static/images/landing/auto_summary.png", "width": "528", "height": "396", "credit": "", "caption": ""}, "9": {"item_id": "2916170851", "image_id": "9", "src": "https://tldrthis.com/static/images/landing/article_metadata.png", "width": "300", "height": "200", "credit": "", "caption": ""}, "10": {"item_id": "2916170851", "image_id": "10", "src": "https://tldrthis.com/static/images/landing/distraction_free.png", "width": "528", "height": "396", "credit": "", "caption": ""}, "11": {"item_id": "2916170851", "image_id": "11", "src": "https://tldrthis.com/static/images/landing/harekrishna.png", "width": "528", "height": "396", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "2916170851", "video_id": "1", "src": "https://tldrthis.com/static/videos/tldrthis-narad.mp4", "width": "0", "height": "0", "type": "5", "vid": "", "length": "0"}}, "listen_duration_estimate": 168}, "2922312331": {"item_id": "2922312331", "resolved_id": "2922312331", "given_url": "https://blog.insightdatascience.com/ai-for-3d-generative-design-17503d0b3943", "given_title": "", "favorite": "0", "status": "1", "time_added": "1584729270", "time_updated": "1638708525", "time_read": "1589542170", "time_favorited": "0", "sort_id": 76, "resolved_title": "AI for 3D Generative Design", "resolved_url": "https://blog.insightdatascience.com/ai-for-3d-generative-design-17503d0b3943", "excerpt": "Making the design process faster and more efficient by generating 3D objects from natural language descriptions. See the live demo here: datanexus.xyz The same fundamental process is used to design every modern physical object from tables to spacecraft.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2914", "lang": "en", "time_to_read": 13, "top_image_url": "https://miro.medium.com/max/1200/1*E4Yffq-_ynqgvz00vQN9gg.png", "tags": {"deep-learning": {"item_id": "2922312331", "tag": "deep-learning"}}, "authors": {"152338728": {"item_id": "2922312331", "author_id": "152338728", "name": "Tyler Habowski", "url": "https://medium.com/@starstorms"}}, "image": {"item_id": "2922312331", "src": "https://miro.medium.com/max/1050/1*zX0rauRrbybo8Ba2yD8QDA.png", "width": "525", "height": "394"}, "images": {"1": {"item_id": "2922312331", "image_id": "1", "src": "https://miro.medium.com/max/1050/1*zX0rauRrbybo8Ba2yD8QDA.png", "width": "525", "height": "394", "credit": "", "caption": "Standard design process"}, "2": {"item_id": "2922312331", "image_id": "2", "src": "https://miro.medium.com/max/698/0*etlbNXMxwqjyqxSZ", "width": "349", "height": "231", "credit": "", "caption": "Interpolating between different swivel chairs designs, read on for details!"}, "3": {"item_id": "2922312331", "image_id": "3", "src": "https://miro.medium.com/max/2622/1*E4Yffq-_ynqgvz00vQN9gg.png", "width": "1311", "height": "652", "credit": "", "caption": "My proposed design process with Machine Learning"}, "4": {"item_id": "2922312331", "image_id": "4", "src": "https://miro.medium.com/max/1160/1*2CkMAXHYeAEfx-QB5RRLDA.png", "width": "580", "height": "521", "credit": "", "caption": "Example: PartNet models with different colors showing the distinctly annotated subparts"}, "5": {"item_id": "2922312331", "image_id": "5", "src": "https://miro.medium.com/max/2654/1*1fie7sUederhhOmfJypRhQ.png", "width": "1327", "height": "623", "credit": "", "caption": "Building my text descriptions into a 3D model database"}, "6": {"item_id": "2922312331", "image_id": "6", "src": "https://miro.medium.com/max/2526/1*eiWOFYBKbxP8Vhfe6rTkIg.png", "width": "1263", "height": "616", "credit": "", "caption": "Model training architecture for the shape autoencoder and the text encoder"}, "7": {"item_id": "2922312331", "image_id": "7", "src": "https://miro.medium.com/max/2180/1*3c8psoh6AQjspG8tthF1pQ.png", "width": "1090", "height": "767", "credit": "", "caption": "TSNE map of the latent space vectors colored according to object category."}, "8": {"item_id": "2922312331", "image_id": "8", "src": "https://miro.medium.com/max/698/1*p0Y9MG-TK-jXSXp5RR6hdQ.gif", "width": "349", "height": "231", "credit": "", "caption": ""}, "9": {"item_id": "2922312331", "image_id": "9", "src": "https://miro.medium.com/max/698/1*mAiXJsWBCGkQAyr86Qw1xQ.gif", "width": "349", "height": "231", "credit": "", "caption": ""}, "10": {"item_id": "2922312331", "image_id": "10", "src": "https://miro.medium.com/max/698/1*wUQcV54SqSMX8ciqniKblg.gif", "width": "349", "height": "231", "credit": "many more GIF examples on my github, can also be generated realtime on the app here", "caption": "Interpolating between different types of swivel chairs"}, "11": {"item_id": "2922312331", "image_id": "11", "src": "https://miro.medium.com/max/1362/1*RCQbO3Mo7ugBa0wMdI0M0A.png", "width": "681", "height": "516", "credit": "", "caption": "Output models for various simple descriptions showing how the model changes"}, "12": {"item_id": "2922312331", "image_id": "12", "src": "https://miro.medium.com/max/308/1*JtQ5x_i5g3GhyRYYkIjxaA.png", "width": "154", "height": "249", "credit": "", "caption": "Input was: ‚Äòa chair that looks like a lamp‚Äô."}}, "listen_duration_estimate": 1128}, "2924356383": {"item_id": "2924356383", "resolved_id": "2924356383", "given_url": "https://towardsdatascience.com/ai-papers-to-read-in-2020-ac0e4e91d915", "given_title": "", "favorite": "0", "status": "1", "time_added": "1600600907", "time_updated": "1638708525", "time_read": "1604362468", "time_favorited": "0", "sort_id": 77, "resolved_title": "AI Papers to Read in 2020", "resolved_url": "https://towardsdatascience.com/ai-papers-to-read-in-2020-ac0e4e91d915", "excerpt": "Artificial Intelligence is one of the most rapidly growing fields in science and is one of the most sought skills of the past few years, commonly labeled as Data Science.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2581", "lang": "en", "time_to_read": 12, "top_image_url": "https://miro.medium.com/max/1200/0*zcAVUdLYO_3NmqqQ", "tags": {"deep-learning": {"item_id": "2924356383", "tag": "deep-learning"}}, "authors": {"128487571": {"item_id": "2924356383", "author_id": "128487571", "name": "Ygor Rebou√ßas Serpa", "url": "https://medium.com/@ygorrebouasserpa"}}, "image": {"item_id": "2924356383", "src": "https://miro.medium.com/max/1400/0*zcAVUdLYO_3NmqqQ", "width": "700", "height": "411"}, "images": {"1": {"item_id": "2924356383", "image_id": "1", "src": "https://miro.medium.com/max/1400/0*zcAVUdLYO_3NmqqQ", "width": "700", "height": "411", "credit": "Alfons Morales on Unsplash", "caption": ""}, "2": {"item_id": "2924356383", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*JeIdmJcZAdUNtCL7tL35fA.png", "width": "700", "height": "237", "credit": "", "caption": "The original portrayal of the AlexNet structure. The top and bottom halves are processed by GPU 1 and 2, respectively. An earlier form of model parallelism. Source: The Alexnet Paper"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 999}, "2948496375": {"item_id": "2948496375", "resolved_id": "2948496375", "given_url": "https://towardsdatascience.com/google-open-sources-simclr-a-framework-for-self-supervised-and-semi-supervised-image-training-72b06d5d58a0", "given_title": "", "favorite": "0", "status": "1", "time_added": "1587997825", "time_updated": "1638708525", "time_read": "1588026402", "time_favorited": "0", "sort_id": 78, "resolved_title": "", "resolved_url": "https://towardsdatascience.com/google-open-sources-simclr-a-framework-for-self-supervised-and-semi-supervised-image-training-72b06d5d58a0", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"deep-learning": {"item_id": "2948496375", "tag": "deep-learning"}, "vision": {"item_id": "2948496375", "tag": "vision"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "2948842334": {"item_id": "2948842334", "resolved_id": "2948842334", "given_url": "https://towardsdatascience.com/3d-photography-inpainting-exploring-art-with-ai-adb390a09810", "given_title": "", "favorite": "0", "status": "1", "time_added": "1588808893", "time_updated": "1638708525", "time_read": "1589542033", "time_favorited": "0", "sort_id": 79, "resolved_title": "3D Photography Inpainting: Exploring Art with AI.", "resolved_url": "https://towardsdatascience.com/3d-photography-inpainting-exploring-art-with-ai-adb390a09810", "excerpt": "We are living in a Great Epoche of Experiments. Well, science, society, and culture experience new narratives all the time. Think about Renaissance or Dadaist movements. But data science, empowered by the current state of the computational periphery, allows us to do something beyond our imagination.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "864", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/freeze/max/600/1*VUHsZCmLQ1WQXMh3qivanQ.gif", "tags": {"art": {"item_id": "2948842334", "tag": "art"}, "deep-learning": {"item_id": "2948842334", "tag": "deep-learning"}}, "authors": {"143338775": {"item_id": "2948842334", "author_id": "143338775", "name": "Vlad Alex (Merzmensch)", "url": "https://merzmensch.medium.com"}}, "image": {"item_id": "2948842334", "src": "https://miro.medium.com/fit/c/56/56/2*XPoW5L0wjAVfzQRjjXlo8w.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2948842334", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*XPoW5L0wjAVfzQRjjXlo8w.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2948842334", "image_id": "2", "src": "https://miro.medium.com/max/1200/1*VUHsZCmLQ1WQXMh3qivanQ.gif", "width": "600", "height": "300", "credit": "", "caption": "Da Vinci, ‚ÄúThe Last Supper‚Äù. Converted with 3D Photo Inpainting by Merzmensch"}, "3": {"item_id": "2948842334", "image_id": "3", "src": "https://miro.medium.com/max/390/1*ZlZs_8C0nPdNDZqBgtXHBw.gif", "width": "195", "height": "325", "credit": "Source", "caption": "Screencap from 3D Photography Inpaiting demo video"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 334}, "2953140089": {"item_id": "2953140089", "resolved_id": "2953140129", "given_url": "https://www.kdnuggets.com/2020/04/openai-open-sources-microscope-lucid-library-neural-networks.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1587145071", "time_updated": "1706656364", "time_read": "1587748189", "time_favorited": "0", "sort_id": 80, "resolved_title": "OpenAI Open Sources Microscope and the Lucid Library to Visualize Neurons in Deep Neural Networks", "resolved_url": "https://www.kdnuggets.com/openai-open-sources-microscope-and-the-lucid-library-to-visualize-neurons-in-deep-neural-networks.html/", "excerpt": "The new tools shows the potential of data visualizations for understanding features in a neural network. Interpretability is one of the most challenging aspects of the deep learning space.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "936", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/max/1500/0*UxmSDQnDxGMhQG28.jpg", "tags": {"deep-learning": {"item_id": "2953140089", "tag": "deep-learning"}, "visualization": {"item_id": "2953140089", "tag": "visualization"}}, "authors": {"116022451": {"item_id": "2953140089", "author_id": "116022451", "name": "Jesus Rodriguez", "url": "https://www.kdnuggets.com/author/jesus-rodriguez"}}, "image": {"item_id": "2953140089", "src": "https://miro.medium.com/max/96/1*MnJuRrITYz9LEIfDsEBQ6A.png", "width": "200", "height": "0"}, "images": {"1": {"item_id": "2953140089", "image_id": "1", "src": "https://miro.medium.com/max/96/1*MnJuRrITYz9LEIfDsEBQ6A.png", "width": "200", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2953140089", "image_id": "2", "src": "https://miro.medium.com/max/96/1*o6Q5_pDSJy8X2vVWgltMDg.png", "width": "200", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 362}, "3013222001": {"item_id": "3013222001", "resolved_id": "3013222001", "given_url": "https://blog.roboflow.ai/yolov5-is-here/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1591816496", "time_updated": "1638708525", "time_read": "1593020571", "time_favorited": "0", "sort_id": 81, "resolved_title": "YOLOv5 is Here: State-of-the-Art Object Detection at 140 FPS", "resolved_url": "https://blog.roboflow.ai/yolov5-is-here/", "excerpt": "Less than 50 days after the release YOLOv4, YOLOv5 improves accessibility for realtime object detection. June 29, YOLOv5 has released the first official version of the repository. We wrote a new deep dive on YOLOv5.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "835", "lang": "en", "time_to_read": 4, "amp_url": "https://blog.roboflow.ai/yolov5-is-here/amp/", "top_image_url": "https://blog.roboflow.ai/content/images/2020/06/ezgif.com-video-to-gif--3--1.gif", "tags": {"deep-learning": {"item_id": "3013222001", "tag": "deep-learning"}, "vision": {"item_id": "3013222001", "tag": "vision"}}, "authors": {"128257915": {"item_id": "3013222001", "author_id": "128257915", "name": "Joseph Nelson", "url": "https://blog.roboflow.ai/author/joseph/"}, "133025027": {"item_id": "3013222001", "author_id": "133025027", "name": "Jacob Solawetz", "url": "https://blog.roboflow.ai/author/jacob/"}}, "image": {"item_id": "3013222001", "src": "https://blog.roboflow.ai/content/images/2020/06/yolov4-results.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3013222001", "image_id": "1", "src": "https://blog.roboflow.ai/content/images/2020/06/yolov4-results.png", "width": "0", "height": "0", "credit": "", "caption": "Image via the YOLOv4 paper."}, "2": {"item_id": "3013222001", "image_id": "2", "src": "https://blog.roboflow.ai/content/images/2020/06/image-51.png", "width": "0", "height": "0", "credit": "", "caption": "Our YOLOv5 weights file stored in S3 for future inference."}, "3": {"item_id": "3013222001", "image_id": "3", "src": "https://blog.roboflow.ai/content/images/2020/06/yolov5-performance.png", "width": "0", "height": "0", "credit": "", "caption": "YOLO is more accurate and faster than EfficientDet. Credit: Glenn Jocher"}}, "listen_duration_estimate": 323}, "3096394886": {"item_id": "3096394886", "resolved_id": "3095842548", "given_url": "https://www.reddit.com/r/learnmachinelearning/comments/ij6xgx/periodic_table_of_deep_learning_patterns_via/?utm_source=share&utm_medium=ios_app&utm_name=iossmf", "given_title": "", "favorite": "0", "status": "1", "time_added": "1598816531", "time_updated": "1706633668", "time_read": "1604369103", "time_favorited": "0", "sort_id": 82, "resolved_title": "Periodic Table of Deep Learning Patterns / Via DataCamp", "resolved_url": "https://www.reddit.com/r/learnmachinelearning/comments/ij6xgx/periodic_table_of_deep_learning_patterns_via/", "excerpt": "‚Ä¢Posted by8 minutes ago Discussion100% Upvoted", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "6", "lang": "en", "amp_url": "https://amp.reddit.com/r/learnmachinelearning/comments/ij6xgx/periodic_table_of_deep_learning_patterns_via/", "top_image_url": "https://preview.redd.it/eoojh689j2k51.jpg?auto=webp&s=02f070839dda0f82cfba9363f186365ab3e89ce3", "tags": {"deep-learning": {"item_id": "3096394886", "tag": "deep-learning"}, "glossaries": {"item_id": "3096394886", "tag": "glossaries"}}, "image": {"item_id": "3096394886", "src": "https://i.redd.it/eoojh689j2k51.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3096394886", "image_id": "1", "src": "https://i.redd.it/eoojh689j2k51.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Reddit", "logo": "https://logo.clearbit.com/reddit.com?size=800", "greyscale_logo": "https://logo.clearbit.com/reddit.com?size=800&greyscale=true"}, "listen_duration_estimate": 2}, "3098126892": {"item_id": "3098126892", "resolved_id": "3098126892", "given_url": "https://towardsdatascience.com/new-approaches-to-object-detection-f5cbc925e00e", "given_title": "", "favorite": "0", "status": "1", "time_added": "1600260276", "time_updated": "1638708525", "time_read": "1604364097", "time_favorited": "0", "sort_id": 83, "resolved_title": "New Approaches to Object Detection", "resolved_url": "https://towardsdatascience.com/new-approaches-to-object-detection-f5cbc925e00e", "excerpt": "I will start with a short introduction of different approaches to object detection. After both traditional and newer approaches are presented, you can read about the most important parts of CenterNet and TTFNet. Many ideas in both models are similar, therefore they will be introduced together.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1205", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/1*_ssXB-7gYmIwif0mxjncYg.jpeg", "tags": {"deep-learning": {"item_id": "3098126892", "tag": "deep-learning"}, "object-detection": {"item_id": "3098126892", "tag": "object-detection"}, "vision": {"item_id": "3098126892", "tag": "vision"}}, "authors": {"152215953": {"item_id": "3098126892", "author_id": "152215953", "name": "Libor Vanek", "url": "https://libor-vanek.medium.com"}}, "image": {"item_id": "3098126892", "src": "https://miro.medium.com/fit/c/56/56/1*YUYMuqs815KxE1iR6QtVJQ.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3098126892", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*YUYMuqs815KxE1iR6QtVJQ.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3098126892", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*_ssXB-7gYmIwif0mxjncYg.jpeg", "width": "700", "height": "394", "credit": "", "caption": "source: pexels.com"}, "3": {"item_id": "3098126892", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*QSdw1M6FkmarZXbD0PQs_A.jpeg", "width": "700", "height": "333", "credit": "", "caption": "source: pexels.com"}, "4": {"item_id": "3098126892", "image_id": "4", "src": "https://miro.medium.com/max/4400/1*60ROU3IyeI3U8ryAUXs-2A.png", "width": "2200", "height": "617", "credit": "Yellow: convolutional layer, red: max pooling, blue: upsampling.", "caption": "Simplified visualization of CenterNet with ResNet18, using upsampling and concatenation."}, "5": {"item_id": "3098126892", "image_id": "5", "src": "https://miro.medium.com/max/1084/1*lVma1W94MGETfUVaGEpF0g.png", "width": "542", "height": "256", "credit": "left", "caption": "A heatmap for CenterNet"}, "6": {"item_id": "3098126892", "image_id": "6", "src": "https://miro.medium.com/max/1084/1*khKe6aSlYkjjzUaCzRbhVw.png", "width": "542", "height": "238", "credit": "", "caption": "Selection of values for standard vs deformable convolution.FI"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 466}, "3100203046": {"item_id": "3100203046", "resolved_id": "3100203046", "given_url": "https://www.amazon.science/deep-learning-book-adds-pytorch-tensorflow", "given_title": "", "favorite": "0", "status": "1", "time_added": "1600523288", "time_updated": "1638708525", "time_read": "1600555991", "time_favorited": "0", "sort_id": 84, "resolved_title": "Amazon team adds key programming frameworks to Dive into Deep Learning book", "resolved_url": "https://www.amazon.science/deep-learning-book-adds-pytorch-tensorflow", "excerpt": "Over the past few years, a team of Amazon scientists has been developing a book that is gaining popularity with students and developers attracted to the booming field of deep learning, a subset of machine learning focused on large-scale artificial neural networks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1195", "lang": "en", "time_to_read": 5, "top_image_url": "https://assets.amazon.science/dims4/default/a21bee6/2147483647/strip/true/crop/2001x1051+0+0/resize/1200x630!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F97%2F62%2Fe2de1eeb42cd80928aaeba62e7b5%2Fdeep-learning-book-cover.png", "tags": {"deep-learning": {"item_id": "3100203046", "tag": "deep-learning"}}, "authors": {"131573555": {"item_id": "3100203046", "author_id": "131573555", "name": "Douglas Gantenbein", "url": "https://www.amazon.science/author/douglas-gantenbein"}}, "listen_duration_estimate": 463}, "3103256197": {"item_id": "3103256197", "resolved_id": "3028725521", "given_url": "https://mlwhiz.com/blog/2020/06/06/multiclass_image_classification_pytorch/?utm_campaign=end-to-end-pipeline-for-setting-up-multiclass-image-classification-for-data-scientists&utm_medium=social_link&utm_source=missinglettr", "given_title": "", "favorite": "0", "status": "1", "time_added": "1599414945", "time_updated": "1638708525", "time_read": "1604363722", "time_favorited": "0", "sort_id": 85, "resolved_title": "End to End Pipeline for setting up Multiclass Image Classification for Data Scientists", "resolved_url": "https://mlwhiz.com/blog/2020/06/06/multiclass_image_classification_pytorch/", "excerpt": "Have you ever wondered how Facebook takes care of the abusive and inappropriate images shared by some of its users? Or how Facebook‚Äôs tagging feature works? Or how Google Lens recognizes products through images? All of the above are examples of image classification in different settings.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3891", "lang": "en", "time_to_read": 18, "top_image_url": "https://mlwhiz.com/images/multiclass_image_classification_pytorch/main.png", "tags": {"deep-learning": {"item_id": "3103256197", "tag": "deep-learning"}, "vision": {"item_id": "3103256197", "tag": "vision"}}, "authors": {"8623619": {"item_id": "3103256197", "author_id": "8623619", "name": "Rahul Agarwal", "url": ""}}, "image": {"item_id": "3103256197", "src": "https://mlwhiz.com/images/multiclass_image_classification_pytorch/0.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3103256197", "image_id": "1", "src": "https://mlwhiz.com/images/multiclass_image_classification_pytorch/0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3103256197", "image_id": "2", "src": "https://mlwhiz.com/images/multiclass_image_classification_pytorch/1.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3103256197", "image_id": "3", "src": "https://mlwhiz.com/images/multiclass_image_classification_pytorch/2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3103256197", "image_id": "4", "src": "https://mlwhiz.com/images/multiclass_image_classification_pytorch/3.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3103256197", "image_id": "5", "src": "https://mlwhiz.com/images/multiclass_image_classification_pytorch/4.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3103256197", "image_id": "6", "src": "https://mlwhiz.com/images/multiclass_image_classification_pytorch/5.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3103256197", "image_id": "7", "src": "https://mlwhiz.com/images/multiclass_image_classification_pytorch/6.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3103256197", "image_id": "8", "src": "https://mlwhiz.com/images/multiclass_image_classification_pytorch/7.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3103256197", "image_id": "9", "src": "https://mlwhiz.com/images/multiclass_image_classification_pytorch/8.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3103256197", "image_id": "10", "src": "https://mlwhiz.com/images/multiclass_image_classification_pytorch/9.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3103256197", "image_id": "11", "src": "https://mlwhiz.com/images/multiclass_image_classification_pytorch/10.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3103256197", "image_id": "12", "src": "https://mlwhiz.com/images/multiclass_image_classification_pytorch/11.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1506}, "3106397394": {"item_id": "3106397394", "resolved_id": "3106397394", "given_url": "https://medium.com/rapids-ai/state-of-the-art-nlp-at-scale-with-rapids-huggingface-and-dask-a885c19ce87b", "given_title": "", "favorite": "0", "status": "1", "time_added": "1617461903", "time_updated": "1638708525", "time_read": "1617546158", "time_favorited": "0", "sort_id": 86, "resolved_title": "State of the art NLP at scale with RAPIDS, HuggingFace and Dask", "resolved_url": "https://medium.com/rapids-ai/state-of-the-art-nlp-at-scale-with-rapids-huggingface-and-dask-a885c19ce87b", "excerpt": "Modern natural language processing (NLP) mixes modeling, feature engineering, and general text processing. Deep learning NLP models can provide fantastic performance for tasks like named-entity recognition (NER), sentiment classification, and text summarization.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1016", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/0*w9WCIHyMuQ9h5Pee", "tags": {"dask": {"item_id": "3106397394", "tag": "dask"}, "deep-learning": {"item_id": "3106397394", "tag": "deep-learning"}, "gpus": {"item_id": "3106397394", "tag": "gpus"}, "nlp": {"item_id": "3106397394", "tag": "nlp"}, "nvidia": {"item_id": "3106397394", "tag": "nvidia"}}, "authors": {"138755693": {"item_id": "3106397394", "author_id": "138755693", "name": "Vibhu Jawa", "url": "https://medium.com/@vibhujawa"}}, "image": {"item_id": "3106397394", "src": "https://miro.medium.com/max/2550/1*E99P4x4anW9ziECVSqO1xQ.png", "width": "1275", "height": "203"}, "images": {"1": {"item_id": "3106397394", "image_id": "1", "src": "https://miro.medium.com/max/2550/1*E99P4x4anW9ziECVSqO1xQ.png", "width": "1275", "height": "203", "credit": "", "caption": ""}, "2": {"item_id": "3106397394", "image_id": "2", "src": "https://miro.medium.com/max/1742/0*eCtirKVYGeEZjmg4", "width": "871", "height": "521", "credit": "", "caption": "NLP workflow using Rapids and HuggingFace"}, "3": {"item_id": "3106397394", "image_id": "3", "src": "https://miro.medium.com/max/3096/0*w9WCIHyMuQ9h5Pee", "width": "1548", "height": "1082", "credit": "", "caption": "Example of NER in action from https://huggingface.co/dslim/bert-base-NER"}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 393}, "3115308139": {"item_id": "3115308139", "resolved_id": "3115308139", "given_url": "https://info.cloudfactory.com/image-annotation-for-computer-vision", "given_title": "", "favorite": "0", "status": "1", "time_added": "1600425848", "time_updated": "1638708525", "time_read": "1604363960", "time_favorited": "0", "sort_id": 87, "resolved_title": "Image Annotation for Computer Vision", "resolved_url": "https://info.cloudfactory.com/image-annotation-for-computer-vision", "excerpt": "Getting images annotated according to your specifications can be a challenge that slows your machine learning or deep learning project and, as a result, your speed to market. The choices you make about your image annotation techniques, tools, and workforce are worth thoughtful consideration.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "95", "lang": "en", "tags": {"deep-learning": {"item_id": "3115308139", "tag": "deep-learning"}, "vision": {"item_id": "3115308139", "tag": "vision"}}, "authors": {"5266235": {"item_id": "3115308139", "author_id": "5266235", "name": "CloudFactory", "url": ""}}, "listen_duration_estimate": 37}, "3121568791": {"item_id": "3121568791", "resolved_id": "3121518728", "given_url": "https://t.co/SU17kgm7yT?amp=1", "given_title": "", "favorite": "0", "status": "1", "time_added": "1600963933", "time_updated": "1638708525", "time_read": "1600965197", "time_favorited": "0", "sort_id": 88, "resolved_title": "Wav2vec 2.0: Learning the structure of speech from raw audio", "resolved_url": "https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/", "excerpt": "We are releasing pretrained models and code for wav2vec 2.0, the successor to wav2vec. This new model learns basic speech units used to tackle a self-supervised task.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1324", "lang": "en", "time_to_read": 6, "tags": {"audio": {"item_id": "3121568791", "tag": "audio"}, "deep-learning": {"item_id": "3121568791", "tag": "deep-learning"}}, "image": {"item_id": "3121568791", "src": "https://scontent.fzty3-2.fna.fbcdn.net/v/t39.2365-6/119150200_747255232501771_541209739950663784_n.jpg?_nc_cat=101&ccb=1-3&_nc_sid=ad8a9d&_nc_ohc=trVSgU2vQt4AX-In1uh&_nc_ht=scontent.fzty3-2.fna&oh=8a66565895872a549f2ab8a9e62de5f9&oe=60F1E4B4", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3121568791", "image_id": "1", "src": "https://scontent.fzty3-2.fna.fbcdn.net/v/t39.2365-6/119150200_747255232501771_541209739950663784_n.jpg?_nc_cat=101&ccb=1-3&_nc_sid=ad8a9d&_nc_ohc=trVSgU2vQt4AX-In1uh&_nc_ht=scontent.fzty3-2.fna&oh=8a66565895872a549f2ab8a9e62de5f9&oe=60F1E4B4", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3121568791", "image_id": "2", "src": "https://scontent.fzty3-2.fna.fbcdn.net/v/t39.2365-6/119181553_1427407894135552_5355496588865165150_n.jpg?_nc_cat=107&ccb=1-3&_nc_sid=ad8a9d&_nc_ohc=AYvgNhRAJacAX8b1ZBx&_nc_ht=scontent.fzty3-2.fna&oh=31b37bc787cd36c9e179c274316e9f38&oe=60F4FAE5", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3121568791", "image_id": "3", "src": "https://scontent.fzty3-2.fna.fbcdn.net/v/t39.2365-6/119054969_1985100375122929_8575206486520302035_n.jpg?_nc_cat=108&ccb=1-3&_nc_sid=ad8a9d&_nc_ohc=Pn5wMB1GlKkAX9OJ6Uu&_nc_ht=scontent.fzty3-2.fna&oh=dc20d9ded043b6d41bf7e6e35877df7e&oe=60F36B40", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 513}, "3125482453": {"item_id": "3125482453", "resolved_id": "3125482453", "given_url": "https://getpocket.com/explore/item/an-idea-from-physics-helps-ai-see-in-higher-dimensions", "given_title": "", "favorite": "0", "status": "1", "time_added": "1613869779", "time_updated": "1638708525", "time_read": "1614024020", "time_favorited": "0", "sort_id": 89, "resolved_title": "An Idea From Physics Helps AI See in Higher Dimensions", "resolved_url": "https://getpocket.com/explore/item/an-idea-from-physics-helps-ai-see-in-higher-dimensions", "excerpt": "The laws of physics stay the same no matter one‚Äôs perspective. Now this idea is allowing computers to detect features in curved and higher-dimensional space.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2960", "lang": "en", "time_to_read": 13, "top_image_url": "https://pocket-image-cache.com/1200x/filters:format(jpg):extract_focal()/https%3A%2F%2Fpocket-syndicated-images.s3.amazonaws.com%2Farticles%2F5812%2F1601307462_Lung-Scan_2880x1860_Lede.jpg", "tags": {"deep-learning": {"item_id": "3125482453", "tag": "deep-learning"}, "spatial": {"item_id": "3125482453", "tag": "spatial"}}, "authors": {"42172": {"item_id": "3125482453", "author_id": "42172", "name": "John Pavlus", "url": ""}}, "image": {"item_id": "3125482453", "src": "https://pocket-syndicated-images.s3.amazonaws.com/5f72031198ccd.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3125482453", "image_id": "1", "src": "https://pocket-syndicated-images.s3.amazonaws.com/5f72031198ccd.jpg", "width": "0", "height": "0", "credit": "", "caption": "The new deep learning techniques, which have shown promise in identifying lung tumors in CT scans more accurately than before, could someday lead to better medical diagnostics. Credit: Olena Shmahalo / Quanta Magazine."}, "2": {"item_id": "3125482453", "image_id": "2", "src": "https://pocket-syndicated-images.s3.amazonaws.com/5f72036f28f8b.jpg", "width": "0", "height": "0", "credit": "Lucy Reading-Ikkanda / Quanta Magazine", "caption": ""}, "3": {"item_id": "3125482453", "image_id": "3", "src": "https://pocket-syndicated-images.s3.amazonaws.com/5f7203ba94a35.jpg", "width": "0", "height": "0", "credit": "", "caption": "Miranda Cheng, a physicist at the University of Amsterdam. Credit: Ilvy Njiokiktjien for Quanta Magazine."}, "4": {"item_id": "3125482453", "image_id": "4", "src": "https://pocket-syndicated-images.s3.amazonaws.com/5f7203dfc57bb.jpg", "width": "0", "height": "0", "credit": "Lucy Reading-Ikkanda / Quanta Magazine", "caption": ""}, "5": {"item_id": "3125482453", "image_id": "5", "src": "https://pocket-syndicated-publisher-logos.s3.amazonaws.com/5f64c938572a8.png", "width": "0", "height": "0", "credit": "", "caption": "This post originally appeared on Quanta Magazine and was published January 9, 2020. This article is republished here with permission.Get math and science news, explainers, interviews and more in your inbox.Get Quanta‚Äôs weekly newsletter"}}, "domain_metadata": {"name": "Pocket", "logo": "https://logo.clearbit.com/getpocket.com?size=800", "greyscale_logo": "https://logo.clearbit.com/getpocket.com?size=800&greyscale=true"}, "listen_duration_estimate": 1146}, "3131820715": {"item_id": "3131820715", "resolved_id": "3131820715", "given_url": "https://github.com/lucidrains/vit-pytorch", "given_title": "", "favorite": "0", "status": "1", "time_added": "1671369674", "time_updated": "1671403223", "time_read": "1671403222", "time_favorited": "0", "sort_id": 90, "resolved_title": "lucidrains/vit-pytorch", "resolved_url": "https://github.com/lucidrains/vit-pytorch", "excerpt": "Implementation of Vision Transformer, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch. Significance is further explained in Yannic Kilcher's video.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2899", "lang": "en", "time_to_read": 13, "top_image_url": "https://opengraph.githubassets.com/e225c022a1f8272134515bd1488ec8fb876695df81a4b08ea2057d7bc9cc877e/lucidrains/vit-pytorch", "tags": {"deep-learning": {"item_id": "3131820715", "tag": "deep-learning"}, "machine-vision": {"item_id": "3131820715", "tag": "machine-vision"}, "pytorch": {"item_id": "3131820715", "tag": "pytorch"}, "transformers": {"item_id": "3131820715", "tag": "transformers"}}, "image": {"item_id": "3131820715", "src": "https://github.com/lucidrains/vit-pytorch/raw/main/images/vit.gif", "width": "500", "height": "0"}, "images": {"1": {"item_id": "3131820715", "image_id": "1", "src": "https://github.com/lucidrains/vit-pytorch/raw/main/images/vit.gif", "width": "500", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3131820715", "image_id": "2", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/distill.png", "width": "300", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3131820715", "image_id": "3", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/t2t.png", "width": "400", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3131820715", "image_id": "4", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/cross_vit.png", "width": "400", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3131820715", "image_id": "5", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/pit.png", "width": "400", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3131820715", "image_id": "6", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/levit.png", "width": "300", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3131820715", "image_id": "7", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/cvt.png", "width": "400", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3131820715", "image_id": "8", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/twins_svt.png", "width": "400", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3131820715", "image_id": "9", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/nest.png", "width": "400", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3131820715", "image_id": "10", "src": "https://github.com/lucidrains/vit-pytorch/blob/main/images/dino.png", "width": "350", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 1122}, "3143047992": {"item_id": "3143047992", "resolved_id": "3143047992", "given_url": "https://www.newsweek.com/hacked-billboards-can-make-teslas-see-phantom-objects-1539478", "given_title": "", "favorite": "0", "status": "1", "time_added": "1602846527", "time_updated": "1638708525", "time_read": "1604360939", "time_favorited": "0", "sort_id": 91, "resolved_title": "Hacked Billboards Can Make Teslas See 'Phantom Objects,' Causing Them to Swerve or Stop Abruptly", "resolved_url": "https://www.newsweek.com/hacked-billboards-can-make-teslas-see-phantom-objects-1539478", "excerpt": "Security researchers have demonstrated how Tesla's Autopilot driver-assistance systems can be tricked into changing speed, swerving or stopping abruptly, simply by projecting fake road signs or virtual objects in front of them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "465", "lang": "en", "amp_url": "https://www.newsweek.com/hacked-billboards-can-make-teslas-see-phantom-objects-1539478?amp=1", "top_image_url": "https://d.newsweek.com/en/full/1653142/tesla-model-x-electric-car-dashboard.jpg", "tags": {"deep-learning": {"item_id": "3143047992", "tag": "deep-learning"}, "deepfakes": {"item_id": "3143047992", "tag": "deepfakes"}, "vision": {"item_id": "3143047992", "tag": "vision"}}, "authors": {"139995941": {"item_id": "3143047992", "author_id": "139995941", "name": "Aatif Sulleyman", "url": "https://www.newsweek.com/authors/aatif-sulleyman"}}, "domain_metadata": {"name": "Newsweek", "logo": "https://logo.clearbit.com/newsweek.com?size=800", "greyscale_logo": "https://logo.clearbit.com/newsweek.com?size=800&greyscale=true"}, "listen_duration_estimate": 180}, "3170977506": {"item_id": "3170977506", "resolved_id": "3170977506", "given_url": "https://rltheorybook.github.io/rltheorybook_AJKS.pdf", "given_title": "", "favorite": "0", "status": "1", "time_added": "1624215057", "time_updated": "1638708525", "time_read": "1624292161", "time_favorited": "0", "sort_id": 92, "resolved_title": "", "resolved_url": "https://rltheorybook.github.io/rltheorybook_AJKS.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"deep-learning": {"item_id": "3170977506", "tag": "deep-learning"}, "reinforcement-learning": {"item_id": "3170977506", "tag": "reinforcement-learning"}}, "listen_duration_estimate": 0}, "3184244689": {"item_id": "3184244689", "resolved_id": "3184244689", "given_url": "https://lionbridge.ai/articles/everything-you-need-to-know-about-object-detection-systems/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1606404966", "time_updated": "1638708525", "time_read": "1608290468", "time_favorited": "0", "sort_id": 93, "resolved_title": "Everything You Need to Know About Object Detection Systems", "resolved_url": "https://lionbridge.ai/articles/everything-you-need-to-know-about-object-detection-systems/", "excerpt": "With the advent of deep learning, implementing an object detection system has become fairly trivial. There are a great many frameworks facilitating the process, and as I showed in a previous post, it‚Äôs quite easy to create a fast object detection model with YOLOv5.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3902", "lang": "en", "time_to_read": 18, "top_image_url": "https://lionbridge.ai/wp-content/uploads/2020/11/2020-11-20_object-detection.jpg", "tags": {"deep-learning": {"item_id": "3184244689", "tag": "deep-learning"}, "object-detection": {"item_id": "3184244689", "tag": "object-detection"}, "vision": {"item_id": "3184244689", "tag": "vision"}}, "authors": {"8623619": {"item_id": "3184244689", "author_id": "8623619", "name": "Rahul Agarwal", "url": ""}}, "image": {"item_id": "3184244689", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/01-1.png", "width": "700", "height": "295"}, "images": {"1": {"item_id": "3184244689", "image_id": "1", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/01-1.png", "width": "700", "height": "295", "credit": "", "caption": "http://cs231n.github.io/transfer-learning/#tf"}, "2": {"item_id": "3184244689", "image_id": "2", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/02-1.png", "width": "700", "height": "352", "credit": "", "caption": "Source: http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture11.pdf"}, "3": {"item_id": "3184244689", "image_id": "3", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/03-1.png", "width": "700", "height": "253", "credit": "", "caption": "And example of efficient graph-based image segmentation. Source: http://people.cs.uchicago.edu/~pff/papers/seg-ijcv.pdf"}, "4": {"item_id": "3184244689", "image_id": "4", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/05-1.png", "width": "700", "height": "614", "credit": "", "caption": "The algorithm for region proposal used in RCNN"}, "5": {"item_id": "3184244689", "image_id": "5", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/06-1.png", "width": "700", "height": "359", "credit": "", "caption": ""}, "6": {"item_id": "3184244689", "image_id": "6", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/07.jpeg", "width": "700", "height": "496", "credit": "", "caption": "Source: https://www.pyimagesearch.com/wp-content/uploads/2014/10/hog_object_detection_nms.jpg"}, "7": {"item_id": "3184244689", "image_id": "7", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/08-1.png", "width": "700", "height": "352", "credit": "", "caption": ""}, "8": {"item_id": "3184244689", "image_id": "8", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/09-1.png", "width": "470", "height": "276", "credit": "", "caption": "VGG 16 Architecture"}, "9": {"item_id": "3184244689", "image_id": "9", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/10.png", "width": "700", "height": "393", "credit": "", "caption": "We need fixed-sized feature maps for the final classifier."}, "10": {"item_id": "3184244689", "image_id": "10", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/11.gif", "width": "700", "height": "525", "credit": "", "caption": "Source: https://deepsense.ai/region-of-interest-pooling-explained/"}, "11": {"item_id": "3184244689", "image_id": "11", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/13.png", "width": "700", "height": "432", "credit": "", "caption": "Runtime dominated by region proposals!"}, "12": {"item_id": "3184244689", "image_id": "12", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/14.png", "width": "700", "height": "627", "credit": "", "caption": ""}, "13": {"item_id": "3184244689", "image_id": "13", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/15.png", "width": "700", "height": "525", "credit": "", "caption": "Anchor centers throughout the original image."}, "14": {"item_id": "3184244689", "image_id": "14", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/16.png", "width": "700", "height": "253", "credit": "", "caption": "Left: Anchors, Center: Anchor for a single point, Right: All anchors"}, "15": {"item_id": "3184244689", "image_id": "15", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/17.jpeg", "width": "638", "height": "359", "credit": "", "caption": "Results on VOC Dataset for the three different approaches."}, "16": {"item_id": "3184244689", "image_id": "16", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/1_4Q56usZkTr_003z6CnCKhw.png", "width": "1000", "height": "247", "credit": "", "caption": ""}, "17": {"item_id": "3184244689", "image_id": "17", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/18.png", "width": "700", "height": "462", "credit": "", "caption": ""}, "18": {"item_id": "3184244689", "image_id": "18", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/19.png", "width": "700", "height": "376", "credit": "", "caption": "Some images with masks from this paper: https://arxiv.org/abs/1703.06870"}, "19": {"item_id": "3184244689", "image_id": "19", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/20.png", "width": "700", "height": "230", "credit": "", "caption": "Everything remains the same. Just one more output layer to predict masks and ROI pooling replaced by ROIAlign"}, "20": {"item_id": "3184244689", "image_id": "20", "src": "https://lionbridge.ai/wp-content/uploads/2020/11/21.png", "width": "700", "height": "550", "credit": "", "caption": "Source: https://medium.com/@jonathan_hui/image-segmentation-with-mask-r-cnn-ebe6d793272"}}, "listen_duration_estimate": 1510}, "3191240650": {"item_id": "3191240650", "resolved_id": "3191240650", "given_url": "https://www.amazon.science/blog/a-version-of-the-bert-language-model-thats-20-times-as-fast", "given_title": "", "favorite": "0", "status": "1", "time_added": "1607165245", "time_updated": "1638708525", "time_read": "1607639414", "time_favorited": "0", "sort_id": 94, "resolved_title": "A version of the BERT language model that‚Äôs 20 times as fast", "resolved_url": "https://www.amazon.science/blog/a-version-of-the-bert-language-model-thats-20-times-as-fast", "excerpt": "In natural-language understanding (NLU), the Transformer-based BERT language model is king. Its high performance on multiple tasks has strongly influenced contemporary NLU research. On the other hand, it is a relatively big and slow model, which makes it unsuitable for some applications.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1349", "lang": "en", "time_to_read": 6, "top_image_url": "https://assets.amazon.science/dims4/default/7d37b6f/2147483647/strip/true/crop/951x499+0+17/resize/1200x630!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F91%2Fc9%2F4aab043e4973805be90d1737bba1%2Fagora.png", "tags": {"bert": {"item_id": "3191240650", "tag": "bert"}, "deep-learning": {"item_id": "3191240650", "tag": "deep-learning"}, "nlp": {"item_id": "3191240650", "tag": "nlp"}}, "authors": {"143590884": {"item_id": "3191240650", "author_id": "143590884", "name": "Adrian de Wynter", "url": "https://www.amazon.science/author/adrian-de-wynter"}}, "image": {"item_id": "3191240650", "src": "https://assets.amazon.science/dims4/default/9898d05/2147483647/strip/true/crop/951x534+0+0/resize/1200x674!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F4a%2Fa5%2Fdd99dd5b4b5599ec3ab958a979bb%2Fbort-models.png", "width": "1200", "height": "674"}, "images": {"1": {"item_id": "3191240650", "image_id": "1", "src": "https://assets.amazon.science/dims4/default/9898d05/2147483647/strip/true/crop/951x534+0+0/resize/1200x674!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F4a%2Fa5%2Fdd99dd5b4b5599ec3ab958a979bb%2Fbort-models.png", "width": "1200", "height": "674", "credit": "", "caption": ""}, "2": {"item_id": "3191240650", "image_id": "2", "src": "https://assets.amazon.science/dims4/default/6d6d332/2147483647/strip/true/crop/951x534+0+0/resize/1200x674!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F91%2Fc9%2F4aab043e4973805be90d1737bba1%2Fagora.png", "width": "1200", "height": "674", "credit": "", "caption": ""}}, "listen_duration_estimate": 522}, "3210738206": {"item_id": "3210738206", "resolved_id": "3210738206", "given_url": "https://theaisummer.com/transformer/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1621036985", "time_updated": "1638708525", "time_read": "1621356967", "time_favorited": "0", "sort_id": 95, "resolved_title": "How Transformers work in deep learning and NLP: an intuitive introduction", "resolved_url": "https://theaisummer.com/transformer/", "excerpt": "The famous paper ‚ÄúAttention is all you need‚Äù in 2017 changed the way we were thinking about attention. With enough data, matrix multiplications, linear layers, and layer normalization we can perform state-of-the-art-machine-translation.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "3778", "lang": "en", "time_to_read": 17, "top_image_url": "https://theaisummer.com/static/6122618d7e1466853e88473ba375cdc7/ee604/transformer.png", "tags": {"deep-learning": {"item_id": "3210738206", "tag": "deep-learning"}, "nlp": {"item_id": "3210738206", "tag": "nlp"}, "transformers": {"item_id": "3210738206", "tag": "transformers"}}, "authors": {"136374887": {"item_id": "3210738206", "author_id": "136374887", "name": "Nikolas Adaloglou", "url": "https://theaisummer.com/author/Nikolas-Adaloglou/"}}, "image": {"item_id": "3210738206", "src": "https://theaisummer.com/static/c9a851690a62f1faaf054430ca35ab20/c7dcc/tokenization.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3210738206", "image_id": "1", "src": "https://theaisummer.com/static/c9a851690a62f1faaf054430ca35ab20/c7dcc/tokenization.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3210738206", "image_id": "2", "src": "https://theaisummer.com/static/257848131da90edbf099aa8c4bf392c4/27524/input-processing-tokenization-embedding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3210738206", "image_id": "3", "src": "https://theaisummer.com/static/a662e9c10a5401d1bd1ccdce52dfdbd6/eb645/positional-encoding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3210738206", "image_id": "4", "src": "https://theaisummer.com/static/2e000851b686eb35c6c3c06522437715/26a94/attention-as-database-query.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3210738206", "image_id": "5", "src": "https://theaisummer.com/static/ebfe1b1dbab018e608a77f85457e52db/16caa/vector-similarity.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3210738206", "image_id": "6", "src": "https://theaisummer.com/static/4022cf02281d234e0e85fa44ad08b4e2/9f933/self-attention-probability-score-matrix.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3210738206", "image_id": "7", "src": "https://theaisummer.com/static/56773616d30b9dcb31aa792f2d701276/3096d/key-query-value.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3210738206", "image_id": "8", "src": "https://theaisummer.com/static/3ed7199184645f3e632d17ab6441244f/63a68/layer-norm.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3210738206", "image_id": "9", "src": "https://theaisummer.com/static/f6068bcb3559a017af003c2bde071bcf/e3b18/encoders-attention-with-normalizarion.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3210738206", "image_id": "10", "src": "https://theaisummer.com/static/dc71435f329458ee5cc09cb2ea09ebf8/7bc0b/encoder-without-multi-head.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3210738206", "image_id": "11", "src": "https://theaisummer.com/static/9dc2e417714211a5166ece483b862d75/442cb/parallel-multi-head-attention.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3210738206", "image_id": "12", "src": "https://theaisummer.com/static/bba48bd14e38ede88ac1cacd8a638d6d/a4078/multi-head-attention.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3210738206", "image_id": "13", "src": "https://theaisummer.com/static/18072c01858310b080b3b6d9b4950175/e45a9/encoder.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "3210738206", "image_id": "14", "src": "https://theaisummer.com/static/7d6c2aa7af90f14cf44d533cbf88726e/8ff13/decoder.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1462}, "3215517403": {"item_id": "3215517403", "resolved_id": "3215517403", "given_url": "https://medium.com/paperswithcode/papers-with-code-2020-review-938146ab9658", "given_title": "", "favorite": "0", "status": "1", "time_added": "1609366712", "time_updated": "1638708525", "time_read": "1609624981", "time_favorited": "0", "sort_id": 96, "resolved_title": "Papers with Code 2020 Review", "resolved_url": "https://medium.com/paperswithcode/papers-with-code-2020-review-938146ab9658", "excerpt": "Papers with Code indexes various machine learning artifacts ‚Äî papers, code, results ‚Äî to facilitate discovery and comparison. Using this data we can get a sense of what the ML community found useful and interesting this year.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "432", "lang": "en", "top_image_url": "https://miro.medium.com/max/1200/1*rErHDsF_8dtSYWjs0rpcTQ.png", "tags": {"deep-learning": {"item_id": "3215517403", "tag": "deep-learning"}, "paperswithcode": {"item_id": "3215517403", "tag": "paperswithcode"}}, "authors": {"88016789": {"item_id": "3215517403", "author_id": "88016789", "name": "Ross Taylor", "url": "https://medium.com/@rosstaylor_6848"}}, "image": {"item_id": "3215517403", "src": "https://miro.medium.com/max/1600/1*rErHDsF_8dtSYWjs0rpcTQ.png", "width": "700", "height": "312"}, "images": {"1": {"item_id": "3215517403", "image_id": "1", "src": "https://miro.medium.com/max/1600/1*rErHDsF_8dtSYWjs0rpcTQ.png", "width": "700", "height": "312", "credit": "", "caption": "EfficientDet by Tan et al was the most viewed paper on Papers with Code for 2020"}, "2": {"item_id": "3215517403", "image_id": "2", "src": "https://miro.medium.com/max/1600/1*xytUHGN59M3zTmzUwzOU-A.png", "width": "700", "height": "389", "credit": "", "caption": "? Transformers was the most viewed library on Papers with Code for 2020"}, "3": {"item_id": "3215517403", "image_id": "3", "src": "https://miro.medium.com/max/1600/1*2rTBFFd14DtI12wAPbT-3g.png", "width": "700", "height": "292", "credit": "", "caption": "ImageNet was the most viewed benchmark on Papers with Code for 2020"}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 167}, "3221856737": {"item_id": "3221856737", "resolved_id": "3221856737", "given_url": "https://deeplearningsystems.ai/#ch01/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1609944683", "time_updated": "1638708525", "time_read": "1610019288", "time_favorited": "0", "sort_id": 97, "resolved_title": "Deep Learning Systems: Algorithms, Compilers, and Processors for Large-Scale Production", "resolved_url": "https://deeplearningsystems.ai/#ch01/", "excerpt": "This book describes deep learning systems: the algorithms, compilers, processors, and platforms to efficiently train and deploy deep learning models at scale in production. Andres Rodriguez. Deep Learning Systems: Algorithms, Compilers, and Processors for Large-Scale Production.", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "233", "lang": "en", "tags": {"books": {"item_id": "3221856737", "tag": "books"}, "deep-learning": {"item_id": "3221856737", "tag": "deep-learning"}}, "authors": {"145042893": {"item_id": "3221856737", "author_id": "145042893", "name": "Author's Biography", "url": "https://deeplearningsystems.ai/bio/"}}, "image": {"item_id": "3221856737", "src": "https://deeplearningsystems.ai/figures/bookcover.jpg", "width": "50", "height": "50"}, "images": {"1": {"item_id": "3221856737", "image_id": "1", "src": "https://deeplearningsystems.ai/figures/bookcover.jpg", "width": "50", "height": "50", "credit": "", "caption": ""}}, "listen_duration_estimate": 90}, "3266401672": {"item_id": "3266401672", "resolved_id": "3265116344", "given_url": "https://link.medium.com/MBOlUwEWaeb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1614293473", "time_updated": "1638708525", "time_read": "1614780587", "time_favorited": "0", "sort_id": 98, "resolved_title": "How to Use Roboflow and Streamlit to Visualize Object Detection Output", "resolved_url": "https://towardsdatascience.com/how-to-use-roboflow-and-streamlit-to-visualize-object-detection-output-672ba11b2f7c", "excerpt": "Most technology is designed to make your life, or your work, easier. If your work involves building computer vision into your applications, using the Roboflow platform gives you everything you need.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1889", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/freeze/max/1200/0*asY-S_5_Nf5x__Mc.gif", "tags": {"deep-learning": {"item_id": "3266401672", "tag": "deep-learning"}, "machine-vision": {"item_id": "3266401672", "tag": "machine-vision"}, "object-detection": {"item_id": "3266401672", "tag": "object-detection"}}, "authors": {"142575116": {"item_id": "3266401672", "author_id": "142575116", "name": "Matt Brems", "url": "https://matthew-brems.medium.com"}}, "image": {"item_id": "3266401672", "src": "https://miro.medium.com/max/1400/0*asY-S_5_Nf5x__Mc.gif", "width": "700", "height": "389"}, "images": {"1": {"item_id": "3266401672", "image_id": "1", "src": "https://miro.medium.com/max/1400/0*asY-S_5_Nf5x__Mc.gif", "width": "700", "height": "389", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "The app in action."}, "2": {"item_id": "3266401672", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*xCjlACpcSRVnrrOA.png", "width": "700", "height": "700", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "Red blood cells, white blood cells, and platelets."}, "3": {"item_id": "3266401672", "image_id": "3", "src": "https://miro.medium.com/max/1400/0*_n5TdunZkKtFYjK9", "width": "700", "height": "258", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "The computer vision workflow."}, "4": {"item_id": "3266401672", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*S5mhEGuLm86pDvK_kQBCJw.gif", "width": "700", "height": "467", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "Forking a public dataset."}, "5": {"item_id": "3266401672", "image_id": "5", "src": "https://miro.medium.com/max/1400/0*tX8Xm3C5w0s4QzrK.png", "width": "700", "height": "546", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "Image preprocessing and image augmentation techniques."}, "6": {"item_id": "3266401672", "image_id": "6", "src": "https://miro.medium.com/max/1400/0*0FWS3P6jwF_9aEOm.png", "width": "700", "height": "199", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "Training, validation, and testing splits."}, "7": {"item_id": "3266401672", "image_id": "7", "src": "https://miro.medium.com/max/1400/0*rAF8tqbEi6-mcR55.png", "width": "700", "height": "444", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "Two clicks to train a computer vision model."}, "8": {"item_id": "3266401672", "image_id": "8", "src": "https://miro.medium.com/max/1400/0*hk-VHM2HWbOoxIx6.png", "width": "700", "height": "438", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "Build a model from scratch or use transfer learning."}, "9": {"item_id": "3266401672", "image_id": "9", "src": "https://miro.medium.com/max/1400/0*rTFWrwX3kqcLwYIS.png", "width": "700", "height": "409", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "Overall results for our model‚Äôs performance, including mean average precision."}, "10": {"item_id": "3266401672", "image_id": "10", "src": "https://miro.medium.com/max/1400/0*c1FZLjbEuBZiBY1N.png", "width": "700", "height": "386", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "Looking at model performance by class."}, "11": {"item_id": "3266401672", "image_id": "11", "src": "https://miro.medium.com/max/1400/0*oUbz9kf8asy4h42a.png", "width": "700", "height": "628", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "The app sidebar, enabling you to quickly change the parameters of your predictions."}, "12": {"item_id": "3266401672", "image_id": "12", "src": "https://miro.medium.com/max/1400/0*uXP3jt3pkyCswWrs.png", "width": "700", "height": "486", "credit": "Image by Roboflow and Streamlit; authorized to use.", "caption": "The main app area, visualizing predicted output, summary statistics, and bounding box confidence levels."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 731}, "3266868372": {"item_id": "3266868372", "resolved_id": "3266868372", "given_url": "https://elvissaravia.substack.com/p/10-must-read-ml-blog-posts", "given_title": "", "favorite": "0", "status": "1", "time_added": "1622247483", "time_updated": "1638708525", "time_read": "1622249154", "time_favorited": "0", "sort_id": 99, "resolved_title": "10 Must Read ML Blog Posts", "resolved_url": "https://elvissaravia.substack.com/p/10-must-read-ml-blog-posts", "excerpt": "I have been doing NLP/ML research for the last 6 years. I have come across a lot of machine learning resources and papers. Today, I kept thinking about the machine learning / NLP / deep learning related blog posts (not papers) that have been transformational for me.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "243", "lang": "en", "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F06e501e0-26b4-47a4-9718-6ecbcf2d19fc_1668x938.png", "tags": {"deep-learning": {"item_id": "3266868372", "tag": "deep-learning"}, "machine-learning": {"item_id": "3266868372", "tag": "machine-learning"}}, "authors": {"173922699": {"item_id": "3266868372", "author_id": "173922699", "name": "elvis", "url": "https://substack.com/profile/16905758-elvis"}}, "listen_duration_estimate": 94}, "3322333081": {"item_id": "3322333081", "resolved_id": "3322333107", "given_url": "https://towardsdatascience.com/beginner-guide-to-variational-autoencoders-vae-with-pytorch-lightning-part-2-6b79ad697c79?source=rss----7f60cf5620c9---4", "given_title": "", "favorite": "0", "status": "1", "time_added": "1620047400", "time_updated": "1673901753", "time_read": "1620052748", "time_favorited": "0", "sort_id": 100, "resolved_title": "Beginner guide to Variational Autoencoders (VAE) with PyTorch Lightning (Part 2)", "resolved_url": "https://towardsdatascience.com/beginner-guide-to-variational-autoencoders-vae-with-pytorch-lightning-part-2-6b79ad697c79", "excerpt": "In Part 1, we looked at the variational autoencoder, a model based on the autoencoder but allows for data generation. We learned about the overall architecture and the implementation details that allow it to learn successfully.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1289", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/0*eFzoUZatvbK4m3zK", "tags": {"autoencoders": {"item_id": "3322333081", "tag": "autoencoders"}, "deep-learning": {"item_id": "3322333081", "tag": "deep-learning"}, "pytorch": {"item_id": "3322333081", "tag": "pytorch"}}, "authors": {"126262743": {"item_id": "3322333081", "author_id": "126262743", "name": "reo neo", "url": "https://medium.com/@reoneo97"}}, "image": {"item_id": "3322333081", "src": "https://miro.medium.com/fit/c/56/56/1*HD8pJNnA7NpdzOc2JxgcMQ.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3322333081", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*HD8pJNnA7NpdzOc2JxgcMQ.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3322333081", "image_id": "2", "src": "https://miro.medium.com/max/11910/0*eFzoUZatvbK4m3zK", "width": "5955", "height": "3350", "credit": "Marc-Olivier Jodoin on Unsplash", "caption": ""}, "3": {"item_id": "3322333081", "image_id": "3", "src": "https://miro.medium.com/max/1052/1*IDWKLfpuiZ6cYCJmPy97Bg.png", "width": "526", "height": "436", "credit": "", "caption": "Tracking loss function using TensorBoard"}, "4": {"item_id": "3322333081", "image_id": "4", "src": "https://miro.medium.com/max/484/1*TwErmNaLLFdRHWcwtamgAg.png", "width": "242", "height": "242", "credit": "", "caption": ""}, "5": {"item_id": "3322333081", "image_id": "5", "src": "https://miro.medium.com/max/484/1*0yLwZQEs6b8Ni40SqfQqzA.png", "width": "242", "height": "242", "credit": "Left", "caption": "Comparing image sample during first epoch"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 499}, "3328921155": {"item_id": "3328921155", "resolved_id": "3329137732", "given_url": "https://arxiv.org/abs/2105.04026", "given_title": "", "favorite": "0", "status": "1", "time_added": "1651363883", "time_updated": "1651418266", "time_read": "1651418265", "time_favorited": "0", "sort_id": 101, "resolved_title": "Title:The Modern Mathematics of Deep Learning", "resolved_url": "https://arxiv.org/abs/2105.04026v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"arxiv": {"item_id": "3328921155", "tag": "arxiv"}, "deep-learning": {"item_id": "3328921155", "tag": "deep-learning"}}, "authors": {"63380735": {"item_id": "3328921155", "author_id": "63380735", "name": "cs stat stat.ML", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3329055377": {"item_id": "3329055377", "resolved_id": "3318723767", "given_url": "https://t.co/ysoRJp93lk?ssr=true", "given_title": "", "favorite": "0", "status": "1", "time_added": "1620734655", "time_updated": "1656591161", "time_read": "1620841377", "time_favorited": "0", "sort_id": 102, "resolved_title": "", "resolved_url": "https://arxiv.org/abs/2104.13478", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"books": {"item_id": "3329055377", "tag": "books"}, "deep-learning": {"item_id": "3329055377", "tag": "deep-learning"}, "geography": {"item_id": "3329055377", "tag": "geography"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3335039230": {"item_id": "3335039230", "resolved_id": "3335039230", "given_url": "https://venturebeat.com/2021/05/18/google-details-new-ai-accelerator-chips/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1621371170", "time_updated": "1638708525", "time_read": "1621395727", "time_favorited": "0", "sort_id": 103, "resolved_title": "Google details new AI accelerator chips", "resolved_url": "https://venturebeat.com/2021/05/18/google-details-new-ai-accelerator-chips/", "excerpt": "Elevate your enterprise data technology and strategy at Transform 2021. At Google I/O 2021, Google today formally announced its fourth-generation tensor processing units (TPUs), which the company claims can complete AI and machine learning training workloads in close-to-record wall clock time.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "574", "lang": "en", "time_to_read": 3, "amp_url": "https://venturebeat.com/2021/05/18/google-details-new-ai-accelerator-chips/amp/", "top_image_url": "https://venturebeat.com/wp-content/uploads/2020/07/ml-perf-e1595989974532.jpg?w=1200&strip=all", "tags": {"deep-learning": {"item_id": "3335039230", "tag": "deep-learning"}, "semiconductors": {"item_id": "3335039230", "tag": "semiconductors"}, "tpu": {"item_id": "3335039230", "tag": "tpu"}}, "authors": {"89415017": {"item_id": "3335039230", "author_id": "89415017", "name": "Kyle Wiggers", "url": "https://venturebeat.com/author/kylewiggers/"}}, "image": {"item_id": "3335039230", "src": "https://venturebeat.com/wp-content/uploads/2020/07/ml-perf-e1595989974532.jpg?resize=1198%2C600&strip=all", "width": "1200", "height": "600"}, "images": {"1": {"item_id": "3335039230", "image_id": "1", "src": "https://venturebeat.com/wp-content/uploads/2020/07/ml-perf-e1595989974532.jpg?resize=1198%2C600&strip=all", "width": "1200", "height": "600", "credit": "TPUs", "caption": "Tensor processing units"}}, "domain_metadata": {"name": "VentureBeat", "logo": "https://logo.clearbit.com/venturebeat.com?size=800", "greyscale_logo": "https://logo.clearbit.com/venturebeat.com?size=800&greyscale=true"}, "listen_duration_estimate": 222}, "3335081777": {"item_id": "3335081777", "resolved_id": "3335081777", "given_url": "https://ai.facebook.com/blog/pytorchvideo-a-deep-learning-library-for-video-understanding/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1621427197", "time_updated": "1638708525", "time_read": "1621465460", "time_favorited": "0", "sort_id": 104, "resolved_title": "PyTorchVideo: A deep learning library for video understanding", "resolved_url": "https://ai.facebook.com/blog/pytorchvideo-a-deep-learning-library-for-video-understanding/", "excerpt": "PyTorchVideo is a deep learning library for research and applications in video understanding. It provides easy-to-use, efficient, and reproducible implementations of state-of-the-art video models, data sets, transforms, and tools in PyTorch.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "605", "lang": "en", "time_to_read": 3, "tags": {"deep-learning": {"item_id": "3335081777", "tag": "deep-learning"}, "python": {"item_id": "3335081777", "tag": "python"}, "pytorch": {"item_id": "3335081777", "tag": "pytorch"}, "video": {"item_id": "3335081777", "tag": "video"}}, "image": {"item_id": "3335081777", "src": "https://scontent-lga3-2.xx.fbcdn.net/v/t39.2365-6/185917599_1453878801615224_1414293669561819038_n.png?_nc_cat=102&ccb=1-3&_nc_sid=ad8a9d&_nc_ohc=zBtDNQ2truAAX_IWypr&_nc_ht=scontent-lga3-2.xx&oh=c292392753a182066cc36216db5cb5e4&oe=60C8B916", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3335081777", "image_id": "1", "src": "https://scontent-lga3-2.xx.fbcdn.net/v/t39.2365-6/185917599_1453878801615224_1414293669561819038_n.png?_nc_cat=102&ccb=1-3&_nc_sid=ad8a9d&_nc_ohc=zBtDNQ2truAAX_IWypr&_nc_ht=scontent-lga3-2.xx&oh=c292392753a182066cc36216db5cb5e4&oe=60C8B916", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 234}, "3347876702": {"item_id": "3347876702", "resolved_id": "3239387150", "given_url": "https://email.mg2.substack.com/c/eJwlkE1vwyAMhn9NuS3iIwFy4LDLjjtMvUd8uJSVQARkVf79SCtZtmzLev0-VjfwuRxqy7WhMy3t2EAleNYIrUFBe4WyBKcIYdMoZ-TU6IicJAp1uRWAVYeoWtkBbbuJweoWcjoPqJwZFeiuRiLsbI1xYJnUTFvDRi2oBYuJJOP81tW7C5AsKPiDcuQEKKp7a1u9sM8L_erhQ7vvZrB57c13gFh_svfQm2vRqd5yWaHUj-vecgk6VhQUxZRgjll_fqR8IAOfhaZMymniBBNiwFCwhhOjRw5YssuIV0-HupvatH2cYqgo87vZ363v_On2Nexml17XPYV2LJC0ieDeHNqb5ovM4iFB6ZTdopsinFJBMRZYdjIv2x0UE1hwwQjqqi73q6QcwBZBlxSSfwI84vEPRvWPwA", "given_title": "", "favorite": "0", "status": "1", "time_added": "1622726820", "time_updated": "1638708525", "time_read": "1622759063", "time_favorited": "0", "sort_id": 105, "resolved_title": "NielsRogge/Transformers-Tutorials", "resolved_url": "https://github.com/NielsRogge/Transformers-Tutorials", "excerpt": "Hi there! This repository contains demos I made with the Transformers library by ü§ó HuggingFace. Currently, all of them are implemented in PyTorch.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1807", "lang": "en", "time_to_read": 8, "top_image_url": "https://opengraph.githubassets.com/3b208c07dc4ee4522d96eda369ab3bcf27f59e4bd6de79b344609cc919b3d371/NielsRogge/Transformers-Tutorials", "tags": {"deep-learning": {"item_id": "3347876702", "tag": "deep-learning"}, "transformers": {"item_id": "3347876702", "tag": "transformers"}}, "authors": {"172835540": {"item_id": "3347876702", "author_id": "172835540", "name": "NielsRogge", "url": "https://github.com/NielsRogge/Transformers-Tutorials/commits?author=NielsRogge"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 699}, "3352505292": {"item_id": "3352505292", "resolved_id": "3352505292", "given_url": "https://arxiv.org/pdf/2106.04554.pdf", "given_title": "", "favorite": "0", "status": "1", "time_added": "1623669909", "time_updated": "1638708525", "time_read": "1623716076", "time_favorited": "0", "sort_id": 106, "resolved_title": "", "resolved_url": "https://arxiv.org/pdf/2106.04554.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"deep-learning": {"item_id": "3352505292", "tag": "deep-learning"}, "transformers": {"item_id": "3352505292", "tag": "transformers"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3356687434": {"item_id": "3356687434", "resolved_id": "3356687434", "given_url": "https://huggingface.co/course/chapter1", "given_title": "", "favorite": "0", "status": "1", "time_added": "1623785720", "time_updated": "1638708525", "time_read": "1624292704", "time_favorited": "0", "sort_id": 107, "resolved_title": "Introduction", "resolved_url": "https://huggingface.co/course/chapter1", "excerpt": "Welcome to the ü§ó Course! This course will teach you about natural language processing (NLP) using libraries from the Hugging Face ecosystem ‚Äî ü§ó Transformers, ü§ó Datasets, ü§ó Tokenizers, and ü§ó Accelerate ‚Äî as well as the Hugging Face Hub. It‚Äôs completely free and without ads.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "452", "lang": "en", "top_image_url": "https://huggingface.co/front/thumbnails/course.png", "tags": {"deep-learning": {"item_id": "3356687434", "tag": "deep-learning"}, "python": {"item_id": "3356687434", "tag": "python"}, "pytorch": {"item_id": "3356687434", "tag": "pytorch"}}, "image": {"item_id": "3356687434", "src": "https://huggingface.co/course/static/chapter1/summary.png", "width": "100", "height": "0"}, "images": {"1": {"item_id": "3356687434", "image_id": "1", "src": "https://huggingface.co/course/static/chapter1/summary.png", "width": "100", "height": "0", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "3356687434", "video_id": "1", "src": "https://www.youtube-nocookie.com/embed/7PhlevizVB4", "width": "0", "height": "0", "type": "1", "vid": "7PhlevizVB4", "length": "0"}}, "listen_duration_estimate": 175}, "3363845760": {"item_id": "3363845760", "resolved_id": "3357395561", "given_url": "https://link.medium.com/DLlcQFcOjhb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1624437365", "time_updated": "1706233547", "time_read": "1624454064", "time_favorited": "0", "sort_id": 108, "resolved_title": "A Guide to Genetic ‚ÄòLearning‚Äô Algorithms for Optimization", "resolved_url": "https://towardsdatascience.com/a-guide-to-genetic-learning-algorithms-for-optimization-e1067cdc77e7", "excerpt": "In a broader mathematical or computational perspective, an optimization problem is defined as a problem of finding the best solution from all feasible solutions.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1912", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/1200/1*VLCGlJWrtVceZ9NqVqWTxQ.jpeg", "tags": {"algorithms-math": {"item_id": "3363845760", "tag": "algorithms-math"}, "deep-learning": {"item_id": "3363845760", "tag": "deep-learning"}, "image-generation": {"item_id": "3363845760", "tag": "image-generation"}}, "authors": {"128557452": {"item_id": "3363845760", "author_id": "128557452", "name": "Rahulraj Singh", "url": "https://medium.com/@rahul.roger24"}}, "image": {"item_id": "3363845760", "src": "https://miro.medium.com/fit/c/56/56/2*UTAccDYWxJrH9LtJG3iyXw.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3363845760", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*UTAccDYWxJrH9LtJG3iyXw.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3363845760", "image_id": "2", "src": "https://miro.medium.com/max/6144/1*VLCGlJWrtVceZ9NqVqWTxQ.jpeg", "width": "3072", "height": "1723", "credit": "", "caption": "Repeated Gene Mutations and Recursions form the basis of Genetic Algorithm | Image by The Digital Artist on Pixabay"}, "3": {"item_id": "3363845760", "image_id": "3", "src": "https://miro.medium.com/max/1002/1*tcO0tNunf-VIQfROKAzXbQ.png", "width": "501", "height": "224", "credit": "", "caption": "Mechanism of Operation for Reinforcement Learning algorithms | Image by Author"}, "4": {"item_id": "3363845760", "image_id": "4", "src": "https://miro.medium.com/max/3674/1*oxiddevb1NZ6eu-xjf-UdA@2x.jpeg", "width": "1837", "height": "1309", "credit": "RL", "caption": "Adding the Reinforcement Learning"}, "5": {"item_id": "3363845760", "image_id": "5", "src": "https://miro.medium.com/max/4776/1*jl-9WuztuvXulYemQHx9Vw@2x.jpeg", "width": "2388", "height": "1219", "credit": "", "caption": "A General Image Processing Workflow | Image by Author"}, "6": {"item_id": "3363845760", "image_id": "6", "src": "https://miro.medium.com/max/4608/1*N4inyyYCY9URc6x1xAT6TA@2x.jpeg", "width": "2304", "height": "1130", "credit": "", "caption": ""}, "7": {"item_id": "3363845760", "image_id": "7", "src": "https://miro.medium.com/max/7680/0*ZePJOZQKbDXkzRsy", "width": "3840", "height": "5760", "credit": "", "caption": "The majority of Robot Applications we see today are constructed using GAs | Photo by Sebastian Kurpiel on Unsplash"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 740}, "3366588236": {"item_id": "3366588236", "resolved_id": "3364082081", "given_url": "https://www.quantamagazine.org/same-or-different-ai-cant-tell-20210623/?utm_source=DamnInteresting&fbclid=IwAR0tGsjpYIg0UnsKf7ZN_qDqfU0-KFWFKTEUbGxNhzy7scUzixyn8HJDG6s", "given_title": "", "favorite": "0", "status": "1", "time_added": "1624714070", "time_updated": "1638708525", "time_read": "1624744021", "time_favorited": "0", "sort_id": 109, "resolved_title": "Same or Different? The Question Flummoxes Neural Networks.", "resolved_url": "https://www.quantamagazine.org/same-or-different-ai-cant-tell-20210623/", "excerpt": "For all their triumphs, AI systems can‚Äôt seem to generalize the concepts of ‚Äúsame‚Äù and ‚Äúdifferent.‚Äù Without that, researchers worry, the quest to create truly intelligent machines may be hopeless.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1250", "lang": "en", "time_to_read": 6, "top_image_url": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2021/06/Same_different_1200_Social.jpg", "tags": {"deep-learning": {"item_id": "3366588236", "tag": "deep-learning"}, "machine-learning": {"item_id": "3366588236", "tag": "machine-learning"}, "machine-vision": {"item_id": "3366588236", "tag": "machine-vision"}}, "authors": {"39714489": {"item_id": "3366588236", "author_id": "39714489", "name": "John Pavlus", "url": "https://www.quantamagazine.org/authors/john-pavlus/"}}, "image": {"item_id": "3366588236", "src": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2021/06/Same_different_2880x1620_Lede.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3366588236", "image_id": "1", "src": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2021/06/Same_different_2880x1620_Lede.jpg", "width": "0", "height": "0", "credit": "", "caption": "Samuel Velasco/Quanta Magazine"}}, "domain_metadata": {"name": "Quanta Magazine", "logo": "https://logo.clearbit.com/quantamagazine.org?size=800", "greyscale_logo": "https://logo.clearbit.com/quantamagazine.org?size=800&greyscale=true"}, "listen_duration_estimate": 484}, "3372760393": {"item_id": "3372760393", "resolved_id": "3372760393", "given_url": "https://duckduckgo.com/?q=variational+autoencoders&t=canonical&ia=web", "given_title": "", "favorite": "0", "status": "1", "time_added": "1625354076", "time_updated": "1673901753", "time_read": "1625354152", "time_favorited": "0", "sort_id": 110, "resolved_title": "variational autoencoders at DuckDuckGo", "resolved_url": "https://duckduckgo.com/?q=variational+autoencoders&t=canonical&ia=web", "excerpt": "DuckDuckGo. Privacy, Simplified.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"autoencoders": {"item_id": "3372760393", "tag": "autoencoders"}, "deep-learning": {"item_id": "3372760393", "tag": "deep-learning"}, "variational": {"item_id": "3372760393", "tag": "variational"}}, "domain_metadata": {"name": "DuckDuckGo", "logo": "https://logo.clearbit.com/duckduckgo.com?size=800", "greyscale_logo": "https://logo.clearbit.com/duckduckgo.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3373753180": {"item_id": "3373753180", "resolved_id": "3373753180", "given_url": "https://github.com/graviraja/MLOps-Basics", "given_title": "", "favorite": "0", "status": "1", "time_added": "1631625939", "time_updated": "1706833159", "time_read": "1633122054", "time_favorited": "0", "sort_id": 111, "resolved_title": "MLOps-Basics", "resolved_url": "https://github.com/graviraja/MLOps-Basics", "excerpt": "There is nothing magic about magic. The magician merely understands something simple which doesn‚Äôt appear to be simple or natural to the untrained audience. Once you learn how to hold a card while making your hand look empty, you only need practice before you, too, can ‚Äúdo magic.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "751", "lang": "en", "time_to_read": 3, "top_image_url": "https://opengraph.githubassets.com/63bb070132eecca1508a4ea4d16bd8fa39d87df40c3ae5b732fa7ae0533ccd89/graviraja/MLOps-Basics", "tags": {"deep-learning": {"item_id": "3373753180", "tag": "deep-learning"}, "devops": {"item_id": "3373753180", "tag": "devops"}, "machine-learning": {"item_id": "3373753180", "tag": "machine-learning"}, "programming": {"item_id": "3373753180", "tag": "programming"}}, "image": {"item_id": "3373753180", "src": "https://github.com/graviraja/MLOps-Basics/blob/main/images/pl.jpeg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3373753180", "image_id": "1", "src": "https://github.com/graviraja/MLOps-Basics/blob/main/images/pl.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3373753180", "image_id": "2", "src": "https://github.com/graviraja/MLOps-Basics/blob/main/images/wandb.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3373753180", "image_id": "3", "src": "https://github.com/graviraja/MLOps-Basics/blob/main/images/hydra.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3373753180", "image_id": "4", "src": "https://github.com/graviraja/MLOps-Basics/blob/main/images/dvc.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3373753180", "image_id": "5", "src": "https://camo.githubusercontent.com/33504bf8b940c840f4b07e959a7582fb7a6e2a673d1c09001273fcda50cbebc1/68747470733a2f2f696d672e736869656c64732e696f2f7374617469632f76312e7376673f7374796c653d666f722d7468652d6261646765266c6162656c3d646966666963756c7479266d6573736167653d6d656469756d26636f6c6f723d6f72616e6765", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3373753180", "image_id": "6", "src": "https://github.com/graviraja/MLOps-Basics/blob/main/images/onnx.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3373753180", "image_id": "7", "src": "https://github.com/graviraja/MLOps-Basics/blob/main/images/docker_flow.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 291}, "3383786615": {"item_id": "3383786615", "resolved_id": "3383786615", "given_url": "https://paperswithcode.com/newsletter", "given_title": "", "favorite": "0", "status": "1", "time_added": "1626524167", "time_updated": "1638708525", "time_read": "1626779021", "time_favorited": "0", "sort_id": 112, "resolved_title": "Paper with Code Newsletter", "resolved_url": "https://paperswithcode.com/newsletter", "excerpt": "Papers With Code highlights trending Machine Learning research and the code to implement it.", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "top_image_url": "https://paperswithcode.com/static/logo.png", "tags": {"deep-learning": {"item_id": "3383786615", "tag": "deep-learning"}, "machine-learning": {"item_id": "3383786615", "tag": "machine-learning"}, "paperswithcode": {"item_id": "3383786615", "tag": "paperswithcode"}}, "listen_duration_estimate": 0}, "3403298073": {"item_id": "3403298073", "resolved_id": "3403298073", "given_url": "https://www.vice.com/en/article/k78ygn/researchers-create-master-faces-to-bypass-facial-recognition", "given_title": "", "favorite": "0", "status": "1", "time_added": "1628710912", "time_updated": "1628775331", "time_read": "1628775330", "time_favorited": "0", "sort_id": 113, "resolved_title": "Researchers Create 'Master Faces' to Bypass Facial Recognition", "resolved_url": "https://www.vice.com/en/article/k78ygn/researchers-create-master-faces-to-bypass-facial-recognition", "excerpt": "In their paper, researchers at the Blavatnik School of Computer Science and the School of Electrical Engineering in Tel Aviv detail how they successfully created nine \"master key\" faces that are able to impersonate almost half the faces in a dataset of three leading face recognition systems.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "503", "lang": "en", "amp_url": "https://www.vice.com/amp/en/article/k78ygn/researchers-create-master-faces-to-bypass-facial-recognition", "top_image_url": "https://video-images.vice.com/articles/6111605f1540c500957240e0/lede/1628529155600-gettyimages-607358443.jpeg?image-resize-opts=Y3JvcD0xeHc6MC44NDUzNzU3MjI1NDMzNTI2eGg7Y2VudGVyLGNlbnRlciZyZXNpemU9MTIwMDoqJnJlc2l6ZT0xMjAwOio", "tags": {"deep-learning": {"item_id": "3403298073", "tag": "deep-learning"}, "machine-vision": {"item_id": "3403298073", "tag": "machine-vision"}}, "authors": {"152131252": {"item_id": "3403298073", "author_id": "152131252", "name": "Radhamely De Leon", "url": "https://www.vice.com/en/contributor/radhamely-de-leon"}}, "image": {"item_id": "3403298073", "src": "https://video-images.vice.com/articles/6111605f1540c500957240e0/lede/1628529155600-gettyimages-607358443.jpeg?crop=1xw:0.8453757225433526xh;center,center&resize=20:*", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3403298073", "image_id": "1", "src": "https://video-images.vice.com/articles/6111605f1540c500957240e0/lede/1628529155600-gettyimages-607358443.jpeg?crop=1xw:0.8453757225433526xh;center,center&resize=20:*", "width": "0", "height": "0", "credit": "Image: Getty Images", "caption": ""}, "2": {"item_id": "3403298073", "image_id": "2", "src": "https://video-images.vice.com/_uncategorized/1628528999696-image1.png", "width": "518", "height": "494", "credit": "", "caption": ""}}, "domain_metadata": {"name": "VICE", "logo": "https://logo.clearbit.com/vice.com?size=800", "greyscale_logo": "https://logo.clearbit.com/vice.com?size=800&greyscale=true"}, "listen_duration_estimate": 195}, "3425933690": {"item_id": "3425933690", "resolved_id": "3425933690", "given_url": "https://www.exxactcorp.com/blog/Deep-Learning/introduction-to-pytorch-lightning", "given_title": "", "favorite": "0", "status": "1", "time_added": "1633349487", "time_updated": "1638708525", "time_read": "1634511700", "time_favorited": "0", "sort_id": 114, "resolved_title": "An Introduction to PyTorch Lightning", "resolved_url": "https://www.exxactcorp.com/blog/Deep-Learning/introduction-to-pytorch-lightning", "excerpt": "Anyone who‚Äôs been working with deep learning for more than a few years knows that it wasn't always as easy as it is today.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1793", "lang": "en", "time_to_read": 8, "tags": {"deep-learning": {"item_id": "3425933690", "tag": "deep-learning"}, "machine-learning": {"item_id": "3425933690", "tag": "machine-learning"}, "pytorch": {"item_id": "3425933690", "tag": "pytorch"}}, "authors": {"156457556": {"item_id": "3425933690", "author_id": "156457556", "name": "structural biology", "url": "https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology"}}, "image": {"item_id": "3425933690", "src": "https://images.contentstack.io/v3/assets/blt71da4c740e00faaa/bltf231241e1af4b6ce/60c122a42d47ce78c28ad331/grid.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3425933690", "image_id": "1", "src": "https://images.contentstack.io/v3/assets/blt71da4c740e00faaa/bltf231241e1af4b6ce/60c122a42d47ce78c28ad331/grid.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 694}, "3465800320": {"item_id": "3465800320", "resolved_id": "3465800328", "given_url": "https://arxiv.org/abs/2110.13041#", "given_title": "", "favorite": "0", "status": "1", "time_added": "1635294687", "time_updated": "1635468996", "time_read": "1635468996", "time_favorited": "0", "sort_id": 115, "resolved_title": "Title:Applications and Techniques for Fast Machine Learning in Science", "resolved_url": "https://arxiv.org/abs/2110.13041v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"arxiv": {"item_id": "3465800320", "tag": "arxiv"}, "deep-learning": {"item_id": "3465800320", "tag": "deep-learning"}, "machine-learning": {"item_id": "3465800320", "tag": "machine-learning"}}, "authors": {"152897030": {"item_id": "3465800320", "author_id": "152897030", "name": "cs cs.AR physics", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3469204119": {"item_id": "3469204119", "resolved_id": "3469204119", "given_url": "https://e2eml.school/transformers.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1637869636", "time_updated": "1638708525", "time_read": "1638202072", "time_favorited": "0", "sort_id": 116, "resolved_title": "", "resolved_url": "https://e2eml.school/transformers.html", "excerpt": "I procrastinated a deep dive into transformers for a few years. Finally the discomfort of not knowing what makes them tick grew too great for me. Here is that dive. Transformers were introduced in this 2017 paper as a tool for sequence transduction‚Äîconverting one sequence of symbols to another.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "11242", "lang": "", "tags": {"deep-learning": {"item_id": "3469204119", "tag": "deep-learning"}, "transformers": {"item_id": "3469204119", "tag": "transformers"}}, "image": {"item_id": "3469204119", "src": "https://e2eml.school/images/transformers/one_hot_vocabulary.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3469204119", "image_id": "1", "src": "https://e2eml.school/images/transformers/one_hot_vocabulary.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3469204119", "image_id": "2", "src": "https://e2eml.school/images/transformers/one_hot_sentence.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3469204119", "image_id": "3", "src": "https://e2eml.school/images/transformers/dot_product.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3469204119", "image_id": "4", "src": "https://e2eml.school/images/transformers/match.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3469204119", "image_id": "5", "src": "https://e2eml.school/images/transformers/non_match.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3469204119", "image_id": "6", "src": "https://e2eml.school/images/transformers/similarity.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3469204119", "image_id": "7", "src": "https://e2eml.school/images/transformers/matrix_mult_one_row_one_col.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3469204119", "image_id": "8", "src": "https://e2eml.school/images/transformers/matrix_mult_two_row_one_col.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3469204119", "image_id": "9", "src": "https://e2eml.school/images/transformers/matrix_mult_one_row_two_col.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3469204119", "image_id": "10", "src": "https://e2eml.school/images/transformers/matrix_mult_three_row_two_col.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3469204119", "image_id": "11", "src": "https://e2eml.school/images/transformers/markov_chain.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3469204119", "image_id": "12", "src": "https://e2eml.school/images/transformers/transition_matrix.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3469204119", "image_id": "13", "src": "https://e2eml.school/images/transformers/transition_lookups.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "3469204119", "image_id": "14", "src": "https://e2eml.school/images/transformers/markov_chain_2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "3469204119", "image_id": "15", "src": "https://e2eml.school/images/transformers/markov_chain_second_order.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "3469204119", "image_id": "16", "src": "https://e2eml.school/images/transformers/transition_matrix_first_order_2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "3469204119", "image_id": "17", "src": "https://e2eml.school/images/transformers/transition_matrix_second_order.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "3469204119", "image_id": "18", "src": "https://e2eml.school/images/transformers/feature_voting.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "3469204119", "image_id": "19", "src": "https://e2eml.school/images/transformers/transition_matrix_second_order_skips.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "3469204119", "image_id": "20", "src": "https://e2eml.school/images/transformers/feature_selection.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "3469204119", "image_id": "21", "src": "https://e2eml.school/images/transformers/masked_feature_activities.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "3469204119", "image_id": "22", "src": "https://e2eml.school/images/transformers/masked_transition_matrix.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "23": {"item_id": "3469204119", "image_id": "23", "src": "https://e2eml.school/images/transformers/mask_matrix_lookup.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "3469204119", "image_id": "24", "src": "https://e2eml.school/images/transformers/attention_equation_QKT.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "3469204119", "image_id": "25", "src": "https://e2eml.school/images/transformers/feature_creation_layer.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "26": {"item_id": "3469204119", "image_id": "26", "src": "https://e2eml.school/images/transformers/feature_creation_matrix.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "27": {"item_id": "3469204119", "image_id": "27", "src": "https://e2eml.school/images/transformers/second_order_feature_battery.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "28": {"item_id": "3469204119", "image_id": "28", "src": "https://e2eml.school/images/transformers/second_order_feature_program.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "29": {"item_id": "3469204119", "image_id": "29", "src": "https://e2eml.school/images/transformers/feedforward_equations.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "30": {"item_id": "3469204119", "image_id": "30", "src": "https://e2eml.school/images/transformers/architecture_feedforward.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "31": {"item_id": "3469204119", "image_id": "31", "src": "https://e2eml.school/images/transformers/one_hot_vs_embedding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "32": {"item_id": "3469204119", "image_id": "32", "src": "https://e2eml.school/images/transformers/embedded_words.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "33": {"item_id": "3469204119", "image_id": "33", "src": "https://e2eml.school/images/transformers/embedding_projection.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "34": {"item_id": "3469204119", "image_id": "34", "src": "https://e2eml.school/images/transformers/architecture_embedding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "35": {"item_id": "3469204119", "image_id": "35", "src": "https://e2eml.school/images/transformers/positional_encoding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "36": {"item_id": "3469204119", "image_id": "36", "src": "https://e2eml.school/images/transformers/architecture_positional.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "37": {"item_id": "3469204119", "image_id": "37", "src": "https://e2eml.school/images/transformers/de_embedding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "38": {"item_id": "3469204119", "image_id": "38", "src": "https://e2eml.school/images/transformers/de_embedded_results.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "39": {"item_id": "3469204119", "image_id": "39", "src": "https://e2eml.school/images/transformers/architecture_de_embedding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "40": {"item_id": "3469204119", "image_id": "40", "src": "https://e2eml.school/images/transformers/matrix_multiply_shape.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "41": {"item_id": "3469204119", "image_id": "41", "src": "https://e2eml.school/images/transformers/matrix_shapes.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "42": {"item_id": "3469204119", "image_id": "42", "src": "https://e2eml.school/images/transformers/architecture_multihead.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "43": {"item_id": "3469204119", "image_id": "43", "src": "https://e2eml.school/images/transformers/multihead_attention_equation.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "44": {"item_id": "3469204119", "image_id": "44", "src": "https://e2eml.school/images/transformers/architecture_single_head.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "45": {"item_id": "3469204119", "image_id": "45", "src": "https://e2eml.school/images/transformers/attention_equation.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "46": {"item_id": "3469204119", "image_id": "46", "src": "https://e2eml.school/images/transformers/mask.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "47": {"item_id": "3469204119", "image_id": "47", "src": "https://e2eml.school/images/transformers/architecture_add_norm.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "48": {"item_id": "3469204119", "image_id": "48", "src": "https://e2eml.school/images/transformers/skip_connection_gradients.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "49": {"item_id": "3469204119", "image_id": "49", "src": "https://e2eml.school/images/transformers/normalization.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "50": {"item_id": "3469204119", "image_id": "50", "src": "https://e2eml.school/images/transformers/layer_conveyer.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "51": {"item_id": "3469204119", "image_id": "51", "src": "https://e2eml.school/images/transformers/gpt_architecture.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "52": {"item_id": "3469204119", "image_id": "52", "src": "https://e2eml.school/images/transformers/architecture_cross_attention.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 4352}, "3475172610": {"item_id": "3475172610", "resolved_id": "3475172610", "given_url": "https://github.com/louisfb01/best_AI_papers_2021", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638485938", "time_updated": "1638535484", "time_read": "1638535484", "time_favorited": "0", "sort_id": 117, "resolved_title": "2021: A Year Full of Amazing AI papers- A Review üìå", "resolved_url": "https://github.com/louisfb01/best_AI_papers_2021", "excerpt": "2021: A Year Full of Amazing AI papers- A Review üìå A curated list of the latest breakthroughs in AI by release date with a clear video explanation, link to a more in-depth article, and¬†code.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "5411", "lang": "en", "time_to_read": 25, "top_image_url": "https://opengraph.githubassets.com/fb1c6973f8eb18430fea4be9eab642f453e3e0009d93f18cfb391113886be941/louisfb01/best_AI_papers_2021", "tags": {"arxiv": {"item_id": "3475172610", "tag": "arxiv"}, "deep-learning": {"item_id": "3475172610", "tag": "deep-learning"}, "paperswithcode": {"item_id": "3475172610", "tag": "paperswithcode"}}, "authors": {"145487610": {"item_id": "3475172610", "author_id": "145487610", "name": "StyleGAN Interpolation Optimization", "url": ""}}, "image": {"item_id": "3475172610", "src": "https://camo.githubusercontent.com/ac03d4551fb2b24c33e58bcfdde1be521e68380bdb674ff734bdc53a18406028/68747470733a2f2f696d6775722e636f6d2f334f6f4e4f67312e706e67", "width": "512", "height": "0"}, "images": {"1": {"item_id": "3475172610", "image_id": "1", "src": "https://camo.githubusercontent.com/ac03d4551fb2b24c33e58bcfdde1be521e68380bdb674ff734bdc53a18406028/68747470733a2f2f696d6775722e636f6d2f334f6f4e4f67312e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3475172610", "image_id": "2", "src": "https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3475172610", "image_id": "3", "src": "https://camo.githubusercontent.com/654857df9fd7bf3491c650549e85a5f0885ec643b769c97d0d4e8f060e0964f0/68747470733a2f2f696d6775722e636f6d2f437a64797563652e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3475172610", "image_id": "4", "src": "https://camo.githubusercontent.com/9cdda4947f8b5d0c94c7ea663fbee70969323d1fb5c9efecb81411a1bb426f51/68747470733a2f2f696d6775722e636f6d2f46514c396277552e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3475172610", "image_id": "5", "src": "https://camo.githubusercontent.com/43e4dedbd953f8705325634e9653f79ed075ae9754bce1faf0e9dc04b1f89fca/68747470733a2f2f696d6775722e636f6d2f307a555931746d2e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3475172610", "image_id": "6", "src": "https://camo.githubusercontent.com/a89999da84f042015aefc440eadd3f666b4fe5545ae5f225d72a2c18270d6af5/68747470733a2f2f696d6775722e636f6d2f48385835386c622e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3475172610", "image_id": "7", "src": "https://camo.githubusercontent.com/659f7904f8db16bf47e074e150f211a4ae143e69bd7dc2eaae4432a87d195f1f/68747470733a2f2f696d6775722e636f6d2f4d6d6c59626c562e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3475172610", "image_id": "8", "src": "https://camo.githubusercontent.com/70b56c1f96eeb4545b9822178608e71e95c4ba6eca0e74661ed90d456cebd6d9/68747470733a2f2f696d6775722e636f6d2f5756366c7135732e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3475172610", "image_id": "9", "src": "https://camo.githubusercontent.com/1d972300e6ec5b53428c42f081b48b72ed8c11f1c5d0bd14ab1b81d94bd765cd/68747470733a2f2f696d6775722e636f6d2f434a7a474878612e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3475172610", "image_id": "10", "src": "https://camo.githubusercontent.com/383c783dd9d928a7eebcb6f422d0c0c0accc5dab6811005db33c0d75416734b4/68747470733a2f2f696d6775722e636f6d2f564b5a725442482e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3475172610", "image_id": "11", "src": "https://camo.githubusercontent.com/0129edc64e51857cb185698e4ce94853faf28cd777ee0c7f16c59e4354d151d2/68747470733a2f2f696d6775722e636f6d2f7239614c3269552e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3475172610", "image_id": "12", "src": "https://camo.githubusercontent.com/ec90296a1bb5788b3817397cebbb4be4f5f59f459d6ec5306ee409a6a015d971/68747470733a2f2f696d6775722e636f6d2f4a4a35554145702e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3475172610", "image_id": "13", "src": "https://camo.githubusercontent.com/c8a620db88e78103508e944188a852f8d6d01368b8d8fda33054a0b96454760b/68747470733a2f2f696d6775722e636f6d2f5051583850686a2e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "3475172610", "image_id": "14", "src": "https://camo.githubusercontent.com/f27cc7b02ef17b773f39a4dca6c339aad787b90ecafa4ade4d12cadc60f58edf/68747470733a2f2f696d6775722e636f6d2f657a49596365372e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "3475172610", "image_id": "15", "src": "https://camo.githubusercontent.com/1799545a9f506b342726ffb45498f02b2266763ad3ea59d93cfab5685729451d/68747470733a2f2f696d6775722e636f6d2f3037736f736c722e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "3475172610", "image_id": "16", "src": "https://camo.githubusercontent.com/719dd38c489e64bc37d714b8a1bd527745d10c2613d975c75acd882c106342e0/68747470733a2f2f696d6775722e636f6d2f61344b434368662e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "3475172610", "image_id": "17", "src": "https://camo.githubusercontent.com/2a732979092e161e3610861b716916dd21f5460a245566db5c21480431f2aeab/68747470733a2f2f696d6775722e636f6d2f39506d496232652e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "3475172610", "image_id": "18", "src": "https://camo.githubusercontent.com/8fadb1a40cd7c4b39bd756d5140b7f7d73cbba2900f264eeee0316ea947edd97/68747470733a2f2f696d6775722e636f6d2f4d4e705943566a2e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "3475172610", "image_id": "19", "src": "https://camo.githubusercontent.com/4243f9b89748d74686dd526793f07d9e786214f6afb5eeb359d7b1e271efcc52/68747470733a2f2f696d6775722e636f6d2f5a73794a79654a2e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "3475172610", "image_id": "20", "src": "https://camo.githubusercontent.com/64103240ceaabf26d438e00cee5b619e7ad1b366f9ffae069d8d88b0568182a5/68747470733a2f2f696d6775722e636f6d2f365a324f76426d2e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "3475172610", "image_id": "21", "src": "https://camo.githubusercontent.com/971403ac75caf3a1b2c67e0b4273bda3285e588632b77ec7e2ce23a58cb92e25/68747470733a2f2f696d6775722e636f6d2f54597a586351302e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "3475172610", "image_id": "22", "src": "https://camo.githubusercontent.com/2c13237dcd04b625825a9e64e5619053dd204bc29857ab5625aaa2ba48e3d54d/68747470733a2f2f696d6775722e636f6d2f4a444271726c762e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "23": {"item_id": "3475172610", "image_id": "23", "src": "https://camo.githubusercontent.com/cf45ef790fe21210bab5a71a184c9e9b540f00bf53cb5b9134721a00f957699b/68747470733a2f2f696d6775722e636f6d2f4a7961727042762e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "3475172610", "image_id": "24", "src": "https://camo.githubusercontent.com/2f23a1f6b7b3192b3184fd52b2696ca4da7446e3848bd0dd4bbb881c01332f3d/68747470733a2f2f696d6775722e636f6d2f5a5036463953462e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "3475172610", "image_id": "25", "src": "https://camo.githubusercontent.com/6abffd9ec16ea2d1f1446cc83b846b801c8794ad62dce006c2cb69d4e501ed3c/68747470733a2f2f696d6775722e636f6d2f67464f6e686d562e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "26": {"item_id": "3475172610", "image_id": "26", "src": "https://camo.githubusercontent.com/58614835afe0cab6705e2335215929299cb1cfff5c7bc0f85cee6c0c7ce5a714/68747470733a2f2f696d6775722e636f6d2f4842754f7a72472e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "27": {"item_id": "3475172610", "image_id": "27", "src": "https://camo.githubusercontent.com/0d515e5c027e91ca9a3ce38e92650afe10ed26c60e5acb89dba8f3987ed390a5/68747470733a2f2f696d6775722e636f6d2f496472527869782e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "28": {"item_id": "3475172610", "image_id": "28", "src": "https://camo.githubusercontent.com/047bec95179af250d03e9cc03baa95a3b7fa24a39874c4110cbf6f1ae57f3104/68747470733a2f2f696d6775722e636f6d2f7a6244395438652e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "29": {"item_id": "3475172610", "image_id": "29", "src": "https://camo.githubusercontent.com/23dd4026b7d9a2ede1da93294cb74de58f9190d689b2efdfec048a056f2aeac4/68747470733a2f2f696d6775722e636f6d2f4c6f37733764622e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "30": {"item_id": "3475172610", "image_id": "30", "src": "https://camo.githubusercontent.com/795acc254e67b6f906dae08ab4c8111a58bf4d40696ab662100198bfc1ccdf48/68747470733a2f2f696d6775722e636f6d2f4b4a49706d79732e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "31": {"item_id": "3475172610", "image_id": "31", "src": "https://camo.githubusercontent.com/5242fcbc195f2ab112bbf42254747cdb6e3e7713cf826278bf2a15854ad73cd9/68747470733a2f2f696d6775722e636f6d2f5a4634664b33312e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "32": {"item_id": "3475172610", "image_id": "32", "src": "https://camo.githubusercontent.com/3f21ffab234e5a3738df7eb22bcf5012cf0f813d3c8b8c66d61110c860b9223f/68747470733a2f2f696d6775722e636f6d2f344f45373157492e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "33": {"item_id": "3475172610", "image_id": "33", "src": "https://camo.githubusercontent.com/0d8d5092ff44236e53184c2126e27322ab3368a8a1333013f6cc34b04771d70c/68747470733a2f2f696d6775722e636f6d2f6445374d5136452e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "34": {"item_id": "3475172610", "image_id": "34", "src": "https://camo.githubusercontent.com/77352880dbd32838037a25ad40b999aec202c1b51397672e7a123a5b8c25df12/68747470733a2f2f696d6775722e636f6d2f336851655769472e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "35": {"item_id": "3475172610", "image_id": "35", "src": "https://camo.githubusercontent.com/589c4fdb1b3197109bdc4666b6bb7541c3be87b0abd850b3c6e8aadf6700a54a/68747470733a2f2f696d6775722e636f6d2f614d41577a4a552e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "36": {"item_id": "3475172610", "image_id": "36", "src": "https://camo.githubusercontent.com/24be2c1fbc8759c470b5571b499fcdeb7b22dc86ba2cded8adee663af79ce115/68747470733a2f2f696d6775722e636f6d2f57495a597830642e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "37": {"item_id": "3475172610", "image_id": "37", "src": "https://camo.githubusercontent.com/9b6ad6c5d7d20df9c1057ebb01da003d034c33bd2bcfb16242a92f7ed36ffb35/68747470733a2f2f696d6775722e636f6d2f71447976626b762e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "38": {"item_id": "3475172610", "image_id": "38", "src": "https://camo.githubusercontent.com/926ee26b5cd328a7cc13fe25dcb6b4afb5fb15fd339d1a5ae41418ad2d078fb5/68747470733a2f2f696d6775722e636f6d2f454d363875554a2e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "39": {"item_id": "3475172610", "image_id": "39", "src": "https://camo.githubusercontent.com/b7857bc05491e1fa7a6c1a0fe434f21741837cc25e722b8819eb2f5278e8004c/68747470733a2f2f696d6775722e636f6d2f747672304c59392e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}, "40": {"item_id": "3475172610", "image_id": "40", "src": "https://camo.githubusercontent.com/dc9f4ae97c839138e06915f0cea3d38040b3978dad08bfafa49bb1a256057767/68747470733a2f2f696d6775722e636f6d2f51747a366850412e706e67", "width": "512", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 2095}, "3492021007": {"item_id": "3492021007", "resolved_id": "3489008558", "given_url": "https://link.medium.com/cGyoMaNLylb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638126158", "time_updated": "1638708525", "time_read": "1638135852", "time_favorited": "0", "sort_id": 118, "resolved_title": "AI-Based Image Compression: The State of the Art", "resolved_url": "https://towardsdatascience.com/ai-based-image-compression-the-state-of-the-art-fb5aa6042bfa", "excerpt": "Image compression involves reducing the pixels, dimensions or color components of images in order to reduce their file size. This reduces their storage and processing burden (for web performance).", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1204", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/960/0*bfV9kGEdQmSns3w3", "tags": {"deep-learning": {"item_id": "3492021007", "tag": "deep-learning"}, "image-compression": {"item_id": "3492021007", "tag": "image-compression"}}, "authors": {"113414427": {"item_id": "3492021007", "author_id": "113414427", "name": "Gilad David Maayan", "url": "https://medium.com/@giladm_95339"}}, "image": {"item_id": "3492021007", "src": "https://miro.medium.com/fit/c/56/56/2*wnTridTy7lGsfXWBNJZ6_Q.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3492021007", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*wnTridTy7lGsfXWBNJZ6_Q.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3492021007", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*bfV9kGEdQmSns3w3", "width": "700", "height": "319", "credit": "", "caption": "Image Source: Pixabay"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 466}, "3493082098": {"item_id": "3493082098", "resolved_id": "3493082098", "given_url": "https://github.com/bjpcjp/scikit-and-tensorflow-workbooks/blob/master/ch14-Recurrent-NNs.ipynb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638239964", "time_updated": "1642439727", "time_read": "1642439727", "time_favorited": "0", "sort_id": 119, "resolved_title": "", "resolved_url": "https://github.com/bjpcjp/scikit-and-tensorflow-workbooks/blob/master/ch14-Recurrent-NNs.ipynb", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"deep-learning": {"item_id": "3493082098", "tag": "deep-learning"}, "rnns": {"item_id": "3493082098", "tag": "rnns"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3493082100": {"item_id": "3493082100", "resolved_id": "3493082100", "given_url": "https://github.com/bjpcjp/scikit-and-tensorflow-workbooks/blob/master/ch15-autoencoders.ipynb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638239964", "time_updated": "1673901753", "time_read": "1642374645", "time_favorited": "0", "sort_id": 120, "resolved_title": "", "resolved_url": "https://github.com/bjpcjp/scikit-and-tensorflow-workbooks/blob/master/ch15-autoencoders.ipynb", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"autoencoders": {"item_id": "3493082100", "tag": "autoencoders"}, "deep-learning": {"item_id": "3493082100", "tag": "deep-learning"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3493090993": {"item_id": "3493090993", "resolved_id": "3493090993", "given_url": "https://hgpu.org/?p=19047", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638241035", "time_updated": "1638650969", "time_read": "1638650969", "time_favorited": "0", "sort_id": 121, "resolved_title": "Survey paper on Deep Learning on GPUs", "resolved_url": "https://hgpu.org/?p=19047", "excerpt": "The rise of deep-learning (DL) has been fuelled by the improvements in accelerators. GPU continues to remain the most widely used accelerator for DL applications. We present a survey of architecture and system-level techniques for optimizing DL applications on GPUs.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "107", "lang": "en", "top_image_url": "https://hgpu.org/img/social-logo.png", "tags": {"deep-learning": {"item_id": "3493090993", "tag": "deep-learning"}, "gpus": {"item_id": "3493090993", "tag": "gpus"}}, "authors": {"1282511": {"item_id": "3493090993", "author_id": "1282511", "name": "sparsh", "url": ""}}, "listen_duration_estimate": 41}, "3493091032": {"item_id": "3493091032", "resolved_id": "3493091032", "given_url": "https://www.nextplatform.com.cdn.ampproject.org/c/s/www.nextplatform.com/2018/05/10/tearing-apart-googles-tpu-3-0-ai-coprocessor/amp/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638241035", "time_updated": "1638839193", "time_read": "1638839193", "time_favorited": "0", "sort_id": 122, "resolved_title": "Tearing Apart Google‚Äôs TPU 3.0 AI Coprocessor", "resolved_url": "https://www.nextplatform.com.cdn.ampproject.org/c/s/www.nextplatform.com/2018/05/10/tearing-apart-googles-tpu-3-0-ai-coprocessor/amp/", "excerpt": "Google did its best to impress this week at its annual IO conference. While Google rolled out a bunch of benchmarks that were run on its current Cloud TPU instances, based on TPUv2 chips, the company divulged a few skimpy details about its next generation TPU chip and its systems architecture.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2136", "lang": "en", "time_to_read": 10, "top_image_url": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/05/tpu2.jpg", "tags": {"deep-learning": {"item_id": "3493091032", "tag": "deep-learning"}, "tpu": {"item_id": "3493091032", "tag": "tpu"}}, "image": {"item_id": "3493091032", "src": "https://3s81si1s5ygj3mzby34dq6qf--wpengine-netdna--ssl-com.cdn.ampproject.org/i/s/3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/05/tpu2.jpg", "width": "678", "height": "351"}, "images": {"1": {"item_id": "3493091032", "image_id": "1", "src": "https://3s81si1s5ygj3mzby34dq6qf--wpengine-netdna--ssl-com.cdn.ampproject.org/i/s/3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2017/05/tpu2.jpg", "width": "678", "height": "351", "credit": "", "caption": ""}, "2": {"item_id": "3493091032", "image_id": "2", "src": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/image017.jpg", "width": "500", "height": "262", "credit": "left", "caption": "Toroidal mesh interconnect diagrams: 2D"}, "3": {"item_id": "3493091032", "image_id": "3", "src": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/bfloat.jpg", "width": "1088", "height": "610", "credit": "", "caption": ""}, "4": {"item_id": "3493091032", "image_id": "4", "src": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/image019.jpg", "width": "650", "height": "262", "credit": "left", "caption": "Block diagrams: TPUv2"}, "5": {"item_id": "3493091032", "image_id": "5", "src": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/image021.png", "width": "550", "height": "268", "credit": "", "caption": ""}}, "listen_duration_estimate": 827}, "3499221725": {"item_id": "3499221725", "resolved_id": "3499221725", "given_url": "https://github.com/pylabel-project/pylabel", "given_title": "", "favorite": "0", "status": "1", "time_added": "1638913809", "time_updated": "1638962493", "time_read": "1638962493", "time_favorited": "0", "sort_id": 123, "resolved_title": "PyLabel", "resolved_url": "https://github.com/pylabel-project/pylabel", "excerpt": "PyLabel is a Python package to help you prepare image datasets for computer vision models including PyTorch and YOLOv5. It can translate bounding box annotations between different formats. (For example, COCO to YOLO.) And it includes an AI-assisted labeling tool that runs in a Jupyter notebook.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "251", "lang": "en", "top_image_url": "https://opengraph.githubassets.com/3b926b99a1a32553e2c43c658e075bed27500b6c8873673c746a14e3cd67c6c6/pylabel-project/pylabel", "tags": {"deep-learning": {"item_id": "3499221725", "tag": "deep-learning"}, "labeling": {"item_id": "3499221725", "tag": "labeling"}}, "image": {"item_id": "3499221725", "src": "https://camo.githubusercontent.com/0ba569306dd97f7476724c3ef3f5bd60e0cea23440586caf3d5daee0f97b25d4/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f70796c6162656c3f7374796c653d706c6173746963", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3499221725", "image_id": "1", "src": "https://camo.githubusercontent.com/0ba569306dd97f7476724c3ef3f5bd60e0cea23440586caf3d5daee0f97b25d4/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f70796c6162656c3f7374796c653d706c6173746963", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3499221725", "image_id": "2", "src": "https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3499221725", "image_id": "3", "src": "https://raw.githubusercontent.com/pylabel-project/datasets_models/main/pylabel_assets/train_test_split.png", "width": "400", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3499221725", "image_id": "4", "src": "https://raw.githubusercontent.com/pylabel-project/datasets_models/main/pylabel_assets/pylaber_screenshot.png", "width": "400", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 97}, "3504505844": {"item_id": "3504505844", "resolved_id": "3504505844", "given_url": "https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2022/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1639518395", "time_updated": "1639519985", "time_read": "1639519985", "time_favorited": "0", "sort_id": 124, "resolved_title": "PyTorch vs TensorFlow in 2022", "resolved_url": "https://www.assemblyai.com/blog/pytorch-vs-tensorflow-in-2022/", "excerpt": "PyTorch and TensorFlow are far and away the two most popular Deep Learning frameworks today. The debate over which framework is superior is a longstanding point of contentious debate, with each camp having its share of fervent supporters.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "5451", "lang": "en", "time_to_read": 25, "top_image_url": "https://www.assemblyai.com/blog/content/images/2021/12/PyTorch-vs-TensorFlow-in-2022.png", "tags": {"deep-learning": {"item_id": "3504505844", "tag": "deep-learning"}, "machine-learning": {"item_id": "3504505844", "tag": "machine-learning"}, "paperswithcode": {"item_id": "3504505844", "tag": "paperswithcode"}, "pytorch": {"item_id": "3504505844", "tag": "pytorch"}, "tensorflow": {"item_id": "3504505844", "tag": "tensorflow"}}, "authors": {"160653555": {"item_id": "3504505844", "author_id": "160653555", "name": "Ryan O'Connor", "url": "https://www.assemblyai.com/blog/author/ryan/"}}, "image": {"item_id": "3504505844", "src": "https://lh4.googleusercontent.com/Q_STziz6TIpPtb2lxgLA3G7v9ugxDcX_5D5ZnLBl0ZroHrzfBKy-FXP4KNnUsYrGJn4M8fg32JQWgsX-opK5rNqX0dOxrLffKYib7wKnCAP7wiV2PoCQSH1G9362BHXfkwEMlyjN", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3504505844", "image_id": "1", "src": "https://lh4.googleusercontent.com/Q_STziz6TIpPtb2lxgLA3G7v9ugxDcX_5D5ZnLBl0ZroHrzfBKy-FXP4KNnUsYrGJn4M8fg32JQWgsX-opK5rNqX0dOxrLffKYib7wKnCAP7wiV2PoCQSH1G9362BHXfkwEMlyjN", "width": "0", "height": "0", "credit": "", "caption": "Image source"}, "2": {"item_id": "3504505844", "image_id": "2", "src": "https://www.assemblyai.com/blog/content/images/2021/12/Hobbyist_cropped.png", "width": "960", "height": "499", "credit": "", "caption": ""}, "3": {"item_id": "3504505844", "image_id": "3", "src": "https://www.assemblyai.com/blog/content/images/2021/12/Beginner_cropped.png", "width": "960", "height": "546", "credit": "", "caption": ""}}, "listen_duration_estimate": 2110}, "3520056132": {"item_id": "3520056132", "resolved_id": "3520056136", "given_url": "https://arxiv.org/abs/2201.00650", "given_title": "", "favorite": "0", "status": "1", "time_added": "1641311703", "time_updated": "1642360532", "time_read": "1642360532", "time_favorited": "0", "sort_id": 125, "resolved_title": "Title:Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI", "resolved_url": "https://arxiv.org/abs/2201.00650v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"deep-learning": {"item_id": "3520056132", "tag": "deep-learning"}, "interviewing": {"item_id": "3520056132", "tag": "interviewing"}}, "authors": {"106135038": {"item_id": "3520056132", "author_id": "106135038", "name": "cs   cs.AI   cs.IT", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3524055507": {"item_id": "3524055507", "resolved_id": "3521963967", "given_url": "https://link.medium.com/PdMh44o0Fmb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1641730313", "time_updated": "1642360402", "time_read": "1642360402", "time_favorited": "0", "sort_id": 126, "resolved_title": "Curating a Dataset from Raw Images and Videos", "resolved_url": "https://towardsdatascience.com/curating-a-dataset-from-raw-images-and-videos-c8b962eca9ba", "excerpt": "Data is hoarded in large quantities by almost every organization. People coining phrases like ‚Äúdata is the new oil‚Äù further incentivizes this. Visual data is no different. Logs and video snippets are constantly packaged and stored in robot fleets.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2258", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/max/1200/0*xNDajhqQHMydCUrB", "tags": {"datasets": {"item_id": "3524055507", "tag": "datasets"}, "deep-learning": {"item_id": "3524055507", "tag": "deep-learning"}, "machine-vision": {"item_id": "3524055507", "tag": "machine-vision"}}, "authors": {"161621023": {"item_id": "3524055507", "author_id": "161621023", "name": "Mokshith Voodarla", "url": "https://medium.com/@mvoodarla"}}, "image": {"item_id": "3524055507", "src": "https://miro.medium.com/fit/c/56/56/1*FSuXj-pnj4UxvG7kL80f1A.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3524055507", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*FSuXj-pnj4UxvG7kL80f1A.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3524055507", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*xNDajhqQHMydCUrB", "width": "700", "height": "203", "credit": "", "caption": "Image by Author"}, "3": {"item_id": "3524055507", "image_id": "3", "src": "https://miro.medium.com/max/1400/0*ggpimVHI1bEiZbTM", "width": "700", "height": "478", "credit": "", "caption": "Sample Image from CamNet dataset, provided by UC Riverside. Link to raw data."}, "4": {"item_id": "3524055507", "image_id": "4", "src": "https://miro.medium.com/max/2000/0*5zIXu4q5apwNRjxX", "width": "1000", "height": "215", "credit": "", "caption": "Image by Author"}, "5": {"item_id": "3524055507", "image_id": "5", "src": "https://miro.medium.com/max/1400/0*WZ2SFf2mxnv9CAZe", "width": "700", "height": "392", "credit": "", "caption": "Tagged Image from CamNet Dataset by Sieve ‚Äî Image by Author"}, "6": {"item_id": "3524055507", "image_id": "6", "src": "https://miro.medium.com/max/1400/0*VdGvK3LH6PMMxY2y", "width": "700", "height": "629", "credit": "", "caption": "Example Video Filtering Setup, courtesy of Sieve ‚Äî Image by Author"}, "7": {"item_id": "3524055507", "image_id": "7", "src": "https://miro.medium.com/max/1400/0*W4pe5llFy9KvHE0x", "width": "700", "height": "265", "credit": "", "caption": "Example for percentage-based sampling query from Sieve website ‚Äî Image by Author"}, "8": {"item_id": "3524055507", "image_id": "8", "src": "https://miro.medium.com/max/1400/0*C20JQ_9lyrHOxgdQ", "width": "700", "height": "228", "credit": "", "caption": "Create different subset scenarios to test models on, photo from Sieve ‚Äî Image by Author"}, "9": {"item_id": "3524055507", "image_id": "9", "src": "https://miro.medium.com/max/1400/0*4XVJipZFPPDbAtlR", "width": "700", "height": "223", "credit": "", "caption": "Image by Author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 874}, "3526769589": {"item_id": "3526769589", "resolved_id": "3526769589", "given_url": "https://arxiv.org/abs/2201.02605v2", "given_title": "", "favorite": "0", "status": "1", "time_added": "1642022243", "time_updated": "1642028814", "time_read": "1642028813", "time_favorited": "0", "sort_id": 127, "resolved_title": "Title:Detecting Twenty-thousand Classes using Image-level Supervision", "resolved_url": "https://arxiv.org/abs/2201.02605v2", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"arxiv": {"item_id": "3526769589", "tag": "arxiv"}, "deep-learning": {"item_id": "3526769589", "tag": "deep-learning"}, "machine-vision": {"item_id": "3526769589", "tag": "machine-vision"}}, "authors": {"162218028": {"item_id": "3526769589", "author_id": "162218028", "name": "cs", "url": "https://arxiv.org/abs/2201.02605?context=cs"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3547556621": {"item_id": "3547556621", "resolved_id": "3547556621", "given_url": "https://restofworld.org/2022/indus-translation-ai-code-script/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1659476160", "time_updated": "1659479184", "time_read": "1659479184", "time_favorited": "0", "sort_id": 128, "resolved_title": "An ancient language has defied translation for 100 years. Can AI crack the code?", "resolved_url": "https://restofworld.org/2022/indus-translation-ai-code-script/", "excerpt": "Jiaming Luo grew up in mainland China thinking about neglected languages. When he was younger, he wondered why the different languages his mother and father spoke were often lumped together as Chinese ‚Äúdialects.‚Äù", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3195", "lang": "en", "time_to_read": 15, "top_image_url": "https://149346090.v2.pressablecdn.com/wp-content/uploads/2022/01/Indus-768x432.jpg", "tags": {"deep-learning": {"item_id": "3547556621", "tag": "deep-learning"}, "history": {"item_id": "3547556621", "tag": "history"}, "language-linguistics": {"item_id": "3547556621", "tag": "language-linguistics"}}, "authors": {"143203666": {"item_id": "3547556621", "author_id": "143203666", "name": "Alizeh Kohari", "url": "https://restofworld.org/author/alizeh-kohari/"}}, "image": {"item_id": "3547556621", "src": "https://149346090.v2.pressablecdn.com/wp-content/uploads/2022/02/Jiaming-11-600x1066.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3547556621", "image_id": "1", "src": "https://149346090.v2.pressablecdn.com/wp-content/uploads/2022/02/Jiaming-11-600x1066.jpg", "width": "0", "height": "0", "credit": "Tim Dunk for Rest of World", "caption": "Jiaming Luo, a Phd student at the Massachusetts Institute of Technology. Tim Dunk for Rest of World"}, "2": {"item_id": "3547556621", "image_id": "2", "src": "https://149346090.v2.pressablecdn.com/wp-content/uploads/2022/02/Stone1-768x432.png", "width": "0", "height": "0", "credit": "The Trustees of the British Museum", "caption": "A stone stamp-seal found at Harappa in the Indus Valley, mondern-day Pakistan‚Äôs Punjab and Sindh provinces. The Trustees of the British Museum"}, "3": {"item_id": "3547556621", "image_id": "3", "src": "https://149346090.v2.pressablecdn.com/wp-content/uploads/2022/02/Ronojoy-12-600x1066.jpg", "width": "0", "height": "0", "credit": "Tim Dunk for Rest of World", "caption": "Ronojoy Adhikari, a professor of statistical physics at the University of Cambridge. Tim Dunk for Rest of World"}, "4": {"item_id": "3547556621", "image_id": "4", "src": "https://149346090.v2.pressablecdn.com/wp-content/uploads/2022/02/Stone3-768x432.png", "width": "0", "height": "0", "credit": "The Trustees of the British Museum", "caption": "A stamp-seal carved from grey steatite with a rhinoceros and an inscription in the Indus script, found at the Mohenjo-daro archaeological site in Sindh, Pakistan. The Trustees of the British Museum"}, "5": {"item_id": "3547556621", "image_id": "5", "src": "https://149346090.v2.pressablecdn.com/wp-content/uploads/2022/02/Bahata-14-600x1000.jpg", "width": "0", "height": "0", "credit": "Tim Dunk for Rest of World", "caption": "Bahata Ansumali Mukhopadhyay, a researcher of Indus script. Tim Dunk for Rest of World"}, "6": {"item_id": "3547556621", "image_id": "6", "src": "https://149346090.v2.pressablecdn.com/wp-content/uploads/2022/02/Stone2-768x432.png", "width": "0", "height": "0", "credit": "The Trustees of the British Museum", "caption": "A stamp-seal made of glazed white steatite with a bull standing over a manger, found in Babylon, Iraq. The Trustees of the British Museum"}}, "listen_duration_estimate": 1237}, "3560623648": {"item_id": "3560623648", "resolved_id": "2813929046", "given_url": "https://mlwhiz.com/blog/2019/12/05/od/?utm_campaign=demystifying-object-detection-and-instance-segmentation-for-data-scientists&utm_medium=social_link&utm_source=missinglettr", "given_title": "", "favorite": "0", "status": "1", "time_added": "1662388521", "time_updated": "1662416124", "time_read": "1662416123", "time_favorited": "0", "sort_id": 129, "resolved_title": "Demystifying Object Detection and Instance Segmentation for Data Scientists", "resolved_url": "https://mlwhiz.com/blog/2019/12/05/od/", "excerpt": "And Object detection is important and does have its uses. Most common of them being self-driving cars, medical imaging and face detection. It is definitely a hard problem to solve.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3493", "lang": "en", "time_to_read": 16, "top_image_url": "https://mlwhiz.com/images/od/main.jpeg", "tags": {"deep-learning": {"item_id": "3560623648", "tag": "deep-learning"}, "machine-learning": {"item_id": "3560623648", "tag": "machine-learning"}, "object-detection": {"item_id": "3560623648", "tag": "object-detection"}}, "authors": {"8623619": {"item_id": "3560623648", "author_id": "8623619", "name": "Rahul Agarwal", "url": ""}}, "image": {"item_id": "3560623648", "src": "https://mlwhiz.com/images/od/0.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3560623648", "image_id": "1", "src": "https://mlwhiz.com/images/od/0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3560623648", "image_id": "2", "src": "https://mlwhiz.com/images/od/1.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3560623648", "image_id": "3", "src": "https://mlwhiz.com/images/od/2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3560623648", "image_id": "4", "src": "https://mlwhiz.com/images/od/3.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3560623648", "image_id": "5", "src": "https://mlwhiz.com/images/od/4.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3560623648", "image_id": "6", "src": "https://mlwhiz.com/images/od/5.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3560623648", "image_id": "7", "src": "https://mlwhiz.com/images/od/6.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3560623648", "image_id": "8", "src": "https://mlwhiz.com/images/od/7.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3560623648", "image_id": "9", "src": "https://mlwhiz.com/images/od/8.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3560623648", "image_id": "10", "src": "https://mlwhiz.com/images/od/9.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3560623648", "image_id": "11", "src": "https://mlwhiz.com/images/od/11.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3560623648", "image_id": "12", "src": "https://mlwhiz.com/images/od/12.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3560623648", "image_id": "13", "src": "https://mlwhiz.com/images/od/13.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "3560623648", "image_id": "14", "src": "https://mlwhiz.com/images/od/14.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "3560623648", "image_id": "15", "src": "https://mlwhiz.com/images/od/15.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "3560623648", "image_id": "16", "src": "https://mlwhiz.com/images/od/16.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "3560623648", "image_id": "17", "src": "https://mlwhiz.com/images/od/17.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "3560623648", "image_id": "18", "src": "https://mlwhiz.com/images/od/18.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "3560623648", "image_id": "19", "src": "https://mlwhiz.com/images/od/19.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "3560623648", "image_id": "20", "src": "https://mlwhiz.com/images/od/20.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1352}, "3587663927": {"item_id": "3587663927", "resolved_id": "3578791287", "given_url": "https://link.medium.com/Mv5y1iN5Tob", "given_title": "", "favorite": "0", "status": "1", "time_added": "1648918614", "time_updated": "1673901753", "time_read": "1648943586", "time_favorited": "0", "sort_id": 130, "resolved_title": "Autoencoders (AE)‚Ää‚Äî‚ÄäA Smart Way to Process Your Data Using Unsupervised Neural Networks", "resolved_url": "https://towardsdatascience.com/autoencoders-ae-a-smart-way-to-process-your-data-using-unsupervised-neural-networks-9661f93a8509", "excerpt": "Autoencoders present an efficient way to learn a representation of your data that focuses on the signal, not the noise. You can use them for a variety of tasks such as:", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1132", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/1*JgMGbqdPXCpDjfbQWzyAzQ.png", "tags": {"autoencoders": {"item_id": "3587663927", "tag": "autoencoders"}, "deep-learning": {"item_id": "3587663927", "tag": "deep-learning"}}, "authors": {"148379686": {"item_id": "3587663927", "author_id": "148379686", "name": "Saul Dobilas", "url": "https://solclover.com"}}, "image": {"item_id": "3587663927", "src": "https://miro.medium.com/max/1400/1*JgMGbqdPXCpDjfbQWzyAzQ.png", "width": "700", "height": "586"}, "images": {"1": {"item_id": "3587663927", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*JgMGbqdPXCpDjfbQWzyAzQ.png", "width": "700", "height": "586", "credit": "", "caption": "Undercomplete Autoencoders. Image by author, created using AlexNail‚Äôs NN-SVG tool."}, "2": {"item_id": "3587663927", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*1JwnlfIm4MmlFcPH5QaUIg.png", "width": "700", "height": "427", "credit": "", "caption": "A high-level illustration of layers within an Autoencoder Neural Network. Image by author."}, "3": {"item_id": "3587663927", "image_id": "3", "src": "https://miro.medium.com/max/2708/1*qkXay39OnVc2IosW6rkxtw.png", "width": "1354", "height": "460", "credit": "", "caption": ""}, "4": {"item_id": "3587663927", "image_id": "4", "src": "https://miro.medium.com/max/2708/1*vabxOXtQ4T034N_mscHSmQ.png", "width": "1354", "height": "460", "credit": "", "caption": ""}, "5": {"item_id": "3587663927", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*Cc-HFI93fc3mc56YWPn95A.png", "width": "700", "height": "638", "credit": "", "caption": "Undercomplete Autoencoder. Image by author, created using AlexNail‚Äôs NN-SVG tool."}, "6": {"item_id": "3587663927", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*C7cJ7SUyZ0TL5OW-H5EdAg.png", "width": "700", "height": "357", "credit": "", "caption": "A snippet of Kaggle‚Äôs Australian weather data with some modifications. Image by author."}, "7": {"item_id": "3587663927", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*P3m2edKPTzoX-JJetMkYsA.png", "width": "700", "height": "643", "credit": "", "caption": "Autoencoder model summary. Image by author."}, "8": {"item_id": "3587663927", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*EgSCTvKKxh1-bMCUaKkpgw.png", "width": "700", "height": "1391", "credit": "", "caption": "Autoencoder model diagram. Image by author."}, "9": {"item_id": "3587663927", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*TVXOmG9-0k6T_IXB6mth-A.png", "width": "700", "height": "401", "credit": "", "caption": "Autoencoder model loss by epoch. Image by author."}, "10": {"item_id": "3587663927", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*6VBiWFiTu0ex1FW-pILKEg.png", "width": "700", "height": "749", "credit": "", "caption": "Encoder model diagram. Image by author."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 438}, "3589009231": {"item_id": "3589009231", "resolved_id": "3589009231", "given_url": "http://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1649278135", "time_updated": "1649451252", "time_read": "1649451253", "time_favorited": "0", "sort_id": 131, "resolved_title": "Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance", "resolved_url": "http://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html", "excerpt": "In recent years, large neural networks trained for language understanding and generation have achieved impressive results across a wide range of tasks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1569", "lang": "en", "time_to_read": 7, "top_image_url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLXCWMlipdu0gFF6hsiJHbxg1zSaEkdDWfl-8RakQuW__8RPvlOS9KGIScNCytxT4jz9isnx0GLMwbS1G0Q4WdXzT42GszgfwIIAVX1H3J-43lVWWqcb--q9cPsxCsJFFz2dRfpKgEmLe-xfIyBqQuPq1BPYcK9CtAK1_xnhgvgAAx0GeZmODJxGNMYQ/s72-c/image8.gif", "tags": {"deep-learning": {"item_id": "3589009231", "tag": "deep-learning"}}, "authors": {"56442592": {"item_id": "3589009231", "author_id": "56442592", "name": "Sharan Narang", "url": ""}, "84774930": {"item_id": "3589009231", "author_id": "84774930", "name": "Aakanksha Chowdhery", "url": ""}}, "image": {"item_id": "3589009231", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLXCWMlipdu0gFF6hsiJHbxg1zSaEkdDWfl-8RakQuW__8RPvlOS9KGIScNCytxT4jz9isnx0GLMwbS1G0Q4WdXzT42GszgfwIIAVX1H3J-43lVWWqcb--q9cPsxCsJFFz2dRfpKgEmLe-xfIyBqQuPq1BPYcK9CtAK1_xnhgvgAAx0GeZmODJxGNMYQ/s16000/image8.gif", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3589009231", "image_id": "1", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgLXCWMlipdu0gFF6hsiJHbxg1zSaEkdDWfl-8RakQuW__8RPvlOS9KGIScNCytxT4jz9isnx0GLMwbS1G0Q4WdXzT42GszgfwIIAVX1H3J-43lVWWqcb--q9cPsxCsJFFz2dRfpKgEmLe-xfIyBqQuPq1BPYcK9CtAK1_xnhgvgAAx0GeZmODJxGNMYQ/s16000/image8.gif", "width": "0", "height": "0", "credit": "", "caption": "As the scale of the model increases, the performance improves across tasks while also unlocking new capabilities."}, "2": {"item_id": "3589009231", "image_id": "2", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhJ0IurIGscLmiuGVKNqXv3G_vKjlSpRbL_wkMSSiva3SGwOtHcHKWGab324yW6-TpmfnsNNlO9fqw2KtqFPa6X4AwAqdLSlEkPsF22NZSu1HaaOImnshjq0ahMlr6C1sh5NlvnZ2OqFg0D-7FY5w1KR-mqy3IJPOvqe6hrRfGcabJa7xSjhtYbWv4SiA/s1312/chart.png", "width": "0", "height": "0", "credit": "SOTA", "caption": "PaLM 540B performance improvement over prior state-of-the-art"}, "3": {"item_id": "3589009231", "image_id": "3", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgz-gW-L-HTRNa4FFX_HrnUnoQhXc2b7tjd-NFV_3KqG0n2pDrPzAhP-3Zx70jtygkDZV_VeE6u-XCjRWgY3ec_Ise8lK02iRuv6VzhJcayGnze6fv65oc3TgZ6JvfRso_xCW56-xI4xnScI0-oVsOu2kH3mBoU1CvtBVD99twdUtqsxyJj1DlAt3m1nQ/s1172/Screenshot%202022-04-01%205.25.47%20PM.png", "width": "0", "height": "0", "credit": "", "caption": "Scaling behavior of PaLM on a subset of 58 BIG-bench tasks."}, "4": {"item_id": "3589009231", "image_id": "4", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiCZkpChUnyojDE_nPmg-xZyTFgjo4qgBB7Pmbi0ZlIVNiiD2DXV1dcMW-QMIn-CTNNTA7bJlln0p8wuNju06E62adtn4C-sRngwKhvhA1-f0-8knYuWB-m3MyIXclYAQNkojWaf-kfibm1OjFfhC45EHkeJkVNKid-K2dd_O1c5H-rVx8ypOTuQv8ELQ/s1228/Screenshot%202022-04-01%205.34.54%20PM.png", "width": "0", "height": "0", "credit": "highlighted in yellow", "caption": "Standard prompting versus chain-of-thought prompting for an example grade-school math problem. Chain-of-thought prompting decomposes the prompt for a multi-step reasoning problem into intermediate steps"}, "5": {"item_id": "3589009231", "image_id": "5", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgHKfA6Vxw9li1vDfDChv-yzCp4ubKpOR2D62IMui3mAe5Un0jZ3P2_60stEZdtJNUt1b2XNzXbPoM0EO6B7UGneMd-2Bq0JK0gC5rIMSgQM02jwe5VmGxYLo_jz78vnG79oDIpv3mNu6kD0tqAUT6pcYkbkRpeoO9P-92I5O8ZsZefCpcxfIfEJREAyA/s1999/image5.png", "width": "0", "height": "0", "credit": "", "caption": "PaLM explains an original joke with two-shot prompts."}, "6": {"item_id": "3589009231", "image_id": "6", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjU6EWTNme8i8UftAzTxGA9X0n8nLzA5pkVV0BgzCRrxqddh7A65r4_svL5vYJl49HWN2QYNRFQgF6TrGpncz2Q_TuLvA2ynGZq9wnFP7wEnhSbkS-_viwhHtdahGozhCxHeILT7XS4w4cfGkJtum5nbUk6Mi9TP5s_OWRkvPAznhfWIOsvuVX8QgoisA/s2951/deepfix_task_879.png", "width": "0", "height": "0", "credit": "left, in red", "caption": "An example from the DeepFix Code Repair task. The fine-tuned PaLM-Coder 540B fixes compilation errors"}}, "listen_duration_estimate": 607}, "3609218254": {"item_id": "3609218254", "resolved_id": "3609218254", "given_url": "https://www.nytimes.com/2022/05/02/technology/google-fires-ai-researchers.html", "given_title": "", "favorite": "0", "status": "1", "time_added": "1651493319", "time_updated": "1656167906", "time_read": "1651496130", "time_favorited": "0", "sort_id": 132, "resolved_title": "Another Firing Among Google‚Äôs A.I. Brain Trust, and More Discord", "resolved_url": "https://www.nytimes.com/2022/05/02/technology/google-fires-ai-researchers.html", "excerpt": "Less than two years after Google dismissed two researchers who criticized the biases built into artificial intelligence systems, the company has fired a researcher who questioned a paper it published on the abilities of a specialized type of artificial intelligence used in making computer chips.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1373", "lang": "en", "time_to_read": 6, "top_image_url": "https://static01.nyt.com/images/2022/04/25/business/00aiexodus1/00aiexodus1-facebookJumbo.jpg?year=2022&h=550&w=1050&s=04b9a6403606dfe18eed4b6d3fa17795aa738498fba759d59bbca6e5e03b5696&k=ZQJBKqZ0VN", "tags": {"arxiv": {"item_id": "3609218254", "tag": "arxiv"}, "chip-design": {"item_id": "3609218254", "tag": "chip-design"}, "deep-learning": {"item_id": "3609218254", "tag": "deep-learning"}, "semiconductors": {"item_id": "3609218254", "tag": "semiconductors"}}, "authors": {"82689593": {"item_id": "3609218254", "author_id": "82689593", "name": "Cade Metz", "url": "https://www.nytimes.com/by/cade-metz"}, "89773737": {"item_id": "3609218254", "author_id": "89773737", "name": "Daisuke Wakabayashi", "url": "https://www.nytimes.com/by/daisuke-wakabayashi"}}, "image": {"item_id": "3609218254", "src": "https://static01.nyt.com/images/2022/04/25/business/00aiexodus1/merlin_178423734_12da72a6-6b6b-495e-b905-a3c7cba1d7a4-articleLarge.jpg?quality=75&auto=webp&disable=upscale", "width": "600", "height": "400"}, "images": {"1": {"item_id": "3609218254", "image_id": "1", "src": "https://static01.nyt.com/images/2022/04/25/business/00aiexodus1/merlin_178423734_12da72a6-6b6b-495e-b905-a3c7cba1d7a4-articleLarge.jpg?quality=75&auto=webp&disable=upscale", "width": "600", "height": "400", "credit": "", "caption": ""}, "2": {"item_id": "3609218254", "image_id": "2", "src": "https://static01.nyt.com/images/2018/07/30/multimedia/author-daisuke-wakabayashi/author-daisuke-wakabayashi-thumbLarge.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3609218254", "image_id": "3", "src": "https://static01.nyt.com/images/2018/11/26/multimedia/author-cade-metz/author-cade-metz-thumbLarge.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The New York Times", "logo": "https://logo.clearbit.com/nytimes.com?size=800", "greyscale_logo": "https://logo.clearbit.com/nytimes.com?size=800&greyscale=true"}, "listen_duration_estimate": 531}, "3626021631": {"item_id": "3626021631", "resolved_id": "3626021631", "given_url": "https://towardsdatascience.com/similarity-search-with-ivfpq-9c6348fd4db3", "given_title": "", "favorite": "0", "status": "1", "time_added": "1663460615", "time_updated": "1665774107", "time_read": "1665774107", "time_favorited": "0", "sort_id": 133, "resolved_title": "Similarity Search with IVFPQ", "resolved_url": "https://towardsdatascience.com/similarity-search-with-ivfpq-9c6348fd4db3", "excerpt": "In the previous article on Product Quantization for Similarity Search, we explained what product quantization is and went through in detail how product quantization works for similarity search.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1873", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/892/1*mW-Au0Aicq3ZHt_dXc_jbQ.png", "tags": {"deep-learning": {"item_id": "3626021631", "tag": "deep-learning"}, "search": {"item_id": "3626021631", "tag": "search"}}, "authors": {"155494397": {"item_id": "3626021631", "author_id": "155494397", "name": "Peggy Chang", "url": "https://peggy1502.medium.com"}}, "image": {"item_id": "3626021631", "src": "https://miro.medium.com/max/1400/1*mW-Au0Aicq3ZHt_dXc_jbQ.png", "width": "700", "height": "443"}, "images": {"1": {"item_id": "3626021631", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*mW-Au0Aicq3ZHt_dXc_jbQ.png", "width": "700", "height": "443", "credit": "", "caption": "Voronoi cells. All images are by the author unless otherwise specified"}, "2": {"item_id": "3626021631", "image_id": "2", "src": "https://miro.medium.com/max/850/1*BtuQKl80aU1b8WSZxMKh9Q.png", "width": "425", "height": "299", "credit": "", "caption": ""}, "3": {"item_id": "3626021631", "image_id": "3", "src": "https://miro.medium.com/max/1206/1*bInx8pS8USZK4_mNCf59Bg.png", "width": "603", "height": "334", "credit": "", "caption": "Example of Voronoi cells"}, "4": {"item_id": "3626021631", "image_id": "4", "src": "https://miro.medium.com/max/1286/1*o6tLFAPCY5kZWIGOLOn8gw.png", "width": "643", "height": "303", "credit": "", "caption": "Computing residual, the offset of the vector from its partition centroid"}, "5": {"item_id": "3626021631", "image_id": "5", "src": "https://miro.medium.com/max/918/1*dYa4Ltel6uvSOn2emvUlqg.png", "width": "459", "height": "426", "credit": "", "caption": "First plot ‚Äî Original vectors with two partitions"}, "6": {"item_id": "3626021631", "image_id": "6", "src": "https://miro.medium.com/max/1008/1*IpQ2CU7pLZsyJ5GHbd6-7A.png", "width": "504", "height": "432", "credit": "", "caption": "Second plot ‚Äî Residual vectors"}, "7": {"item_id": "3626021631", "image_id": "7", "src": "https://miro.medium.com/max/1086/1*7UyGJJUczxctJ7jPoVyptA.png", "width": "543", "height": "488", "credit": "", "caption": "The product quantization training and encoding process"}, "8": {"item_id": "3626021631", "image_id": "8", "src": "https://miro.medium.com/max/1092/1*Z4X6nergVs5Svg2fqwQFug.png", "width": "546", "height": "368", "credit": "", "caption": "An inverted list entry consisting of Vector Id and PQ code"}, "9": {"item_id": "3626021631", "image_id": "9", "src": "https://miro.medium.com/max/1216/1*LNC39yBtm0WsIY-RKKGyWQ.png", "width": "608", "height": "397", "credit": "", "caption": ""}, "10": {"item_id": "3626021631", "image_id": "10", "src": "https://miro.medium.com/max/1364/1*NCraGdCIeGBt0GZmqZOkQA.png", "width": "682", "height": "690", "credit": "IVFPQ", "caption": "Similarity search with inverted file index and product quantization"}, "11": {"item_id": "3626021631", "image_id": "11", "src": "https://miro.medium.com/max/1400/0*kYvPP5cXW9gOJUKl", "width": "700", "height": "394", "credit": "James Baltz on Unsplash", "caption": ""}, "12": {"item_id": "3626021631", "image_id": "12", "src": "https://miro.medium.com/fit/c/40/40/1*4RiPT4MGaV1PUkLGaNirFQ.png", "width": "20", "height": "20", "credit": "", "caption": ""}, "13": {"item_id": "3626021631", "image_id": "13", "src": "https://miro.medium.com/fit/c/388/388/1*c0gU2CkZ880j1_pfnGS1fw.png", "width": "194", "height": "194", "credit": "", "caption": ""}, "14": {"item_id": "3626021631", "image_id": "14", "src": "https://miro.medium.com/fit/c/388/388/1*2hR-6vz3mdHIh8hS0GXanA.png", "width": "194", "height": "194", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 725}, "3629605227": {"item_id": "3629605227", "resolved_id": "3629605227", "given_url": "https://astralcodexten.substack.com/p/a-guide-to-asking-robots-to-design", "given_title": "", "favorite": "0", "status": "1", "time_added": "1653960102", "time_updated": "1654123063", "time_read": "1654123063", "time_favorited": "0", "sort_id": 134, "resolved_title": "A Guide To Asking Robots To Design Stained Glass Windows", "resolved_url": "https://astralcodexten.substack.com/p/a-guide-to-asking-robots-to-design", "excerpt": "I love stained glass. Not so much your usual suburban house stained glass with a picture of lilies. The good stuff. Cathedral windows, Art Nouveau, Art Deco. Why did we stop doing that? I blame the conspiracy. Recently I‚Äôve been experimenting with small-scale alternatives.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2816", "lang": "en", "time_to_read": 13, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc97677e3-9c88-4c6c-85b2-93fc66788b54_323x239.png", "tags": {"deep-learning": {"item_id": "3629605227", "tag": "deep-learning"}, "image-generation": {"item_id": "3629605227", "tag": "image-generation"}}, "authors": {"2827369": {"item_id": "3629605227", "author_id": "2827369", "name": "Scott Alexander", "url": ""}}, "image": {"item_id": "3629605227", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F328f57c7-98f0-443d-b39a-20ebdb816417_672x257.png", "width": "696", "height": "266"}, "images": {"1": {"item_id": "3629605227", "image_id": "1", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F328f57c7-98f0-443d-b39a-20ebdb816417_672x257.png", "width": "696", "height": "266", "credit": "", "caption": ""}, "2": {"item_id": "3629605227", "image_id": "2", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F306201a2-9715-43d4-a406-a72d8b53cbd5_746x241.png", "width": "746", "height": "241", "credit": "", "caption": "If Darwin had really looked like this, I bet he would have had an easier time convincing people of evolution."}, "3": {"item_id": "3629605227", "image_id": "3", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faff70a0c-4205-4968-869d-cb67235f0e9b_697x260.png", "width": "697", "height": "260", "credit": "", "caption": ""}, "4": {"item_id": "3629605227", "image_id": "4", "src": "https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3ef36b98-e19e-4abb-8a9a-79970172f2d0_304x326.gif", "width": "270", "height": "290", "credit": "", "caption": ""}, "5": {"item_id": "3629605227", "image_id": "5", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5a4bee1-e12e-4db5-b660-bffad1473d6b_694x277.png", "width": "694", "height": "277", "credit": "", "caption": ""}, "6": {"item_id": "3629605227", "image_id": "6", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd26593ca-fafb-4b43-9a50-983616dce1cf_680x249.png", "width": "680", "height": "249", "credit": "", "caption": ""}, "7": {"item_id": "3629605227", "image_id": "7", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fbada9fa0-fae1-4c7f-b2e3-0b69daea2176_739x278.png", "width": "739", "height": "278", "credit": "", "caption": "Is it just me, or is that last one Elon Musk?"}, "8": {"item_id": "3629605227", "image_id": "8", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0f6ceed-f556-4225-b7bf-0d891eafe878_742x280.png", "width": "742", "height": "280", "credit": "", "caption": ""}, "9": {"item_id": "3629605227", "image_id": "9", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff105b46a-78cd-4959-af6b-bf371ba31b95_749x296.png", "width": "749", "height": "296", "credit": "", "caption": ""}, "10": {"item_id": "3629605227", "image_id": "10", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F62894192-86fb-4f14-8143-b2669baa1108_785x306.png", "width": "785", "height": "306", "credit": "", "caption": ""}, "11": {"item_id": "3629605227", "image_id": "11", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5984e6aa-958c-4da4-a27e-c8eba6dd3eff_782x295.png", "width": "782", "height": "295", "credit": "", "caption": ""}, "12": {"item_id": "3629605227", "image_id": "12", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0195f7ea-ba82-4c89-92d3-90452d905a50_781x298.png", "width": "781", "height": "298", "credit": "", "caption": ""}, "13": {"item_id": "3629605227", "image_id": "13", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F26e64e83-a87d-4a16-a32d-6f7bb593c920_785x289.png", "width": "785", "height": "289", "credit": "", "caption": ""}, "14": {"item_id": "3629605227", "image_id": "14", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff2a50b69-6a59-4598-a3e1-bd53c26e84f3_786x300.png", "width": "786", "height": "300", "credit": "", "caption": ""}, "15": {"item_id": "3629605227", "image_id": "15", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F63170470-b383-4e7e-9673-a6f01e61d40d_792x293.png", "width": "792", "height": "293", "credit": "", "caption": "GILA-WHAMM!"}, "16": {"item_id": "3629605227", "image_id": "16", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fef8dbcca-99db-4193-ac33-a648c556399f_450x337.png", "width": "450", "height": "337", "credit": "", "caption": ""}, "17": {"item_id": "3629605227", "image_id": "17", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0e7927e-0f92-4aff-8006-b1b5ffc45768_483x208.png", "width": "483", "height": "208", "credit": "", "caption": ""}, "18": {"item_id": "3629605227", "image_id": "18", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb873030-45f3-4362-95c6-bc9e7e0d6849_786x289.png", "width": "786", "height": "289", "credit": "", "caption": ""}, "19": {"item_id": "3629605227", "image_id": "19", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6a07a6c3-af87-4359-80df-6073d3d821dc_810x287.png", "width": "810", "height": "287", "credit": "", "caption": "I wish I was as sure of anything as DALL-E is as sure that William Ockham had a giant red beard. Or that ‚ÄúWilliam Ockham‚Äù is spelled ‚ÄúTHAMHHH AR‚Äù"}, "20": {"item_id": "3629605227", "image_id": "20", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8b3b08f-bca1-4966-a198-6ec92627da30_799x314.png", "width": "799", "height": "314", "credit": "", "caption": ""}, "21": {"item_id": "3629605227", "image_id": "21", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc35a32fb-7274-4c52-89d9-f4f44551273f_796x316.png", "width": "796", "height": "316", "credit": "", "caption": ""}, "22": {"item_id": "3629605227", "image_id": "22", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8a5ec912-da3e-4724-b65c-7818df0816fc_775x299.png", "width": "775", "height": "299", "credit": "", "caption": ""}, "23": {"item_id": "3629605227", "image_id": "23", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F98f6d95a-0ed1-4889-91bc-a63dfe8879ec_763x289.png", "width": "763", "height": "289", "credit": "", "caption": ""}, "24": {"item_id": "3629605227", "image_id": "24", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7ce8bd33-5788-4e06-933c-31bc8ae90031_688x277.png", "width": "688", "height": "277", "credit": "", "caption": ""}, "25": {"item_id": "3629605227", "image_id": "25", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fbcd12d10-4826-465f-8294-f472cc4147e6_778x282.png", "width": "778", "height": "282", "credit": "", "caption": ""}, "26": {"item_id": "3629605227", "image_id": "26", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5eb34e40-29b3-4a47-8461-8e62efa5c2ed_800x304.png", "width": "800", "height": "304", "credit": "", "caption": ""}, "27": {"item_id": "3629605227", "image_id": "27", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd0b6579d-3f44-4e08-be82-15720890f4fc_395x335.png", "width": "395", "height": "335", "credit": "", "caption": ""}, "28": {"item_id": "3629605227", "image_id": "28", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe26be402-2915-4eca-9efe-a9295f9d4b30_786x292.png", "width": "786", "height": "292", "credit": "", "caption": ""}, "29": {"item_id": "3629605227", "image_id": "29", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4f1c5f9-99ac-45af-86ad-217295204faa_779x306.png", "width": "779", "height": "306", "credit": "", "caption": ""}, "30": {"item_id": "3629605227", "image_id": "30", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb282aee-f159-499a-947d-44cef273ec21_776x294.png", "width": "776", "height": "294", "credit": "", "caption": ""}, "31": {"item_id": "3629605227", "image_id": "31", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fad4722f3-597e-482d-954b-335713fa2b88_770x314.png", "width": "770", "height": "314", "credit": "", "caption": ""}}, "listen_duration_estimate": 1090}, "3631108522": {"item_id": "3631108522", "resolved_id": "3631108522", "given_url": "https://techcrunch.com/2022/06/01/2328459/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1654514235", "time_updated": "1654601423", "time_read": "1654601422", "time_favorited": "0", "sort_id": 135, "resolved_title": "Google bans deepfake-generating AI from Colab", "resolved_url": "https://techcrunch.com/2022/06/01/2328459/", "excerpt": "Google has banned the training of AI systems that can be used to generate deepfakes on its Google Colaboratory platform. The updated terms of use, spotted over the weekend by Unite.ai and BleepingComputer, includes deepfakes-related work in the list of disallowed projects.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1052", "lang": "en", "time_to_read": 5, "amp_url": "https://techcrunch.com/2022/06/01/2328459/amp/", "top_image_url": "https://techcrunch.com/wp-content/uploads/2021/07/GettyImages-1207206237.jpg?w=600", "tags": {"deep-learning": {"item_id": "3631108522", "tag": "deep-learning"}, "deepfakes": {"item_id": "3631108522", "tag": "deepfakes"}}, "authors": {"165625342": {"item_id": "3631108522", "author_id": "165625342", "name": "Kyle Wiggers", "url": "https://techcrunch.com/author/kyle-wiggers/"}}, "image": {"item_id": "3631108522", "src": "https://techcrunch.com/wp-content/uploads/2021/07/GettyImages-1207206237.jpg?w=600", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3631108522", "image_id": "1", "src": "https://techcrunch.com/wp-content/uploads/2021/07/GettyImages-1207206237.jpg?w=600", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "TechCrunch", "logo": "https://logo.clearbit.com/techcrunch.com?size=800", "greyscale_logo": "https://logo.clearbit.com/techcrunch.com?size=800&greyscale=true"}, "listen_duration_estimate": 407}, "3632408784": {"item_id": "3632408784", "resolved_id": "3632408784", "given_url": "https://bigtechnology.substack.com/p/face-to-face-with-dall-e-the-ai-artist", "given_title": "", "favorite": "0", "status": "1", "time_added": "1654349653", "time_updated": "1654374393", "time_read": "1654374393", "time_favorited": "0", "sort_id": 136, "resolved_title": "Face to Face With Dall-E, The AI Artist That Might Change The World", "resolved_url": "https://bigtechnology.substack.com/p/face-to-face-with-dall-e-the-ai-artist", "excerpt": "Dall-E's power becomes evident within the first minute of seeing it. The AI program creates intricate, original images when you feed it short text prompts. Its only limit is your imagination.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1454", "lang": "en", "time_to_read": 7, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdccd0ee1-d890-44f2-856e-58769659356c_1024x1024.png", "tags": {"deep-learning": {"item_id": "3632408784", "tag": "deep-learning"}, "image-generation": {"item_id": "3632408784", "tag": "image-generation"}}, "authors": {"157586793": {"item_id": "3632408784", "author_id": "157586793", "name": "Alex Kantrowitz", "url": "https://substack.com/profile/52351-alex-kantrowitz"}}, "listen_duration_estimate": 563}, "3649931229": {"item_id": "3649931229", "resolved_id": "3649931229", "given_url": "https://www.surgehq.ai//blog/generating-childrens-stories-using-gpt-3-and-dall-e", "given_title": "", "favorite": "0", "status": "1", "time_added": "1656872143", "time_updated": "1671724937", "time_read": "1657051488", "time_favorited": "0", "sort_id": 137, "resolved_title": "Generating Children's Stories Using GPT-3 and DALL¬∑E", "resolved_url": "https://www.surgehq.ai//blog/generating-childrens-stories-using-gpt-3-and-dall-e", "excerpt": "Imagine being 5 years old, dreaming of new adventures for Pikachu and Aladdin, and turning those tales into a cartoon right in front of your eyes‚Ä¶¬†(Perhaps even with you as the main character!) What kinds of new storybook experiences could GPT-3 and DALL¬∑E enable?", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "507", "lang": "en", "top_image_url": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb785bbd308083974abdae_d2.png", "tags": {"chatbots": {"item_id": "3649931229", "tag": "chatbots"}, "deep-learning": {"item_id": "3649931229", "tag": "deep-learning"}, "nlp": {"item_id": "3649931229", "tag": "nlp"}, "storytelling": {"item_id": "3649931229", "tag": "storytelling"}}, "authors": {"118701": {"item_id": "3649931229", "author_id": "118701", "name": "Edwin Chen", "url": ""}}, "image": {"item_id": "3649931229", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb785bbd308083974abdae_d2.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3649931229", "image_id": "1", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb785bbd308083974abdae_d2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3649931229", "image_id": "2", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb745889868a47c3f3bb3c_IlB-TYxtuvn3mfN4bam64yWLSW8NooJVjLkUanUMh5Dj-2xnnqo7eONzaRHQeuFmNgEusbrHZu4r00W1BPzm53CK4pRbyP4ehQy6_Jyjm7OSKkiRvi-n4N1gumpZR38fNOkmq9hZ233d0JeemQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3649931229", "image_id": "3", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb7459d3b3c89b945368c8_ApucvO2nLC93o55Nu5wtVn6AymcMoyj_nvNTLM9Qub2y1Y-rYQPwz0HWoWdC5g3IDYpWa3OOBoeutQ1wU9vC-7zGqQUCqdIBJpJ9n88PZdp9aT2UPgWR5PJsxPJn3huzTiB9z6imNPixc7vlOA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3649931229", "image_id": "4", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb7459e4b7d252016889ce_uO9fbdGXgNtjf8-YORknzMKbVUFJPGaDnbxGMzCRlT7RHqHjSpAwj7ePjuHtdI0EmXx4qiNJevpkDBMl253wWaxt9utQ63FUhh8cS9DisQpijXAbg4HHqmD_X77lqpHbDqQVbnfb6tIRJ3GPpQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3649931229", "image_id": "5", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb7459be9e0ace0e3c3eab_I1jXdeifi6lgxK0y5_9WSywzXRo_oeM29nsfMkxlkkczCHEcIj-J60dukXXT1YhubpEJOc9ljzk91TiJCanDjpX-TG-wd70GISHALDY3q3mj05pKB7iT6fnndtdi2QRinuYn1vkZ6PZb9EhoVw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3649931229", "image_id": "6", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb7459a1d2660228d6f88c_NayOvC8fA8tJhJdGDXQE5LAH2oBAApzOCDaPj-iVdr_Z1QucakYdndaJbZfBAL5iNd14wr-SMx2o2z6AfK0tuQBjTLHaA-nodE4UDsmnJPtslM-WdjPVwhXdrs5R5ORFi0C8oYiiKHFMuWv1Fg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3649931229", "image_id": "7", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb7459a0ee4638ba59b262_jkSo732BeGQNSf5YaN5O4WTX8v3-ZZJZPutn21HCcasAoHHB8sMBH5KDng1o9958FXYQyluxiveWzHQ_2amvpLVZCSDi0nVFxAY3_ovrk_vxQPDU22gsQ1FeNKC_-glWoLdUC6uMrKUS49-xNQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3649931229", "image_id": "8", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb745af1a69c24754d3367_lKb7G2r4jP40CUDCvwnZJGUKh80VqkYJYvcPLHhPxte3HP6aC8-lw-_nP_3VJcPMVi5-OZhcKe8jp8lkvxgqL9mNu0btVvLid6WU5xcMnZ_6FTtKOsvoNjCm3WONL5uwnS_QHTLb_Zwp9Dc1bA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3649931229", "image_id": "9", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb7ffb165404a2c4a62ffe_d5.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3649931229", "image_id": "10", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb745a76d06c4afba28af4_yOeYVb3uCbgRPU6bBaX_8Dn_m-fMXpE9KQ-8NHOVTuQTGAfvkgsbvVXQHwNBj5Ys1atLTuaoBPS4WPG8g0Dcb8Qqg3ZpY-ztBBsQItBAx8B1KR_tQJVHGQD0fDlX04tS6RMrgRUmZAp7IcylLw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3649931229", "image_id": "11", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb745ace9374f1fd7b93d9_vZxCg62SvefyQRMOQ87hrY4MnVxqiNKz4QOiHIKsUwnEhkix7by87r9efDbIxVVoibTCC__xg9ozx6X-4M_Cobh6REIeeKxxzOujLwJOWdP6OwnXudy65ZPY2DVdPQ8g34Q08iLd93U8oyRXvA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3649931229", "image_id": "12", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb745b0a345ac18bcd7ab8_JCvE8RcgEg1UCuCZ6zOWuvj1KhjTgvtLr-2bKXXahqZ6X0efEtQoZGUR2d2OcRfQxfi4ybgxcD5QGDUG8Z9EhyUeJoenSq5pgrlbde6Ne49Z3bYwdUj17clY5aQT-0fbOXG41CtL_oGcxgdV7Q.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3649931229", "image_id": "13", "src": "https://assets.website-files.com/610770ea9c21ff57ccb6a6a9/62bb745ab1d2d8458633ccae_ydKIoYYX-tyYOhxeKrd7L8DikrlKqBDeyQYXk7F4NOTxUY4_yKmswSFu17wypzFN8cx786YOGskOj4VvUlQkm6XCOHdOHgIENgJGQy4fuXfckcgcBrZPDyvjJxG8KS6iZW6UrB8WzAiB6abWuw.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 196}, "3650982176": {"item_id": "3650982176", "resolved_id": "3646180111", "given_url": "https://substack.com/redirect/0bce3d6d-715f-4aac-9135-200722adac11?u=1135489", "given_title": "", "favorite": "0", "status": "1", "time_added": "1656523130", "time_updated": "1657053989", "time_read": "1657053989", "time_favorited": "0", "sort_id": 138, "resolved_title": "How Imagen Actually Works", "resolved_url": "https://www.assemblyai.com/blog/how-imagen-actually-works/", "excerpt": "While the Machine Learning world was still coming to terms with the impressive results of DALL-E 2, released earlier this year, Google upped the ante by releasing its own text-to-image model Imagen, which appears to push the boundaries of caption-conditional image generation even further.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "5331", "lang": "en", "time_to_read": 24, "top_image_url": "https://www.assemblyai.com/blog/content/images/2022/07/How-Imagen-Actually-Works.png", "tags": {"deep-learning": {"item_id": "3650982176", "tag": "deep-learning"}, "images": {"item_id": "3650982176", "tag": "images"}}, "authors": {"2484349": {"item_id": "3650982176", "author_id": "2484349", "name": "s", "url": ""}}, "image": {"item_id": "3650982176", "src": "https://www.assemblyai.com/blog/content/images/2022/06/tti_annotation_crop.png", "width": "563", "height": "473"}, "images": {"1": {"item_id": "3650982176", "image_id": "1", "src": "https://www.assemblyai.com/blog/content/images/2022/06/tti_annotation_crop.png", "width": "563", "height": "473", "credit": "", "caption": ""}, "2": {"item_id": "3650982176", "image_id": "2", "src": "https://www.assemblyai.com/blog/content/images/2022/06/t5_tasksgif.gif", "width": "640", "height": "240", "credit": "", "caption": ""}, "3": {"item_id": "3650982176", "image_id": "3", "src": "https://www.assemblyai.com/blog/content/images/2022/06/image-18.png", "width": "2000", "height": "613", "credit": "", "caption": ""}, "4": {"item_id": "3650982176", "image_id": "4", "src": "https://www.assemblyai.com/blog/content/images/2022/06/image-22.png", "width": "1408", "height": "575", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "3650982176", "video_id": "1", "src": "https://www.assemblyai.com/blog/content/media/2022/06/birds_eye.mp4", "width": "1920", "height": "1080", "type": "5", "vid": "", "length": "0"}, "2": {"item_id": "3650982176", "video_id": "2", "src": "https://www.assemblyai.com/blog/content/media/2022/06/cap_cond.mp4", "width": "1920", "height": "1080", "type": "5", "vid": "", "length": "0"}, "3": {"item_id": "3650982176", "video_id": "3", "src": "https://www.assemblyai.com/blog/content/media/2022/06/super_res.mp4", "width": "1920", "height": "1080", "type": "5", "vid": "", "length": "0"}, "4": {"item_id": "3650982176", "video_id": "4", "src": "https://github.com/AssemblyAI-Examples/how-Imagen-actually-works/raw/main/transfer_learning.mp4", "width": "700", "height": "0", "type": "5", "vid": "", "length": "0"}, "5": {"item_id": "3650982176", "video_id": "5", "src": "https://github.com/AssemblyAI-Examples/how-Imagen-actually-works/raw/main/pos_enc.mp4", "width": "700", "height": "0", "type": "5", "vid": "", "length": "0"}, "6": {"item_id": "3650982176", "video_id": "6", "src": "https://www.assemblyai.com/blog/content/media/2022/06/time_enc.mp4", "width": "1920", "height": "1080", "type": "5", "vid": "", "length": "0"}, "7": {"item_id": "3650982176", "video_id": "7", "src": "https://github.com/AssemblyAI-Examples/how-Imagen-actually-works/raw/main/class_guide.mp4", "width": "700", "height": "0", "type": "5", "vid": "", "length": "0"}, "8": {"item_id": "3650982176", "video_id": "8", "src": "https://www.assemblyai.com/blog/content/media/2022/06/static_threshold.mp4", "width": "2400", "height": "1168", "type": "5", "vid": "", "length": "0"}, "9": {"item_id": "3650982176", "video_id": "9", "src": "https://www.assemblyai.com/blog/content/media/2022/06/dynamic_threshold.mp4", "width": "2400", "height": "1168", "type": "5", "vid": "", "length": "0"}}, "listen_duration_estimate": 2064}, "3650982180": {"item_id": "3650982180", "resolved_id": "3646500367", "given_url": "https://substack.com/redirect/56cdaf86-f132-4f32-8661-d1c1bfd03ac9?u=1135489", "given_title": "", "favorite": "0", "status": "1", "time_added": "1656523259", "time_updated": "1706833159", "time_read": "1657065647", "time_favorited": "0", "sort_id": 139, "resolved_title": "Title:The ArtBench Dataset: Benchmarking Generative Models with Artworks", "resolved_url": "https://arxiv.org/abs/2206.11404v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"art": {"item_id": "3650982180", "tag": "art"}, "datasets": {"item_id": "3650982180", "tag": "datasets"}, "deep-learning": {"item_id": "3650982180", "tag": "deep-learning"}, "programming": {"item_id": "3650982180", "tag": "programming"}}, "authors": {"79708950": {"item_id": "3650982180", "author_id": "79708950", "name": "cs  cs.AI  cs.LG", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3651527930": {"item_id": "3651527930", "resolved_id": "3651521154", "given_url": "https://arxiv.org/abs/2206.15378", "given_title": "", "favorite": "0", "status": "1", "time_added": "1657566601", "time_updated": "1657571886", "time_read": "1657571886", "time_favorited": "0", "sort_id": 140, "resolved_title": "Title:Mastering the Game of Stratego with Model-Free Multiagent Reinforcement Learning", "resolved_url": "https://arxiv.org/abs/2206.15378v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"deep-learning": {"item_id": "3651527930", "tag": "deep-learning"}, "game-theory": {"item_id": "3651527930", "tag": "game-theory"}, "games": {"item_id": "3651527930", "tag": "games"}, "reinforcement-learning": {"item_id": "3651527930", "tag": "reinforcement-learning"}, "stratego": {"item_id": "3651527930", "tag": "stratego"}}, "authors": {"65395181": {"item_id": "3651527930", "author_id": "65395181", "name": "cs cs.GT cs.MA", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3657512717": {"item_id": "3657512717", "resolved_id": "3284358751", "given_url": "https://substack.com/redirect/6f628369-5291-4b55-b14e-40815d5b112a?u=1135489", "given_title": "", "favorite": "0", "status": "1", "time_added": "1657449048", "time_updated": "1657466055", "time_read": "1657466054", "time_favorited": "0", "sort_id": 141, "resolved_title": "Topological Data Analysis for Machine Learning", "resolved_url": "https://bastian.rieck.me/talks/ecml_pkdd_2020/", "excerpt": "The goal of this tutorial is to give an introduction to the nascent field of topological machine learning, with the express purpose of being accessible to all audiences.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "412", "lang": "en", "tags": {"deep-learning": {"item_id": "3657512717", "tag": "deep-learning"}, "machine-learning": {"item_id": "3657512717", "tag": "machine-learning"}, "topology": {"item_id": "3657512717", "tag": "topology"}}, "image": {"item_id": "3657512717", "src": "http://img.youtube.com/vi/gVq_xXnwV-4/0.jpg", "width": "480", "height": "360"}, "images": {"1": {"item_id": "3657512717", "image_id": "1", "src": "http://img.youtube.com/vi/gVq_xXnwV-4/0.jpg", "width": "480", "height": "360", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "3657512717", "video_id": "1", "src": "https://www.youtube.com/embed/gVq_xXnwV-4", "width": "560", "height": "315", "type": "1", "vid": "gVq_xXnwV-4", "length": "0"}, "2": {"item_id": "3657512717", "video_id": "2", "src": "https://www.youtube.com/embed/UKXIyC7l16g", "width": "560", "height": "315", "type": "1", "vid": "UKXIyC7l16g", "length": "0"}, "3": {"item_id": "3657512717", "video_id": "3", "src": "https://www.youtube.com/embed/7i1kabhl5IU", "width": "560", "height": "315", "type": "1", "vid": "7i1kabhl5IU", "length": "0"}, "4": {"item_id": "3657512717", "video_id": "4", "src": "https://www.youtube.com/embed/-SqbDUiutu8", "width": "560", "height": "315", "type": "1", "vid": "-SqbDUiutu8", "length": "0"}}, "listen_duration_estimate": 159}, "3668010395": {"item_id": "3668010395", "resolved_id": "3668010395", "given_url": "https://towardsdatascience.com/a-brief-introduction-to-geometric-deep-learning-dae114923ddb", "given_title": "", "favorite": "0", "status": "1", "time_added": "1659006228", "time_updated": "1659215003", "time_read": "1659215002", "time_favorited": "0", "sort_id": 142, "resolved_title": "A Brief Introduction to Geometric Deep Learning", "resolved_url": "https://towardsdatascience.com/a-brief-introduction-to-geometric-deep-learning-dae114923ddb", "excerpt": "Deep learning is hard. While universal approximation theorems show that sufficiently complex neural networks can in principle approximate ‚Äúanything‚Äù, there is no guarantee that we can find good models.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1745", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1200/1*IpQzyB6cFhqk0bENNyFaew.png", "tags": {"deep-learning": {"item_id": "3668010395", "tag": "deep-learning"}, "geometry": {"item_id": "3668010395", "tag": "geometry"}}, "authors": {"147532492": {"item_id": "3668010395", "author_id": "147532492", "name": "Jason McEwen", "url": "https://jasonmcewen.medium.com"}}, "image": {"item_id": "3668010395", "src": "https://miro.medium.com/max/1400/1*IpQzyB6cFhqk0bENNyFaew.png", "width": "700", "height": "934"}, "images": {"1": {"item_id": "3668010395", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*IpQzyB6cFhqk0bENNyFaew.png", "width": "700", "height": "934", "credit": "SIMON LEE on Unsplash", "caption": ""}, "2": {"item_id": "3668010395", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*j5YQbvogagXkC9EbHKYgDQ.png", "width": "700", "height": "703", "credit": "top left", "caption": "Illustration of translational equivariance. Given an image"}, "3": {"item_id": "3668010395", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*bxB_BCaQeBbwinSyF0wJzA.png", "width": "700", "height": "466", "credit": "", "caption": "Illustration of stability of mapping to representation space. Small distortions are responsible for intra-class variations, whereas large distortions are responsible for inter-class variations. Stability of the mapping is required to ensure measures of similarity between data instances, i.e. the size of the distortion between them, is preserved in the representation space in order to facilitate effective learning. [Diagram created by author for [2].]"}, "4": {"item_id": "3668010395", "image_id": "4", "src": "https://miro.medium.com/max/600/1*COh1GxmkcW8NQk52GLhzuw.png", "width": "300", "height": "300", "credit": "Source wikipedia.", "caption": "A multiscale, hierarchical representation of an image. A low-resolution version of the original image is shown in the top-left corner and then remaining image content at different resolutions is captured in the other panels of the diagram. Similar representations can be exploited to provide effective representational spaces for learning."}, "5": {"item_id": "3668010395", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*J6Ipo8rqdjpsN3_9LafnQw.png", "width": "700", "height": "273", "credit": "", "caption": "Categories of geometric deep learning. [Image sourced from article [1], with permission, with annotated overview and examples added.]"}, "6": {"item_id": "3668010395", "image_id": "6", "src": "https://miro.medium.com/max/946/1*C0XySvqy3_dpuRg_QlpxQA.png", "width": "473", "height": "446", "credit": "Photo by Sen on Unsplash.", "caption": "All approaches to geometric deep learning leverage a core set of fundamental underlying building blocks."}, "7": {"item_id": "3668010395", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*-lIw_z6HEPHaGSpSOhyBow.png", "width": "700", "height": "411", "credit": "CNN", "caption": "VGG-16 convolutional neural network"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 675}, "3677584461": {"item_id": "3677584461", "resolved_id": "3677584461", "given_url": "https://www.amazon.science/blog/automated-reasoning-at-federated-logic-conference-floc", "given_title": "", "favorite": "0", "status": "1", "time_added": "1659994870", "time_updated": "1706624319", "time_read": "1660003587", "time_favorited": "0", "sort_id": 143, "resolved_title": "Automated reasoning at Amazon: a conversation", "resolved_url": "https://www.amazon.science/blog/automated-reasoning-at-federated-logic-conference-floc", "excerpt": "The Federated Logic Conference (FLoC) is a superconference that, like the Olympics, happens every four years. FLoC draws together 12 distinct conferences on logic-related topics, most of which meet annually.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "2358", "lang": "en", "time_to_read": 11, "amp_url": "https://www.amazon.science/blog/automated-reasoning-at-federated-logic-conference-floc?_amp=true", "top_image_url": "https://assets.amazon.science/dims4/default/ac3a4a5/2147483647/strip/true/crop/1616x848+0+32/resize/1200x630!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F51%2Fc1%2F9de030384a66a9c41b7bef707401%2Far-scientists.png", "tags": {"deep-learning": {"item_id": "3677584461", "tag": "deep-learning"}, "federated-learning": {"item_id": "3677584461", "tag": "federated-learning"}}, "authors": {"126047177": {"item_id": "3677584461", "author_id": "126047177", "name": "Larry Hardesty", "url": "https://www.amazon.science/author/larry-hardesty"}}, "image": {"item_id": "3677584461", "src": "https://assets.amazon.science/dims4/default/0f91e16/2147483647/strip/true/crop/1616x912+0+0/resize/1200x677!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F51%2Fc1%2F9de030384a66a9c41b7bef707401%2Far-scientists.png", "width": "1200", "height": "677"}, "images": {"1": {"item_id": "3677584461", "image_id": "1", "src": "https://assets.amazon.science/dims4/default/0f91e16/2147483647/strip/true/crop/1616x912+0+0/resize/1200x677!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F51%2Fc1%2F9de030384a66a9c41b7bef707401%2Far-scientists.png", "width": "1200", "height": "677", "credit": "", "caption": ""}, "2": {"item_id": "3677584461", "image_id": "2", "src": "https://assets.amazon.science/dims4/default/dd6970e/2147483647/strip/true/crop/5522x5120+0+0/resize/1200x1113!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2Fcd%2F30%2Fab6d340d40d08abe93695788fb1e%2Fcollatz-27.png", "width": "1200", "height": "1113", "credit": "", "caption": ""}, "3": {"item_id": "3677584461", "image_id": "3", "src": "https://assets.amazon.science/dims4/default/325d9f1/2147483647/strip/true/crop/1265x715+3+0/resize/400x226!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2Fab%2F5b%2F8538b92a44228ccb617d642b1b6e%2Fsat-graphs-16x9.png", "width": "400", "height": "226", "credit": "", "caption": ""}, "4": {"item_id": "3677584461", "image_id": "4", "src": "https://assets.amazon.science/dims4/default/4d85839/2147483647/strip/true/crop/2566x1450+0+57/resize/400x226!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2F44%2F99%2F125a56a74da0add98882b16da884%2Fembedded-verification-code.png", "width": "400", "height": "226", "credit": "", "caption": ""}, "5": {"item_id": "3677584461", "image_id": "5", "src": "https://assets.amazon.science/dims4/default/b11d13d/2147483647/strip/true/crop/2081x1689+0+0/resize/1200x974!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2Fb7%2Fb8%2Faf49b62a44999c17be597506c68c%2Fsat-results.png", "width": "1200", "height": "974", "credit": "", "caption": ""}, "6": {"item_id": "3677584461", "image_id": "6", "src": "https://assets.amazon.science/dims4/default/20598ef/2147483647/strip/true/crop/2732x754+0+0/resize/1200x331!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2Fd8%2Fe5%2Fb9ede3c3487c853e3db4ebcc9889%2Fiterated-sat-solver.png", "width": "1200", "height": "331", "credit": "", "caption": ""}, "7": {"item_id": "3677584461", "image_id": "7", "src": "https://assets.amazon.science/dims4/default/bd982b6/2147483647/strip/true/crop/1264x714+5+0/resize/400x226!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2Ff5%2F64%2Fc12a75e24909be22704ef5af877f%2Fbugbearscreenshot.large.png", "width": "400", "height": "226", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "3677584461", "video_id": "1", "src": "https://www.youtube.com/embed/JfjLKBO27nw?enablejsapi=1", "width": "0", "height": "0", "type": "1", "vid": "JfjLKBO27nw", "length": "0"}}, "listen_duration_estimate": 913}, "3712137297": {"item_id": "3712137297", "resolved_id": "3712137297", "given_url": "https://towardsdatascience.com/improving-vector-quantization-in-vector-quantized-variational-autoencoders-vq-vae-915f5814b5ce", "given_title": "", "favorite": "0", "status": "1", "time_added": "1665661436", "time_updated": "1673901753", "time_read": "1665670109", "time_favorited": "0", "sort_id": 144, "resolved_title": "NSVQ: Improved Vector Quantization technique for Neural Networks Training", "resolved_url": "https://towardsdatascience.com/improving-vector-quantization-in-vector-quantized-variational-autoencoders-vq-vae-915f5814b5ce", "excerpt": "Vector quantization (VQ) is a data compression technique which models the probability density function of the data by some representative vectors called codebooks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1347", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/0*mQbE21i6fsfqpU3L", "tags": {"autoencoders": {"item_id": "3712137297", "tag": "autoencoders"}, "compression-encoding": {"item_id": "3712137297", "tag": "compression-encoding"}, "deep-learning": {"item_id": "3712137297", "tag": "deep-learning"}, "machine-learning": {"item_id": "3712137297", "tag": "machine-learning"}, "search": {"item_id": "3712137297", "tag": "search"}}, "authors": {"172754577": {"item_id": "3712137297", "author_id": "172754577", "name": "Mohammad Vali", "url": "https://medium.com/@mohammad.vali"}}, "image": {"item_id": "3712137297", "src": "https://miro.medium.com/max/1400/0*mQbE21i6fsfqpU3L", "width": "700", "height": "467"}, "images": {"1": {"item_id": "3712137297", "image_id": "1", "src": "https://miro.medium.com/max/1400/0*mQbE21i6fsfqpU3L", "width": "700", "height": "467", "credit": "vackground.com on Unsplash", "caption": ""}, "2": {"item_id": "3712137297", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*_j4iFnsv7Xt5CoeZ40rZoQ.png", "width": "700", "height": "558", "credit": "image from here", "caption": "Vector Quantization operation"}, "3": {"item_id": "3712137297", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*pTECMRydvo-e3j58W75Hnw.png", "width": "700", "height": "390", "credit": "Image from here", "caption": "Straight Through Estimator"}, "4": {"item_id": "3712137297", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*xvwZLWlnBY41-4dlyEZE-Q.png", "width": "700", "height": "310", "credit": "Image by author", "caption": "Block diagram of NSVQ: Noise Substitution in Vector Quantization"}, "5": {"item_id": "3712137297", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*fobBGu61-2QmsNsvuIwktA.png", "width": "700", "height": "357", "credit": "Image by author", "caption": "Performance of the proposed NSVQ and STE in terms of PESQ and pSNR metrics for 12 bit VQ at overall bitrates of 8, 9.6, 13.2, 16.4, 24.4 and 32 kbit/s in the speech coding scenario; solid lines refer to the mean values of PESQ and pSNR, and the corresponding filled areas refer to their 95% quantiles."}, "6": {"item_id": "3712137297", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*P0LWep6XHRHZT-e3nnfr5A.png", "width": "700", "height": "362", "credit": "Image by author", "caption": "SSIM and Peak SNR values of STE and the proposed NSVQ for different VQ bitrates after 15 k training updates and over 20 individual experiments in the image compression scenario; solid lines refer to the mean values of SSIM and Peak SNR, and the corresponding filled areas refer to their 95% quantiles."}, "7": {"item_id": "3712137297", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*xZS1wtQHkWXTCXBo3OvdxA.png", "width": "700", "height": "352", "credit": "MSE", "caption": "Smoothed training error"}, "8": {"item_id": "3712137297", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*ZYByHhJjFqfzRtEIzX7npA.png", "width": "700", "height": "440", "credit": "Image by author", "caption": "Final optimized codebooks for 8 bit vector quantization using NSVQ method"}, "9": {"item_id": "3712137297", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*6diWUUxradTGbc7ZnAtA_g.png", "width": "700", "height": "441", "credit": "Image by author", "caption": "Final optimized codebooks for 8 bit vector quantization using STE method"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 521}, "3718988973": {"item_id": "3718988973", "resolved_id": "3718988973", "given_url": "https://undark.org/2022/10/07/interview-why-mastering-language-is-so-difficult-for-ai/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1665968804", "time_updated": "1665968863", "time_read": "1665968862", "time_favorited": "0", "sort_id": 145, "resolved_title": "Interview: Why Mastering Language Is So Difficult for AI", "resolved_url": "https://undark.org/2022/10/07/interview-why-mastering-language-is-so-difficult-for-ai/", "excerpt": "The field of artificial intelligence has never lacked for hype. Back in 1965, AI pioneer Herb Simon declared, ‚ÄúMachines will be capable, within 20 years, of doing any work a man can do.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1799", "lang": "en", "time_to_read": 8, "top_image_url": "https://undark.org/wp-content/uploads/2022/10/GettyImages-1355827275_edit.jpg", "tags": {"deep-learning": {"item_id": "3718988973", "tag": "deep-learning"}, "goodreads": {"item_id": "3718988973", "tag": "goodreads"}, "language-linguistics": {"item_id": "3718988973", "tag": "language-linguistics"}, "nlp": {"item_id": "3718988973", "tag": "nlp"}}, "authors": {"122246514": {"item_id": "3718988973", "author_id": "122246514", "name": "Dan Falk", "url": "https://undark.org/undark-author/dan-falk/"}}, "listen_duration_estimate": 696}, "3745149571": {"item_id": "3745149571", "resolved_id": "3745149571", "given_url": "https://www.tomshardware.com/news/cerebras-reveals-andromeda-a-135-million-core-ai-supercomputer", "given_title": "", "favorite": "0", "status": "1", "time_added": "1668509944", "time_updated": "1668511464", "time_read": "1668511464", "time_favorited": "0", "sort_id": 146, "resolved_title": "Cerebras Reveals Andromeda, a 13.5 Million Core AI Supercomputer", "resolved_url": "https://www.tomshardware.com/news/cerebras-reveals-andromeda-a-135-million-core-ai-supercomputer", "excerpt": "Cerebras, the company that builds the world's largest chip, the Wafer Scale Engine 2 (WSE-2), unveiled its Andromeda supercomputer today. Andromeda combines 16 of the wafer-sized WSE-2 chips into one cluster with 13.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "482", "lang": "en", "top_image_url": "https://cdn.mos.cms.futurecdn.net/QDGHobTS56GF94GsXHu2PV-1200-80.jpg", "tags": {"deep-learning": {"item_id": "3745149571", "tag": "deep-learning"}, "hpc": {"item_id": "3745149571", "tag": "hpc"}, "interconnects": {"item_id": "3745149571", "tag": "interconnects"}, "semiconductors": {"item_id": "3745149571", "tag": "semiconductors"}}, "authors": {"121060879": {"item_id": "3745149571", "author_id": "121060879", "name": "Paul Alcorn", "url": "https://www.tomshardware.com/author/paul-alcorn"}}, "domain_metadata": {"name": "Tom's Hardware", "logo": "https://logo.clearbit.com/tomshardware.com?size=800", "greyscale_logo": "https://logo.clearbit.com/tomshardware.com?size=800&greyscale=true"}, "listen_duration_estimate": 187}, "3753103267": {"item_id": "3753103267", "resolved_id": "3753103267", "given_url": "https://towardsdatascience.com/6-reinforcement-learning-algorithms-explained-237a79dbd8e", "given_title": "", "favorite": "0", "status": "1", "time_added": "1669552844", "time_updated": "1669667175", "time_read": "1669667174", "time_favorited": "0", "sort_id": 147, "resolved_title": "6 Reinforcement Learning Algorithms Explained", "resolved_url": "https://towardsdatascience.com/6-reinforcement-learning-algorithms-explained-237a79dbd8e", "excerpt": "Machine Learning (ML) is split into three branches: Supervised Learning, Unsupervised Learning, and Reinforcement Learning.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "3280", "lang": "en", "time_to_read": 15, "top_image_url": "https://miro.medium.com/max/1200/0*bo5XH0yQcOvHpKWh", "tags": {"deep-learning": {"item_id": "3753103267", "tag": "deep-learning"}, "reinforcement-learning": {"item_id": "3753103267", "tag": "reinforcement-learning"}}, "authors": {"162188001": {"item_id": "3753103267", "author_id": "162188001", "name": "Kay Jan Wong", "url": "https://kayjanwong.medium.com"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1270}, "3765918890": {"item_id": "3765918890", "resolved_id": "3765918890", "given_url": "https://www.ben-evans.com/benedictevans/2022/12/14/ChatGPT-imagenet", "given_title": "", "favorite": "0", "status": "1", "time_added": "1671155259", "time_updated": "1671155598", "time_read": "1671155598", "time_favorited": "0", "sort_id": 148, "resolved_title": "ChatGPT and the Imagenet moment", "resolved_url": "https://www.ben-evans.com/benedictevans/2022/12/14/ChatGPT-imagenet", "excerpt": "A decade or so ago, systems based on something called ‚Äòmachine learning‚Äô started producing really good results in Imagenet, a contest for computer vision researchers.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1920", "lang": "en", "time_to_read": 9, "top_image_url": "http://static1.squarespace.com/static/50363cf324ac8e905e7df861/t/639997a380800648445acf3f/1671010211384/B4AAC213-3764-4A49-A1F1-CA18B3368CF0.jpeg?format=1500w", "tags": {"chatgpt": {"item_id": "3765918890", "tag": "chatgpt"}, "deep-learning": {"item_id": "3765918890", "tag": "deep-learning"}, "generative": {"item_id": "3765918890", "tag": "generative"}, "ideas": {"item_id": "3765918890", "tag": "ideas"}, "machine-learning": {"item_id": "3765918890", "tag": "machine-learning"}, "nlp": {"item_id": "3765918890", "tag": "nlp"}}, "authors": {"116009647": {"item_id": "3765918890", "author_id": "116009647", "name": "Benedict Evans", "url": "https://www.ben-evans.com/benedictevans?author=50363cf324ac8e905e7df863"}}, "image": {"item_id": "3765918890", "src": "https://images.squarespace-cdn.com/content/v1/50363cf324ac8e905e7df861/18e369f9-d96f-4f12-a8ab-caa6943af902/B4AAC213-3764-4A49-A1F1-CA18B3368CF0.jpeg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3765918890", "image_id": "1", "src": "https://images.squarespace-cdn.com/content/v1/50363cf324ac8e905e7df861/18e369f9-d96f-4f12-a8ab-caa6943af902/B4AAC213-3764-4A49-A1F1-CA18B3368CF0.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Benedict Evans", "logo": "https://logo.clearbit.com/ben-evans.com?size=800", "greyscale_logo": "https://logo.clearbit.com/ben-evans.com?size=800&greyscale=true"}, "listen_duration_estimate": 743}, "3783881703": {"item_id": "3783881703", "resolved_id": "3783881703", "given_url": "https://www.infoq.com/news/2023/01/hinton-forward-algorithm/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1673533112", "time_updated": "1706233547", "time_read": "1673558742", "time_favorited": "0", "sort_id": 149, "resolved_title": "Deep Learning Pioneer Geoffrey Hinton Publishes New Deep Learning Algorithm", "resolved_url": "https://www.infoq.com/news/2023/01/hinton-forward-algorithm/", "excerpt": "Geoffrey Hinton, professor at the University of Toronto and engineering fellow at Google Brain, recently published a paper on the Forward-Forward algorithm (FF), a technique for training neural networks that uses two forward passes of data through the network, instead of backpropagation, to update t", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "542", "lang": "en", "top_image_url": "https://res.infoq.com/news/2023/01/hinton-forward-algorithm/en/headerimage/generatedHeaderImage-1671889757056.jpg", "tags": {"algorithms-math": {"item_id": "3783881703", "tag": "algorithms-math"}, "deep-learning": {"item_id": "3783881703", "tag": "deep-learning"}}, "authors": {"111950033": {"item_id": "3783881703", "author_id": "111950033", "name": "Anthony Alford", "url": "https://www.infoq.com/profile/Anthony-Alford/"}}, "domain_metadata": {"name": "InfoQ", "logo": "https://logo.clearbit.com/infoq.com?size=800", "greyscale_logo": "https://logo.clearbit.com/infoq.com?size=800&greyscale=true"}, "listen_duration_estimate": 210}, "3817269280": {"item_id": "3817269280", "resolved_id": "3817269280", "given_url": "https://www.zeta-alpha.com/post/must-read-the-100-most-cited-ai-papers-in-2022", "given_title": "", "favorite": "0", "status": "1", "time_added": "1678016255", "time_updated": "1679307360", "time_read": "1679307360", "time_favorited": "0", "sort_id": 150, "resolved_title": "Must read: the 100 most cited AI papers in 2022", "resolved_url": "https://www.zeta-alpha.com/post/must-read-the-100-most-cited-ai-papers-in-2022", "excerpt": "Who Is publishing the most Impactful AI research right now? With the breakneck pace of innovation in AI, it is crucial to pick up some signal as soon as possible. No one has the time to read everything, but these 100 papers are sure to bend the road as to where our AI technology is going.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1385", "lang": "en", "time_to_read": 6, "top_image_url": "https://static.wixstatic.com/media/111555_f4dabd45181244a89a61cc2abc1c7785~mv2.jpg/v1/fill/w_1000,h_618,al_c,q_85,usm_0.66_1.00_0.01/111555_f4dabd45181244a89a61cc2abc1c7785~mv2.jpg", "tags": {"arxiv": {"item_id": "3817269280", "tag": "arxiv"}, "deep-learning": {"item_id": "3817269280", "tag": "deep-learning"}}, "authors": {"150098771": {"item_id": "3817269280", "author_id": "150098771", "name": "Sergi Castella i Sap√©", "url": ""}}, "image": {"item_id": "3817269280", "src": "https://static.wixstatic.com/media/111555_f4dabd45181244a89a61cc2abc1c7785~mv2.jpg/v1/fill/w_980,h_606,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/111555_f4dabd45181244a89a61cc2abc1c7785~mv2.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3817269280", "image_id": "1", "src": "https://static.wixstatic.com/media/111555_f4dabd45181244a89a61cc2abc1c7785~mv2.jpg/v1/fill/w_980,h_606,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/111555_f4dabd45181244a89a61cc2abc1c7785~mv2.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3817269280", "image_id": "2", "src": "https://static.wixstatic.com/media/cfb1e3_748c6102f00c45678b75b0d4e2f62224~mv2.png/v1/fill/w_600,h_371,al_c,q_85,enc_auto/cfb1e3_748c6102f00c45678b75b0d4e2f62224~mv2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3817269280", "image_id": "3", "src": "https://static.wixstatic.com/media/cfb1e3_b4137b6a08e743fc95c00eba04c74ee1~mv2.png/v1/fill/w_938,h_585,al_c,q_90,enc_auto/cfb1e3_b4137b6a08e743fc95c00eba04c74ee1~mv2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3817269280", "image_id": "4", "src": "https://static.wixstatic.com/media/cfb1e3_e725943182924653a717da3b31363a73~mv2.png/v1/fill/w_600,h_371,al_c,q_85,enc_auto/cfb1e3_e725943182924653a717da3b31363a73~mv2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3817269280", "image_id": "5", "src": "https://static.wixstatic.com/media/cfb1e3_68723c87523f47f7aa4ddf60ec590aab~mv2.png/v1/fill/w_735,h_454,al_c,q_85,enc_auto/cfb1e3_68723c87523f47f7aa4ddf60ec590aab~mv2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3817269280", "image_id": "6", "src": "https://static.wixstatic.com/media/cfb1e3_846aa367a6094ccc96b0e1e16556fb91~mv2.png/v1/fill/w_927,h_572,al_c,q_90,enc_auto/cfb1e3_846aa367a6094ccc96b0e1e16556fb91~mv2.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 536}, "3824289621": {"item_id": "3824289621", "resolved_id": "3824289627", "given_url": "https://cocktailpeanut.github.io/dalai/#/", "given_title": "", "favorite": "0", "status": "1", "time_added": "1678707382", "time_updated": "1678882332", "time_read": "1678882332", "time_favorited": "0", "sort_id": 151, "resolved_title": "cocktailpeanut/dalai", "resolved_url": "https://github.com/cocktailpeanut/dalai", "excerpt": "Run LLaMA and Alpaca on your computer. Both alpaca and llama working on your computer!", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "1794", "lang": "en", "time_to_read": 8, "top_image_url": "https://opengraph.githubassets.com/17560ced9fe722110f4c540433743ce56a26b8052fe2525fcde957d9d0d2bd59/cocktailpeanut/dalai", "tags": {"deep-learning": {"item_id": "3824289621", "tag": "deep-learning"}, "llama": {"item_id": "3824289621", "tag": "llama"}, "nlp": {"item_id": "3824289621", "tag": "nlp"}}, "authors": {"179263246": {"item_id": "3824289621", "author_id": "179263246", "name": "cocktailpeanut", "url": "https://github.com/cocktailpeanut/dalai/commits?author=cocktailpeanut"}}, "image": {"item_id": "3824289621", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/npx2.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3824289621", "image_id": "1", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/npx2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3824289621", "image_id": "2", "src": "https://github.com/cocktailpeanut/dalai/raw/main/docs/alpaca.gif", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3824289621", "image_id": "3", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/alpaca_7b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3824289621", "image_id": "4", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/alpaca_13b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3824289621", "image_id": "5", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/7b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3824289621", "image_id": "6", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/13b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3824289621", "image_id": "7", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/30b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3824289621", "image_id": "8", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/65b.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3824289621", "image_id": "9", "src": "https://github.com/cocktailpeanut/dalai/blob/main/docs/vs.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 694}, "3825489839": {"item_id": "3825489839", "resolved_id": "3824217216", "given_url": "https://nlpnews.substack.com/p/top-ml-papers-of-the-week-8f6?publication_id=103238&post_id=107962254&isFreemail=true", "given_title": "?Top ML Papers of the Week - by elvis - NLP Newsletter", "favorite": "0", "status": "1", "time_added": "1678814572", "time_updated": "1678824314", "time_read": "1678824313", "time_favorited": "0", "sort_id": 152, "resolved_title": "ü•áTop ML Papers of the Week", "resolved_url": "https://nlpnews.substack.com/p/top-ml-papers-of-the-week-8f6", "excerpt": "1). PaLM-E - incorporates real-world continuous sensor modalities resulting in an embodied LM that performs tasks such as robotic manipulation planning, visual QA, and other embodied reasoning tasks. (paper | demo) 2).", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "641", "lang": "en", "time_to_read": 3, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFqvskpvXsAEIy5u.jpg", "tags": {"arxiv": {"item_id": "3825489839", "tag": "arxiv"}, "deep-learning": {"item_id": "3825489839", "tag": "deep-learning"}, "machine-learning": {"item_id": "3825489839", "tag": "machine-learning"}}, "authors": {"173922699": {"item_id": "3825489839", "author_id": "173922699", "name": "elvis", "url": "https://substack.com/profile/16905758-elvis"}}, "image": {"item_id": "3825489839", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFqo3xncaAAAWQnE.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3825489839", "image_id": "1", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFqo3xncaAAAWQnE.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3825489839", "image_id": "2", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFqvdJqxX0AAU9MW.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3825489839", "image_id": "3", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFqvskpvXsAEIy5u.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3825489839", "image_id": "4", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFquHXhkaEAEsLe-.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3825489839", "image_id": "5", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFqtxK6kaMAAl8lT.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3825489839", "image_id": "6", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFqorspragAAqGFu.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3825489839", "image_id": "7", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFqladuZX0AAB4S1.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3825489839", "image_id": "8", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFq0tzrNWcAI5ge8.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3825489839", "image_id": "9", "src": "https://substackcdn.com/image/fetch/w_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fpbs.substack.com%2Fmedia%2FFq0nlVMaMAECs3a.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "3825489839", "video_id": "1", "src": "https://video.twimg.com/ext_tw_video/1632902055030398976/pu/vid/360x270/JL4DHxz9ymrT-6pa.mp4?tag=12", "width": "0", "height": "0", "type": "5", "vid": "", "length": "0"}}, "listen_duration_estimate": 248}, "1618411073": {"item_id": "1618411073", "resolved_id": "1618411073", "given_url": "https://arxiv.org/abs/1605.09782v6", "given_title": "[1605.09782v6] Adversarial Feature Learning", "favorite": "0", "status": "1", "time_added": "1612436973", "time_updated": "1691366676", "time_read": "1612436988", "time_favorited": "0", "sort_id": 153, "resolved_title": "Title:Adversarial Feature Learning", "resolved_url": "https://arxiv.org/abs/1605.09782v6", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"adversarial": {"item_id": "1618411073", "tag": "adversarial"}, "deep-learning": {"item_id": "1618411073", "tag": "deep-learning"}, "feature-engineering": {"item_id": "1618411073", "tag": "feature-engineering"}}, "authors": {"63424573": {"item_id": "1618411073", "author_id": "63424573", "name": "cs cs.AI cs.CV", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "2489395368": {"item_id": "2489395368", "resolved_id": "2489395386", "given_url": "https://arxiv.org/abs/1902.04615", "given_title": "[1902.04615] Gauge Equivariant Convolutional Networks and the Icosahedral C", "favorite": "0", "status": "1", "time_added": "1614023055", "time_updated": "1656591161", "time_read": "1614023071", "time_favorited": "0", "sort_id": 154, "resolved_title": "Title:Gauge Equivariant Convolutional Networks and the Icosahedral CNN", "resolved_url": "https://arxiv.org/abs/1902.04615v1", "excerpt": "Authors:Taco S. Cohen, Maurice Weiler, Berkay Kicanaoglu, Max Welling Abstract: The idea of equivariance to symmetry transformations provides one of the first theoretically grounded principles for neural network architecture design.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "162", "lang": "en", "tags": {"deep-learning": {"item_id": "2489395368", "tag": "deep-learning"}, "geography": {"item_id": "2489395368", "tag": "geography"}}, "authors": {"63239927": {"item_id": "2489395368", "author_id": "63239927", "name": "cs cs.CV cs.NE", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 63}, "2735491976": {"item_id": "2735491976", "resolved_id": "3387105921", "given_url": "https://arxiv.org/abs/1909.10140", "given_title": "[1909.10140] A new coefficient of correlation", "favorite": "0", "status": "1", "time_added": "1640568086", "time_updated": "1640623176", "time_read": "1640623176", "time_favorited": "0", "sort_id": 155, "resolved_title": "Title:A new coefficient of correlation", "resolved_url": "https://arxiv.org/abs/1909.10140v4", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"deep-learning": {"item_id": "2735491976", "tag": "deep-learning"}}, "authors": {"64448422": {"item_id": "2735491976", "author_id": "64448422", "name": "math math.PR stat", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3844572536": {"item_id": "3844572536", "resolved_id": "3844572551", "given_url": "https://arxiv.org/abs/2304.05055", "given_title": "[2304.05055] A Comprehensive Survey on Deep Graph Representation Learning", "favorite": "0", "status": "1", "time_added": "1709517919", "time_updated": "1709597877", "time_read": "1709597877", "time_favorited": "0", "sort_id": 156, "resolved_title": "Title:A Comprehensive Survey on Deep Graph Representation Learning", "resolved_url": "https://arxiv.org/abs/2304.05055v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "72", "lang": "en", "top_image_url": "https://static.arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png", "tags": {"deep-learning": {"item_id": "3844572536", "tag": "deep-learning"}, "glossaries": {"item_id": "3844572536", "tag": "glossaries"}, "graphs": {"item_id": "3844572536", "tag": "graphs"}}, "authors": {"180485745": {"item_id": "3844572536", "author_id": "180485745", "name": "Wei Ju", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 28}, "3276029047": {"item_id": "3276029047", "resolved_id": "3276029047", "given_url": "https://www.reddit.com/r/MachineLearning/comments/m13oyv/r_deep_generative_modelling_a_comparative_review/", "given_title": "[R] Deep Generative Modelling: A Comparative Review of VAEs, GANs, Normaliz", "favorite": "0", "status": "1", "time_added": "1615339422", "time_updated": "1638708525", "time_read": "1615384233", "time_favorited": "0", "sort_id": 157, "resolved_title": "[R] Deep Generative Modelling: A Comparative Review of VAEs, GANs, Normalizing Flows, Energy-Based and Autoregressive Models", "resolved_url": "https://www.reddit.com/r/MachineLearning/comments/m13oyv/r_deep_generative_modelling_a_comparative_review/", "excerpt": "If anyone wants to brush up on recent methods in EBMs, Normalizing Flows, GANs, VAEs, and Autoregressive models, I just finished and submitted to arXiv a massive 21-page review comparing all these methods.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "67", "lang": "en", "amp_url": "https://amp.reddit.com/r/MachineLearning/comments/m13oyv/r_deep_generative_modelling_a_comparative_review/", "tags": {"deep-learning": {"item_id": "3276029047", "tag": "deep-learning"}}, "image": {"item_id": "3276029047", "src": "https://preview.redd.it/ezjgxlkkazl61.png?width=1387&format=png&auto=webp&s=79f354e8103bab85007b7412fc5d184aa6f3bc0d", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3276029047", "image_id": "1", "src": "https://preview.redd.it/ezjgxlkkazl61.png?width=1387&format=png&auto=webp&s=79f354e8103bab85007b7412fc5d184aa6f3bc0d", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Reddit", "logo": "https://logo.clearbit.com/reddit.com?size=800", "greyscale_logo": "https://logo.clearbit.com/reddit.com?size=800&greyscale=true"}, "listen_duration_estimate": 26}, "2961504793": {"item_id": "2961504793", "resolved_id": "2961504793", "given_url": "https://www.reddit.com/r/MachineLearning/comments/g7gkbf/r_suprise_exponentially_increasing_learning_rate/", "given_title": "[R] Suprise: Exponentially increasing Learning Rate for Deep Learning", "favorite": "0", "status": "1", "time_added": "1587821457", "time_updated": "1638708525", "time_read": "1587919479", "time_favorited": "0", "sort_id": 158, "resolved_title": "Reddit - Dive into anything", "resolved_url": "https://www.reddit.com/r/MachineLearning/comments/g7gkbf/r_suprise_exponentially_increasing_learning_rate/", "excerpt": "Scan this QR code to download the app now Or check it out in the app stores", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "17", "lang": "en", "tags": {"deep-learning": {"item_id": "2961504793", "tag": "deep-learning"}}, "authors": {"181836087": {"item_id": "2961504793", "author_id": "181836087", "name": "iidealized", "url": "https://www.reddit.com/user/iidealized/"}}, "domain_metadata": {"name": "Reddit", "logo": "https://logo.clearbit.com/reddit.com?size=800", "greyscale_logo": "https://logo.clearbit.com/reddit.com?size=800&greyscale=true"}, "listen_duration_estimate": 7}, "1847217981": {"item_id": "1847217981", "resolved_id": "1847217981", "given_url": "http://machinelearningmastery.com/command-line-recipes-deep-learning-amazon-web-services/", "given_title": "10 Command Line Recipes for Deep Learning on Amazon Web Services - Machine ", "favorite": "0", "status": "1", "time_added": "1517595804", "time_updated": "1638708525", "time_read": "1523378097", "time_favorited": "0", "sort_id": 159, "resolved_title": "10 Command Line Recipes for Deep Learning on Amazon Web Services", "resolved_url": "https://machinelearningmastery.com/command-line-recipes-deep-learning-amazon-web-services/", "excerpt": "Running large deep learning processes on Amazon Web Services EC2 is a cheap and effective way to learn and develop models. For just a few dollars you can get access to tens of gigabytes of RAM, tens of CPU cores, and multiple GPUs. I highly recommend it.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1627", "lang": "en", "time_to_read": 7, "top_image_url": "https://machinelearningmastery.com/wp-content/uploads/2017/08/10-Command-Line-Recipes-for-Deep-Learning-on-Amazon-Web-Services.jpg", "tags": {"aws": {"item_id": "1847217981", "tag": "aws"}, "deep-learning": {"item_id": "1847217981", "tag": "deep-learning"}, "linux": {"item_id": "1847217981", "tag": "linux"}}, "authors": {"26997241": {"item_id": "1847217981", "author_id": "26997241", "name": "Jason Brownlee", "url": "https://machinelearningmastery.com/author/jasonb/"}}, "image": {"item_id": "1847217981", "src": "https://machinelearningmastery.com/wp-content/uploads/2017/08/10-Command-Line-Recipes-for-Deep-Learning-on-Amazon-Web-Services.jpg", "width": "640", "height": "369"}, "images": {"1": {"item_id": "1847217981", "image_id": "1", "src": "https://machinelearningmastery.com/wp-content/uploads/2017/08/10-Command-Line-Recipes-for-Deep-Learning-on-Amazon-Web-Services.jpg", "width": "640", "height": "369", "credit": "", "caption": "10 Command Line Recipes for Deep Learning on Amazon Web Services   \nPhoto by chascar, some rights reserved."}, "2": {"item_id": "1847217981", "image_id": "2", "src": "https://machinelearningmastery.com/wp-content/uploads/2016/05/DeepLearningWithPython-220.png", "width": "220", "height": "311", "credit": "", "caption": ""}}, "listen_duration_estimate": 630}, "3411518543": {"item_id": "3411518543", "resolved_id": "3411518561", "given_url": "https://towardsdatascience.com/10-computer-vision-terms-everyone-must-know-about-687a98845fc8?source=rss----7f60cf5620c9---4", "given_title": "10 Computer Vision Terms Everyone Must Know About!", "favorite": "0", "status": "1", "time_added": "1629481209", "time_updated": "1706233547", "time_read": "1629666990", "time_favorited": "0", "sort_id": 160, "resolved_title": "10 Computer Vision Terms Everyone Must Know About!", "resolved_url": "https://towardsdatascience.com/10-computer-vision-terms-everyone-must-know-about-687a98845fc8", "excerpt": "The notion that machines or computers could perceive images in the real world and interpret them accordingly was once deemed impossible.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2386", "lang": "en", "time_to_read": 11, "top_image_url": "https://miro.medium.com/max/1200/0*LFhMuFB1_hyYnoE2", "tags": {"algorithms-math": {"item_id": "3411518543", "tag": "algorithms-math"}, "deep-learning": {"item_id": "3411518543", "tag": "deep-learning"}, "machine-vision": {"item_id": "3411518543", "tag": "machine-vision"}}, "authors": {"144409854": {"item_id": "3411518543", "author_id": "144409854", "name": "Bharath K", "url": "https://bharath-k1297.medium.com"}}, "image": {"item_id": "3411518543", "src": "https://miro.medium.com/max/2000/0*LFhMuFB1_hyYnoE2", "width": "1000", "height": "667"}, "images": {"1": {"item_id": "3411518543", "image_id": "1", "src": "https://miro.medium.com/max/2000/0*LFhMuFB1_hyYnoE2", "width": "1000", "height": "667", "credit": "Brooke Cagle on Unsplash", "caption": ""}, "2": {"item_id": "3411518543", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*9U8ZGWvLj1sEtmjD.png", "width": "700", "height": "417", "credit": "", "caption": ""}, "3": {"item_id": "3411518543", "image_id": "3", "src": "https://miro.medium.com/max/680/1*hDustSl11Py-vFlrBDqffA.png", "width": "340", "height": "94", "credit": "", "caption": "Dice Similarity Coefficient"}, "4": {"item_id": "3411518543", "image_id": "4", "src": "https://miro.medium.com/max/1400/0*IxXXM1M-PuXmp8u0", "width": "700", "height": "467", "credit": "Jackie Zhao on Unsplash", "caption": ""}, "5": {"item_id": "3411518543", "image_id": "5", "src": "https://miro.medium.com/max/1400/0*TcbseoIR_tvGnOEY", "width": "700", "height": "467", "credit": "C D-X on Unsplash", "caption": ""}, "6": {"item_id": "3411518543", "image_id": "6", "src": "https://miro.medium.com/max/670/1*q4eWelNCz1Yu2RbxusVyHQ.png", "width": "335", "height": "362", "credit": "", "caption": "Image By Author"}, "7": {"item_id": "3411518543", "image_id": "7", "src": "https://miro.medium.com/max/1400/0*o7TfTqm7qN_JGiCA", "width": "700", "height": "433", "credit": "Mike Dorner on Unsplash", "caption": ""}, "8": {"item_id": "3411518543", "image_id": "8", "src": "https://miro.medium.com/max/1400/0*oCFochYai3A2h5ez", "width": "700", "height": "466", "credit": "Eric Prouzet on Unsplash", "caption": ""}, "9": {"item_id": "3411518543", "image_id": "9", "src": "https://miro.medium.com/max/1400/0*RPUGZ9ySmAGVcIWE", "width": "700", "height": "394", "credit": "Austin Distel on Unsplash", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 924}, "3099548160": {"item_id": "3099548160", "resolved_id": "3099548192", "given_url": "https://towardsdatascience.com/10-invaluable-tips-tricks-for-building-successful-neural-networks-566aca17a0f1?source=rss----7f60cf5620c9---4", "given_title": "10 Invaluable Tips & Tricks for Building Successful Neural Networks", "favorite": "0", "status": "1", "time_added": "1599088543", "time_updated": "1638708525", "time_read": "1606696848", "time_favorited": "0", "sort_id": 161, "resolved_title": "10 Invaluable Tips & Tricks for Building Successful Neural Networks", "resolved_url": "https://towardsdatascience.com/10-invaluable-tips-tricks-for-building-successful-neural-networks-566aca17a0f1", "excerpt": "Building neural networks is difficult because there is so much variability involved. With these 10 tips and tricks, you‚Äôll not only have concrete pointers on changes to try but a strategy and mentality towards approaching the ambiguous task of building a successful neural network.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1953", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/1200/1*NcynxacTURLrpFPptsSreA.png", "tags": {"deep-learning": {"item_id": "3099548160", "tag": "deep-learning"}}, "authors": {"144200356": {"item_id": "3099548160", "author_id": "144200356", "name": "Andre Ye", "url": "https://andre-ye.medium.com"}}, "image": {"item_id": "3099548160", "src": "https://miro.medium.com/max/1400/1*NcynxacTURLrpFPptsSreA.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3099548160", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*NcynxacTURLrpFPptsSreA.png", "width": "0", "height": "0", "credit": "", "caption": "Source: Unsplash"}, "2": {"item_id": "3099548160", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*6fzV5Xet99Y829n5X_aWwQ.png", "width": "0", "height": "0", "credit": "", "caption": "Source: Sigmoid function. Source: Wikimedia. Image free to share."}, "3": {"item_id": "3099548160", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*1vEOdjywwHy_QM702sIamQ.png", "width": "0", "height": "0", "credit": "", "caption": "Source: ML From Scratch. Image free to share."}, "4": {"item_id": "3099548160", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*QSw8tc734qWsqtKixeg7sQ.png", "width": "0", "height": "0", "credit": "", "caption": "Capabilities of embeddings. Source: Tensorflow. Image free to share"}, "5": {"item_id": "3099548160", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*lCL1SFChZWXvbZVQ9EhbVQ.png", "width": "0", "height": "0", "credit": "", "caption": "Source. Image free to share."}, "6": {"item_id": "3099548160", "image_id": "6", "src": "https://miro.medium.com/max/1200/0*wy5ezs5qY72bq8_W.png", "width": "0", "height": "0", "credit": "", "caption": "Example results of data augmentation. Source: Keras. Image free to share."}, "7": {"item_id": "3099548160", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*Hl1_RIorXC8cGjmROlkRHA.png", "width": "0", "height": "0", "credit": "", "caption": "The innovative Inception v3 architecture, full of brilliant architectural decisions. Source: Jeremy Jordan. Image free to share."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 756}, "3032627546": {"item_id": "3032627546", "resolved_id": "3032627565", "given_url": "https://towardsdatascience.com/11-essential-neural-network-architectures-visualized-explained-7fc7da3486d8?source=rss----7f60cf5620c9---4", "given_title": "11 Essential Neural Network Architectures, Visualized & Explained", "favorite": "0", "status": "1", "time_added": "1593390945", "time_updated": "1638708525", "time_read": "1597023314", "time_favorited": "0", "sort_id": 162, "resolved_title": "11 Essential Neural Network Architectures, Visualized & Explained", "resolved_url": "https://towardsdatascience.com/11-essential-neural-network-architectures-visualized-explained-7fc7da3486d8", "excerpt": "With the rapid development of deep learning, an entire host of neural network architectures have been created to address a wide variety of tasks and problems.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1367", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/960/0*dbumSoFxrvm0WgIG.jpg", "tags": {"deep-learning": {"item_id": "3032627546", "tag": "deep-learning"}}, "authors": {"129297771": {"item_id": "3032627546", "author_id": "129297771", "name": "Andre Ye", "url": "https://towardsdatascience.com/@andre_ye"}}, "image": {"item_id": "3032627546", "src": "https://miro.medium.com/max/1920/0*dbumSoFxrvm0WgIG.jpg", "width": "960", "height": "540"}, "images": {"1": {"item_id": "3032627546", "image_id": "1", "src": "https://miro.medium.com/max/1920/0*dbumSoFxrvm0WgIG.jpg", "width": "960", "height": "540", "credit": "", "caption": "Source: Pixabay"}, "2": {"item_id": "3032627546", "image_id": "2", "src": "https://miro.medium.com/max/2932/1*7sQbwKEzdzOtxLza90EGCg.png", "width": "1466", "height": "421", "credit": "", "caption": ""}, "3": {"item_id": "3032627546", "image_id": "3", "src": "https://miro.medium.com/max/2914/1*Ja7Ft5xN9wuLT03ptHnj7Q.png", "width": "1457", "height": "623", "credit": "", "caption": ""}, "4": {"item_id": "3032627546", "image_id": "4", "src": "https://miro.medium.com/max/3734/1*5h4rYcLc7eG9YRtOfUVfog.png", "width": "1867", "height": "682", "credit": "", "caption": ""}, "5": {"item_id": "3032627546", "image_id": "5", "src": "https://miro.medium.com/max/2644/1*M7FD9ZiNK9RG0HhGtytPJQ.png", "width": "1322", "height": "836", "credit": "", "caption": "Two RNN visualization methods."}, "6": {"item_id": "3032627546", "image_id": "6", "src": "https://miro.medium.com/max/2658/1*R1HHdhSJOV8bEqKqg8eezg.png", "width": "1329", "height": "389", "credit": "", "caption": ""}, "7": {"item_id": "3032627546", "image_id": "7", "src": "https://miro.medium.com/max/3014/1*dBWqzWNXm5T3SM9r4jELHw.png", "width": "1507", "height": "443", "credit": "", "caption": ""}, "8": {"item_id": "3032627546", "image_id": "8", "src": "https://miro.medium.com/max/3554/1*qst6oiNEl_gSrWpEeshs_w.png", "width": "1777", "height": "680", "credit": "", "caption": ""}, "9": {"item_id": "3032627546", "image_id": "9", "src": "https://miro.medium.com/max/3034/1*xFWFKr_v0gOUkXyAg28Aew.png", "width": "1517", "height": "715", "credit": "", "caption": ""}, "10": {"item_id": "3032627546", "image_id": "10", "src": "https://miro.medium.com/max/2772/1*q4yoGDJHQ3nrmIbGvBtzaA.png", "width": "1386", "height": "646", "credit": "", "caption": "Generator diagram."}, "11": {"item_id": "3032627546", "image_id": "11", "src": "https://miro.medium.com/max/3954/1*TVeyq7NrnXkcapGh0NF8gQ.png", "width": "1977", "height": "812", "credit": "", "caption": ""}, "12": {"item_id": "3032627546", "image_id": "12", "src": "https://miro.medium.com/max/3932/1*101ZmCxJ-MBDCSIYKP0V6g.png", "width": "1966", "height": "797", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 529}, "3330781047": {"item_id": "3330781047", "resolved_id": "3330781047", "given_url": "https://semiengineering.com/11-ways-to-reduce-ai-energy-consumption/", "given_title": "11 Ways To Reduce AI Energy Consumption", "favorite": "0", "status": "1", "time_added": "1620908287", "time_updated": "1638708525", "time_read": "1620931740", "time_favorited": "0", "sort_id": 163, "resolved_title": "11 Ways To Reduce AI Energy Consumption", "resolved_url": "https://semiengineering.com/11-ways-to-reduce-ai-energy-consumption/", "excerpt": "As the machine-learning industry evolves, the focus has expanded from merely solving the problem to solving the problem better.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3313", "lang": "en", "time_to_read": 15, "top_image_url": "https://i2.wp.com/semiengineering.com/wp-content/uploads/Fig03_in_memory_computer_LinleyGroup.png?fit=499%2C377&ssl=1", "tags": {"deep-learning": {"item_id": "3330781047", "tag": "deep-learning"}, "semiconductor-memory": {"item_id": "3330781047", "tag": "semiconductor-memory"}, "semiconductors": {"item_id": "3330781047", "tag": "semiconductors"}}, "authors": {"129568072": {"item_id": "3330781047", "author_id": "129568072", "name": "Bryon Moyer", "url": "https://semiengineering.com/author/bryon-moyer/"}}, "image": {"item_id": "3330781047", "src": "https://i2.wp.com/semiengineering.com/wp-content/uploads/Fig01_Nvidia_LinleyGroup.png?resize=977%2C164&ssl=1", "width": "977", "height": "164"}, "images": {"1": {"item_id": "3330781047", "image_id": "1", "src": "https://i2.wp.com/semiengineering.com/wp-content/uploads/Fig01_Nvidia_LinleyGroup.png?resize=977%2C164&ssl=1", "width": "977", "height": "164", "credit": "", "caption": ""}, "2": {"item_id": "3330781047", "image_id": "2", "src": "https://i0.wp.com/semiengineering.com/wp-content/uploads/Fig04_photonic_circuits_LinleyGroup.png?resize=977%2C239&ssl=1", "width": "977", "height": "239", "credit": "", "caption": ""}}, "listen_duration_estimate": 1282}, "3006026888": {"item_id": "3006026888", "resolved_id": "3006021856", "given_url": "https://towardsdatascience.com/12-main-dropout-methods-mathematical-and-visual-explanation-58cdc2112293?source=rss----7f60cf5620c9---4", "given_title": "12 Main Dropout Methods¬†: Mathematical and Visual Explanation", "favorite": "0", "status": "1", "time_added": "1591272048", "time_updated": "1638708525", "time_read": "1593020508", "time_favorited": "0", "sort_id": 164, "resolved_title": "12 Main Dropout Methods: Mathematical and Visual Explanation for DNNs, CNNs, and RNNs", "resolved_url": "https://towardsdatascience.com/12-main-dropout-methods-mathematical-and-visual-explanation-58cdc2112293", "excerpt": "One of the major challenges when training a model in (Deep) Machine Learning is co-adaptation. This means that the neurons are very dependent on each other. They influence each other considerably and are not independent enough regarding their inputs.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2648", "lang": "en", "time_to_read": 12, "top_image_url": "https://miro.medium.com/max/1090/1*EqBoJoNt6VhWF_AXVYrjCw.png", "tags": {"deep-learning": {"item_id": "3006026888", "tag": "deep-learning"}}, "authors": {"152254245": {"item_id": "3006026888", "author_id": "152254245", "name": "‚≠êAxel Thevenot", "url": "https://axel-thevenot.medium.com"}}, "image": {"item_id": "3006026888", "src": "https://miro.medium.com/max/1400/1*EqBoJoNt6VhWF_AXVYrjCw.png", "width": "700", "height": "151"}, "images": {"1": {"item_id": "3006026888", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*EqBoJoNt6VhWF_AXVYrjCw.png", "width": "700", "height": "151", "credit": "", "caption": ""}, "2": {"item_id": "3006026888", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*uNI2MEBhWUqTcZy1ZreRtw.png", "width": "700", "height": "151", "credit": "", "caption": ""}, "3": {"item_id": "3006026888", "image_id": "3", "src": "https://miro.medium.com/max/1920/1*TCxHXQixO2IHUxg0MbqzDQ.png", "width": "960", "height": "540", "credit": "", "caption": ""}, "4": {"item_id": "3006026888", "image_id": "4", "src": "https://miro.medium.com/max/1920/1*n-7aBFrGvc3P_HjfybTPKw.png", "width": "960", "height": "540", "credit": "", "caption": "Dropout with p=0.5"}, "5": {"item_id": "3006026888", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*QXGCIgSDrhEiqTJi2kQxtg.png", "width": "700", "height": "125", "credit": "", "caption": ""}, "6": {"item_id": "3006026888", "image_id": "6", "src": "https://miro.medium.com/max/1920/1*bW1D2Cf8bygBkRNg-hm_Rg.png", "width": "960", "height": "540", "credit": "", "caption": "Dropout with p=0.5"}, "7": {"item_id": "3006026888", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*l5FTocBWKdVvp4OGqPULRg.png", "width": "700", "height": "236", "credit": "", "caption": ""}, "8": {"item_id": "3006026888", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*hdAxjZlABzYVNhS1LQbPrw.png", "width": "700", "height": "176", "credit": "", "caption": ""}, "9": {"item_id": "3006026888", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*VdXDL8muSS3IPjMpjj3hiA.png", "width": "700", "height": "90", "credit": "", "caption": ""}, "10": {"item_id": "3006026888", "image_id": "10", "src": "https://miro.medium.com/max/1920/1*Fgy_ZOKucO-Ma6aKix16nA.png", "width": "960", "height": "540", "credit": "", "caption": ""}, "11": {"item_id": "3006026888", "image_id": "11", "src": "https://miro.medium.com/max/1920/1*P0ZgcBHjeePpSCb_WAXmMg.png", "width": "960", "height": "540", "credit": "", "caption": "Standard dropout with p=0.5 compared to a Standout Example"}, "12": {"item_id": "3006026888", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*sO6RgR__S5sWGj95AtVZpQ.png", "width": "700", "height": "394", "credit": "", "caption": "Dropout with p=0.5"}, "13": {"item_id": "3006026888", "image_id": "13", "src": "https://miro.medium.com/max/1400/1*pgvyS519-G_ebE6Ixg-BoQ.png", "width": "700", "height": "127", "credit": "", "caption": ""}, "14": {"item_id": "3006026888", "image_id": "14", "src": "https://miro.medium.com/max/1400/1*jyww8BNA-6xRom6Z1Q-hig.png", "width": "700", "height": "394", "credit": "", "caption": ""}, "15": {"item_id": "3006026888", "image_id": "15", "src": "https://miro.medium.com/max/1400/1*3VnFDZNKypFsV8oVAaGOww.png", "width": "700", "height": "394", "credit": "", "caption": ""}, "16": {"item_id": "3006026888", "image_id": "16", "src": "https://miro.medium.com/max/1400/1*rMnN_OuCRXmqJSYs3xkkCA.png", "width": "700", "height": "129", "credit": "", "caption": ""}, "17": {"item_id": "3006026888", "image_id": "17", "src": "https://miro.medium.com/max/1400/1*S1zdA9EqnciiwoPeXBU4mw.png", "width": "700", "height": "128", "credit": "", "caption": ""}, "18": {"item_id": "3006026888", "image_id": "18", "src": "https://miro.medium.com/max/1400/1*KkqxjvXTIV_b365B41ltfg.png", "width": "700", "height": "394", "credit": "", "caption": ""}, "19": {"item_id": "3006026888", "image_id": "19", "src": "https://miro.medium.com/max/1400/1*bDAv5Rh-90cSszPnsddzBA.png", "width": "700", "height": "394", "credit": "", "caption": ""}, "20": {"item_id": "3006026888", "image_id": "20", "src": "https://miro.medium.com/max/1400/1*PpsBp9a3NmXXH-5YbsANAg.png", "width": "700", "height": "135", "credit": "", "caption": ""}, "21": {"item_id": "3006026888", "image_id": "21", "src": "https://miro.medium.com/max/1920/1*VeUzm8zAWYJIOu89on_irQ.png", "width": "960", "height": "540", "credit": "", "caption": ""}, "22": {"item_id": "3006026888", "image_id": "22", "src": "https://miro.medium.com/max/1920/1*5vzCb_vDRRjLnyiQ5DgFoQ.png", "width": "960", "height": "540", "credit": "", "caption": ""}, "23": {"item_id": "3006026888", "image_id": "23", "src": "https://miro.medium.com/max/1920/1*7dOgTorubL2oih51Qdlp9Q.png", "width": "960", "height": "540", "credit": "", "caption": ""}, "24": {"item_id": "3006026888", "image_id": "24", "src": "https://miro.medium.com/max/1920/1*7iWaDTmGFgdFpYHQWMNaIg.png", "width": "960", "height": "540", "credit": "", "caption": ""}, "25": {"item_id": "3006026888", "image_id": "25", "src": "https://miro.medium.com/max/1920/1*l7xVOOzKgp9d0mRRtStd0g.png", "width": "960", "height": "540", "credit": "", "caption": ""}, "26": {"item_id": "3006026888", "image_id": "26", "src": "https://miro.medium.com/max/1920/1*V5omZ493bo_6o5SxlNX-_g.png", "width": "960", "height": "540", "credit": "", "caption": ""}, "27": {"item_id": "3006026888", "image_id": "27", "src": "https://miro.medium.com/max/1920/1*N_NxTuAkqG03ehi2JVJiaA.png", "width": "960", "height": "540", "credit": "", "caption": ""}, "28": {"item_id": "3006026888", "image_id": "28", "src": "https://miro.medium.com/max/1920/1*JeTJJCCY4R6S790s1g-Zdg.png", "width": "960", "height": "540", "credit": "", "caption": ""}, "29": {"item_id": "3006026888", "image_id": "29", "src": "https://miro.medium.com/max/1400/1*KpaDxwalfKUvKnLw_6yFMw.gif", "width": "700", "height": "394", "credit": "", "caption": ""}, "30": {"item_id": "3006026888", "image_id": "30", "src": "https://miro.medium.com/max/1400/1*eGtKKRvZfNm6mIdQlVXisA.png", "width": "700", "height": "83", "credit": "", "caption": ""}, "31": {"item_id": "3006026888", "image_id": "31", "src": "https://miro.medium.com/max/1400/1*y7Q5U2MjIji7pvt6DRzq3A.png", "width": "700", "height": "83", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1025}, "1672904266": {"item_id": "1672904266", "resolved_id": "1672904266", "given_url": "https://arxiv.org/pdf/1703.09039.pdf", "given_title": "1703.09039.pdf", "favorite": "1", "status": "1", "time_added": "1518926437", "time_updated": "1638708525", "time_read": "1519228987", "time_favorited": "1519228976", "sort_id": 165, "resolved_title": "", "resolved_url": "https://arxiv.org/pdf/1703.09039.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"deep-learning": {"item_id": "1672904266", "tag": "deep-learning"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "2864300397": {"item_id": "2864300397", "resolved_id": "2864300397", "given_url": "https://blog.paperspace.com/2020-guide-to-synthetic-media/", "given_title": "2020 Guide to Synthetic Media | Paperspace Blog", "favorite": "0", "status": "1", "time_added": "1580390596", "time_updated": "1638708525", "time_read": "1582142608", "time_favorited": "0", "sort_id": 166, "resolved_title": "A 2020 Guide to Synthetic Media", "resolved_url": "https://blog.paperspace.com/2020-guide-to-synthetic-media/", "excerpt": "From deepfakes and virtual celebrities to \"fake news,\" we'll cover popular cases of media synthesis and the research publications detailing how it's done. Synthetic media is an exciting new area of research that has seen great advancements in the past few years.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "4048", "lang": "en", "time_to_read": 18, "amp_url": "https://blog.paperspace.com/2020-guide-to-synthetic-media/amp/", "top_image_url": "https://blog.paperspace.com/content/images/2020/01/Screenshot-from-2020-01-08-21-59-04.png", "tags": {"deep-learning": {"item_id": "2864300397", "tag": "deep-learning"}, "deepfakes": {"item_id": "2864300397", "tag": "deepfakes"}}, "authors": {"152623890": {"item_id": "2864300397", "author_id": "152623890", "name": "Sudharshan Chandra Babu", "url": "https://blog.paperspace.com/author/sudharshan/"}}, "image": {"item_id": "2864300397", "src": "https://blog.paperspace.com/content/images/2020/01/image.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2864300397", "image_id": "1", "src": "https://blog.paperspace.com/content/images/2020/01/image.png", "width": "0", "height": "0", "credit": "Image credit: https://vriparbelli.medium.com/our-vision-for-the-future-of-synthetic-media-8791059e8f3a", "caption": "Evolution of Media"}, "2": {"item_id": "2864300397", "image_id": "2", "src": "https://blog.paperspace.com/content/images/2020/01/image-26.png", "width": "0", "height": "0", "credit": "", "caption": "A Virtual Influencer, \"Lil Miquela,\" Endorsing Prada"}, "3": {"item_id": "2864300397", "image_id": "3", "src": "https://blog.paperspace.com/content/images/2020/01/image-25.png", "width": "0", "height": "0", "credit": "", "caption": "The Verified Instagram Account of Zlatan Ibrahimoviƒá"}, "4": {"item_id": "2864300397", "image_id": "4", "src": "https://blog.paperspace.com/content/images/2020/01/image-1.png", "width": "0", "height": "0", "credit": "", "caption": "Lil Miquela's Instagram"}, "5": {"item_id": "2864300397", "image_id": "5", "src": "https://blog.paperspace.com/content/images/2020/01/image-3.png", "width": "0", "height": "0", "credit": "", "caption": "RADiCAL‚Äôs Awesome Tech"}, "6": {"item_id": "2864300397", "image_id": "6", "src": "https://blog.paperspace.com/content/images/2020/01/image-4.png", "width": "0", "height": "0", "credit": "", "caption": "Jennifer Buscemi - One of the more popular Deepfake videos"}, "7": {"item_id": "2864300397", "image_id": "7", "src": "https://blog.paperspace.com/content/images/2020/01/image-5.png", "width": "0", "height": "0", "credit": "", "caption": "Synthetic Stock photos from Rosebud AI. None of these models are real."}, "8": {"item_id": "2864300397", "image_id": "8", "src": "https://blog.paperspace.com/content/images/2020/01/image-6.png", "width": "0", "height": "0", "credit": "", "caption": "Training phase"}, "9": {"item_id": "2864300397", "image_id": "9", "src": "https://blog.paperspace.com/content/images/2020/01/image-7.png", "width": "0", "height": "0", "credit": "", "caption": "Generation"}, "10": {"item_id": "2864300397", "image_id": "10", "src": "https://blog.paperspace.com/content/images/2020/01/image-8.png", "width": "0", "height": "0", "credit": "", "caption": "Samsung AI animating portraits"}, "11": {"item_id": "2864300397", "image_id": "11", "src": "https://blog.paperspace.com/content/images/2020/01/image-10.png", "width": "0", "height": "0", "credit": "", "caption": "Method Overview"}, "12": {"item_id": "2864300397", "image_id": "12", "src": "https://blog.paperspace.com/content/images/2020/01/image-15.png", "width": "0", "height": "0", "credit": "", "caption": "The cGAN"}, "13": {"item_id": "2864300397", "image_id": "13", "src": "https://blog.paperspace.com/content/images/2020/01/image-16.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "2864300397", "image_id": "14", "src": "https://blog.paperspace.com/content/images/2020/01/image-17.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "2864300397", "image_id": "15", "src": "https://blog.paperspace.com/content/images/2020/01/image-18.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "2864300397", "image_id": "16", "src": "https://blog.paperspace.com/content/images/2020/01/image-19.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "2864300397", "image_id": "17", "src": "https://blog.paperspace.com/content/images/2020/01/image-20.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "2864300397", "image_id": "18", "src": "https://blog.paperspace.com/content/images/2020/01/image-21.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "2864300397", "image_id": "19", "src": "https://blog.paperspace.com/content/images/2020/01/image-22.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "2864300397", "image_id": "20", "src": "https://blog.paperspace.com/content/images/2020/01/image-23.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "2864300397", "image_id": "21", "src": "https://blog.paperspace.com/content/images/2020/01/image-24.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "2864300397", "video_id": "1", "src": "https://www.youtube.com/embed/KHMNPjkd5-0?feature=oembed", "width": "200", "height": "113", "type": "1", "vid": "KHMNPjkd5-0", "length": "0"}, "2": {"item_id": "2864300397", "video_id": "2", "src": "https://www.youtube.com/embed/9Yq67CjDqvw?feature=oembed", "width": "480", "height": "270", "type": "1", "vid": "9Yq67CjDqvw", "length": "0"}, "3": {"item_id": "2864300397", "video_id": "3", "src": "https://www.youtube.com/embed/PCBTZh41Ris?feature=oembed", "width": "480", "height": "270", "type": "1", "vid": "PCBTZh41Ris", "length": "0"}}, "listen_duration_estimate": 1567}, "3763435562": {"item_id": "3763435562", "resolved_id": "3763435562", "given_url": "https://arxiv.org/pdf/2212.03551.pdf", "given_title": "2212.03551.pdf", "favorite": "0", "status": "1", "time_added": "1670772971", "time_updated": "1675817032", "time_read": "1670778218", "time_favorited": "0", "sort_id": 167, "resolved_title": "", "resolved_url": "https://arxiv.org/pdf/2212.03551.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"arxiv": {"item_id": "3763435562", "tag": "arxiv"}, "chatgpt": {"item_id": "3763435562", "tag": "chatgpt"}, "deep-learning": {"item_id": "3763435562", "tag": "deep-learning"}, "nlp": {"item_id": "3763435562", "tag": "nlp"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3109704343": {"item_id": "3109704343", "resolved_id": "3109704367", "given_url": "http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:980404", "given_title": "4 Steps to Building a Video Search System", "favorite": "0", "status": "1", "time_added": "1599963627", "time_updated": "1638708525", "time_read": "1604363436", "time_favorited": "0", "sort_id": 168, "resolved_title": "4 Steps to Building a Video Search System", "resolved_url": "https://www.datasciencecentral.com/profiles/blogs/4-steps-to-building-a-video-search-system", "excerpt": "As¬†its name suggests, searching for videos by image is the process of retrieving from the repository videos containing similar frames to the input image. One of the key steps is to turn videos into embeddings, which is to say, extract the keyframes and convert their features to vectors.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "796", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/max/960/1*IXJq0bxa1vwqg0GICv6kNg.gif", "tags": {"deep-learning": {"item_id": "3109704343", "tag": "deep-learning"}, "search": {"item_id": "3109704343", "tag": "search"}, "video": {"item_id": "3109704343", "tag": "video"}}, "authors": {"134648541": {"item_id": "3109704343", "author_id": "134648541", "name": "Kate Shao", "url": "https://www.datasciencecentral.com/profile/KateShao"}}, "image": {"item_id": "3109704343", "src": "https://storage.ning.com/topology/rest/1.0/file/get/7904317863?profile=RESIZE_710x", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3109704343", "image_id": "1", "src": "https://storage.ning.com/topology/rest/1.0/file/get/7904317863?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Data Science Central", "logo": "https://logo.clearbit.com/datasciencecentral.com?size=800", "greyscale_logo": "https://logo.clearbit.com/datasciencecentral.com?size=800&greyscale=true"}, "listen_duration_estimate": 308}, "3699499996": {"item_id": "3699499996", "resolved_id": "3699500003", "given_url": "http://www.wnycstudios.org/story/40000-recipes-murder/", "given_title": "40,000 Recipes for Murder", "favorite": "0", "status": "1", "time_added": "1662749399", "time_updated": "1706620607", "time_read": "1662772576", "time_favorited": "0", "sort_id": 169, "resolved_title": "40,000 Recipes for Murder", "resolved_url": "https://radiolab.org/episodes/40000-recipes-murder", "excerpt": "Two scientists inadvertently open THE Pandora&rsquo;s Box of WMDs. What now?", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "top_image_url": "https://media.wnyc.org/i/1600/1200/c/80/2022/09/40krecipes-EPS-220909_eKr7lEX.png", "tags": {"deep-learning": {"item_id": "3699499996", "tag": "deep-learning"}, "exercise-health-medicine": {"item_id": "3699499996", "tag": "exercise-health-medicine"}, "podcast": {"item_id": "3699499996", "tag": "podcast"}, "search": {"item_id": "3699499996", "tag": "search"}}, "listen_duration_estimate": 0}, "3142930414": {"item_id": "3142930414", "resolved_id": "3142930448", "given_url": "https://towardsdatascience.com/5-articles-to-understand-generative-adversarial-networks-69c268814e79?source=rss----7f60cf5620c9---4", "given_title": "5 Articles to Understand Generative Adversarial Networks", "favorite": "0", "status": "1", "time_added": "1602812957", "time_updated": "1638708525", "time_read": "1604360991", "time_favorited": "0", "sort_id": 170, "resolved_title": "5 Articles to Understand Generative Adversarial Networks", "resolved_url": "https://towardsdatascience.com/5-articles-to-understand-generative-adversarial-networks-69c268814e79", "excerpt": "A Generative Adversarial Network (GAN) is a generative network architecture, capable of generating new content, such as images and audio, made to look real. They can be used to generate special effects in movies, new data for small datasets and speed up photo editing.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "748", "lang": "en", "time_to_read": 3, "top_image_url": "https://miro.medium.com/max/1200/0*lCMud5Wn3d6GJNM9", "tags": {"deep-learning": {"item_id": "3142930414", "tag": "deep-learning"}}, "authors": {"152200449": {"item_id": "3142930414", "author_id": "152200449", "name": "Arthur Mello", "url": "https://medium.com/@arthurmello_"}}, "image": {"item_id": "3142930414", "src": "https://miro.medium.com/max/1400/0*lCMud5Wn3d6GJNM9", "width": "700", "height": "467"}, "images": {"1": {"item_id": "3142930414", "image_id": "1", "src": "https://miro.medium.com/max/1400/0*lCMud5Wn3d6GJNM9", "width": "700", "height": "467", "credit": "Moritz Kindler on Unsplash", "caption": ""}, "2": {"item_id": "3142930414", "image_id": "2", "src": "https://miro.medium.com/fit/c/56/56/2*HaBZPDAXFaA_YBw2byKwkA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 290}, "2622604741": {"item_id": "2622604741", "resolved_id": "2622604741", "given_url": "https://lionbridge.ai/datasets/5-million-faces-top-15-free-image-datasets-for-facial-recognition/", "given_title": "5 Million Faces ‚Äî Free Image Datasets for Facial Recognition | Lionbridge A", "favorite": "0", "status": "1", "time_added": "1596658522", "time_updated": "1638708525", "time_read": "1606680658", "time_favorited": "0", "sort_id": 171, "resolved_title": "5 Million Faces ‚Äî Top 15 Free Image Datasets for Facial Recognition", "resolved_url": "https://lionbridge.ai/datasets/5-million-faces-top-15-free-image-datasets-for-facial-recognition/", "excerpt": "From mobile phone security and surveillance cameras to augmented reality and photography, the facial recognition branch of computer vision has a variety of useful applications.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "747", "lang": "en", "time_to_read": 3, "top_image_url": "https://lionbridge.ai/wp-content/uploads/2019/06/2019-06-07_top-10-free-image-dataset-facial-recognition-hero.jpg", "tags": {"datasets": {"item_id": "2622604741", "tag": "datasets"}, "deep-learning": {"item_id": "2622604741", "tag": "deep-learning"}, "vision": {"item_id": "2622604741", "tag": "vision"}}, "authors": {"89330520": {"item_id": "2622604741", "author_id": "89330520", "name": "Limarc Ambalina", "url": ""}}, "listen_duration_estimate": 289}, "2814887792": {"item_id": "2814887792", "resolved_id": "2814887811", "given_url": "https://www.kdnuggets.com/2019/12/5-techniques-prevent-overfitting-neural-networks.html", "given_title": "5 Techniques to Prevent Overfitting in Neural Networks", "favorite": "0", "status": "1", "time_added": "1575662713", "time_updated": "1638708525", "time_read": "1576355735", "time_favorited": "0", "sort_id": 172, "resolved_title": "5 Techniques to Prevent Overfitting in Neural Networks", "resolved_url": "https://www.kdnuggets.com/5-techniques-to-prevent-overfitting-in-neural-networks.html", "excerpt": "In this article, I will present five techniques to prevent overfitting while training neural networks. I have been working on deep learning for more than a year now.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1122", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/408/1*Ly-z0OX0mwPiIckvVrQ8pA.png", "tags": {"deep-learning": {"item_id": "2814887792", "tag": "deep-learning"}}, "authors": {"135267749": {"item_id": "2814887792", "author_id": "135267749", "name": "Abhinav Sagar", "url": "https://www.kdnuggets.com/author/abhinav-sagar"}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 434}, "2932441152": {"item_id": "2932441152", "resolved_id": "2932433090", "given_url": "https://towardsdatascience.com/50-deep-learning-interview-questions-part-1-2-8bbc8a00ec61?source=rss----7f60cf5620c9---4", "given_title": "50 Deep Learning Interview Questions", "favorite": "0", "status": "1", "time_added": "1585582933", "time_updated": "1638708525", "time_read": "1585740047", "time_favorited": "0", "sort_id": 173, "resolved_title": "25 Deep Learning Interview Questions", "resolved_url": "https://towardsdatascience.com/50-deep-learning-interview-questions-part-1-2-8bbc8a00ec61", "excerpt": "Below are 25 questions on deep learning which can help you test your knowledge, as well as being a good review resource for interview preparation. 1. Why is it necessary to introduce non-linearities in a neural network?", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1362", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/1*wW78UQQc85T5zlZFvK0tpA.jpeg", "tags": {"deep-learning": {"item_id": "2932441152", "tag": "deep-learning"}, "interviewing": {"item_id": "2932441152", "tag": "interviewing"}}, "authors": {"110790448": {"item_id": "2932441152", "author_id": "110790448", "name": "Tomer Amit", "url": "https://medium.com/@tomer1amit"}}, "image": {"item_id": "2932441152", "src": "https://miro.medium.com/fit/c/56/56/1*jhUPy6OkdScx0rY8akJRQg.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2932441152", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*jhUPy6OkdScx0rY8akJRQg.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2932441152", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*wW78UQQc85T5zlZFvK0tpA.jpeg", "width": "700", "height": "467", "credit": "", "caption": ""}, "3": {"item_id": "2932441152", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*vK8yAvd98fPHEoJlbFCmVw.png", "width": "700", "height": "219", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 527}, "2995524414": {"item_id": "2995524414", "resolved_id": "2995524445", "given_url": "https://towardsdatascience.com/6-gan-architectures-you-really-should-know-d0b7373a2585?source=rss----7f60cf5620c9---4", "given_title": "6 GAN Architectures You Really Should Know", "favorite": "0", "status": "1", "time_added": "1590452486", "time_updated": "1638708525", "time_read": "1591030001", "time_favorited": "0", "sort_id": 174, "resolved_title": "6 GAN Architectures You Really Should Know", "resolved_url": "https://towardsdatascience.com/6-gan-architectures-you-really-should-know-d0b7373a2585", "excerpt": "Generative Adversarial Networks (GANs) were first introduced in 2014 by Ian Goodfellow et. al. and since then this topic itself opened up a new area of research. Within a few years, the research community came up with plenty of papers on this topic some of which have very interesting names :).", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3299", "lang": "en", "time_to_read": 15, "top_image_url": "https://miro.medium.com/max/601/1*_2KGRqxlMA3s2hZYWzI6UA.png", "tags": {"deep-learning": {"item_id": "2995524414", "tag": "deep-learning"}}, "authors": {"95626215": {"item_id": "2995524414", "author_id": "95626215", "name": "Jakub Czakon", "url": "https://medium.com/@jakub.czakon"}}, "image": {"item_id": "2995524414", "src": "https://miro.medium.com/fit/c/56/56/1*76yVgFSE4AoNMqmT7VD9rw.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2995524414", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*76yVgFSE4AoNMqmT7VD9rw.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2995524414", "image_id": "2", "src": "https://miro.medium.com/max/1202/1*_2KGRqxlMA3s2hZYWzI6UA.png", "width": "601", "height": "296", "credit": "", "caption": "source:neptune.ai"}, "3": {"item_id": "2995524414", "image_id": "3", "src": "https://miro.medium.com/max/1112/0*cddWm5l-bthJKmfb", "width": "556", "height": "292", "credit": "", "caption": "source:neptune.ai"}, "4": {"item_id": "2995524414", "image_id": "4", "src": "https://miro.medium.com/max/1112/0*rPQ_oGktHKpT7kXy", "width": "556", "height": "292", "credit": "", "caption": "source:neptune.ai"}, "5": {"item_id": "2995524414", "image_id": "5", "src": "https://miro.medium.com/max/1240/0*WklTgbxAcNYrQJQh", "width": "620", "height": "254", "credit": "", "caption": "source:neptune.ai"}, "6": {"item_id": "2995524414", "image_id": "6", "src": "https://miro.medium.com/max/1272/0*Ne6omMDYUDjvgwq5", "width": "636", "height": "254", "credit": "", "caption": "source:neptune.ai"}, "7": {"item_id": "2995524414", "image_id": "7", "src": "https://miro.medium.com/max/1192/0*rvbRtcmIV97_paVZ", "width": "596", "height": "145", "credit": "", "caption": "source:neptune.ai"}, "8": {"item_id": "2995524414", "image_id": "8", "src": "https://miro.medium.com/max/1248/0*sMr9Dt-mXY1SKKse", "width": "624", "height": "38", "credit": "", "caption": "source:neptune.ai"}, "9": {"item_id": "2995524414", "image_id": "9", "src": "https://miro.medium.com/max/760/0*UgUEKDvtBWA0bJOo", "width": "380", "height": "60", "credit": "", "caption": "source:neptune.ai"}, "10": {"item_id": "2995524414", "image_id": "10", "src": "https://miro.medium.com/max/1202/0*yj8SOtBn5NknYWTb", "width": "601", "height": "275", "credit": "", "caption": "source:neptune.ai"}, "11": {"item_id": "2995524414", "image_id": "11", "src": "https://miro.medium.com/max/1202/0*Wu74q3H-rUJ1Ohk_", "width": "601", "height": "296", "credit": "", "caption": "source:neptune.ai"}, "12": {"item_id": "2995524414", "image_id": "12", "src": "https://miro.medium.com/max/1176/0*gY9zfH2PYSFM6Ecq", "width": "588", "height": "294", "credit": "", "caption": "source:neptune.ai"}, "13": {"item_id": "2995524414", "image_id": "13", "src": "https://miro.medium.com/max/508/0*FT1p8kxN0izB1wy1", "width": "254", "height": "290", "credit": "", "caption": "source:neptune.ai"}, "14": {"item_id": "2995524414", "image_id": "14", "src": "https://miro.medium.com/max/120/0*4wRzwU4n9CtvS-BS", "width": "60", "height": "10", "credit": "", "caption": ""}, "15": {"item_id": "2995524414", "image_id": "15", "src": "https://miro.medium.com/max/600/0*y7_Oe9kYtDocW56H", "width": "300", "height": "52", "credit": "", "caption": "source:neptune.ai"}, "16": {"item_id": "2995524414", "image_id": "16", "src": "https://miro.medium.com/max/326/0*RVauQUSrAJQVcXkN", "width": "163", "height": "159", "credit": "", "caption": "source:neptune.ai"}, "17": {"item_id": "2995524414", "image_id": "17", "src": "https://miro.medium.com/max/512/0*-GCQ5DIX8hZW_WUQ", "width": "256", "height": "219", "credit": "", "caption": "source:neptune.ai"}, "18": {"item_id": "2995524414", "image_id": "18", "src": "https://miro.medium.com/max/1202/0*4fhkGsx_Ec6g6rLi", "width": "601", "height": "102", "credit": "", "caption": "source:neptune.ai"}, "19": {"item_id": "2995524414", "image_id": "19", "src": "https://miro.medium.com/max/1202/0*83xNrNyyogVpZkIo", "width": "601", "height": "270", "credit": "", "caption": "source:neptune.ai"}, "20": {"item_id": "2995524414", "image_id": "20", "src": "https://miro.medium.com/max/1248/0*cR7BtzpKm9QMpjhm", "width": "624", "height": "169", "credit": "", "caption": "source:neptune.ai"}, "21": {"item_id": "2995524414", "image_id": "21", "src": "https://miro.medium.com/max/1202/0*hs64_N1XDTffNdSH", "width": "601", "height": "141", "credit": "", "caption": "source:neptune.ai"}, "22": {"item_id": "2995524414", "image_id": "22", "src": "https://miro.medium.com/max/1118/0*cdHcTVkHfItTii0C", "width": "559", "height": "201", "credit": "", "caption": "source:neptune.ai"}, "23": {"item_id": "2995524414", "image_id": "23", "src": "https://miro.medium.com/max/1186/0*E7DnhvTiDpnZ3nVu", "width": "593", "height": "258", "credit": "", "caption": "source:neptune.ai"}, "24": {"item_id": "2995524414", "image_id": "24", "src": "https://miro.medium.com/max/1248/0*-XafDP3FVuKMA6TB", "width": "624", "height": "126", "credit": "", "caption": "source:neptune.ai"}, "25": {"item_id": "2995524414", "image_id": "25", "src": "https://miro.medium.com/max/1212/0*1k--RMdoPBGBHt8e", "width": "606", "height": "52", "credit": "", "caption": "source:neptune.ai"}, "26": {"item_id": "2995524414", "image_id": "26", "src": "https://miro.medium.com/max/1212/0*MIrpMBZ2OGDbGJrl", "width": "606", "height": "102", "credit": "", "caption": "source:neptune.ai"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1277}, "2560109132": {"item_id": "2560109132", "resolved_id": "2557165370", "given_url": "https://blog.nanonets.com/human-pose-estimation-2d-guide/?utm_source=reddit&utm_medium=social&utm_campaign=pose&utm_content=GROUP_NAME", "given_title": "A 2019 guide to Human Pose Estimation with Deep Learning", "favorite": "0", "status": "1", "time_added": "1555469373", "time_updated": "1638708525", "time_read": "1555553498", "time_favorited": "0", "sort_id": 175, "resolved_title": "", "resolved_url": "https://blog.nanonets.com/human-pose-estimation-2d-guide/", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"deep-learning": {"item_id": "2560109132", "tag": "deep-learning"}, "pose-estimation": {"item_id": "2560109132", "tag": "pose-estimation"}}, "listen_duration_estimate": 0}, "3178955873": {"item_id": "3178955873", "resolved_id": "3178955890", "given_url": "https://towardsdatascience.com/a-beginners-guide-to-use-bert-for-the-first-time-2e99b8c5423?source=rss----7f60cf5620c9---4", "given_title": "A Beginner‚Äôs Guide to Use BERT for the First Time", "favorite": "0", "status": "1", "time_added": "1605880848", "time_updated": "1638708525", "time_read": "1608290463", "time_favorited": "0", "sort_id": 176, "resolved_title": "A Beginner‚Äôs Guide to Use BERT for the First Time", "resolved_url": "https://towardsdatascience.com/a-beginners-guide-to-use-bert-for-the-first-time-2e99b8c5423", "excerpt": "BERT has become a new standard for Natural Language Processing (NLP). It achieved a whole new state-of-the-art on eleven NLP task, including text classification, sequence labeling, question answering, and many more. Even better, it can also give incredible results using only a small amount of data.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1086", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/0*w3-dy3whMFXPz2XI", "tags": {"bert": {"item_id": "3178955873", "tag": "bert"}, "deep-learning": {"item_id": "3178955873", "tag": "deep-learning"}, "nlp": {"item_id": "3178955873", "tag": "nlp"}}, "authors": {"142700337": {"item_id": "3178955873", "author_id": "142700337", "name": "Arfinda Ilmania", "url": "https://medium.com/@arfinda"}}, "image": {"item_id": "3178955873", "src": "https://miro.medium.com/fit/c/56/56/1*qmzNM2JZ7ryilbnKElpCLg.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3178955873", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*qmzNM2JZ7ryilbnKElpCLg.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3178955873", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*w3-dy3whMFXPz2XI", "width": "700", "height": "472", "credit": "Jamie Street on Unsplash", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 420}, "3556954695": {"item_id": "3556954695", "resolved_id": "3556954695", "given_url": "https://arxiv.org/pdf/2202.06512.pdf", "given_title": "A Comprehensive Benchmark of Deep Learning Libraries on Mobile DevicesA Com", "favorite": "0", "status": "1", "time_added": "1645365754", "time_updated": "1645367131", "time_read": "1645367131", "time_favorited": "0", "sort_id": 177, "resolved_title": "", "resolved_url": "https://arxiv.org/pdf/2202.06512.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"arxiv": {"item_id": "3556954695", "tag": "arxiv"}, "deep-learning": {"item_id": "3556954695", "tag": "deep-learning"}, "mobile": {"item_id": "3556954695", "tag": "mobile"}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3237663910": {"item_id": "3237663910", "resolved_id": "3051762578", "given_url": "https://www.technologyreview.com/2020/07/17/1005415/a-concept-in-psychology-is-helping-ai-to-better-navigate-our-world/?utm_medium=tr_social&utm_campaign=site_visitor.unpaid.engagement&utm_source=Facebook&fbclid=IwAR148-mHuu-DMXLjs3xuVgNlWqSTB_0agHPHU2l9iQu7XzdQEOISB1i_UBg#Echobox=1611272470", "given_title": "A concept in psychology is helping AI to better navigate our world | MIT Te", "favorite": "0", "status": "1", "time_added": "1611451644", "time_updated": "1709152706", "time_read": "1611520215", "time_favorited": "0", "sort_id": 178, "resolved_title": "A concept in psychology is helping AI to better navigate our world", "resolved_url": "https://www.technologyreview.com/2020/07/17/1005415/a-concept-in-psychology-is-helping-ai-to-better-navigate-our-world/#Echobox=1623872323-1", "excerpt": "The concept: When we look at a chair, regardless of its shape and color, we know that we can sit on it. When a fish is in water, regardless of its location, it knows that it can swim. This is known as the theory of affordance, a term coined by psychologist James J. Gibson.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "453", "lang": "en", "amp_url": "https://www.technologyreview.com/2020/07/17/1005415/a-concept-in-psychology-is-helping-ai-to-better-navigate-our-world/amp/", "top_image_url": "https://wp.technologyreview.com/wp-content/uploads/2020/07/fishbike-web.jpg?resize=1200,600", "tags": {"affordance": {"item_id": "3237663910", "tag": "affordance"}, "deep-learning": {"item_id": "3237663910", "tag": "deep-learning"}, "neurology": {"item_id": "3237663910", "tag": "neurology"}}, "authors": {"131673475": {"item_id": "3237663910", "author_id": "131673475", "name": "Karen Hao", "url": "https://www.technologyreview.com/author/karen-hao/"}}, "domain_metadata": {"name": "MIT Technology Review", "logo": "https://logo.clearbit.com/technologyreview.com?size=800", "greyscale_logo": "https://logo.clearbit.com/technologyreview.com?size=800&greyscale=true"}, "listen_duration_estimate": 175}, "3626708599": {"item_id": "3626708599", "resolved_id": "3626708599", "given_url": "https://www.nytimes.com/2022/05/26/technology/pimeyes-facial-recognition-search.html", "given_title": "A Face Search Engine Anyone Can Use Is Alarmingly Accurate", "favorite": "0", "status": "1", "time_added": "1653825363", "time_updated": "1653928242", "time_read": "1653928241", "time_favorited": "0", "sort_id": 179, "resolved_title": "A Face Search Engine Anyone Can Use Is Alarmingly Accurate", "resolved_url": "https://www.nytimes.com/2022/05/26/technology/pimeyes-facial-recognition-search.html", "excerpt": "For $29.99 a month, a website called PimEyes offers a potentially dangerous superpower from the world of science fiction: the ability to search for a face, finding obscure photos that would otherwise have been as safe as the proverbial needle in the vast digital haystack of the internet.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2327", "lang": "en", "time_to_read": 11, "top_image_url": "https://static01.nyt.com/images/2022/05/29/business/00PimEyes-Kashmir-Hill/00PimEyes-Kashmir-Hill-facebookJumbo.jpg?year=2022&h=550&w=1050&s=5e30107a251f32745d667b887197727b6e90d483f53244eeb81f6a8153eb8847&k=ZQJBKqZ0VN", "tags": {"deep-learning": {"item_id": "3626708599", "tag": "deep-learning"}, "face-recognition": {"item_id": "3626708599", "tag": "face-recognition"}, "search": {"item_id": "3626708599", "tag": "search"}}, "authors": {"123765804": {"item_id": "3626708599", "author_id": "123765804", "name": "Kashmir Hill", "url": "https://www.nytimes.com/by/kashmir-hill"}}, "image": {"item_id": "3626708599", "src": "https://static01.nyt.com/images/2022/05/29/business/00PimEyes-Kashmir-Hill/00PimEyes-Kashmir-Hill-articleLarge.jpg?quality=75&auto=webp&disable=upscale", "width": "600", "height": "400"}, "images": {"1": {"item_id": "3626708599", "image_id": "1", "src": "https://static01.nyt.com/images/2022/05/29/business/00PimEyes-Kashmir-Hill/00PimEyes-Kashmir-Hill-articleLarge.jpg?quality=75&auto=webp&disable=upscale", "width": "600", "height": "400", "credit": "", "caption": ""}, "2": {"item_id": "3626708599", "image_id": "2", "src": "https://static01.nyt.com/images/2020/07/24/business/author-hill-kashmir/author-hill-kashmir-thumbLarge-v3.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The New York Times", "logo": "https://logo.clearbit.com/nytimes.com?size=800", "greyscale_logo": "https://logo.clearbit.com/nytimes.com?size=800&greyscale=true"}, "listen_duration_estimate": 901}, "1996069713": {"item_id": "1996069713", "resolved_id": "1996069713", "given_url": "https://machinelearningmastery.com/exploding-gradients-in-neural-networks/", "given_title": "A Gentle Introduction to Exploding Gradients in Neural Networks", "favorite": "0", "status": "1", "time_added": "1513534363", "time_updated": "1638708525", "time_read": "1513567374", "time_favorited": "0", "sort_id": 180, "resolved_title": "A Gentle Introduction to Exploding Gradients in Neural Networks", "resolved_url": "https://machinelearningmastery.com/exploding-gradients-in-neural-networks/", "excerpt": "Exploding gradients are a problem where large error gradients accumulate and result in very large updates to neural network model weights during training. This has the effect of your model being unstable and unable to learn from your training data.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1150", "lang": "en", "time_to_read": 5, "top_image_url": "https://machinelearningmastery.com/wp-content/uploads/2017/12/A-Gentle-Introduction-to-Exploding-Gradients-in-Recurrent-Neural-Networks.jpg", "tags": {"deep-learning": {"item_id": "1996069713", "tag": "deep-learning"}, "gradients": {"item_id": "1996069713", "tag": "gradients"}}, "authors": {"26997241": {"item_id": "1996069713", "author_id": "26997241", "name": "Jason Brownlee", "url": "https://machinelearningmastery.com/author/jasonb/"}}, "image": {"item_id": "1996069713", "src": "https://machinelearningmastery.com/wp-content/uploads/2017/12/A-Gentle-Introduction-to-Exploding-Gradients-in-Recurrent-Neural-Networks.jpg", "width": "640", "height": "428"}, "images": {"1": {"item_id": "1996069713", "image_id": "1", "src": "https://machinelearningmastery.com/wp-content/uploads/2017/12/A-Gentle-Introduction-to-Exploding-Gradients-in-Recurrent-Neural-Networks.jpg", "width": "640", "height": "428", "credit": "", "caption": "A Gentle Introduction to Exploding Gradients in Recurrent Neural Networks   \nPhoto by Taro Taylor, some rights reserved."}, "2": {"item_id": "1996069713", "image_id": "2", "src": "https://machinelearningmastery.com/wp-content/uploads/2017/07/Cover-220.png", "width": "220", "height": "311", "credit": "", "caption": ""}}, "listen_duration_estimate": 445}, "2902701301": {"item_id": "2902701301", "resolved_id": "2902699888", "given_url": "https://towardsdatascience.com/my-journey-into-reinforcement-learning-part-5-temporal-difference-learning-d0cae79e850?source=rss----7f60cf5620c9---4", "given_title": "A Journey Into Reinforcement Learning‚Ää‚Äî‚ÄäTemporal-Difference Learning", "favorite": "0", "status": "1", "time_added": "1583179388", "time_updated": "1638708525", "time_read": "1583785007", "time_favorited": "0", "sort_id": 181, "resolved_title": "Temporal-Difference Methods in Reinforcement Learning", "resolved_url": "https://towardsdatascience.com/my-journey-into-reinforcement-learning-part-5-temporal-difference-learning-d0cae79e850", "excerpt": "Welcome to the next exciting chapter of my reinforcement learning studies, in which we‚Äôll cover temporal-difference learning. As always I‚Äôll link to the resources that taught and guided me at the bottom of the post.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "779", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/max/479/1*_kPn3GgMWtVj7t3nIuVXvw.png", "tags": {"deep-learning": {"item_id": "2902701301", "tag": "deep-learning"}}, "authors": {"126531483": {"item_id": "2902701301", "author_id": "126531483", "name": "Reuben Kavalov", "url": "https://medium.com/@reubena.kavalov"}}, "image": {"item_id": "2902701301", "src": "https://miro.medium.com/fit/c/56/56/2*oiWZB798SzqPgjr6VkFt2g.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2902701301", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*oiWZB798SzqPgjr6VkFt2g.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2902701301", "image_id": "2", "src": "https://miro.medium.com/max/650/1*Ms80os43GYglmakAUya89Q.png", "width": "325", "height": "61", "credit": "", "caption": ""}, "3": {"item_id": "2902701301", "image_id": "3", "src": "https://miro.medium.com/max/874/1*ayERPEN1mdu7vaE-9PX0hQ.png", "width": "437", "height": "69", "credit": "", "caption": ""}, "4": {"item_id": "2902701301", "image_id": "4", "src": "https://miro.medium.com/max/1346/1*exB9JFjO21PqP6CaytwsuQ.png", "width": "673", "height": "201", "credit": "", "caption": ""}, "5": {"item_id": "2902701301", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*t4Rn8vmBxOvUWyzqjYPUow.png", "width": "700", "height": "282", "credit": "left", "caption": "Monte Carlo"}, "6": {"item_id": "2902701301", "image_id": "6", "src": "https://miro.medium.com/max/586/1*6lDckk0Xc3jrg4ID-FV9tA.png", "width": "293", "height": "39", "credit": "", "caption": ""}, "7": {"item_id": "2902701301", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*Peb30YebQWaF6R2MP2Bv3A.png", "width": "700", "height": "306", "credit": "", "caption": "http://incompleteideas.net/book/RLbook2018.pdf"}, "8": {"item_id": "2902701301", "image_id": "8", "src": "https://miro.medium.com/max/958/1*_kPn3GgMWtVj7t3nIuVXvw.png", "width": "479", "height": "327", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 302}, "3365845245": {"item_id": "3365845245", "resolved_id": "3365845245", "given_url": "https://www.nextplatform.com/2021/06/25/a-look-at-baidus-industrial-scale-gpu-training-architecture/", "given_title": "A Look at Baidu‚Äôs Industrial-Scale GPU Training Architecture", "favorite": "0", "status": "1", "time_added": "1624669850", "time_updated": "1638708525", "time_read": "1624723186", "time_favorited": "0", "sort_id": 182, "resolved_title": "A Look at Baidu‚Äôs Industrial-Scale GPU Training Architecture", "resolved_url": "https://www.nextplatform.com/2021/06/25/a-look-at-baidus-industrial-scale-gpu-training-architecture/", "excerpt": "Like its U.S. counterpart, Google, Baidu has made significant investments to build robust, large-scale systems to support global advertising programs. As one might imagine, AL/ML has been playing a central role in how these systems are built.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "809", "lang": "en", "time_to_read": 4, "amp_url": "https://www.nextplatform.com/2021/06/25/a-look-at-baidus-industrial-scale-gpu-training-architecture/amp/", "top_image_url": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2018/04/baidu_front.jpg", "tags": {"deep-learning": {"item_id": "3365845245", "tag": "deep-learning"}, "gpus": {"item_id": "3365845245", "tag": "gpus"}, "semiconductors": {"item_id": "3365845245", "tag": "semiconductors"}}, "authors": {"58691955": {"item_id": "3365845245", "author_id": "58691955", "name": "Nicole Hemsoth", "url": "https://www.nextplatform.com/author/nicole/"}}, "image": {"item_id": "3365845245", "src": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2018/04/baidu_front.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3365845245", "image_id": "1", "src": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2018/04/baidu_front.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3365845245", "image_id": "2", "src": "http://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2021/06/Baidu1.png", "width": "1033", "height": "380", "credit": "", "caption": ""}, "3": {"item_id": "3365845245", "image_id": "3", "src": "http://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2021/06/Baidu2.png", "width": "869", "height": "427", "credit": "", "caption": ""}}, "listen_duration_estimate": 313}, "3762688794": {"item_id": "3762688794", "resolved_id": "3762688843", "given_url": "https://towardsdatascience.com/a-quick-start-on-your-journey-to-federated-learning-c54ef27bc031?source=rss----7f60cf5620c9---4", "given_title": "A Quick Start on Your Journey to Federated Learning", "favorite": "0", "status": "1", "time_added": "1670594242", "time_updated": "1706624319", "time_read": "1670683542", "time_favorited": "0", "sort_id": 183, "resolved_title": "A Quick Start on Your Journey to Federated Learning", "resolved_url": "https://towardsdatascience.com/a-quick-start-on-your-journey-to-federated-learning-c54ef27bc031", "excerpt": "In my earlier post, I described the importance of federal learning from a data scientist‚Äôs view. I will now get you started on FL using your own datasets. There are several FL frameworks available, along with tutorials and user guides.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1218", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/1*1zLp7pZQEqxn0A2HMoiIpQ.jpeg", "tags": {"deep-learning": {"item_id": "3762688794", "tag": "deep-learning"}, "federated-learning": {"item_id": "3762688794", "tag": "federated-learning"}}, "authors": {"155726744": {"item_id": "3762688794", "author_id": "155726744", "name": "Poornachandra Sarang", "url": "https://medium.com/@profsarang"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 471}, "3248632724": {"item_id": "3248632724", "resolved_id": "3248632724", "given_url": "https://developer.nvidia.com/blog/achieving-high-quality-search-and-recommendation-results-with-deepnlp/", "given_title": "Achieving High-Quality Search and Recommendation Results with DeepNLP", "favorite": "0", "status": "1", "time_added": "1612482220", "time_updated": "1638708525", "time_read": "1612564847", "time_favorited": "0", "sort_id": 184, "resolved_title": "Achieving High-Quality Search and Recommendation Results with DeepNLP", "resolved_url": "https://developer.nvidia.com/blog/achieving-high-quality-search-and-recommendation-results-with-deepnlp/", "excerpt": "Speech and natural language processing (NLP) have become the foundation for most of the AI development in the enterprise today, as textual data represents a significant portion of unstructured content.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2047", "lang": "en", "time_to_read": 9, "top_image_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2021/02/DeText.png", "tags": {"deep-learning": {"item_id": "3248632724", "tag": "deep-learning"}, "nlp": {"item_id": "3248632724", "tag": "nlp"}, "recommenders": {"item_id": "3248632724", "tag": "recommenders"}, "search": {"item_id": "3248632724", "tag": "search"}}, "authors": {"146399023": {"item_id": "3248632724", "author_id": "146399023", "name": "Weiwei Guo", "url": "https://developer.nvidia.com/blog/author/wguo/"}}, "image": {"item_id": "3248632724", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2021/02/DeText-625x618.png", "width": "313", "height": "309"}, "images": {"1": {"item_id": "3248632724", "image_id": "1", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2021/02/DeText-625x618.png", "width": "313", "height": "309", "credit": "", "caption": ""}, "2": {"item_id": "3248632724", "image_id": "2", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2021/02/DeText_Figure1-625x392.png", "width": "580", "height": "363", "credit": "", "caption": ""}, "3": {"item_id": "3248632724", "image_id": "3", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2021/02/DeText_Figure2-625x335.png", "width": "625", "height": "335", "credit": "", "caption": ""}, "4": {"item_id": "3248632724", "image_id": "4", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2021/02/DeText_Figure3-625x281.png", "width": "625", "height": "281", "credit": "", "caption": ""}, "5": {"item_id": "3248632724", "image_id": "5", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2021/02/DeText_Figure4.png", "width": "370", "height": "201", "credit": "", "caption": ""}, "6": {"item_id": "3248632724", "image_id": "6", "src": "https://developer-blogs.nvidia.com/wp-content/uploads/2021/02/DeText_Figure5-625x282.png", "width": "625", "height": "282", "credit": "", "caption": ""}}, "listen_duration_estimate": 792}, "1357940427": {"item_id": "1357940427", "resolved_id": "1357940427", "given_url": "https://adeshpande3.github.io/", "given_title": "Adit Deshpande ‚Äì CS Undergrad at UCLA ('19)", "favorite": "0", "status": "1", "time_added": "1525969423", "time_updated": "1638708525", "time_read": "1526093355", "time_favorited": "0", "sort_id": 185, "resolved_title": "Adit Deshpande ‚Äì Engineering at Forward : UCLA CS '19", "resolved_url": "https://adeshpande3.github.io/", "excerpt": "The Last 5 Years In Deep Learning We've come quite a long way Read More", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "14", "lang": "en", "tags": {"deep-learning": {"item_id": "1357940427", "tag": "deep-learning"}}, "authors": {"53325162": {"item_id": "1357940427", "author_id": "53325162", "name": "Adit Deshpande", "url": ""}}, "image": {"item_id": "1357940427", "src": "https://adeshpande3.github.io/adeshpande3.github.io/assets/Cover11th.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1357940427", "image_id": "1", "src": "https://adeshpande3.github.io/adeshpande3.github.io/assets/Cover11th.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 5}, "1364605909": {"item_id": "1364605909", "resolved_id": "1364605909", "given_url": "https://adeshpande3.github.io/adeshpande3.github.io/", "given_title": "Adit Deshpande ‚Äì CS Undergrad at UCLA ('19)", "favorite": "0", "status": "1", "time_added": "1537630810", "time_updated": "1638708525", "time_read": "1569277590", "time_favorited": "0", "sort_id": 186, "resolved_title": "Adit Deshpande ‚Äì Engineering at Forward : UCLA CS '19", "resolved_url": "https://adeshpande3.github.io/adeshpande3.github.io/", "excerpt": "The Last 5 Years In Deep Learning We've come quite a long way Read More", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "14", "lang": "", "tags": {"deep-learning": {"item_id": "1364605909", "tag": "deep-learning"}}, "authors": {"53325162": {"item_id": "1364605909", "author_id": "53325162", "name": "Adit Deshpande", "url": ""}}, "image": {"item_id": "1364605909", "src": "https://adeshpande3.github.io/assets/Cover11th.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1364605909", "image_id": "1", "src": "https://adeshpande3.github.io/assets/Cover11th.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 5}, "2484221084": {"item_id": "2484221084", "resolved_id": "2484221084", "given_url": "https://paperswithcode.com/area/adversarial", "given_title": "Adversarial | Papers With Code", "favorite": "0", "status": "1", "time_added": "1612436828", "time_updated": "1691366676", "time_read": "1612436840", "time_favorited": "0", "sort_id": 187, "resolved_title": "Papers with Code : Adversarial", "resolved_url": "https://paperswithcode.com/area/adversarial", "excerpt": "Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "16", "lang": "en", "top_image_url": "https://paperswithcode.com/static/sota.jpeg", "tags": {"adversarial": {"item_id": "2484221084", "tag": "adversarial"}, "deep-learning": {"item_id": "2484221084", "tag": "deep-learning"}}, "listen_duration_estimate": 6}, "2973412111": {"item_id": "2973412111", "resolved_id": "2973412111", "given_url": "https://openai.com/blog/ai-and-efficiency/", "given_title": "AI and Efficiency", "favorite": "0", "status": "1", "time_added": "1589515443", "time_updated": "1638708525", "time_read": "1589851129", "time_favorited": "0", "sort_id": 188, "resolved_title": "AI and Efficiency", "resolved_url": "https://openai.com/blog/ai-and-efficiency/", "excerpt": "Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., & Fei-Fei, L. (2009). \"ImageNet: A Large-Scale Hierarchical Image Database.\" In CVPR09. Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). \"Imagenet classification with deep convolutional neural networks.\" In F. Pereira, C. J. C. Burges, L.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "734", "lang": "en", "time_to_read": 3, "top_image_url": "https://openai.com/content/images/2020/05/ai-and-efficiency-social.png", "tags": {"benchmarks": {"item_id": "2973412111", "tag": "benchmarks"}, "deep-learning": {"item_id": "2973412111", "tag": "deep-learning"}}, "authors": {"131819009": {"item_id": "2973412111", "author_id": "131819009", "name": "Danny Hernandez", "url": "https://openai.com/blog/authors/danny/"}}, "domain_metadata": {"name": "OpenAI", "logo": "https://logo.clearbit.com/openai.com?size=800", "greyscale_logo": "https://logo.clearbit.com/openai.com?size=800&greyscale=true"}, "listen_duration_estimate": 284}, "3123102629": {"item_id": "3123102629", "resolved_id": "3123102629", "given_url": "https://thegradient.pub/ai-democratization-in-the-era-of-gpt-3/", "given_title": "AI Democratization in the Era of GPT-3", "favorite": "0", "status": "1", "time_added": "1601114010", "time_updated": "1638708525", "time_read": "1604362158", "time_favorited": "0", "sort_id": 189, "resolved_title": "AI Democratization in the Era of GPT-3", "resolved_url": "https://thegradient.pub/ai-democratization-in-the-era-of-gpt-3/", "excerpt": "On September 22nd, Microsoft announced that ‚ÄúMicrosoft is teaming up with OpenAI to exclusively license GPT-3‚Äù.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1816", "lang": "en", "time_to_read": 8, "top_image_url": "https://thegradient.pub/content/images/2020/09/main.jpg", "tags": {"bert": {"item_id": "3123102629", "tag": "bert"}, "deep-learning": {"item_id": "3123102629", "tag": "deep-learning"}, "nlp": {"item_id": "3123102629", "tag": "nlp"}}, "listen_duration_estimate": 703}, "3118473699": {"item_id": "3118473699", "resolved_id": "3118473699", "given_url": "https://thenextweb.com/neural/2020/09/21/ai-devs-created-a-lean-mean-gpt-3-beating-machine-that-uses-99-9-fewer-parameters/", "given_title": "AI devs created a lean, mean, GPT-3-beating machine that uses 99.9% fewer p", "favorite": "0", "status": "1", "time_added": "1600721897", "time_updated": "1671724937", "time_read": "1604362443", "time_favorited": "0", "sort_id": 190, "resolved_title": "AI devs created a lean, mean, GPT-3-beating machine that uses 99.9% fewer parameters", "resolved_url": "https://thenextweb.com/neural/2020/09/21/ai-devs-created-a-lean-mean-gpt-3-beating-machine-that-uses-99-9-fewer-parameters/", "excerpt": "AI researchers from the Ludwig Maximilian University (LMU) of Munich have developed a bite-sized text generator capable of besting OpenAI‚Äòs state of the art GPT-3 using only a tiny fraction of its parameters.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "417", "lang": "en", "amp_url": "https://thenextweb.com/neural/2020/09/21/ai-devs-created-a-lean-mean-gpt-3-beating-machine-that-uses-99-9-fewer-parameters/amp/", "top_image_url": "https://img-cdn.tnwcdn.com/image/neural?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2017%2F07%2Frobots.jpg&signature=5fcc857cf86c3835a880c08cf8a93783", "tags": {"bert": {"item_id": "3118473699", "tag": "bert"}, "chatbots": {"item_id": "3118473699", "tag": "chatbots"}, "deep-learning": {"item_id": "3118473699", "tag": "deep-learning"}, "nlp": {"item_id": "3118473699", "tag": "nlp"}}, "authors": {"89295889": {"item_id": "3118473699", "author_id": "89295889", "name": "Tristan Greene", "url": "https://thenextweb.com/author/tristangreen"}}, "image": {"item_id": "3118473699", "src": "https://img-cdn.tnwcdn.com/image?fit=1280%2C720&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2017%2F07%2Frobots.jpg&signature=68c051012433431a2dcc7fcb04f7a374", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3118473699", "image_id": "1", "src": "https://img-cdn.tnwcdn.com/image?fit=1280%2C720&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2017%2F07%2Frobots.jpg&signature=68c051012433431a2dcc7fcb04f7a374", "width": "0", "height": "0", "credit": "Rog01", "caption": ""}}, "domain_metadata": {"name": "The Next Web", "logo": "https://logo.clearbit.com/thenextweb.com?size=800", "greyscale_logo": "https://logo.clearbit.com/thenextweb.com?size=800&greyscale=true"}, "listen_duration_estimate": 161}, "3759768466": {"item_id": "3759768466", "resolved_id": "3759768466", "given_url": "https://stratechery.com/2022/ai-homework/", "given_title": "AI Homework ‚Äì Stratechery by Ben Thompson", "favorite": "0", "status": "1", "time_added": "1670275949", "time_updated": "1670454534", "time_read": "1670454533", "time_favorited": "0", "sort_id": 191, "resolved_title": "AI Homework", "resolved_url": "https://stratechery.com/2022/ai-homework/", "excerpt": "It happened to be Wednesday night when my daughter, in the midst of preparing for ‚ÄúThe Trial of Napoleon‚Äù for her European history class, asked for help in her role as Thomas Hobbes, witness for the defense.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3331", "lang": "en", "time_to_read": 15, "top_image_url": "https://i0.wp.com/stratechery.com/wp-content/uploads/2020/03/Stratechery-2020-03-11-23.03.59.png?fit=1200%2C811&ssl=1", "tags": {"chatgpt": {"item_id": "3759768466", "tag": "chatgpt"}, "deep-learning": {"item_id": "3759768466", "tag": "deep-learning"}, "language-linguistics": {"item_id": "3759768466", "tag": "language-linguistics"}, "nlp": {"item_id": "3759768466", "tag": "nlp"}}, "authors": {"33685485": {"item_id": "3759768466", "author_id": "33685485", "name": "Ben Thompson", "url": "https://stratechery.com/author/stratechery/"}}, "image": {"item_id": "3759768466", "src": "https://149384716.v2.pressablecdn.com/wp-content/uploads/2022/09/stratechery-update-marketing.png", "width": "600", "height": "600"}, "images": {"1": {"item_id": "3759768466", "image_id": "1", "src": "https://149384716.v2.pressablecdn.com/wp-content/uploads/2022/09/stratechery-update-marketing.png", "width": "600", "height": "600", "credit": "", "caption": ""}, "2": {"item_id": "3759768466", "image_id": "2", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-9.png?resize=640%2C508&ssl=1", "width": "640", "height": "508", "credit": "", "caption": ""}, "3": {"item_id": "3759768466", "image_id": "3", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-1.png?resize=640%2C295&ssl=1", "width": "640", "height": "295", "credit": "", "caption": ""}, "4": {"item_id": "3759768466", "image_id": "4", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-2.png?resize=640%2C262&ssl=1", "width": "640", "height": "262", "credit": "", "caption": ""}, "5": {"item_id": "3759768466", "image_id": "5", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-3.png?resize=640%2C567&ssl=1", "width": "640", "height": "567", "credit": "", "caption": ""}, "6": {"item_id": "3759768466", "image_id": "6", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-4.png?resize=640%2C528&ssl=1", "width": "640", "height": "528", "credit": "", "caption": ""}, "7": {"item_id": "3759768466", "image_id": "7", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-5.png?resize=640%2C237&ssl=1", "width": "640", "height": "237", "credit": "", "caption": ""}, "8": {"item_id": "3759768466", "image_id": "8", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-6.png?resize=640%2C251&ssl=1", "width": "640", "height": "251", "credit": "", "caption": ""}, "9": {"item_id": "3759768466", "image_id": "9", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-7.png?resize=640%2C285&ssl=1", "width": "640", "height": "285", "credit": "", "caption": ""}, "10": {"item_id": "3759768466", "image_id": "10", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2022/12/aihomework-8.png?resize=640%2C335&ssl=1", "width": "640", "height": "335", "credit": "", "caption": ""}, "11": {"item_id": "3759768466", "image_id": "11", "src": "https://i0.wp.com/stratechery.com/wp-content/uploads/2020/03/Stratechery-2020-03-11-23.03.59.png?resize=640%2C433&ssl=1", "width": "640", "height": "433", "credit": "", "caption": ""}, "12": {"item_id": "3759768466", "image_id": "12", "src": "https://149384716.v2.pressablecdn.com/wp-content/uploads/2022/09/stratechery-interviews-marketing.png", "width": "600", "height": "600", "credit": "", "caption": ""}, "13": {"item_id": "3759768466", "image_id": "13", "src": "https://149384716.v2.pressablecdn.com/wp-content/uploads/2022/09/dithering-marketing.png", "width": "600", "height": "600", "credit": "", "caption": ""}, "14": {"item_id": "3759768466", "image_id": "14", "src": "https://149384716.v2.pressablecdn.com/wp-content/uploads/2022/09/sharptech-marketing-2.png", "width": "600", "height": "600", "credit": "", "caption": ""}, "15": {"item_id": "3759768466", "image_id": "15", "src": "https://149384716.v2.pressablecdn.com/wp-content/uploads/2022/10/Sharp-China-Yellow-1024x1024.png", "width": "667", "height": "667", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Stratechery", "logo": "https://logo.clearbit.com/stratechery.com?size=800", "greyscale_logo": "https://logo.clearbit.com/stratechery.com?size=800&greyscale=true"}, "listen_duration_estimate": 1289}, "2973359507": {"item_id": "2973359507", "resolved_id": "2973359507", "given_url": "https://blog.re-work.co/ai-papers-suggested-by-experts/", "given_title": "AI Paper Recommendations from Experts", "favorite": "0", "status": "1", "time_added": "1589991773", "time_updated": "1638708525", "time_read": "1590064421", "time_favorited": "0", "sort_id": 192, "resolved_title": "13 ‚ÄòMust-Read‚Äô Papers from AI Experts", "resolved_url": "https://blog.re-work.co/ai-papers-suggested-by-experts/", "excerpt": "See part two with new experts here. After the 'top AI books' reading list was so well received, we reached out to some of our community to find out which papers they believe everyone should have read!", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1572", "lang": "en", "time_to_read": 7, "amp_url": "https://blog.re-work.co/ai-papers-suggested-by-experts/amp/", "top_image_url": "http://blog.re-work.co/content/images/2020/05/Untitled-design--29--1.png", "tags": {"deep-learning": {"item_id": "2973359507", "tag": "deep-learning"}}, "authors": {"122273856": {"item_id": "2973359507", "author_id": "122273856", "name": "Read More", "url": "https://blog.re-work.co/author/luke/"}}, "listen_duration_estimate": 609}, "3100344211": {"item_id": "3100344211", "resolved_id": "3100344211", "given_url": "https://venturebeat.com/2020/09/03/ai-researchers-use-heartbeat-detection-to-identify-deepfake-videos/", "given_title": "AI researchers use heartbeat detection to identify deepfake videos", "favorite": "0", "status": "1", "time_added": "1599149610", "time_updated": "1638708525", "time_read": "1604368771", "time_favorited": "0", "sort_id": 193, "resolved_title": "AI researchers use heartbeat detection to identify deepfake videos", "resolved_url": "https://venturebeat.com/2020/09/03/ai-researchers-use-heartbeat-detection-to-identify-deepfake-videos/", "excerpt": "Elevate your enterprise data technology and strategy at Transform 2021. Facebook and Twitter earlier this week took down social media accounts associated with the Internet Research Agency, the Russian troll farm that interfered in the U.S.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "891", "lang": "en", "time_to_read": 4, "amp_url": "https://venturebeat.com/2020/09/03/ai-researchers-use-heartbeat-detection-to-identify-deepfake-videos/amp/", "top_image_url": "https://venturebeat.com/wp-content/uploads/2020/09/ppg-cells.png?w=1200&strip=all", "tags": {"deep-learning": {"item_id": "3100344211", "tag": "deep-learning"}, "deepfakes": {"item_id": "3100344211", "tag": "deepfakes"}}, "authors": {"51503398": {"item_id": "3100344211", "author_id": "51503398", "name": "Khari Johnson", "url": "https://venturebeat.com/author/kjohnson/"}}, "image": {"item_id": "3100344211", "src": "https://venturebeat.com/wp-content/uploads/2020/09/ppg-cells.png?resize=1200%2C600&strip=all", "width": "1200", "height": "600"}, "images": {"1": {"item_id": "3100344211", "image_id": "1", "src": "https://venturebeat.com/wp-content/uploads/2020/09/ppg-cells.png?resize=1200%2C600&strip=all", "width": "1200", "height": "600", "credit": "", "caption": ""}, "2": {"item_id": "3100344211", "image_id": "2", "src": "https://venturebeat.com/wp-content/uploads/2020/09/Disinf-GIF-1.gif?w=640&resize=640%2C360&strip=all", "width": "640", "height": "360", "credit": "", "caption": ""}}, "domain_metadata": {"name": "VentureBeat", "logo": "https://logo.clearbit.com/venturebeat.com?size=800", "greyscale_logo": "https://logo.clearbit.com/venturebeat.com?size=800&greyscale=true"}, "listen_duration_estimate": 345}, "3798496737": {"item_id": "3798496737", "resolved_id": "3798496740", "given_url": "https://www.vice.com/en_us/article/m7gznn/ai-spits-out-exact-copies-of-training-images-real-people-logos-researchers-find", "given_title": "AI Spits Out Exact Copies of Training Images, Real People, Logos, Researche", "favorite": "0", "status": "1", "time_added": "1675298309", "time_updated": "1675429504", "time_read": "1675429503", "time_favorited": "0", "sort_id": 194, "resolved_title": "AI Spits Out Exact Copies of Training Images, Real People, Logos, Researchers Find", "resolved_url": "https://www.vice.com/en/article/m7gznn/ai-spits-out-exact-copies-of-training-images-real-people-logos-researchers-find", "excerpt": "The regurgitation of training data exposes image diffusion models to a number of privacy and copyright risks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1179", "lang": "en", "time_to_read": 5, "top_image_url": "https://video-images.vice.com/articles/63dabf58e5124e0b1f6432ca/lede/1675280802497-your-paragraph-text-52.jpeg?image-resize-opts=Y3JvcD0xeHc6MXhoO2NlbnRlcixjZW50ZXImcmVzaXplPTEyMDA6KiZyZXNpemU9MTIwMDoq", "tags": {"deep-learning": {"item_id": "3798496737", "tag": "deep-learning"}, "image-generation": {"item_id": "3798496737", "tag": "image-generation"}, "stable-diffusion": {"item_id": "3798496737", "tag": "stable-diffusion"}}, "authors": {"169058973": {"item_id": "3798496737", "author_id": "169058973", "name": "Chloe Xiang", "url": "https://www.vice.com/en/contributor/chloe-xiang"}}, "image": {"item_id": "3798496737", "src": "https://video-images.vice.com/articles/63dabf58e5124e0b1f6432ca/lede/1675280802497-your-paragraph-text-52.jpeg?crop=1xw:1xh;center,center&resize=20:*", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3798496737", "image_id": "1", "src": "https://video-images.vice.com/articles/63dabf58e5124e0b1f6432ca/lede/1675280802497-your-paragraph-text-52.jpeg?crop=1xw:1xh;center,center&resize=20:*", "width": "0", "height": "0", "credit": "", "caption": "Image: Carlini, Hayes, et. al."}}, "domain_metadata": {"name": "VICE", "logo": "https://logo.clearbit.com/vice.com?size=800", "greyscale_logo": "https://logo.clearbit.com/vice.com?size=800&greyscale=true"}, "listen_duration_estimate": 456}, "3078968468": {"item_id": "3078968468", "resolved_id": "3078968468", "given_url": "https://www.sciencedaily.com/releases/2020/08/200813103114.htm", "given_title": "AI system for high precision recognition of hand gestures", "favorite": "0", "status": "1", "time_added": "1597346149", "time_updated": "1638708525", "time_read": "1607569814", "time_favorited": "0", "sort_id": 195, "resolved_title": "AI system for high precision recognition of hand gestures", "resolved_url": "https://www.sciencedaily.com/releases/2020/08/200813103114.htm", "excerpt": "Scientists from Nanyang Technological University, Singapore (NTU Singapore) have developed an Artificial Intelligence (AI) system that recognises hand gestures by combining skin-like electronics with computer vision.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "831", "lang": "en", "time_to_read": 4, "top_image_url": "https://www.sciencedaily.com/images/scidaily-icon.png", "tags": {"deep-learning": {"item_id": "3078968468", "tag": "deep-learning"}, "machine-learning": {"item_id": "3078968468", "tag": "machine-learning"}, "vision": {"item_id": "3078968468", "tag": "vision"}}, "authors": {"4112981": {"item_id": "3078968468", "author_id": "4112981", "name": "Nanyang Technological University", "url": ""}}, "domain_metadata": {"name": "ScienceDaily", "logo": "https://logo.clearbit.com/sciencedaily.com?size=800", "greyscale_logo": "https://logo.clearbit.com/sciencedaily.com?size=800&greyscale=true"}, "listen_duration_estimate": 322}, "3578809072": {"item_id": "3578809072", "resolved_id": "3578809072", "given_url": "https://dev.to/evgeniykrasnokutsky/ai-virtual-assistant-technology-guide-2022-3n3i", "given_title": "AI Virtual Assistant Technology Guide 2022", "favorite": "0", "status": "1", "time_added": "1647887454", "time_updated": "1691368576", "time_read": "1647891457", "time_favorited": "0", "sort_id": 196, "resolved_title": "AI Virtual Assistant Technology Guide 2022", "resolved_url": "https://dev.to/evgeniykrasnokutsky/ai-virtual-assistant-technology-guide-2022-3n3i", "excerpt": "They can help you get an appointment or order a pizza, find the best ticket deals and bring your attention to the fact you are spending a lot on entertainment instead of investments. We are talking about AI virtual assistants, which have already become a familiar part of our daily lives.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2968", "lang": "en", "time_to_read": 13, "top_image_url": "https://res.cloudinary.com/practicaldev/image/fetch/s--SNzowUws--/c_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8auc5yhbd3ofsn3mlm9a.jpg", "tags": {"chatbots": {"item_id": "3578809072", "tag": "chatbots"}, "deep-learning": {"item_id": "3578809072", "tag": "deep-learning"}, "machine-learning": {"item_id": "3578809072", "tag": "machine-learning"}, "nlp": {"item_id": "3578809072", "tag": "nlp"}}, "image": {"item_id": "3578809072", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--1RvfWUaY--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8auc5yhbd3ofsn3mlm9a.jpg", "width": "1000", "height": "420"}, "images": {"1": {"item_id": "3578809072", "image_id": "1", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--1RvfWUaY--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8auc5yhbd3ofsn3mlm9a.jpg", "width": "1000", "height": "420", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The Practical Dev", "logo": "https://logo.clearbit.com/dev.to?size=800", "greyscale_logo": "https://logo.clearbit.com/dev.to?size=800&greyscale=true"}, "listen_duration_estimate": 1149}, "3489008533": {"item_id": "3489008533", "resolved_id": "3489008558", "given_url": "https://towardsdatascience.com/ai-based-image-compression-the-state-of-the-art-fb5aa6042bfa?source=rss----7f60cf5620c9---4", "given_title": "AI-Based Image Compression: The State of the Art", "favorite": "0", "status": "1", "time_added": "1637779286", "time_updated": "1638708525", "time_read": "1638203812", "time_favorited": "0", "sort_id": 197, "resolved_title": "AI-Based Image Compression: The State of the Art", "resolved_url": "https://towardsdatascience.com/ai-based-image-compression-the-state-of-the-art-fb5aa6042bfa", "excerpt": "Image compression involves reducing the pixels, dimensions or color components of images in order to reduce their file size. This reduces their storage and processing burden (for web performance).", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1204", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/960/0*bfV9kGEdQmSns3w3", "tags": {"deep-learning": {"item_id": "3489008533", "tag": "deep-learning"}, "image-compression": {"item_id": "3489008533", "tag": "image-compression"}}, "authors": {"113414427": {"item_id": "3489008533", "author_id": "113414427", "name": "Gilad David Maayan", "url": "https://medium.com/@giladm_95339"}}, "image": {"item_id": "3489008533", "src": "https://miro.medium.com/fit/c/56/56/2*wnTridTy7lGsfXWBNJZ6_Q.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3489008533", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*wnTridTy7lGsfXWBNJZ6_Q.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3489008533", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*bfV9kGEdQmSns3w3", "width": "700", "height": "319", "credit": "", "caption": "Image Source: Pixabay"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 466}, "3287707994": {"item_id": "3287707994", "resolved_id": "3287707994", "given_url": "https://www.thedrive.com/the-war-zone/39899/darpa-now-has-ai-controlled-f-16s-working-as-a-team-in-virtual-dogfights", "given_title": "AI-Controlled F-16s Are Now Working As A Team In DARPA's Virtual Dogfights", "favorite": "0", "status": "1", "time_added": "1616501419", "time_updated": "1654647609", "time_read": "1616501539", "time_favorited": "0", "sort_id": 198, "resolved_title": "AI-Controlled F-16s Are Now Working As A Team In DARPA's Virtual Dogfights", "resolved_url": "https://www.thedrive.com/the-war-zone/39899/darpa-now-has-ai-controlled-f-16s-working-as-a-team-in-virtual-dogfights", "excerpt": "The dogfighting AI DARPA is developing is set to make the challenging migration from a synthetic environment to the real world soon.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "1018", "lang": "en", "time_to_read": 5, "top_image_url": "https://www.thedrive.com/content/2021/03/Air-Combat-Evolution-AI-dogfight.jpg?quality=85", "tags": {"deep-learning": {"item_id": "3287707994", "tag": "deep-learning"}, "military-warfare": {"item_id": "3287707994", "tag": "military-warfare"}}, "authors": {"138040232": {"item_id": "3287707994", "author_id": "138040232", "name": "Thomas Newdick", "url": "https://www.thedrive.com/author/thomas-newdick"}}, "image": {"item_id": "3287707994", "src": "https://www.thedrive.com/content/2021/03/Air-Combat-Evolution-AI-dogfight.jpg?quality=85&width=1440&quality=70", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3287707994", "image_id": "1", "src": "https://www.thedrive.com/content/2021/03/Air-Combat-Evolution-AI-dogfight.jpg?quality=85&width=1440&quality=70", "width": "0", "height": "0", "credit": "YOUTUBE SCREENCAP", "caption": ""}, "2": {"item_id": "3287707994", "image_id": "2", "src": "https://www.thedrive.com/content-b/message-editor%2F1616458772414-screenshot2021-03-23at00.45.51.jpg?quality=60", "width": "0", "height": "0", "credit": "YOUTUBE SCREENCAP", "caption": "So far, the Air Combat Evolution has focused on virtual dogfighting, but that‚Äôs due to change later this year."}, "3": {"item_id": "3287707994", "image_id": "3", "src": "https://www.thedrive.com/content-b/message-editor%2F1616459090915-screenshot2021-03-23at00.46.04.jpg?quality=60", "width": "0", "height": "0", "credit": "YOUTUBE SCREENCAP", "caption": "A pilot takes on an AI opponent during the AlphaDogfight Trials."}, "4": {"item_id": "3287707994", "image_id": "4", "src": "https://www.thedrive.com/content-b/message-editor%2F1616459355394-screenshot2021-03-23at00.49.21.jpg?quality=60", "width": "0", "height": "0", "credit": "YOUTUBE SCREENCAP", "caption": "Test pilots in an L-29 Delfin jet trainer assess the pilot‚Äôs physiological responses to AI-generated flight commands."}, "5": {"item_id": "3287707994", "image_id": "5", "src": "https://www.thedrive.com/content-b/message-editor%2F1616458919133-screenshot2021-03-23at00.48.09.jpg?quality=60", "width": "0", "height": "0", "credit": "YOUTUBE SCREENCAP", "caption": "The L-39 Albatros will serve as the mount for an onboard AI ‚Äúpilot‚Äù under Phase 3 of ACE."}, "6": {"item_id": "3287707994", "image_id": "6", "src": "https://www.thedrive.com/content-b/message-editor%2F1616459233966-screenshot2021-03-23at00.51.37.jpg?quality=60", "width": "0", "height": "0", "credit": "YOUTUBE SCREENCAP", "caption": "A slide from a DARPA presentation showing the planned phases within ACE."}}, "videos": {"1": {"item_id": "3287707994", "video_id": "1", "src": "https://www.youtube.com/embed/Sd8ryTWOjBg?rel=0", "width": "0", "height": "0", "type": "1", "vid": "Sd8ryTWOjBg", "length": "0"}}, "domain_metadata": {"name": "The Drive", "logo": "https://logo.clearbit.com/thedrive.com?size=800", "greyscale_logo": "https://logo.clearbit.com/thedrive.com?size=800&greyscale=true"}, "listen_duration_estimate": 394}, "3330236956": {"item_id": "3330236956", "resolved_id": "3330236956", "given_url": "https://multithreaded.stitchfix.com/blog/2021/05/12/algorithm-assisted-inventory-curation/", "given_title": "Algorithm-Assisted Inventory Curation", "favorite": "0", "status": "1", "time_added": "1620871245", "time_updated": "1670682578", "time_read": "1621101403", "time_favorited": "0", "sort_id": 199, "resolved_title": "Algorithm-Assisted Inventory Curation", "resolved_url": "https://multithreaded.stitchfix.com/blog/2021/05/12/algorithm-assisted-inventory-curation/", "excerpt": "Personalizing fashion at scale requires that we build an inventory whose size and complexity are as great as that of our client base.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2984", "lang": "en", "time_to_read": 14, "top_image_url": "https://multithreaded.stitchfix.com/assets/images/logomark-linkedin.jpg", "tags": {"clothes": {"item_id": "3330236956", "tag": "clothes"}, "collecting-curation": {"item_id": "3330236956", "tag": "collecting-curation"}, "deep-learning": {"item_id": "3330236956", "tag": "deep-learning"}, "fashion": {"item_id": "3330236956", "tag": "fashion"}, "machine-learning": {"item_id": "3330236956", "tag": "machine-learning"}, "recommenders": {"item_id": "3330236956", "tag": "recommenders"}}, "image": {"item_id": "3330236956", "src": "https://multithreaded.stitchfix.com/assets/posts/2021-05-11-algorithm-assisted-inventory-curation/style_explorer_architecture_2.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3330236956", "image_id": "1", "src": "https://multithreaded.stitchfix.com/assets/posts/2021-05-11-algorithm-assisted-inventory-curation/style_explorer_architecture_2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3330236956", "image_id": "2", "src": "https://multithreaded.stitchfix.com/assets/posts/2021-05-11-algorithm-assisted-inventory-curation/virtual_inventory_3.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3330236956", "image_id": "3", "src": "https://multithreaded.stitchfix.com/assets/posts/2021-05-11-algorithm-assisted-inventory-curation/metric_2020_3.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1155}, "3225696416": {"item_id": "3225696416", "resolved_id": "3225696416", "given_url": "https://news.ycombinator.com/item?id=25716581", "given_title": "Algorithms for Decision Making | Hacker News", "favorite": "0", "status": "1", "time_added": "1610365167", "time_updated": "1638708525", "time_read": "1610574896", "time_favorited": "0", "sort_id": 200, "resolved_title": "", "resolved_url": "https://news.ycombinator.com/item?id=25716581", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"books": {"item_id": "3225696416", "tag": "books"}, "deep-learning": {"item_id": "3225696416", "tag": "deep-learning"}, "machine-learning": {"item_id": "3225696416", "tag": "machine-learning"}}, "domain_metadata": {"name": "Y Combinator", "logo": "https://logo.clearbit.com/ycombinator.com?size=800", "greyscale_logo": "https://logo.clearbit.com/ycombinator.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3170402481": {"item_id": "3170402481", "resolved_id": "3170402501", "given_url": "https://towardsdatascience.com/practical-guide-to-entity-resolution-part-4-299ac89b9415?source=rss----7f60cf5620c9---4", "given_title": "All Personal Feeds", "favorite": "0", "status": "1", "time_added": "1605138040", "time_updated": "1638708525", "time_read": "1608290451", "time_favorited": "0", "sort_id": 201, "resolved_title": "Practical Guide to Entity Resolution", "resolved_url": "https://towardsdatascience.com/practical-guide-to-entity-resolution-part-4-299ac89b9415", "excerpt": "This is part 4 of a mini-series on entity resolution. Check out part 1, part 2, part 3 if you missed it Candidate pair generation is a fairly straightforward part of ER, as it is essentially a self join on the blocking keys.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "520", "lang": "en", "top_image_url": "https://miro.medium.com/max/1200/0*DIy4DcgKrMCLTqVi", "tags": {"deep-learning": {"item_id": "3170402481", "tag": "deep-learning"}, "entity-resolution": {"item_id": "3170402481", "tag": "entity-resolution"}, "vision": {"item_id": "3170402481", "tag": "vision"}}, "authors": {"142254521": {"item_id": "3170402481", "author_id": "142254521", "name": "Yifei Huang", "url": "https://yifei-huang.medium.com"}}, "image": {"item_id": "3170402481", "src": "https://miro.medium.com/fit/c/56/56/1*c01BdvUOn9xPafDWjDKy2A.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3170402481", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*c01BdvUOn9xPafDWjDKy2A.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3170402481", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*DIy4DcgKrMCLTqVi", "width": "700", "height": "467", "credit": "Alina Grubnyak on Unsplash", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 201}, "3552977122": {"item_id": "3552977122", "resolved_id": "3552977122", "given_url": "https://towardsdatascience.com/all-you-need-to-know-about-attention-and-transformers-in-depth-understanding-part-1-552f0b41d021", "given_title": "All you need to know about ‚ÄòAttention‚Äô and ‚ÄòTransformers‚Äô ‚Äî In-depth Unders", "favorite": "0", "status": "1", "time_added": "1663290084", "time_updated": "1663713072", "time_read": "1663713071", "time_favorited": "0", "sort_id": 202, "resolved_title": "All you need to know about ‚ÄòAttention‚Äô and ‚ÄòTransformers‚Äô‚Ää‚Äî‚ÄäIn-depth Understanding‚Ää‚Äî‚ÄäPart 1", "resolved_url": "https://towardsdatascience.com/all-you-need-to-know-about-attention-and-transformers-in-depth-understanding-part-1-552f0b41d021", "excerpt": "This is a long article that talks about almost everything one needs to know about the Attention mechanism including Self-Attention, Query, Keys, Values, Multi-Head Attention, Masked-Multi Head Attention, and Transformers including some details on BERT and GPT.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "2709", "lang": "en", "time_to_read": 12, "top_image_url": "https://miro.medium.com/v2/resize:fit:925/1*Rv_pntt-N2WL7LMbIptHxQ.png", "tags": {"deep-learning": {"item_id": "3552977122", "tag": "deep-learning"}, "transformers": {"item_id": "3552977122", "tag": "transformers"}}, "authors": {"141711448": {"item_id": "3552977122", "author_id": "141711448", "name": "Arjun Sarkar", "url": "https://arjun-sarkar786.medium.com"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1049}, "3702309716": {"item_id": "3702309716", "resolved_id": "3702309716", "given_url": "https://towardsdatascience.com/all-you-need-to-know-about-attention-and-transformers-in-depth-understanding-part-2-bf2403804ada", "given_title": "All you need to know about ‚ÄòAttention‚Äô and ‚ÄòTransformers‚Äô‚Ää‚Äî‚ÄäIn-depth Unders", "favorite": "0", "status": "1", "time_added": "1663112626", "time_updated": "1663713087", "time_read": "1663713087", "time_favorited": "0", "sort_id": 203, "resolved_title": "All you need to know about ‚ÄòAttention‚Äô and ‚ÄòTransformers‚Äô‚Ää‚Äî‚ÄäIn-depth Understanding‚Ää‚Äî‚ÄäPart 2", "resolved_url": "https://towardsdatascience.com/all-you-need-to-know-about-attention-and-transformers-in-depth-understanding-part-2-bf2403804ada", "excerpt": "In the previous story, I have explained what is the Attention mechanism, and some important keywords and blocks associated with Transformers, such as Self Attention, Query, Keys and Values, and Multi-head Attention.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1826", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1200/0*Wvg_pNDViACfg-IK.png", "tags": {"deep-learning": {"item_id": "3702309716", "tag": "deep-learning"}, "transformers": {"item_id": "3702309716", "tag": "transformers"}}, "authors": {"141711448": {"item_id": "3702309716", "author_id": "141711448", "name": "Arjun Sarkar", "url": "https://arjun-sarkar786.medium.com"}}, "image": {"item_id": "3702309716", "src": "https://miro.medium.com/max/1090/1*9XuOogviDS6hkWGL2qIKQA.png", "width": "545", "height": "0"}, "images": {"1": {"item_id": "3702309716", "image_id": "1", "src": "https://miro.medium.com/max/1090/1*9XuOogviDS6hkWGL2qIKQA.png", "width": "545", "height": "0", "credit": "Source: Image from the original paper", "caption": "Figure 1. The Transformer Network"}, "2": {"item_id": "3702309716", "image_id": "2", "src": "https://miro.medium.com/max/552/1*y12gX71mhbtT96lwM0Zw0A.png", "width": "276", "height": "0", "credit": "Source: image from the original paper", "caption": "Figure 2. The Encoder part of the transformer network"}, "3": {"item_id": "3702309716", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*9-g1EJnHWF5lqFZTYtY68w.png", "width": "700", "height": "0", "credit": "Source: image created by author", "caption": "Figure 3. Input embedding"}, "4": {"item_id": "3702309716", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*xMcS_KlxzTo_X5zsKTpPdg.png", "width": "700", "height": "0", "credit": "Source: image created by author", "caption": "Figure 4. Intuitive understanding of positional embedding"}, "5": {"item_id": "3702309716", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*07Vf8VOpmj7J0wQB3rejSQ.png", "width": "700", "height": "0", "credit": "Source: image from the original paper", "caption": "Figure 5. Positional embedding used in the original paper"}, "6": {"item_id": "3702309716", "image_id": "6", "src": "https://miro.medium.com/max/550/1*Bo8Y3oW_nMqrgkk3ttsb-w.png", "width": "275", "height": "0", "credit": "Source: image from the original paper", "caption": "Figure 6. Scaled Dot-product Attention"}, "7": {"item_id": "3702309716", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*WP24tnEeiPNMHgTRCr-x2w.png", "width": "700", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3702309716", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*iBtLFJu7eiGy5vhmOw56-w.png", "width": "700", "height": "0", "credit": "Source: image created by author", "caption": "Figure 7. The Attention block"}, "9": {"item_id": "3702309716", "image_id": "9", "src": "https://miro.medium.com/max/1400/0*Wvg_pNDViACfg-IK.png", "width": "700", "height": "0", "credit": "source: image created by author", "caption": "Figure 8. Multi-Head Attention"}, "10": {"item_id": "3702309716", "image_id": "10", "src": "https://miro.medium.com/max/552/1*PoM8vzFdcf6AEOMys3DtlA.png", "width": "276", "height": "0", "credit": "Souce: Image from the original paper", "caption": "Figure 9. The Decoder part of the Transformer network"}, "11": {"item_id": "3702309716", "image_id": "11", "src": "https://miro.medium.com/max/1400/1*ag-93N1KFg67-qOjBo9Unw.png", "width": "700", "height": "0", "credit": "Source: image created by author", "caption": "Figure 10. The function of different decoder blocks in sentence translation"}, "12": {"item_id": "3702309716", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*l9bfa_RbYzyTZBcYj9Vkcg.png", "width": "700", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3702309716", "image_id": "13", "src": "https://miro.medium.com/max/1400/1*jxZqxY1sLjx_4i8O6Jt5QA.png", "width": "700", "height": "0", "credit": "source: image from the original paper", "caption": "Figure 11. Results"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 707}, "2825324699": {"item_id": "2825324699", "resolved_id": "2825324699", "given_url": "https://www.altmetric.com/top100/2019/", "given_title": "Altmetric ‚Äì Top 100 articles ‚Äì¬†2019", "favorite": "0", "status": "1", "time_added": "1577728515", "time_updated": "1638708525", "time_read": "1582143051", "time_favorited": "0", "sort_id": 204, "resolved_title": "The Altmetric Top 100 2019", "resolved_url": "https://www.altmetric.com/top100/2019/", "excerpt": "Your browser is out of date. It has known security flaws and may not display all features of this and other websites.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "34", "lang": "en", "top_image_url": "http://www.altmetric.com/top100/2019/intro.png", "tags": {"deep-learning": {"item_id": "2825324699", "tag": "deep-learning"}}, "listen_duration_estimate": 13}, "3412047819": {"item_id": "3412047819", "resolved_id": "3412047819", "given_url": "https://thegradient.pub/an-introduction-to-ai-story-generation/", "given_title": "An Introduction to AI Story Generation", "favorite": "0", "status": "1", "time_added": "1629667081", "time_updated": "1630523619", "time_read": "1630523619", "time_favorited": "0", "sort_id": 205, "resolved_title": "An Introduction to AI Story Generation", "resolved_url": "https://thegradient.pub/an-introduction-to-ai-story-generation/", "excerpt": "Automated story generation is the use of an intelligent system to produce a fictional story from a minimal set of inputs. This is a problem that has long been explored by AI researchers, since it strikes at some fundamental research questions in artificial intelligence.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "6133", "lang": "en", "time_to_read": 28, "top_image_url": "https://thegradient.pub/content/images/2021/08/Screenshot-2021-08-20-020858.png", "tags": {"deep-learning": {"item_id": "3412047819", "tag": "deep-learning"}, "storytelling": {"item_id": "3412047819", "tag": "storytelling"}}, "image": {"item_id": "3412047819", "src": "https://lh4.googleusercontent.com/5O2b9mTfP0f1GxpGQc0zAjG6cCX7n3XIrmeSqwfRp9jPm8YbahX-m693tZNzoZpX70a5DxcnA23nYiiNlgw4BpecvvV9N_XEPuUI6ZAcgw9ueG96EaZmvVCMrz5qicIdhQAm1vfj", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3412047819", "image_id": "1", "src": "https://lh4.googleusercontent.com/5O2b9mTfP0f1GxpGQc0zAjG6cCX7n3XIrmeSqwfRp9jPm8YbahX-m693tZNzoZpX70a5DxcnA23nYiiNlgw4BpecvvV9N_XEPuUI6ZAcgw9ueG96EaZmvVCMrz5qicIdhQAm1vfj", "width": "0", "height": "0", "credit": "", "caption": "This is an article from Popular Mechanics in 1931."}, "2": {"item_id": "3412047819", "image_id": "2", "src": "https://lh5.googleusercontent.com/cQLhZBgDen_GRpt1KG978fe0HmnqwTL1AvbVf9s793HNdoh0_U79j57kAES24O767ISVs1XaOWMnIe-DSNjSpMWmaiQI2JejNTNvuIUd6LUHGCD-e9XYIwuNrdPOvC84uu_wOoIg", "width": "0", "height": "0", "credit": "1960", "caption": "The earliest known story generated by a grammar-based story generation system"}, "3": {"item_id": "3412047819", "image_id": "3", "src": "https://lh6.googleusercontent.com/edoV9zc9fsc_Dka8gdoul73J35G9dx3vGcUdTuU-dgTwpyx8n8V7x4M2sBN1fZ8oKQQE2ionhX_ts-DLh6qnz3Ka2gbyZEWn5EuIfgaErVpboV3sleLAimtk-g9gPD0KkzjWIKcr", "width": "0", "height": "0", "credit": "", "caption": "The Rumelhart story grammar."}, "4": {"item_id": "3412047819", "image_id": "4", "src": "https://lh6.googleusercontent.com/n_0oTuJMEOdN_-6SE6zPPfjogFeQjdfI6YZstUtXuLvtiOWwQmoRbHqCrdXktDChsuwOpm1saF1kqRajxVlRBHWvt1RnwoEArPuDr1tkA7HmB_LKcCsgu7tvkA0Fptn1mT3CE7FT", "width": "0", "height": "0", "credit": "", "caption": "A story generated by the Tale Spin system."}, "5": {"item_id": "3412047819", "image_id": "5", "src": "https://lh5.googleusercontent.com/ukhOIghdNIKVjbFOAKgd5jCUXczmOM_V2MVguv95r-h0Z6azzvDobY_hLbf-ELoG5Sj_eKdzB1XNAfZL7LIdeZ1UKBtuu7cSqfstmf1Al0paP7uxSx3dzhF3BEDT5NOdmgCFttAp", "width": "0", "height": "0", "credit": "", "caption": "Mis-spun tales generated by the Tale Spin system."}, "6": {"item_id": "3412047819", "image_id": "6", "src": "https://lh6.googleusercontent.com/x2cHgYImWXFCw_g5vcyIKHW6OaaKcHO54Fu7v7fZ9wMlDIF6kZnSjLp4SzmzJ7Sy4FslHUqg4hK2PGIsV5_tjs0RcmGRR6fNqNtlDhZuPXMxdcsZRRvKvqyCOCoALaaeoMSejqxb", "width": "0", "height": "0", "credit": "", "caption": "A plot fragment schema from the Universe system."}, "7": {"item_id": "3412047819", "image_id": "7", "src": "https://lh4.googleusercontent.com/2nmxBeaeDGjFvvak2rzESLp-mwHk4JPU_yN9Tl-0zt6ej4RmZ25G0ZoR8wXAWyNZvVlW-JgNmiJeZzPxchx-gakqmWS-9IxpyoGHbmroveNrDiltImPOz6gr6mYZHO_EX9fIbp7-", "width": "0", "height": "0", "credit": "", "caption": "A story generated by the Universe system."}, "8": {"item_id": "3412047819", "image_id": "8", "src": "https://lh4.googleusercontent.com/iFKTOUiYeF0bio5Oz3oDW3KQNgsx1aOUoSJcB6K_Vin_u9KGYnl8Xmb1wtpcus4ZcB6BabsKHeJZHN9FUYQdl6X3J9SDHSMGNnAQUwMw55lQVmV1ExR_95d50YDl9FUokuR3hseL", "width": "0", "height": "0", "credit": "", "caption": "An action schema for a POCL planner."}, "9": {"item_id": "3412047819", "image_id": "9", "src": "https://lh3.googleusercontent.com/b6_XMRjw5Mrkbgt2RPn21T9PI2z4396C_c3MM2vfqZHJXFBQn1EmNdjZuwmUNhVadJpDXN2g7DqA6UAIUZR2Obd5AOzFGYCCSde9QN0Ix2ebTzJ3uO0kcHBH0mGs5dNhUiW1JcQo", "width": "0", "height": "0", "credit": "2010", "caption": "A story plan generated by a POCL planner from Riedl and Young"}, "10": {"item_id": "3412047819", "image_id": "10", "src": "https://lh3.googleusercontent.com/GuZZWlhCqwcBqZykPTECm4pt4_YLBwa87Mr-y_xdHLMSlY2R-GGD41sbETSzs8WInLrbZ6AIohdfefTgllYa61xE4FWXzP1z_rX85_ub_mNWyxtlLnGEaz5ypM1UWa7srC-PGyBO", "width": "0", "height": "0", "credit": "", "caption": "A story plan generated by Fabulist. The orange bubbles show actions that are part of goal hierarchies."}, "11": {"item_id": "3412047819", "image_id": "11", "src": "https://lh5.googleusercontent.com/8563v0BCaM7is9XfACQQsgpP9yGFwpjXSHQVFTO-i3VwuHPgyEQwKYUD899QWPxo2GitYZPp_m91jjIo0_2IJrMiFinySYxBe3bkFryjomVFmnzDYkouI2AYADfWUAjOCO_PpKmP", "width": "0", "height": "0", "credit": "", "caption": "A story generated by Fabulist corresponding to the above plan data structure."}, "12": {"item_id": "3412047819", "image_id": "12", "src": "https://lh3.googleusercontent.com/zXSRWBkXxITbjpJZhBx9cKUE8mUpY5VEZ0rwXJzDMVJIjQmQKqBYNSXVexKJSNBnVoHx1yypqajv0g9dyj2HdvbskjRlhoMBr8oOSQ6VtFwNR8EGu-ZWWP5_73kYVm2WZS3n_UrP", "width": "0", "height": "0", "credit": "", "caption": "An example CPOCL plan with character conflict and un-executed actions."}, "13": {"item_id": "3412047819", "image_id": "13", "src": "https://lh6.googleusercontent.com/_4mGJyzI_VbwSItE_YE2yQkBn9HphodFik7d_GRhokWP3yqpAmGY7OLmiKqkMjNEZc10Fm0QeKbMkyfj1aj4rcJMhwc7pdbC6fzgF_UiQ_ZMb9CSm-B_hFApvl73zPdctqGnx7XT", "width": "0", "height": "0", "credit": "", "caption": "A story generated by CPOCL."}, "14": {"item_id": "3412047819", "image_id": "14", "src": "https://lh3.googleusercontent.com/l7-OCzewOkHe85GFBgA5ebb9KTSE-ZRciZD5lsG3tIWliBD9Lpl2xvoURdkKTavGhLOlmiakjI207nEtyN2BfX1Tq2aOEyJtEHwpdlD30gXzoJctQNWm9bFJUIing7r0Uz5oJvjM", "width": "0", "height": "0", "credit": "", "caption": "A story generated by the Minstrel system."}, "15": {"item_id": "3412047819", "image_id": "15", "src": "https://lh5.googleusercontent.com/_19iHrXp9stmg_PpEb7168QgxL2BI8kVJZ4XJU29gVlWgWAE_QJNuNPeFcB4o8QoRRjfRG9X8E6ih9vDvgoQcQ3D_JS8JjlKZugaglQH4t3KjOocAQmeswii-wcu3hTJgEneOjhH", "width": "0", "height": "0", "credit": "", "caption": "Case library for the ProtoPropp system."}, "16": {"item_id": "3412047819", "image_id": "16", "src": "https://lh3.googleusercontent.com/7_XyR-93MLyrU1YRrS9fBwtCBGNKzyh-4fAWUwbXJstzXv828xROSIEL8gViAj9oFBCw-UGHZpycytNWgWpnQJHWIM6BRIu6enfKpLwQ1Y160JPjEv7h7nbkUqNQgg__DY3LCXw8", "width": "0", "height": "0", "credit": "", "caption": "A story generated by the Mexica system. Regular text was generated during the engagement phase. Text in italics was generated during the reflection phase."}, "17": {"item_id": "3412047819", "image_id": "17", "src": "https://lh4.googleusercontent.com/MxbtSYyHz-G4ZYF255UJVZG8kEgZUNfZFEP73UxmxtL-X4L7Pau--uhW9_qZfhA8zvCS0MkoBf7BMHYJ0YKcSHaA8wVD7J3M0ofNjJv2n0AyQhbt0UEu42LqLVd-TT7JHE2g7pZ6", "width": "0", "height": "0", "credit": "", "caption": "The hierarchical task network for character agents in a story simulation."}, "18": {"item_id": "3412047819", "image_id": "18", "src": "https://lh6.googleusercontent.com/Rtfbp076272o6IsCtJ7Qow049Kuo5QQ66TsfBXOXRDQ2icp5-6jYtN47TPMOgebGKYUBUSAetMsRJBdqOpaJx3k2xgPIoT56TICQhxML7hyclk8GnNIzMmnzBvOOExDqdREYy2se", "width": "0", "height": "0", "credit": "", "caption": "A plot graph learned by Scheherazade for going on a date to a movie theatre."}, "19": {"item_id": "3412047819", "image_id": "19", "src": "https://lh6.googleusercontent.com/oifElz0fcOsLeETOviI-0RSMV3zboxWupGSFh9VdAtZM2fcMMohEFqvUINTkJu0k2q2r_4sfVlGKjPUIY6KYLLREZsiagnZ2D-cLQ0jbbfyUoeNiC-ZFb6zdbidDJ0FX-gQQOn3l", "width": "0", "height": "0", "credit": "", "caption": "A story generated by Scheherazade for the plot graph above."}, "20": {"item_id": "3412047819", "image_id": "20", "src": "https://lh3.googleusercontent.com/6vhfJeAlxe0U8D-V_GTnwoGVQNK6h5UQ2ghTCfw5H7TjOSuM5HOJFnqv8cJucUfMxBhieQqMCF1TpjmnfAvo2VHDoP0elusUKlttYBjo5T14D-wVm_NN68nibzSmFBkTa2gY9F_r", "width": "0", "height": "0", "credit": "2018", "caption": "The generation loop for Martin et al."}, "21": {"item_id": "3412047819", "image_id": "21", "src": "https://lh6.googleusercontent.com/ZiR0LaZrvlX2gPpPaWth-y--M6kfkz5ix58JHNnnlDU4llow0yWJ5mdXVKeXwFM3KqjPpYF5Jzzwh4zOBpNMPrXfKKdF6zJ3Lf8ygOAAoL3p1l9tjIqX6zFe6Sq6hubAlge1XHUr", "width": "0", "height": "0", "credit": "2018", "caption": "Fine-tuning the event2event neural network from the Martin et al."}, "22": {"item_id": "3412047819", "image_id": "22", "src": "https://lh5.googleusercontent.com/-15Qv1DTTnpayPNhlG0W9tpNWE4iibVmyw5x4AcIT0wHLBYKEwCJCpC58U8g2Oh6ez1HsNtZ_1WAfQWrIlIrxgjoPWIZrio--1EyGE6tz-4ExA2ei3CQzhN_o6K3sp5pcNglKzj3", "width": "0", "height": "0", "credit": "", "caption": "Fine-tuning reward is calculated by analyzing how close verbs are to each other in the corpus."}, "23": {"item_id": "3412047819", "image_id": "23", "src": "https://lh5.googleusercontent.com/LNgc4hdBuJJ1gioQP5QEvhibC4D9ZFH7NJwOQJb2TdI7bf4o0dLJIahc3_aKA_QIbhA75KDgtPp50YH-fSMh_6PIYTSWIABwGFQ82YH_2nVJm1nLK_24ZgrRN-9--0yGjXrolKkP", "width": "0", "height": "0", "credit": "", "caption": "Stories generated by the hierarchical fusion model."}, "24": {"item_id": "3412047819", "image_id": "24", "src": "https://lh4.googleusercontent.com/ahDEjD5Fmh6VB85ampmX6bgzpk69RoAVmjlNd4frRPvrBAQkn7a2gGIfBwIbkrHdYebUzP7YjCUyw4MUOCqwPW814TZUa6D5Ir1C2P4mLX_95CP_figgVPSo-8wB8JqSysKl5SGp", "width": "0", "height": "0", "credit": "", "caption": "Stories generated by the plan-and-write system."}, "25": {"item_id": "3412047819", "image_id": "25", "src": "https://lh6.googleusercontent.com/LniujhVRQZzIy18Ej7yKTA8NFM4ikzzKp1iSstORHO30Cj-PXSGKLFRHFbrQs0bJE8Rkap7nQYghCh5we213BSzJ1DoHZvaX0RcfkXUFg3rvL4v7cgCrFyyn0CdvCw-vNwQlm9HL", "width": "0", "height": "0", "credit": "", "caption": "Illustration of inputs and outputs of the PlotMachines system."}, "26": {"item_id": "3412047819", "image_id": "26", "src": "https://lh6.googleusercontent.com/63OpxkD76wh-jO6RKy7cQBHUe-02gW64QE1JsL7lmpwyoETD2jrHz8MueO2Gi3XsVOIVdiAqeR608DYj1PDpAtEzujvlsdXLiHz-0vLe0H-_X746e8yXxlfAiAw-pkDKhCyfkNeT", "width": "0", "height": "0", "credit": "", "caption": "The neurosymbolic architecture by Martin. The World Engine maintains a set of propositions about the story world."}, "27": {"item_id": "3412047819", "image_id": "27", "src": "https://lh5.googleusercontent.com/cv9qJripxhLJ-dQaEDp4selSUITVDJGBFrYCJ4Ihtjn9w4oOMtEVaBXj8dWgNAK0eqV4bqPTi42RP0_4Jm-2qTSc4HKQ1amftlcAGfUSPydVvH9h9RvnGK1FW0EfAuwXDERJ-qzG", "width": "0", "height": "0", "credit": "", "caption": "The CAST pipeline."}, "28": {"item_id": "3412047819", "image_id": "28", "src": "https://lh4.googleusercontent.com/YRdeE_mXK6Y1HN3PRPB39P6oq4usgSqeHawAwHn7npw71ZAMmv3EfcsOyZrB28yudtDCOo8mgNmjnWXA00Eb8a_3LCDmYtWBWu8EFibVB2JoZbSbp8nKAidOjM8W6TzU-DnSURLd", "width": "0", "height": "0", "credit": "", "caption": "The graph built by C2PO. 1) the initial event. 2) the final event. 3) the event found that bridges the forward and backward sub-graphs."}, "29": {"item_id": "3412047819", "image_id": "29", "src": "https://lh4.googleusercontent.com/SxfPt8uyZ3kkVg7vpf0vMZ4tKUEorz_ehlTUMvOYpqAPs7XburnoeHCXllJGL1dq4JkoBy46ZaPY5tsy1ZkxkVCYDs1E8HlFGLxrhShbBmEwvUahEAIMZ2OuRQ7iQkkvWFakmwmC", "width": "0", "height": "0", "credit": "", "caption": "Example stories generated by C2PO."}, "30": {"item_id": "3412047819", "image_id": "30", "src": "https://lh6.googleusercontent.com/ONNiWyr32hOea6lrcEHgLrjpKZzrtlWrJOAyEqGm8D7rQXMTalS4P8ucYtkv4GkgJvHrhdEqjHsIx18B5taMDIPpw-_wiJvX6TVAFaKqxb0yNqJaamlsBcqiVvWXzOvVMlYMqvOH", "width": "0", "height": "0", "credit": "", "caption": "Stories generated via question-answering. The bold text is given input."}}, "listen_duration_estimate": 2374}, "3107429494": {"item_id": "3107429494", "resolved_id": "3107422058", "given_url": "https://towardsdatascience.com/an-intuitive-guide-to-auto-encoders-theory-code-and-visualization-3cc2a6a30d2c?source=rss----7f60cf5620c9---4", "given_title": "An Intuitive Guide to Auto-Encoders: Theory, Code and Visualization", "favorite": "0", "status": "1", "time_added": "1599760442", "time_updated": "1638708525", "time_read": "1604958605", "time_favorited": "0", "sort_id": 206, "resolved_title": "An Intuitive Guide to Auto-Encoders: Theory, Code and Visualization", "resolved_url": "https://towardsdatascience.com/an-intuitive-guide-to-auto-encoders-theory-code-and-visualization-3cc2a6a30d2c", "excerpt": "Auto-Encoders are one of the most useful unsupervised algorithms, to gain insight into the data, and therefore optimize the learning algorithm that trains the algorithm. Auto-Encoders are a neural network, that takes the data as its input, and the data as its output.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1141", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/1*A-Foet4BRO2DJl5R-PCF-w.jpeg", "tags": {"deep-learning": {"item_id": "3107429494", "tag": "deep-learning"}}, "authors": {"150437764": {"item_id": "3107429494", "author_id": "150437764", "name": "Victor S", "url": "https://medium.com/@vs1324"}}, "image": {"item_id": "3107429494", "src": "https://miro.medium.com/fit/c/56/56/1*nwlQK29Z0d-tJF0QuvCXoA.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3107429494", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*nwlQK29Z0d-tJF0QuvCXoA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3107429494", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*A-Foet4BRO2DJl5R-PCF-w.jpeg", "width": "700", "height": "467", "credit": "pixabay on pexels", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 442}, "1871697531": {"item_id": "1871697531", "resolved_id": "1871697531", "given_url": "http://www.kdnuggets.com/2017/08/intuitive-guide-deep-network-architectures.html", "given_title": "An Intuitive Guide to Deep Network Architectures", "favorite": "0", "status": "1", "time_added": "1503938675", "time_updated": "1706633668", "time_read": "1514398069", "time_favorited": "0", "sort_id": 207, "resolved_title": "An Intuitive Guide to Deep Network Architectures", "resolved_url": "https://www.kdnuggets.com/2017/08/intuitive-guide-deep-network-architectures.html", "excerpt": "By Joyce Xu, Stanford. Over the past few years, much of the progress in deep learning for computer vision can be boiled down to just a handful of neural network architectures.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2885", "lang": "en", "time_to_read": 13, "tags": {"deep-learning": {"item_id": "1871697531", "tag": "deep-learning"}, "glossaries": {"item_id": "1871697531", "tag": "glossaries"}}, "image": {"item_id": "1871697531", "src": "https://cdn-images-1.medium.com/max/2000/1*_rCyzi7fQzc_Q1gCqSLM1g.png", "width": "95", "height": "0"}, "images": {"1": {"item_id": "1871697531", "image_id": "1", "src": "https://cdn-images-1.medium.com/max/2000/1*_rCyzi7fQzc_Q1gCqSLM1g.png", "width": "95", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1871697531", "image_id": "2", "src": "https://cdn-images-1.medium.com/max/1600/1*5zSgo2L71FJos8XendgCvQ.jpeg", "width": "95", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "1871697531", "image_id": "3", "src": "https://cdn-images-1.medium.com/max/1600/1*RuR5VAe4WaODcQFrxU6vWw.jpeg", "width": "95", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "1871697531", "image_id": "4", "src": "https://cdn-images-1.medium.com/max/1600/1*lGm8_2SBMkAyechJeznyAQ.png", "width": "95", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "1871697531", "image_id": "5", "src": "https://cdn-images-1.medium.com/max/2000/1*aq4tcBl9t5Z36kTDeZSOHA.png", "width": "95", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "1871697531", "image_id": "6", "src": "https://cdn-images-1.medium.com/max/1600/1*SRBSbojkg48DTUMcP5VVHg.jpeg", "width": "95", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 1117}, "3124619357": {"item_id": "3124619357", "resolved_id": "3124615088", "given_url": "https://towardsdatascience.com/an-intuitive-guide-to-lstms-e26f06273ad3?source=rss----7f60cf5620c9---4", "given_title": "An Intuitive Guide to LSTMs", "favorite": "0", "status": "1", "time_added": "1601247493", "time_updated": "1638708525", "time_read": "1604361981", "time_favorited": "0", "sort_id": 208, "resolved_title": "An Intuitive Guide to LSTMs", "resolved_url": "https://towardsdatascience.com/an-intuitive-guide-to-lstms-e26f06273ad3", "excerpt": "LSTMs are one of the most important breakthroughs in machine learning; Giving machine learning algorithms the ability to recall past information, allows for the realization of temporal patterns. How better to understand a concept, than to create it from scratch?", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2203", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/max/1200/1*6OVV5rtaPqG4Vfezy67Vpg.jpeg", "tags": {"deep-learning": {"item_id": "3124619357", "tag": "deep-learning"}}, "authors": {"150437764": {"item_id": "3124619357", "author_id": "150437764", "name": "Victor S", "url": "https://medium.com/@vs1324"}}, "image": {"item_id": "3124619357", "src": "https://miro.medium.com/fit/c/56/56/1*voAEa5eKXBOz_26X0rFQPA.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3124619357", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*voAEa5eKXBOz_26X0rFQPA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3124619357", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*6OVV5rtaPqG4Vfezy67Vpg.jpeg", "width": "700", "height": "467", "credit": "Brent De Ranter on Unsplash", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 853}, "3263499897": {"item_id": "3263499897", "resolved_id": "3263499928", "given_url": "https://www.kdnuggets.com/2021/02/overview-synthetic-data-types-generation-methods.html", "given_title": "An overview of synthetic data types and generation methods", "favorite": "0", "status": "1", "time_added": "1614015225", "time_updated": "1638708525", "time_read": "1614022830", "time_favorited": "0", "sort_id": 209, "resolved_title": "An overview of synthetic data types and generation methods", "resolved_url": "https://www.kdnuggets.com/an-overview-of-synthetic-data-types-and-generation-methods.html/", "excerpt": "By Elise Devaux & Dr. Christoph Wehmeyer, Statice Synthetic data became a mainstream resource for various applications. It refers to data algorithmically generated approximating original data. The need for it can be a matter of data availability, cost reduction, security, or privacy concerns.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1301", "lang": "en", "time_to_read": 6, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/overview_of_synthetic_data_types-1.jpg", "tags": {"deep-learning": {"item_id": "3263499897", "tag": "deep-learning"}, "machine-learning": {"item_id": "3263499897", "tag": "machine-learning"}, "synthetic-data": {"item_id": "3263499897", "tag": "synthetic-data"}}, "image": {"item_id": "3263499897", "src": "https://www.kdnuggets.com/wp-content/uploads/overview_of_synthetic_data_types-2.jpg", "width": "100", "height": "0"}, "images": {"1": {"item_id": "3263499897", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/uploads/overview_of_synthetic_data_types-2.jpg", "width": "100", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 504}, "3497353395": {"item_id": "3497353395", "resolved_id": "3497353395", "given_url": "https://hgpu.org/?p=25937", "given_title": "Analysis and Comparison of Performance and Power Consumption of Neural Netw", "favorite": "0", "status": "1", "time_added": "1638713512", "time_updated": "1706631486", "time_read": "1638993284", "time_favorited": "0", "sort_id": 210, "resolved_title": "Analysis and Comparison of Performance and Power Consumption of Neural Networks on CPU, GPU, TPU and FPGA", "resolved_url": "https://hgpu.org/?p=25937", "excerpt": "In this work, we analyze the performance of neural networks on a variety of heterogenous platforms. We strive to find the best platform in terms of raw benchmark performance, performance per watt and performance per Euro.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "188", "lang": "en", "top_image_url": "https://hgpu.org/img/social-logo.png", "tags": {"cpus": {"item_id": "3497353395", "tag": "cpus"}, "deep-learning": {"item_id": "3497353395", "tag": "deep-learning"}, "fpgas": {"item_id": "3497353395", "tag": "fpgas"}, "gpus": {"item_id": "3497353395", "tag": "gpus"}, "tpu": {"item_id": "3497353395", "tag": "tpu"}}, "authors": {"65333509": {"item_id": "3497353395", "author_id": "65333509", "name": "hgpu", "url": "https://hgpu.org/?author=351"}}, "listen_duration_estimate": 73}, "3218263117": {"item_id": "3218263117", "resolved_id": "3218263134", "given_url": "https://towardsdatascience.com/anchor-boxes-the-key-to-quality-object-detection-ddf9d612d4f9?source=rss----7f60cf5620c9---4", "given_title": "Anchor Boxes‚Ää‚Äî‚ÄäThe key to quality object detection", "favorite": "0", "status": "1", "time_added": "1609621941", "time_updated": "1638708525", "time_read": "1609624933", "time_favorited": "0", "sort_id": 211, "resolved_title": "Anchor Boxes‚Ää‚Äî‚ÄäThe key to quality object detection", "resolved_url": "https://towardsdatascience.com/anchor-boxes-the-key-to-quality-object-detection-ddf9d612d4f9", "excerpt": "One of the hardest concepts to grasp when learning about Convolutional Neural Networks for object detection is the idea of anchor boxes. It is also one of the most important parameters you can tune for improved performance on your dataset.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1092", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/600/1*SLKgjh8ikR0X4PeZlj3w0A.png", "tags": {"deep-learning": {"item_id": "3218263117", "tag": "deep-learning"}, "object-detection": {"item_id": "3218263117", "tag": "object-detection"}}, "authors": {"144894780": {"item_id": "3218263117", "author_id": "144894780", "name": "Anders Christiansen", "url": "https://andersasac.medium.com"}}, "image": {"item_id": "3218263117", "src": "https://miro.medium.com/fit/c/56/56/1*f8cacNx6wBHHBvXu1Isy1Q.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3218263117", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*f8cacNx6wBHHBvXu1Isy1Q.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3218263117", "image_id": "2", "src": "https://miro.medium.com/max/794/1*wbQKcvM8UW7Wd1iuCsevbg.png", "width": "397", "height": "299", "credit": "", "caption": ""}, "3": {"item_id": "3218263117", "image_id": "3", "src": "https://miro.medium.com/max/1200/1*q7bYvvpZWeZ9dBVB4yI8EA.png", "width": "600", "height": "600", "credit": "", "caption": ""}, "4": {"item_id": "3218263117", "image_id": "4", "src": "https://miro.medium.com/max/1200/1*SLKgjh8ikR0X4PeZlj3w0A.png", "width": "600", "height": "600", "credit": "", "caption": ""}, "5": {"item_id": "3218263117", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*cmca7U_1W7E2EH7sLL03Eg.png", "width": "700", "height": "527", "credit": "", "caption": "Source: WIDER FACE"}, "6": {"item_id": "3218263117", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*rRCpjohTBBDTuVFMaOzfAg.png", "width": "700", "height": "527", "credit": "", "caption": "Source: WIDER FACE"}, "7": {"item_id": "3218263117", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*4t90PoQlLB7eDqRrZ9gGLA.jpeg", "width": "700", "height": "467", "credit": "", "caption": ""}, "8": {"item_id": "3218263117", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*MU-7lszARJ50KWm0ikdp2g.jpeg", "width": "700", "height": "467", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 423}, "3211078388": {"item_id": "3211078388", "resolved_id": "3211021789", "given_url": "http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1006305", "given_title": "Applications of Deep Neural Networks 575 page free book¬†by¬†Jeff Heaton", "favorite": "0", "status": "1", "time_added": "1608900163", "time_updated": "1638708525", "time_read": "1608909805", "time_favorited": "0", "sort_id": 212, "resolved_title": "Applications of Deep Neural Networks 575 page free book by Jeff Heaton", "resolved_url": "https://www.datasciencecentral.com/profiles/blogs/applications-of-deep-neural-networks-575-page-free-book-by-jeff", "excerpt": "13 Advanced/Other Topics 475 13.1 Part 13.1: Flask and Deep Learning Web Services . . . . . . . . . . . . . . . . . . . . . . . . 475 13.1.1 Flask Hello World . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 475 13.1.2 MPG Flask . . . . . . . . . . . . . . . . . . . . .", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1646", "lang": "en", "time_to_read": 7, "top_image_url": "https://storage.ning.com/topology/rest/1.0/file/get/8336238056?profile=RESIZE_710x", "tags": {"books": {"item_id": "3211078388", "tag": "books"}, "deep-learning": {"item_id": "3211078388", "tag": "deep-learning"}, "python": {"item_id": "3211078388", "tag": "python"}, "tensorflow": {"item_id": "3211078388", "tag": "tensorflow"}}, "authors": {"77629130": {"item_id": "3211078388", "author_id": "77629130", "name": "ajit jaokar", "url": "https://www.datasciencecentral.com/profile/ajitjaokar"}}, "image": {"item_id": "3211078388", "src": "https://storage.ning.com/topology/rest/1.0/file/get/8336238056?profile=RESIZE_710x", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3211078388", "image_id": "1", "src": "https://storage.ning.com/topology/rest/1.0/file/get/8336238056?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Data Science Central", "logo": "https://logo.clearbit.com/datasciencecentral.com?size=800", "greyscale_logo": "https://logo.clearbit.com/datasciencecentral.com?size=800&greyscale=true"}, "listen_duration_estimate": 637}, "3818370597": {"item_id": "3818370597", "resolved_id": "3818370597", "given_url": "https://semiengineering.com/asynchronously-parallel-optimization-method-for-sizing-analog-transistors-using-deep-neural-network-learning/", "given_title": "Asynchronously Parallel Optimization Method For Sizing Analog Transistors U", "favorite": "0", "status": "1", "time_added": "1677884479", "time_updated": "1678024172", "time_read": "1678024172", "time_favorited": "0", "sort_id": 213, "resolved_title": "Asynchronously Parallel Optimization Method For Sizing Analog Transistors Using Deep Neural Network Learning", "resolved_url": "https://semiengineering.com/asynchronously-parallel-optimization-method-for-sizing-analog-transistors-using-deep-neural-network-learning/", "excerpt": "A new technical paper titled ‚ÄúAPOSTLE: Asynchronously Parallel Optimization for Sizing Analog Transistors Using DNN Learning‚Äù was published by researchers at UT Austin and Analog Devices.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "240", "lang": "en", "top_image_url": "https://semiengineering.com/wp-content/uploads/AdobeStock_309524207-scaled.jpeg", "tags": {"chip-design": {"item_id": "3818370597", "tag": "chip-design"}, "circuits-electronics": {"item_id": "3818370597", "tag": "circuits-electronics"}, "deep-learning": {"item_id": "3818370597", "tag": "deep-learning"}, "semiconductors": {"item_id": "3818370597", "tag": "semiconductors"}}, "authors": {"68667756": {"item_id": "3818370597", "author_id": "68667756", "name": "Technical Paper Link", "url": "https://semiengineering.com/author/technical-paper-link/"}}, "listen_duration_estimate": 93}, "1151025792": {"item_id": "1151025792", "resolved_id": "1151025792", "given_url": "http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/", "given_title": "Attention and Memory in Deep Learning and NLP ‚Äì WildML", "favorite": "0", "status": "1", "time_added": "1622248138", "time_updated": "1638708525", "time_read": "1622249126", "time_favorited": "0", "sort_id": 214, "resolved_title": "", "resolved_url": "http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"deep-learning": {"item_id": "1151025792", "tag": "deep-learning"}, "nlp": {"item_id": "1151025792", "tag": "nlp"}}, "listen_duration_estimate": 0}, "3574417713": {"item_id": "3574417713", "resolved_id": "3574417741", "given_url": "https://towardsdatascience.com/autoencoders-from-vanilla-to-variational-6f5bb5537e4a?source=rss----7f60cf5620c9---4", "given_title": "Autoencoders: From Vanilla to Variational", "favorite": "0", "status": "1", "time_added": "1647369502", "time_updated": "1673901753", "time_read": "1647383214", "time_favorited": "0", "sort_id": 215, "resolved_title": "Autoencoders: From Vanilla to Variational", "resolved_url": "https://towardsdatascience.com/autoencoders-from-vanilla-to-variational-6f5bb5537e4a", "excerpt": "When you hear about computer-generated images, you probably think about deep fakes, the cats that don‚Äôt exist, or a horse turned zebra. And this, quite reasonably, brings up GANs to your mind.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4035", "lang": "en", "time_to_read": 18, "top_image_url": "https://miro.medium.com/max/1200/1*2n7b1cjwcLzLS12dVf_HuA.png", "tags": {"autoencoders": {"item_id": "3574417713", "tag": "autoencoders"}, "deep-learning": {"item_id": "3574417713", "tag": "deep-learning"}, "gans": {"item_id": "3574417713", "tag": "gans"}}, "authors": {"144032084": {"item_id": "3574417713", "author_id": "144032084", "name": "Micha≈Ç Oleszak", "url": "https://michaloleszak.medium.com"}}, "image": {"item_id": "3574417713", "src": "https://miro.medium.com/max/1400/1*2n7b1cjwcLzLS12dVf_HuA.png", "width": "700", "height": "394"}, "images": {"1": {"item_id": "3574417713", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*2n7b1cjwcLzLS12dVf_HuA.png", "width": "700", "height": "394", "credit": "", "caption": ""}, "2": {"item_id": "3574417713", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*32Dtu22nD4latACr.png", "width": "700", "height": "63", "credit": "", "caption": ""}, "3": {"item_id": "3574417713", "image_id": "3", "src": "https://miro.medium.com/max/1148/1*3YcQBrhJya463vwjS3iopg.png", "width": "574", "height": "329", "credit": "link: arXiv:1906.00446", "caption": "Part of Figure 5 from ‚ÄúGenerating Diverse High-Fidelity Images with VQ-VAE-2‚Äù"}, "4": {"item_id": "3574417713", "image_id": "4", "src": "https://miro.medium.com/max/1206/1*ksT8Zxb3HWZdgJI6UMuLsA.png", "width": "603", "height": "197", "credit": "link:   arXiv:1512.09300", "caption": "Part of Figure 4 from ‚ÄúAutoencoding beyond pixels using a learned similarity metric‚Äù"}, "5": {"item_id": "3574417713", "image_id": "5", "src": "https://miro.medium.com/max/1130/1*mUozcPnJPQ40O_yjoYducw.png", "width": "565", "height": "212", "credit": "", "caption": "Autoencoder learns a low-dim representation of its input. Image by the author."}, "6": {"item_id": "3574417713", "image_id": "6", "src": "https://miro.medium.com/max/710/1*7vKPRYsMODGI9lX29-N9Gw.png", "width": "355", "height": "409", "credit": "", "caption": "Data sample. Source: https://github.com/googlecreativelab/quickdraw-dataset."}, "7": {"item_id": "3574417713", "image_id": "7", "src": "https://miro.medium.com/max/874/1*ndeC_rPoaHYfzGDLwc5w8Q.png", "width": "437", "height": "175", "credit": "top row", "caption": "Original images from the test set"}, "8": {"item_id": "3574417713", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*9BKvSG-q9KsWm__R_4ogGg.png", "width": "700", "height": "548", "credit": "", "caption": "Test images‚Äô latent representations mapped to 2D by t-SNE. Image by the author."}, "9": {"item_id": "3574417713", "image_id": "9", "src": "https://miro.medium.com/max/784/1*C44zmbM3rBzvokUu78lmbw.png", "width": "392", "height": "262", "credit": "", "caption": "Probability density over the latent space values. Image by the author."}, "10": {"item_id": "3574417713", "image_id": "10", "src": "https://miro.medium.com/max/1114/1*njylZDPlcE8WnV7Z-MU6vw.png", "width": "557", "height": "558", "credit": "", "caption": "A 3D subset of test data embedding. Image by the author."}, "11": {"item_id": "3574417713", "image_id": "11", "src": "https://miro.medium.com/max/588/1*w0UVgLuVG5HFezVwa8a5rA.png", "width": "294", "height": "306", "credit": "", "caption": "Generated cats, dogs, and trees ‚Äî kind of. Image by the author."}, "12": {"item_id": "3574417713", "image_id": "12", "src": "https://miro.medium.com/max/1400/0*rynNcRuNo2LvTP_9.png", "width": "700", "height": "63", "credit": "", "caption": ""}, "13": {"item_id": "3574417713", "image_id": "13", "src": "https://miro.medium.com/max/870/1*5T4Cm4SOxJhFl4JzZMW-Hg.png", "width": "435", "height": "185", "credit": "top row", "caption": "Original images from the test set"}, "14": {"item_id": "3574417713", "image_id": "14", "src": "https://miro.medium.com/max/700/1*XbdfgWmJ2xDilhVHEoJwfQ.png", "width": "350", "height": "171", "credit": "", "caption": "Sample images of a cat and a tree. Image by the author."}, "15": {"item_id": "3574417713", "image_id": "15", "src": "https://miro.medium.com/max/1400/1*ABdywfw-DggzULlvbg-Ljw.png", "width": "700", "height": "65", "credit": "", "caption": "A cat morphing into a tree. Image by the author."}, "16": {"item_id": "3574417713", "image_id": "16", "src": "https://miro.medium.com/max/1400/1*_3NS1lNQ49fkRYEGJVw7Pg.png", "width": "700", "height": "67", "credit": "", "caption": "A cat morphing into a dog. Image by the author."}, "17": {"item_id": "3574417713", "image_id": "17", "src": "https://miro.medium.com/max/720/1*auvUaaVg5YgSAmPTD8mXuw.png", "width": "360", "height": "173", "credit": "", "caption": "Cat reconstructions. Image by the author."}, "18": {"item_id": "3574417713", "image_id": "18", "src": "https://miro.medium.com/max/934/1*b4fB9GLl5-OJHsy_wiaPOA.png", "width": "467", "height": "117", "credit": "", "caption": "Arithmetic on images."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1562}, "3128567996": {"item_id": "3128567996", "resolved_id": "3128568008", "given_url": "https://towardsdatascience.com/autoencoders-overview-of-research-and-applications-86135f7c0d35?source=rss----7f60cf5620c9---4", "given_title": "Autoencoders: Overview of Research and Applications", "favorite": "0", "status": "1", "time_added": "1601566325", "time_updated": "1638708525", "time_read": "1604361713", "time_favorited": "0", "sort_id": 216, "resolved_title": "Autoencoders: Overview of Research and Applications", "resolved_url": "https://towardsdatascience.com/autoencoders-overview-of-research-and-applications-86135f7c0d35", "excerpt": "Since the early days of machine learning, it has been attempted to learn good representations of data in an unsupervised manner. The hypothesis underlying this effort is that disentangled representations translate well to downstream supervised tasks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2159", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/max/844/1*6E598D_ma4S2r0eXdsC3pw.png", "tags": {"deep-learning": {"item_id": "3128567996", "tag": "deep-learning"}}, "authors": {"88362859": {"item_id": "3128567996", "author_id": "88362859", "name": "Branislav Holl√§nder", "url": "https://medium.com/@branislav.hollander"}}, "image": {"item_id": "3128567996", "src": "https://miro.medium.com/fit/c/56/56/1*bcZWMxLmxtkA-FZJV1dcvw.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3128567996", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*bcZWMxLmxtkA-FZJV1dcvw.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3128567996", "image_id": "2", "src": "https://miro.medium.com/max/1530/1*3bEgtzk6Nf56WvQ6hZ9BXQ.png", "width": "765", "height": "306", "credit": "", "caption": "Figure 1: Unrolling of the swiss roll manifold. Source: Olivier Grisel ‚Äî Generated using the Modular Data Processing toolkit and matplotlib., CC BY 3.0, https://commons.wikimedia.org/w/index.php?curid=10661091"}, "3": {"item_id": "3128567996", "image_id": "3", "src": "https://miro.medium.com/max/1688/1*6E598D_ma4S2r0eXdsC3pw.png", "width": "844", "height": "371", "credit": "", "caption": "Figure 2: Conceptual view of an undercomplete autoencoder"}, "4": {"item_id": "3128567996", "image_id": "4", "src": "https://miro.medium.com/max/1048/1*-u5VMVUFD5FHetzzJwNAug.png", "width": "524", "height": "135", "credit": "", "caption": ""}, "5": {"item_id": "3128567996", "image_id": "5", "src": "https://miro.medium.com/max/824/1*vK9YXif4FjZh3_VBMF_qPA.png", "width": "412", "height": "116", "credit": "", "caption": ""}, "6": {"item_id": "3128567996", "image_id": "6", "src": "https://miro.medium.com/max/974/1*1Cdi0vO0bWL43GGc3WXuSA.png", "width": "487", "height": "77", "credit": "", "caption": ""}, "7": {"item_id": "3128567996", "image_id": "7", "src": "https://miro.medium.com/max/620/1*jigjM3qmOcrwpKK6zUSoPg.png", "width": "310", "height": "55", "credit": "", "caption": ""}, "8": {"item_id": "3128567996", "image_id": "8", "src": "https://miro.medium.com/max/3630/1*D62BkLDZFjiw-TbQEpqw9A.png", "width": "1815", "height": "450", "credit": "", "caption": "Figure 3: Manipulating the facial hair and glasses latent attribute in CSVAE, a recent variational autoencoder version. Source: Klys, Jack, Jake Snell, and Richard Zemel. ‚ÄúLearning latent subspaces in variational autoencoders.‚Äù Advances in Neural Information Processing Systems. 2018."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 836}, "2044675678": {"item_id": "2044675678", "resolved_id": "2044675678", "given_url": "https://github.com/Microsoft/AutonomousDrivingCookbook/tree/master/AirSimE2EDeepLearning", "given_title": "AutonomousDrivingCookbook/AirSimE2EDeepLearning at master ¬∑ Microsoft/Auton", "favorite": "0", "status": "1", "time_added": "1516934080", "time_updated": "1638708525", "time_read": "1526153057", "time_favorited": "0", "sort_id": 217, "resolved_title": "Microsoft/AutonomousDrivingCookbook", "resolved_url": "https://github.com/Microsoft/AutonomousDrivingCookbook/tree/master/AirSimE2EDeepLearning", "excerpt": "In this tutorial, you will learn how to train and test an end-to-end deep learning model for autonomous driving using data collected from the AirSim simulation environment.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "695", "lang": "en", "time_to_read": 3, "top_image_url": "https://avatars2.githubusercontent.com/u/6154722?s=400&v=4", "tags": {"autonomous-driving": {"item_id": "2044675678", "tag": "autonomous-driving"}, "deep-learning": {"item_id": "2044675678", "tag": "deep-learning"}}, "image": {"item_id": "2044675678", "src": "https://github.com/Microsoft/AutonomousDrivingCookbook/raw/master/AirSimE2EDeepLearning/car_driving.gif", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2044675678", "image_id": "1", "src": "https://github.com/Microsoft/AutonomousDrivingCookbook/raw/master/AirSimE2EDeepLearning/car_driving.gif", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 269}, "1308770801": {"item_id": "1308770801", "resolved_id": "1308770801", "given_url": "https://github.com/terryum/awesome-deep-learning-papers/blob/master/README.md", "given_title": "awesome-deep-learning-papers/README.md at master ¬∑ terryum/awesome-deep-lea", "favorite": "0", "status": "1", "time_added": "1465086347", "time_updated": "1638708525", "time_read": "1482713105", "time_favorited": "0", "sort_id": 218, "resolved_title": "terryum/awesome-deep-learning-papers", "resolved_url": "https://github.com/terryum/awesome-deep-learning-papers/blob/master/README.md", "excerpt": "I believe that there exist classic deep learning papers which are worth reading regardless of their applications. Rather than providing overwhelming amount of papers, I would like to provide a curated list of the classic deep learning papers which can be considered as must-reads in some area.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1901", "lang": "en", "time_to_read": 9, "top_image_url": "https://avatars2.githubusercontent.com/u/12528769?v=3&s=400", "tags": {"deep-learning": {"item_id": "1308770801", "tag": "deep-learning"}}, "image": {"item_id": "1308770801", "src": "https://camo.githubusercontent.com/13c4e50d88df7178ae1882a203ed57b641674f94/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1308770801", "image_id": "1", "src": "https://camo.githubusercontent.com/13c4e50d88df7178ae1882a203ed57b641674f94/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f643733303566333864323966656437386661383536353265336136336531353464643865383832392f6d656469612f62616467652e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1308770801", "image_id": "2", "src": "https://camo.githubusercontent.com/60561947585c982aee67ed3e3b25388184cc0aa3/687474703a2f2f6d6972726f72732e6372656174697665636f6d6d6f6e732e6f72672f70726573736b69742f627574746f6e732f38387833312f7376672f63632d7a65726f2e737667", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 736}, "2091299110": {"item_id": "2091299110", "resolved_id": "2091299110", "given_url": "https://thenextweb.com/artificial-intelligence/2018/02/26/baidus-ai-can-clone-your-voice-and-give-it-a-different-gender-or-accent/", "given_title": "Baidu‚Äôs voice cloning AI can swap genders and remove accents", "favorite": "0", "status": "1", "time_added": "1519676050", "time_updated": "1638708525", "time_read": "1519918612", "time_favorited": "0", "sort_id": 219, "resolved_title": "Baidu‚Äôs voice cloning AI can swap genders and remove accents", "resolved_url": "https://thenextweb.com/artificial-intelligence/2018/02/26/baidus-ai-can-clone-your-voice-and-give-it-a-different-gender-or-accent/", "excerpt": "Chinese AI titan Baidu earlier this month announced its Deep Voice AI had learned some new tricks. Not only can it accurately clone an individual voice faster than ever, but now it knows how to make a British man sound like an American woman.  You can insert your own joke here.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "552", "lang": "en", "time_to_read": 3, "amp_url": "https://thenextweb.com/artificial-intelligence/2018/02/26/baidus-ai-can-clone-your-voice-and-give-it-a-different-gender-or-accent/?amp=1", "top_image_url": "https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2013/11/machine-communication-social.jpg", "tags": {"audio": {"item_id": "2091299110", "tag": "audio"}, "deep-learning": {"item_id": "2091299110", "tag": "deep-learning"}}, "authors": {"69778827": {"item_id": "2091299110", "author_id": "69778827", "name": "Tristan Greene", "url": "https://thenextweb.com/author/tristangreen/"}}, "image": {"item_id": "2091299110", "src": "https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2013/11/machine-communication-730x420.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2091299110", "image_id": "1", "src": "https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2013/11/machine-communication-730x420.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The Next Web", "logo": "https://logo.clearbit.com/thenextweb.com?size=800", "greyscale_logo": "https://logo.clearbit.com/thenextweb.com?size=800&greyscale=true"}, "listen_duration_estimate": 214}, "3759988798": {"item_id": "3759988798", "resolved_id": "3759979257", "given_url": "https://towardsdatascience.com/beginners-guide-to-diffusion-models-8c3435ccb4ae?source=rss----7f60cf5620c9---4", "given_title": "Beginner‚Äôs Guide to Diffusion Models", "favorite": "0", "status": "1", "time_added": "1670325950", "time_updated": "1670443306", "time_read": "1670443305", "time_favorited": "0", "sort_id": 220, "resolved_title": "Beginner‚Äôs Guide to Diffusion Models", "resolved_url": "https://towardsdatascience.com/beginners-guide-to-diffusion-models-8c3435ccb4ae", "excerpt": "Recently, there has been an increased interest in OpenAI‚Äôs DALL-E, Stable Diffusion (the free alternative of DALL-E), and Midjourney (hosted on a Discord server). While AI-generated art is very cool, what is even more captivating is how it works in the first place.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1428", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/512/1*xQrGG_weuH-N2kynjThfwg.png", "tags": {"deep-learning": {"item_id": "3759988798", "tag": "deep-learning"}, "nlp": {"item_id": "3759988798", "tag": "nlp"}, "stable-diffusion": {"item_id": "3759988798", "tag": "stable-diffusion"}}, "authors": {"114410845": {"item_id": "3759988798", "author_id": "114410845", "name": "Yang Chun Wei", "url": "https://medium.com/@yangcw"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 553}, "1865967834": {"item_id": "1865967834", "resolved_id": "1865967834", "given_url": "https://www.oreilly.com/ideas/big-datas-biggest-secret-hyperparameter-tuning", "given_title": "Big data's biggest secret: Hyperparameter tuning", "favorite": "0", "status": "1", "time_added": "1585274099", "time_updated": "1638708525", "time_read": "1585580028", "time_favorited": "0", "sort_id": 221, "resolved_title": "Big data's biggest secret: Hyperparameter tuning", "resolved_url": "https://www.oreilly.com/ideas/big-datas-biggest-secret-hyperparameter-tuning", "excerpt": "Register for the upcoming webcast ‚ÄúLarge-scale machine learning in Spark,‚Äù on August 29, 2017, to learn more about tuning hyperparameters and dealing with large regression models, with TalkingData‚Äôs Andreas Pfadler.  Machine learning may seem magical to the uninitiated.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1340", "lang": "en", "time_to_read": 6, "top_image_url": "https://d3tdunqjn7n0wj.cloudfront.net/1400x933/istock-512455457-(1)-13878bfce1f6671e58e14870ded87aec.jpg", "tags": {"deep-learning": {"item_id": "1865967834", "tag": "deep-learning"}}, "authors": {"69872478": {"item_id": "1865967834", "author_id": "69872478", "name": "Frank Kane", "url": "https://www.oreilly.com/people/frank-kane"}}, "image": {"item_id": "1865967834", "src": "https://d3tdunqjn7n0wj.cloudfront.net/360x240/istock-512455457-(1)-13878bfce1f6671e58e14870ded87aec.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1865967834", "image_id": "1", "src": "https://d3tdunqjn7n0wj.cloudfront.net/360x240/istock-512455457-(1)-13878bfce1f6671e58e14870ded87aec.jpg", "width": "0", "height": "0", "credit": "source: iStock.com, licensed by Frank Kane.", "caption": "Article image: Tuning a grand piano."}}, "domain_metadata": {"name": "O'Reilly Media", "logo": "https://logo.clearbit.com/oreilly.com?size=800", "greyscale_logo": "https://logo.clearbit.com/oreilly.com?size=800&greyscale=true"}, "listen_duration_estimate": 519}, "2932893729": {"item_id": "2932893729", "resolved_id": "2932893774", "given_url": "https://www.kdnuggets.com/2020/03/brain-tumor-detection-mask-r-cnn.html", "given_title": "Brain Tumor Detection using Mask R-CNN", "favorite": "0", "status": "1", "time_added": "1585583620", "time_updated": "1638708525", "time_read": "1585739468", "time_favorited": "0", "sort_id": 222, "resolved_title": "Brain Tumor Detection using Mask R-CNN", "resolved_url": "https://www.kdnuggets.com/brain-tumor-detection-using-mask-r-cnn.html/", "excerpt": "In the health care sector, medical image analysis plays an active role, especially in Non-invasive treatment and clinical study. Medical imaging techniques and analysis tools help medical practitioners and radiologists to correctly diagnose the disease.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2205", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/max/1098/0*-UvZJbq8g1MhotfV.gif", "tags": {"deep-learning": {"item_id": "2932893729", "tag": "deep-learning"}, "vision": {"item_id": "2932893729", "tag": "vision"}}, "authors": {"125144284": {"item_id": "2932893729", "author_id": "125144284", "name": "Nagesh Singh Chauhan", "url": "https://www.kdnuggets.com/author/nagesh-chauhan"}}, "image": {"item_id": "2932893729", "src": "https://miro.medium.com/max/257/0*a_xlnNKpAct01GdD.png", "width": "60", "height": "0"}, "images": {"1": {"item_id": "2932893729", "image_id": "1", "src": "https://miro.medium.com/max/257/0*a_xlnNKpAct01GdD.png", "width": "60", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2932893729", "image_id": "2", "src": "https://miro.medium.com/max/186/0*D8uirYSMZtVZrsnI.png", "width": "60", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2932893729", "image_id": "3", "src": "https://miro.medium.com/max/1206/0*oYUx49JrNx8XzvtN.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2932893729", "image_id": "4", "src": "https://miro.medium.com/max/704/1*RJ5NQhntiPxkjtjTAjictQ.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2932893729", "image_id": "5", "src": "https://miro.medium.com/max/329/1*7ZLWw9D8j4lc485GR1bMlQ.png", "width": "60", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2932893729", "image_id": "6", "src": "https://miro.medium.com/max/420/1*hsBP-r3NyMyhImSlSSPeWw.png", "width": "60", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2932893729", "image_id": "7", "src": "https://miro.medium.com/max/357/1*t7qxWZ6lu4B88StODAlptw.png", "width": "60", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2932893729", "image_id": "8", "src": "https://miro.medium.com/max/470/1*PvpgaIWM1zB1-wPmN9WQow.png", "width": "60", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2932893729", "image_id": "9", "src": "https://miro.medium.com/max/372/1*EBgARqiai5tc-sfptpyXng.png", "width": "60", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2932893729", "image_id": "10", "src": "https://miro.medium.com/max/482/1*1aIrEb38DIKa_XPHU0u5ZA.png", "width": "60", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2932893729", "image_id": "11", "src": "https://miro.medium.com/max/360/1*oNCKn9tYZNVjxgkN4Gipuw.png", "width": "60", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2932893729", "image_id": "12", "src": "https://miro.medium.com/max/473/1*wOaqSaXh5Qi-eP43UHUTjQ.png", "width": "60", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 854}, "2475064074": {"item_id": "2475064074", "resolved_id": "2475064074", "given_url": "https://paperswithcode.com/task/image-classification", "given_title": "Browse the State-of-the-Art in Machine Learning | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572392", "time_updated": "1638708525", "time_read": "1608572406", "time_favorited": "0", "sort_id": 223, "resolved_title": "Image Classification", "resolved_url": "https://paperswithcode.com/task/image-classification", "excerpt": "Image Classification is a fundamental task that attempts to comprehend an entire image as a whole. The goal is to classify the image by assigning it to a specific label. Typically, Image Classification refers to images in which only one object appears and is analyzed.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "79", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/1fTQtXyApxWPoW2vzSEk_Pw_t41Ubes.png", "tags": {"deep-learning": {"item_id": "2475064074", "tag": "deep-learning"}, "image-classification": {"item_id": "2475064074", "tag": "image-classification"}}, "listen_duration_estimate": 31}, "2475112862": {"item_id": "2475112862", "resolved_id": "2475112862", "given_url": "https://paperswithcode.com/task/object-detection", "given_title": "Browse the State-of-the-Art in Machine Learning | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572409", "time_updated": "1638708525", "time_read": "1608572422", "time_favorited": "0", "sort_id": 224, "resolved_title": "Object Detection", "resolved_url": "https://www.paperswithcode.com/task/object-detection", "excerpt": "Object detection is the task of detecting instances of objects of a certain class within an image. The state-of-the-art methods can be categorized into two main types: one-stage methods and two stage-methods.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "83", "lang": "en", "top_image_url": "https://paperswithcode.com/media/tasks/task-0000000004-57dd87c7_D7W1Zlx_S0Efpji.jpeg", "tags": {"deep-learning": {"item_id": "2475112862", "tag": "deep-learning"}, "object-detection": {"item_id": "2475112862", "tag": "object-detection"}}, "listen_duration_estimate": 32}, "2475211640": {"item_id": "2475211640", "resolved_id": "2475211640", "given_url": "https://paperswithcode.com/task/image-generation", "given_title": "Browse the State-of-the-Art in Machine Learning | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572425", "time_updated": "1638708525", "time_read": "1608572443", "time_favorited": "0", "sort_id": 225, "resolved_title": "Papers with Code : Image Generation", "resolved_url": "https://paperswithcode.com/task/image-generation", "excerpt": "Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "16", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/1_6QEwXbE.jpg", "tags": {"deep-learning": {"item_id": "2475211640", "tag": "deep-learning"}, "image-generation": {"item_id": "2475211640", "tag": "image-generation"}}, "listen_duration_estimate": 6}, "2475249858": {"item_id": "2475249858", "resolved_id": "2475249858", "given_url": "https://paperswithcode.com/task/semantic-segmentation", "given_title": "Browse the State-of-the-Art in Machine Learning | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572371", "time_updated": "1638708525", "time_read": "1608572388", "time_favorited": "0", "sort_id": 226, "resolved_title": "Semantic Segmentation", "resolved_url": "https://paperswithcode.com/task/semantic-segmentation", "excerpt": "Semantic segmentation, or image segmentation, is the task of clustering parts of an image together which belong to the same object class. It is a form of pixel-level prediction because each pixel in an image is classified according to a category.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "71", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/Screenshot_2021-01-25_at_13.41.15_e92BZLz.png", "tags": {"deep-learning": {"item_id": "2475249858", "tag": "deep-learning"}, "semantic-segmentation": {"item_id": "2475249858", "tag": "semantic-segmentation"}}, "listen_duration_estimate": 27}, "2476227623": {"item_id": "2476227623", "resolved_id": "2476227623", "given_url": "https://paperswithcode.com/task/pose-estimation", "given_title": "Browse the State-of-the-Art in Machine Learning | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572506", "time_updated": "1638708525", "time_read": "1608603769", "time_favorited": "0", "sort_id": 227, "resolved_title": "Papers with Code : Pose Estimation", "resolved_url": "https://paperswithcode.com/task/pose-estimation", "excerpt": "Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "16", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/Screenshot_2019-11-28_at_22.28.25_6MeKR2X.png", "tags": {"deep-learning": {"item_id": "2476227623", "tag": "deep-learning"}, "pose-estimation": {"item_id": "2476227623", "tag": "pose-estimation"}}, "listen_duration_estimate": 6}, "2941785011": {"item_id": "2941785011", "resolved_id": "2941785060", "given_url": "https://www.kdnuggets.com/2020/04/app-generate-photorealistic-faces-tensorflow-streamlit.html", "given_title": "Build an app to generate photorealistic faces using TensorFlow and Streamli", "favorite": "0", "status": "1", "time_added": "1586262935", "time_updated": "1706623091", "time_read": "1587304731", "time_favorited": "0", "sort_id": 228, "resolved_title": "Build an app to generate photorealistic faces using TensorFlow and Streamlit", "resolved_url": "https://www.kdnuggets.com/build-an-app-to-generate-photorealistic-faces-using-tensorflow-and-streamlit.html/", "excerpt": "Machine learning models are black boxes. Yes, you can run them on test sets and plot fancy performance curves, but it‚Äôs¬†still¬†often hard to answer basic questions about how they perform. A surprisingly powerful source of insight is simply to¬†play with your models! Tweak inputs. Watch outputs.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2182", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/max/1200/0*kqTo76YSl92YkYDV", "tags": {"deep-learning": {"item_id": "2941785011", "tag": "deep-learning"}, "streamlit": {"item_id": "2941785011", "tag": "streamlit"}, "tensorflow": {"item_id": "2941785011", "tag": "tensorflow"}}, "image": {"item_id": "2941785011", "src": "https://miro.medium.com/max/1200/0*BwanS6qqSNmjZr66", "width": "100", "height": "0"}, "images": {"1": {"item_id": "2941785011", "image_id": "1", "src": "https://miro.medium.com/max/1200/0*BwanS6qqSNmjZr66", "width": "100", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 845}, "2928233012": {"item_id": "2928233012", "resolved_id": "2928233051", "given_url": "https://towardsdatascience.com/building-an-image-taking-interface-application-for-your-image-recognition-model-973b121cc9d9?source=rss----7f60cf5620c9---4", "given_title": "Building an Image-Taking Interface Application for Your Image Recognition M", "favorite": "1", "status": "1", "time_added": "1585223943", "time_updated": "1638708525", "time_read": "1585739495", "time_favorited": "1585580102", "sort_id": 229, "resolved_title": "Building an Image-Taking Interface Application for Your Image Recognition Model", "resolved_url": "https://towardsdatascience.com/building-an-image-taking-interface-application-for-your-image-recognition-model-973b121cc9d9", "excerpt": "Often, data scientists build a model for image recognition, see the accuracy, and, if it‚Äôs high enough, consider the job done. Ever since I got into machine learning at 13, I never understood that. Why spend all the time building the best model ‚Äî just to be satisfied with a number?", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "741", "lang": "en", "time_to_read": 3, "top_image_url": "https://miro.medium.com/max/1200/0*JpjypdslhZHdb0-b.jpg", "tags": {"deep-learning": {"item_id": "2928233012", "tag": "deep-learning"}, "vision": {"item_id": "2928233012", "tag": "vision"}}, "authors": {"144200356": {"item_id": "2928233012", "author_id": "144200356", "name": "Andre Ye", "url": "https://andre-ye.medium.com"}}, "image": {"item_id": "2928233012", "src": "https://miro.medium.com/max/2560/0*JpjypdslhZHdb0-b.jpg", "width": "1280", "height": "512"}, "images": {"1": {"item_id": "2928233012", "image_id": "1", "src": "https://miro.medium.com/max/2560/0*JpjypdslhZHdb0-b.jpg", "width": "1280", "height": "512", "credit": "", "caption": "Image from Pixabay"}, "2": {"item_id": "2928233012", "image_id": "2", "src": "https://miro.medium.com/fit/c/56/56/1*agZM8gnrsEIs3InGe8B5EA.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "3": {"item_id": "2928233012", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*LIBJQ4c4IhjDQTUzovdP8w.png", "width": "700", "height": "671", "credit": "", "caption": "The top few printed lines should look like this."}, "4": {"item_id": "2928233012", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*FXeF1mE5vdyojZ26rdnxgQ.png", "width": "700", "height": "180", "credit": "", "caption": ""}, "5": {"item_id": "2928233012", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*RSGmR_oje6FmC3_733Z3lg.png", "width": "700", "height": "575", "credit": "", "caption": ""}, "6": {"item_id": "2928233012", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*9ph6ZVA9hGpCj0F_kbPOyg.png", "width": "700", "height": "341", "credit": "", "caption": "Good job!"}, "7": {"item_id": "2928233012", "image_id": "7", "src": "https://miro.medium.com/max/1014/1*v_khkuKMWwxVUWoiy8OJvQ.png", "width": "507", "height": "499", "credit": "", "caption": ""}, "8": {"item_id": "2928233012", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*uriv4u4LgSZfVDIbbHEQrQ.png", "width": "700", "height": "424", "credit": "", "caption": ""}, "9": {"item_id": "2928233012", "image_id": "9", "src": "https://miro.medium.com/max/962/1*CN0OxCoWJQopSukY4ZlYjw.png", "width": "481", "height": "510", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 287}, "3889979121": {"item_id": "3889979121", "resolved_id": "3889969550", "given_url": "https://www.kdnuggets.com/2023/06/calculate-computational-efficiency-deep-learning-models-flops-macs.html", "given_title": "Calculate Computational Efficiency of Deep Learning Models with FLOPs and M", "favorite": "0", "status": "1", "time_added": "1687310008", "time_updated": "1706233547", "time_read": "1690160727", "time_favorited": "0", "sort_id": 230, "resolved_title": "Calculate Computational Efficiency of Deep Learning Models with FLOPs and MACs", "resolved_url": "https://www.kdnuggets.com/calculate-computational-efficiency-of-deep-learning-models-with-flops-and-macs.html", "excerpt": "FLOPs (Floating Point Operations) and MACs (Multiply-Accumulate Operations) are metrics that are commonly used to calculate the computational complexity of deep learning models. They are a fast and easy way to understand the number of arithmetic operations required to perform a given computation.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "729", "lang": "en", "time_to_read": 3, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/li_calculate_computational_efficiency_deep_learning_models_flops_macs_2.png", "tags": {"algorithms-math": {"item_id": "3889979121", "tag": "algorithms-math"}, "benchmarks": {"item_id": "3889979121", "tag": "benchmarks"}, "cpus": {"item_id": "3889979121", "tag": "cpus"}, "deep-learning": {"item_id": "3889979121", "tag": "deep-learning"}, "gpus": {"item_id": "3889979121", "tag": "gpus"}}, "authors": {"182954750": {"item_id": "3889979121", "author_id": "182954750", "name": "Danni Li", "url": "https://www.kdnuggets.com/author/danni-li"}}, "image": {"item_id": "3889979121", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500"}, "images": {"1": {"item_id": "3889979121", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 282}, "2202653193": {"item_id": "2202653193", "resolved_id": "2202653193", "given_url": "https://www.anandtech.com/show/12815/cambricon-makers-of-huaweis-kirin-npu-ip-build-a-big-ai-chip-and-pcie-card", "given_title": "Cambricon, Makers of Huawei's Kirin NPU IP, Build A Big AI Chip and PCIe Ca", "favorite": "0", "status": "1", "time_added": "1527371362", "time_updated": "1638708525", "time_read": "1527429756", "time_favorited": "0", "sort_id": 231, "resolved_title": "Cambricon, Makers of Huawei's Kirin NPU IP, Build A Big AI Chip and PCIe Card", "resolved_url": "https://www.anandtech.com/show/12815/cambricon-makers-of-huaweis-kirin-npu-ip-build-a-big-ai-chip-and-pcie-card", "excerpt": "Cambricon Technologies, the company in collaboration with HiSilicon / Huawei for licensing specialist AI silicon intellectual property for the Kirin 970 smartphone chipset, have gone solo and created their own series of chips for the data center.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "741", "lang": "en", "time_to_read": 3, "top_image_url": "https://images.anandtech.com/doci/12815/p-r-s-four3_678x452.jpg", "tags": {"deep-learning": {"item_id": "2202653193", "tag": "deep-learning"}, "semiconductors": {"item_id": "2202653193", "tag": "semiconductors"}}, "authors": {"75813123": {"item_id": "2202653193", "author_id": "75813123", "name": "Ian Cutress", "url": "https://www.anandtech.com/Author/140"}}, "image": {"item_id": "2202653193", "src": "https://images.anandtech.com/doci/12815/p-r-s-four2.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2202653193", "image_id": "1", "src": "https://images.anandtech.com/doci/12815/p-r-s-four2.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2202653193", "image_id": "2", "src": "https://images.anandtech.com/doci/12815/p-r-s-four1.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "AnandTech", "logo": "https://logo.clearbit.com/anandtech.com?size=800", "greyscale_logo": "https://logo.clearbit.com/anandtech.com?size=800&greyscale=true"}, "listen_duration_estimate": 287}, "3835004861": {"item_id": "3835004861", "resolved_id": "3835004861", "given_url": "https://www.techmeme.com/230328/p37", "given_title": "Cerebras open sources seven GPT-based LLMs, ranging from 111M to 13B parame", "favorite": "0", "status": "1", "time_added": "1680049296", "time_updated": "1680049767", "time_read": "1680049766", "time_favorited": "0", "sort_id": 232, "resolved_title": "Techmeme", "resolved_url": "https://www.techmeme.com/230328/p37", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"deep-learning": {"item_id": "3835004861", "tag": "deep-learning"}, "semiconductors": {"item_id": "3835004861", "tag": "semiconductors"}}, "domain_metadata": {"name": "Techmeme", "logo": "https://logo.clearbit.com/techmeme.com?size=800", "greyscale_logo": "https://logo.clearbit.com/techmeme.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "2069362558": {"item_id": "2069362558", "resolved_id": "2069362558", "given_url": "https://opendatascience.com/blog/choosing-the-right-activation-function-in-a-neural-network/", "given_title": "Choosing the right activation function in a neural network", "favorite": "0", "status": "1", "time_added": "1518448149", "time_updated": "1673901884", "time_read": "1518461023", "time_favorited": "0", "sort_id": 233, "resolved_title": "Choosing the right activation function in a neural network", "resolved_url": "https://opendatascience.com/blog/choosing-the-right-activation-function-in-a-neural-network/", "excerpt": "Activation functions are one of the many parameters you must choose to gain optimal success and performance with your neural network.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1124", "lang": "en", "time_to_read": 5, "tags": {"activations": {"item_id": "2069362558", "tag": "activations"}, "deep-learning": {"item_id": "2069362558", "tag": "deep-learning"}}, "authors": {"71608348": {"item_id": "2069362558", "author_id": "71608348", "name": "Caspar Wylie", "url": ""}}, "image": {"item_id": "2069362558", "src": "https://opendatascience.com/wp-content/uploads/2018/02/Choosing-the-right-activation-function-in-a-neural-network-1.jpg", "width": "242", "height": "265"}, "images": {"1": {"item_id": "2069362558", "image_id": "1", "src": "https://opendatascience.com/wp-content/uploads/2018/02/Choosing-the-right-activation-function-in-a-neural-network-1.jpg", "width": "242", "height": "265", "credit": "", "caption": ""}, "2": {"item_id": "2069362558", "image_id": "2", "src": "https://opendatascience.com/wp-content/uploads/2018/02/Choosing-the-right-activation-function-in-a-neural-network-2.jpg", "width": "450", "height": "397", "credit": "", "caption": ""}, "3": {"item_id": "2069362558", "image_id": "3", "src": "https://opendatascience.com/wp-content/uploads/2018/02/Screen-Shot-2018-02-06-at-15.37.57.png", "width": "182", "height": "77", "credit": "", "caption": ""}, "4": {"item_id": "2069362558", "image_id": "4", "src": "https://opendatascience.com/wp-content/uploads/2018/02/Screen-Shot-2018-02-05-at-15.59.39.png", "width": "306", "height": "400", "credit": "", "caption": ""}, "5": {"item_id": "2069362558", "image_id": "5", "src": "https://opendatascience.com/wp-content/uploads/2018/02/Screen-Shot-2018-02-06-at-15.37.59.png", "width": "231", "height": "55", "credit": "", "caption": ""}, "6": {"item_id": "2069362558", "image_id": "6", "src": "https://opendatascience.com/wp-content/uploads/2018/02/Screen-Shot-2018-02-06-at-16.25.06.png", "width": "220", "height": "65", "credit": "", "caption": ""}, "7": {"item_id": "2069362558", "image_id": "7", "src": "https://opendatascience.com/wp-content/uploads/2018/02/Screen-Shot-2018-02-06-at-16.23.52.png", "width": "172", "height": "53", "credit": "", "caption": ""}, "8": {"item_id": "2069362558", "image_id": "8", "src": "https://opendatascience.com/wp-content/uploads/2018/02/Choosing-the-right-activation-function-in-a-neural-network.png", "width": "481", "height": "297", "credit": "", "caption": ""}, "9": {"item_id": "2069362558", "image_id": "9", "src": "https://opendatascience.com/wp-content/uploads/2018/02/Choosing-the-right-activation-function-in-a-neural-network-1.png", "width": "456", "height": "263", "credit": "", "caption": ""}, "10": {"item_id": "2069362558", "image_id": "10", "src": "https://opendatascience.com/wp-content/uploads/2018/02/Choosing-the-right-activation-function-in-a-neural-network-3.jpg", "width": "528", "height": "102", "credit": "", "caption": ""}, "11": {"item_id": "2069362558", "image_id": "11", "src": "https://opendatascience.com/wp-content/uploads/2018/02/Choosing-the-right-activation-function-in-a-neural-network-4.jpg", "width": "503", "height": "370", "credit": "", "caption": ""}}, "listen_duration_estimate": 435}, "2993419557": {"item_id": "2993419557", "resolved_id": "2993419578", "given_url": "https://towardsdatascience.com/classification-of-brain-mri-as-tumor-non-tumor-4409ba2293b5?source=rss----7f60cf5620c9---4", "given_title": "Classification of Brain MRI as Tumor/Non Tumor", "favorite": "0", "status": "1", "time_added": "1590285690", "time_updated": "1638708525", "time_read": "1591029821", "time_favorited": "0", "sort_id": 234, "resolved_title": "Classification of Brain MRI as Tumor/Non Tumor", "resolved_url": "https://towardsdatascience.com/classification-of-brain-mri-as-tumor-non-tumor-4409ba2293b5", "excerpt": "Hi Everyone! Being a Biomedical Undergraduate student, wouldn‚Äôt it be wrong on my part if I do not show you all an application of AI in Medicine.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1525", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/257/1*BGxLxoHd8MG9m8gesYIprw.jpeg", "tags": {"deep-learning": {"item_id": "2993419557", "tag": "deep-learning"}, "vision": {"item_id": "2993419557", "tag": "vision"}}, "authors": {"134576740": {"item_id": "2993419557", "author_id": "134576740", "name": "Gurucharan M K", "url": "https://towardsdatascience.com/@mk.gurucharan"}}, "image": {"item_id": "2993419557", "src": "https://miro.medium.com/max/594/1*SN8nPp94AYQslNUyDGkmqA.jpeg", "width": "297", "height": "359"}, "images": {"1": {"item_id": "2993419557", "image_id": "1", "src": "https://miro.medium.com/max/594/1*SN8nPp94AYQslNUyDGkmqA.jpeg", "width": "297", "height": "359", "credit": "", "caption": "MRI with Tumor"}, "2": {"item_id": "2993419557", "image_id": "2", "src": "https://miro.medium.com/max/514/1*BGxLxoHd8MG9m8gesYIprw.jpeg", "width": "257", "height": "251", "credit": "", "caption": "MRI without Tumor"}, "3": {"item_id": "2993419557", "image_id": "3", "src": "https://miro.medium.com/max/1840/1*CHs2-J2Gt8VbZcYTr5D3DQ.jpeg", "width": "920", "height": "311", "credit": "Photo from engmrk.com", "caption": "An example of CNN Architecture."}, "4": {"item_id": "2993419557", "image_id": "4", "src": "https://miro.medium.com/max/1652/1*8neV70cHZL5EdxteHKg6Jg.jpeg", "width": "826", "height": "532", "credit": "Photo from Datascience.aero", "caption": "Data Imbalance"}, "5": {"item_id": "2993419557", "image_id": "5", "src": "https://miro.medium.com/max/360/1*ALFgFFmoKpOvThCs4x030Q.jpeg", "width": "180", "height": "218", "credit": "", "caption": ""}, "6": {"item_id": "2993419557", "image_id": "6", "src": "https://miro.medium.com/max/360/1*ZaI4NDoXv7DAs4kfP0ykmA.jpeg", "width": "180", "height": "218", "credit": "", "caption": ""}, "7": {"item_id": "2993419557", "image_id": "7", "src": "https://miro.medium.com/max/360/1*NQbhc_VCtXray2wOE3RJog.jpeg", "width": "180", "height": "218", "credit": "", "caption": "Data Augmentation"}, "8": {"item_id": "2993419557", "image_id": "8", "src": "https://miro.medium.com/max/986/1*cbTKDEA0LDCEQLFTYVZDaA.jpeg", "width": "493", "height": "269", "credit": "", "caption": ""}, "9": {"item_id": "2993419557", "image_id": "9", "src": "https://miro.medium.com/max/934/1*3sDxKeqxQyEmQe_zEwinIg.jpeg", "width": "467", "height": "276", "credit": "", "caption": "Accuracy and Loss Graph"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 590}, "2993880438": {"item_id": "2993880438", "resolved_id": "2993876275", "given_url": "https://towardsdatascience.com/complete-architectural-details-of-all-efficientnet-models-5fd5b736142?source=rss----7f60cf5620c9---4", "given_title": "Complete Architectural Details of all EfficientNet Models", "favorite": "0", "status": "1", "time_added": "1590318076", "time_updated": "1638708525", "time_read": "1591029941", "time_favorited": "0", "sort_id": 235, "resolved_title": "Complete Architectural Details of all EfficientNet Models", "resolved_url": "https://towardsdatascience.com/complete-architectural-details-of-all-efficientnet-models-5fd5b736142", "excerpt": "I was scrolling through notebooks in a Kaggle competition and found almost everyone was using EfficientNet as their backbone which I had not heard about till then.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "907", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/max/1200/0*34PlrpddgachPgag", "tags": {"deep-learning": {"item_id": "2993880438", "tag": "deep-learning"}}, "authors": {"125024746": {"item_id": "2993880438", "author_id": "125024746", "name": "Vardan Agarwal", "url": "https://medium.com/@vardanagarwal16"}}, "image": {"item_id": "2993880438", "src": "https://miro.medium.com/fit/c/56/56/2*YLwnEUENbzW0X5qj5XL8cQ.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2993880438", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*YLwnEUENbzW0X5qj5XL8cQ.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2993880438", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*34PlrpddgachPgag", "width": "700", "height": "1165", "credit": "Joel Filipe on Unsplash", "caption": ""}, "3": {"item_id": "2993880438", "image_id": "3", "src": "https://miro.medium.com/max/1400/0*FJos7uXvl-uLDpSQ.png", "width": "700", "height": "289", "credit": "a", "caption": "Model Scaling."}, "4": {"item_id": "2993880438", "image_id": "4", "src": "https://miro.medium.com/max/1324/0*09AED_CjE-PUFxKC.png", "width": "662", "height": "517", "credit": "", "caption": "Model Size Vs ImageNet accuracy"}, "5": {"item_id": "2993880438", "image_id": "5", "src": "https://miro.medium.com/max/2000/1*93Ahac6GAA04fnpVPcKZBg.png", "width": "1000", "height": "297", "credit": "", "caption": ""}, "6": {"item_id": "2993880438", "image_id": "6", "src": "https://miro.medium.com/max/2000/1*cwMpOJNhwOeosjwW-usYvA.png", "width": "1000", "height": "417", "credit": "", "caption": "5 modules we will use to make the architecture."}, "7": {"item_id": "2993880438", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*snN5M6WXlqHVFAwi17H9Mw.png", "width": "700", "height": "357", "credit": "", "caption": ""}, "8": {"item_id": "2993880438", "image_id": "8", "src": "https://miro.medium.com/max/2000/1*rnhgFRXetwD8PvxhZIpwIA.png", "width": "1000", "height": "413", "credit": "x2 means that modules inside the bracket are repeated twice", "caption": "Architecture for EfficientNet-B0."}, "9": {"item_id": "2993880438", "image_id": "9", "src": "https://miro.medium.com/max/2000/1*Vm_lmc2p9S8GJmtP2tSfDw.png", "width": "1000", "height": "414", "credit": "", "caption": "Architecture for EfficientNet-B1"}, "10": {"item_id": "2993880438", "image_id": "10", "src": "https://miro.medium.com/max/2000/1*8oE4jOMfOXeEzgsHjSB5ww.png", "width": "1000", "height": "416", "credit": "", "caption": "Architecture for EfficientNet-B3"}, "11": {"item_id": "2993880438", "image_id": "11", "src": "https://miro.medium.com/max/2000/1*4-w-cb0WpFb4pBdf6ZCA7w.png", "width": "1000", "height": "434", "credit": "", "caption": "Architecture for EfficientNet-B4"}, "12": {"item_id": "2993880438", "image_id": "12", "src": "https://miro.medium.com/max/2000/1*6vH0nsxj0_-kHxF09tPFlg.png", "width": "1000", "height": "413", "credit": "", "caption": "Architecture of EfficientNet-B5"}, "13": {"item_id": "2993880438", "image_id": "13", "src": "https://miro.medium.com/max/2000/1*2OXrqNg_7CMuNFg2T6eRUA.png", "width": "1000", "height": "411", "credit": "", "caption": "Architecture of EfficientNet-B6"}, "14": {"item_id": "2993880438", "image_id": "14", "src": "https://miro.medium.com/max/2000/1*9LkWH_LUPi5QD1k-QcUA2g.png", "width": "1000", "height": "414", "credit": "", "caption": "Architecture of EfficientNet-B7"}, "15": {"item_id": "2993880438", "image_id": "15", "src": "https://miro.medium.com/max/1400/0*WP4AKPg1QsrMCKKO.png", "width": "700", "height": "350", "credit": "", "caption": "Kernel Size, resolution, channels, and no. of layers information."}, "16": {"item_id": "2993880438", "image_id": "16", "src": "https://miro.medium.com/max/1400/1*PTmdERX7H11aYT2P2gjJSQ.png", "width": "700", "height": "495", "credit": "", "caption": "Source"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 351}, "2984796092": {"item_id": "2984796092", "resolved_id": "2984791251", "given_url": "https://towardsdatascience.com/complete-guide-to-machine-learning-and-deep-learning-in-retail-ca4e05639806?source=rss----7f60cf5620c9---4", "given_title": "Complete guide to machine learning and deep learning in retail", "favorite": "0", "status": "1", "time_added": "1589565956", "time_updated": "1638708525", "time_read": "1589649056", "time_favorited": "0", "sort_id": 236, "resolved_title": "Complete guide to machine learning and deep learning in retail", "resolved_url": "https://towardsdatascience.com/complete-guide-to-machine-learning-and-deep-learning-in-retail-ca4e05639806", "excerpt": "Stores are changing. We see it happening before our eyes, even if we don‚Äôt always realize it. Little by little, they are becoming just one extra step in an increasingly complex customer journey.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2910", "lang": "en", "time_to_read": 13, "top_image_url": "https://miro.medium.com/max/934/1*PGLcdiGi5f0PdnkxNpcPvw.png", "tags": {"deep-learning": {"item_id": "2984796092", "tag": "deep-learning"}, "machine-learning": {"item_id": "2984796092", "tag": "machine-learning"}, "prodmgmt": {"item_id": "2984796092", "tag": "prodmgmt"}, "retail": {"item_id": "2984796092", "tag": "retail"}}, "authors": {"142045616": {"item_id": "2984796092", "author_id": "142045616", "name": "Adrien Book", "url": "https://adrien-book.medium.com"}}, "image": {"item_id": "2984796092", "src": "https://miro.medium.com/max/1400/1*PGLcdiGi5f0PdnkxNpcPvw.png", "width": "700", "height": "545"}, "images": {"1": {"item_id": "2984796092", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*PGLcdiGi5f0PdnkxNpcPvw.png", "width": "700", "height": "545", "credit": "", "caption": "More fun graphs here!"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1126}, "2902505121": {"item_id": "2902505121", "resolved_id": "2902505141", "given_url": "https://towardsdatascience.com/compressionvae-a-powerful-and-versatile-alternative-to-t-sne-and-umap-5c50898b8696?source=rss----7f60cf5620c9---4", "given_title": "CompressionVAE‚Ää‚Äî‚ÄäA Powerful and Versatile Alternative to t-SNE and UMAP", "favorite": "0", "status": "1", "time_added": "1583180176", "time_updated": "1638708525", "time_read": "1583785007", "time_favorited": "0", "sort_id": 237, "resolved_title": "CompressionVAE", "resolved_url": "https://towardsdatascience.com/compressionvae-a-powerful-and-versatile-alternative-to-t-sne-and-umap-5c50898b8696", "excerpt": "[tl;dr: CompressionVAE is a dimensionality reduction tool based on the idea of Variational Autoencoders. It can be installed via pip install cvae and used very similarly to scikit-learn‚Äôs t-SNE, or UMAP-learn. Full code and documentation can be found here: https://github.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2555", "lang": "en", "time_to_read": 12, "top_image_url": "https://miro.medium.com/max/1200/1*ynaJW99qgvYLYuJ0AbKHaA.png", "tags": {"deep-learning": {"item_id": "2902505121", "tag": "deep-learning"}}, "authors": {"144624854": {"item_id": "2902505121", "author_id": "144624854", "name": "Max Frenzel", "url": "https://maxfrenzel.medium.com"}}, "image": {"item_id": "2902505121", "src": "https://miro.medium.com/fit/c/56/56/0*Lj7i4PWCGNIEsvKi.", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2902505121", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/0*Lj7i4PWCGNIEsvKi.", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2902505121", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*ynaJW99qgvYLYuJ0AbKHaA.png", "width": "700", "height": "467", "credit": "", "caption": "Stylized visualization of MNIST embeddings using CompressionVAE, created by Robin Jungers, programmer at Qosmo."}, "3": {"item_id": "2902505121", "image_id": "3", "src": "https://miro.medium.com/max/1290/1*1iQmi4lrm9CvR1h7EZYHCQ.png", "width": "645", "height": "575", "credit": "", "caption": ""}, "4": {"item_id": "2902505121", "image_id": "4", "src": "https://miro.medium.com/max/1382/1*_AelYIEQw3g5cuYBwSRRPQ.png", "width": "691", "height": "687", "credit": "", "caption": ""}, "5": {"item_id": "2902505121", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*KZlAjCXb3bZiHVq5ZJ0j6g.png", "width": "700", "height": "440", "credit": "", "caption": ""}, "6": {"item_id": "2902505121", "image_id": "6", "src": "https://miro.medium.com/max/1374/1*ts6TJdg7HBI9xT0v5Z1x_Q.png", "width": "687", "height": "344", "credit": "", "caption": "Visualisation of MNIST embeddings and latent space of UMAP, taken from the UMAP documentation."}, "7": {"item_id": "2902505121", "image_id": "7", "src": "https://miro.medium.com/max/1374/1*MUrigYgn3Jx1I2Ln8NXDBg.png", "width": "687", "height": "344", "credit": "", "caption": "Visualisation of Fashion MNIST embeddings and latent space of UMAP, taken from the UMAP documentation."}, "8": {"item_id": "2902505121", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*4DhJXn8uAps92EFW6Vc0Nw.png", "width": "700", "height": "332", "credit": "", "caption": ""}, "9": {"item_id": "2902505121", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*dkwiPjxRgPJpIvekKcdj8w.png", "width": "700", "height": "289", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 989}, "2475849586": {"item_id": "2475849586", "resolved_id": "2475849586", "given_url": "https://paperswithcode.com/task/object-tracking", "given_title": "Computer Vision | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572808", "time_updated": "1638708525", "time_read": "1608572821", "time_favorited": "0", "sort_id": 238, "resolved_title": "Object Tracking", "resolved_url": "https://paperswithcode.com/task/object-tracking", "excerpt": "Object tracking is the task of taking an initial set of object detections, creating a unique ID for each of the initial detections, and then tracking each of the objects as they move around frames in a video, maintaining the ID assignment.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "93", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/Screenshot_2019-11-27_at_20.19.02_be6jLVT_XnabzXC.png", "tags": {"deep-learning": {"item_id": "2475849586", "tag": "deep-learning"}, "object-tracking": {"item_id": "2475849586", "tag": "object-tracking"}}, "listen_duration_estimate": 36}, "2476430429": {"item_id": "2476430429", "resolved_id": "2476430429", "given_url": "https://paperswithcode.com/task/domain-adaptation", "given_title": "Computer Vision | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572547", "time_updated": "1638708525", "time_read": "1608572568", "time_favorited": "0", "sort_id": 239, "resolved_title": "Domain Adaptation", "resolved_url": "https://paperswithcode.com/task/domain-adaptation", "excerpt": "Domain Adaptation is the task of adapting models across domains. This is motivated by the challenge where the test and training datasets fall from different data distributions due to some factor.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "63", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/Webp.net-resizeimage_2_ioK1H9H.png", "tags": {"deep-learning": {"item_id": "2476430429", "tag": "deep-learning"}, "domain-adaptation": {"item_id": "2476430429", "tag": "domain-adaptation"}}, "listen_duration_estimate": 24}, "2483790249": {"item_id": "2483790249", "resolved_id": "2483790249", "given_url": "https://paperswithcode.com/task/denoising", "given_title": "Computer Vision | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572635", "time_updated": "1638708525", "time_read": "1608572645", "time_favorited": "0", "sort_id": 240, "resolved_title": "Denoising", "resolved_url": "https://paperswithcode.com/task/denoising", "excerpt": "Denoising is a task in image processing and computer vision that aims to remove or reduce noise from an image. Noise can be introduced into an image due to various reasons, such as camera sensor limitations, lighting conditions, and compression artifacts.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "67", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/Screenshot_2019-11-28_at_22.38.38_yCcs3qr.png", "tags": {"deep-learning": {"item_id": "2483790249", "tag": "deep-learning"}, "denoising": {"item_id": "2483790249", "tag": "denoising"}}, "listen_duration_estimate": 26}, "2484794195": {"item_id": "2484794195", "resolved_id": "2484794195", "given_url": "https://paperswithcode.com/task/face-recognition", "given_title": "Computer Vision | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572684", "time_updated": "1638708525", "time_read": "1608572694", "time_favorited": "0", "sort_id": 241, "resolved_title": "Face Recognition", "resolved_url": "https://paperswithcode.com/task/face-recognition", "excerpt": "Facial Recognition is the task of making a positive identification of a face in a photo or video image against a pre-existing database of faces. It begins with detection - distinguishing human faces from other objects in the image - and then works on identification of those detected faces.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/Screenshot_2019-11-29_at_14.40.10_hC8LgvP.png", "tags": {"deep-learning": {"item_id": "2484794195", "tag": "deep-learning"}, "face-recognition": {"item_id": "2484794195", "tag": "face-recognition"}}, "listen_duration_estimate": 30}, "2486822390": {"item_id": "2486822390", "resolved_id": "2486822390", "given_url": "https://paperswithcode.com/task/anomaly-detection", "given_title": "Computer Vision | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572753", "time_updated": "1706234301", "time_read": "1608572769", "time_favorited": "0", "sort_id": 242, "resolved_title": "Anomaly Detection", "resolved_url": "https://paperswithcode.com/task/anomaly-detection", "excerpt": "Humans are able to detect heterogeneous or unexpected patterns in a set of homogeneous natural images. This task is known as anomaly or novelty detection and has a large number of applications.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "101", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/22b71572-07c8-4f96-a140-de61335c1ebe.png", "tags": {"anomalies-outliers": {"item_id": "2486822390", "tag": "anomalies-outliers"}, "deep-learning": {"item_id": "2486822390", "tag": "deep-learning"}}, "listen_duration_estimate": 39}, "2487184305": {"item_id": "2487184305", "resolved_id": "2487184305", "given_url": "https://paperswithcode.com/task/dimensionality-reduction", "given_title": "Computer Vision | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572828", "time_updated": "1638708525", "time_read": "1608603760", "time_favorited": "0", "sort_id": 243, "resolved_title": "Dimensionality Reduction", "resolved_url": "https://paperswithcode.com/task/dimensionality-reduction", "excerpt": "Or, discuss a change on Slack. Dimensionality reduction is the task of reducing the dimensionality of a dataset.", "is_article": "0", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "661", "lang": "en", "time_to_read": 3, "top_image_url": "https://paperswithcode.com/media/tasks/dimensionality-reduction_6MLCbyN.png", "tags": {"deep-learning": {"item_id": "2487184305", "tag": "deep-learning"}, "dimentionality-reduction": {"item_id": "2487184305", "tag": "dimentionality-reduction"}}, "image": {"item_id": "2487184305", "src": "https://paperswithcode.com/static/frameworks/pytorch.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2487184305", "image_id": "1", "src": "https://paperswithcode.com/static/frameworks/pytorch.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "2487184305", "video_id": "1", "src": "https://www.youtube.com/embed/3osKNPyAxPM", "width": "100", "height": "0", "type": "1", "vid": "3osKNPyAxPM", "length": "0"}}, "listen_duration_estimate": 256}, "2580135770": {"item_id": "2580135770", "resolved_id": "2580135770", "given_url": "https://paperswithcode.com/task/depth-estimation", "given_title": "Computer Vision | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572718", "time_updated": "1638708525", "time_read": "1608572729", "time_favorited": "0", "sort_id": 244, "resolved_title": "Papers with Code : Depth Estimation", "resolved_url": "https://paperswithcode.com/task/depth-estimation", "excerpt": "Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "16", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/images_c8txmyp.jpg", "tags": {"deep-learning": {"item_id": "2580135770", "tag": "deep-learning"}, "depth-estimation": {"item_id": "2580135770", "tag": "depth-estimation"}}, "listen_duration_estimate": 6}, "2605014729": {"item_id": "2605014729", "resolved_id": "2605014729", "given_url": "https://paperswithcode.com/task/few-shot-learning", "given_title": "Computer Vision | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572735", "time_updated": "1638708525", "time_read": "1608572749", "time_favorited": "0", "sort_id": 245, "resolved_title": "Few-Shot Learning", "resolved_url": "https://paperswithcode.com/task/few-shot-learning", "excerpt": "Few-Shot Learning is an example of meta-learning, where a learner is trained on several related tasks, during the meta-training phase, so that it can generalize well to unseen (but related) tasks with just few examples, during the meta-testing phase.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "74", "lang": "en", "top_image_url": "https://raw.githubusercontent.com/orobix/Prototypical-Networks-for-Few-shot-Learning-PyTorch/master/doc/imgs/proto-1.png", "tags": {"deep-learning": {"item_id": "2605014729", "tag": "deep-learning"}, "few-shot-learning": {"item_id": "2605014729", "tag": "few-shot-learning"}}, "listen_duration_estimate": 29}, "2642391100": {"item_id": "2642391100", "resolved_id": "2642391100", "given_url": "https://paperswithcode.com/task/action-recognition-in-videos", "given_title": "Computer Vision | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572665", "time_updated": "1678056127", "time_read": "1608572678", "time_favorited": "0", "sort_id": 246, "resolved_title": "Action Recognition", "resolved_url": "https://paperswithcode.com/task/action-recognition-in-videos", "excerpt": "Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "16", "lang": "en", "top_image_url": "https://paperswithcode.com/media/tasks/MSR-Action3D_M1wm5kU.jpg", "tags": {"deep-learning": {"item_id": "2642391100", "tag": "deep-learning"}}, "listen_duration_estimate": 6}, "2839388331": {"item_id": "2839388331", "resolved_id": "2839388331", "given_url": "https://paperswithcode.com/task/data-augmentation", "given_title": "Computer Vision | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572578", "time_updated": "1638708525", "time_read": "1608572592", "time_favorited": "0", "sort_id": 247, "resolved_title": "Data Augmentation", "resolved_url": "https://paperswithcode.com/task/data-augmentation", "excerpt": "Data augmentation involves techniques used for increasing the amount of data, based on different modifications, to expand the amount of examples in the original dataset. Data augmentation not only helps to grow the dataset but it also increases the diversity of the dataset.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "102", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/rsz_screenshot_2019-11-29_at_122132_S80u6gv.png", "tags": {"data-augmentation": {"item_id": "2839388331", "tag": "data-augmentation"}, "deep-learning": {"item_id": "2839388331", "tag": "deep-learning"}}, "listen_duration_estimate": 39}, "2849795110": {"item_id": "2849795110", "resolved_id": "2849795110", "given_url": "https://paperswithcode.com/task/image-retrieval", "given_title": "Computer Vision | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572795", "time_updated": "1638708525", "time_read": "1608572805", "time_favorited": "0", "sort_id": 248, "resolved_title": "Image Retrieval", "resolved_url": "https://paperswithcode.com/task/image-retrieval", "excerpt": "Image Retrieval is a fundamental and long-standing computer vision task that involves finding images similar to a provided query from a large database. It's often considered as a form of fine-grained, instance-level classification.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "70", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/4f7e5080-e315-4357-9918-7169df9995db.png", "tags": {"deep-learning": {"item_id": "2849795110", "tag": "deep-learning"}, "image-retrieval": {"item_id": "2849795110", "tag": "image-retrieval"}}, "listen_duration_estimate": 27}, "2984254629": {"item_id": "2984254629", "resolved_id": "2984254629", "given_url": "https://paperswithcode.com/task/autonomous-driving", "given_title": "Computer Vision | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572596", "time_updated": "1638708525", "time_read": "1608572611", "time_favorited": "0", "sort_id": 249, "resolved_title": "Autonomous Driving", "resolved_url": "https://paperswithcode.com/task/autonomous-driving", "excerpt": "Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "16", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/Screenshot_2019-11-29_at_14.32.38_oLh8seV.png", "tags": {"autonomous-driving": {"item_id": "2984254629", "tag": "autonomous-driving"}, "deep-learning": {"item_id": "2984254629", "tag": "deep-learning"}}, "listen_duration_estimate": 6}, "2987723189": {"item_id": "2987723189", "resolved_id": "2987723189", "given_url": "https://paperswithcode.com/task/super-resolution", "given_title": "Computer Vision | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572616", "time_updated": "1638708525", "time_read": "1608572629", "time_favorited": "0", "sort_id": 250, "resolved_title": "Super-Resolution", "resolved_url": "https://paperswithcode.com/task/super-resolution", "excerpt": "Super resolution is the task of taking an input of a low resolution (LR) and upscaling it to that of a high resolution. You can find relevant leaderboards in the subtasks below.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "34", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/task-0000000032-5461795c_qlNRbYP.jpg", "tags": {"deep-learning": {"item_id": "2987723189", "tag": "deep-learning"}, "super-resolution": {"item_id": "2987723189", "tag": "super-resolution"}}, "listen_duration_estimate": 13}, "3207761175": {"item_id": "3207761175", "resolved_id": "3207761175", "given_url": "https://paperswithcode.com/task/zero-shot-learning", "given_title": "Computer Vision | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572779", "time_updated": "1706830946", "time_read": "1608572788", "time_favorited": "0", "sort_id": 251, "resolved_title": "Zero-Shot Learning", "resolved_url": "https://paperswithcode.com/task/zero-shot-learning", "excerpt": "Zero-shot learning (ZSL) is a model's ability to detect classes never seen during training. The condition is that the classes are not known during supervised learning. Earlier work in zero-shot learning use attributes in a two-step approach to infer unknown classes.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "104", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/Screenshot_2019-11-29_at_15.14.04_pYD0tJb.png", "tags": {"deep-learning": {"item_id": "3207761175", "tag": "deep-learning"}, "zero-shot": {"item_id": "3207761175", "tag": "zero-shot"}}, "listen_duration_estimate": 40}, "2569019666": {"item_id": "2569019666", "resolved_id": "2569019691", "given_url": "https://medium.com/@jiwon.jeong/computer-vision-for-beginners-part-4-64a8d9856208?source=rss------artificial_intelligence-5", "given_title": "Computer Vision for Beginners: Part 4", "favorite": "0", "status": "1", "time_added": "1556015608", "time_updated": "1638708525", "time_read": "1567118934", "time_favorited": "0", "sort_id": 252, "resolved_title": "Computer Vision for Beginners: Part¬†4", "resolved_url": "https://medium.com/@jiwon.jeong/computer-vision-for-beginners-part-4-64a8d9856208", "excerpt": "There are lots of ways out there one can adapt to make learning progress efficiently. As for me, combining studies with a little bit of fun is the best strategy. In this series of tutorials, many images have been used to demonstrate image processing concepts.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2194", "lang": "en", "time_to_read": 10, "top_image_url": "https://cdn-images-1.medium.com/max/1200/1*_-Gxkq3Uj804Nc6Wu1DBdA.png", "tags": {"deep-learning": {"item_id": "2569019666", "tag": "deep-learning"}, "vision": {"item_id": "2569019666", "tag": "vision"}}, "authors": {"102777513": {"item_id": "2569019666", "author_id": "102777513", "name": "Jiwon Jeong", "url": "https://medium.com/@jiwon.jeong"}}, "image": {"item_id": "2569019666", "src": "https://cdn-images-1.medium.com/max/1600/1*_-Gxkq3Uj804Nc6Wu1DBdA.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2569019666", "image_id": "1", "src": "https://cdn-images-1.medium.com/max/1600/1*_-Gxkq3Uj804Nc6Wu1DBdA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2569019666", "image_id": "2", "src": "https://cdn-images-1.medium.com/max/1600/1*F2dznG-AJRkklpQcRQm25g.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2569019666", "image_id": "3", "src": "https://cdn-images-1.medium.com/max/1600/1*9p5ZlGFJz0_HFKHthyEvRw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2569019666", "image_id": "4", "src": "https://cdn-images-1.medium.com/max/1600/1*ulXyqlK5LAVhgHe3i4HsKA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2569019666", "image_id": "5", "src": "https://cdn-images-1.medium.com/max/1600/1*OMU_8F-NDbeLbIy8sFj9UA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2569019666", "image_id": "6", "src": "https://cdn-images-1.medium.com/max/1600/1*zh_AX-nV5T-1DqlM2j2mnw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2569019666", "image_id": "7", "src": "https://cdn-images-1.medium.com/max/1600/1*B2veTSIBJBQCw9DmRFrDqg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2569019666", "image_id": "8", "src": "https://cdn-images-1.medium.com/max/1600/1*wtJWfEVQUKyJ-7YullGDbw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2569019666", "image_id": "9", "src": "https://cdn-images-1.medium.com/max/1600/1*GvVB4WgAgRc5WO5NqYZtrw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2569019666", "image_id": "10", "src": "https://cdn-images-1.medium.com/max/1600/1*WhEkPyj_3_e8HgMV05dSqQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2569019666", "image_id": "11", "src": "https://cdn-images-1.medium.com/max/1600/1*JVSrcLV0sK_WJJN8n7ErTA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2569019666", "image_id": "12", "src": "https://cdn-images-1.medium.com/max/1600/1*HLMJBoiVt_MkQlrTdpBw4w.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "2569019666", "image_id": "13", "src": "https://cdn-images-1.medium.com/max/1600/1*eBQDrL6BaspKXXfV1mxBgQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 849}, "3099309929": {"item_id": "3099309929", "resolved_id": "3099309976", "given_url": "https://www.kdnuggets.com/2020/09/computer-vision-recipes-best-practices-examples.html", "given_title": "Computer Vision Recipes: Best Practices and Examples", "favorite": "0", "status": "1", "time_added": "1599070194", "time_updated": "1638708525", "time_read": "1604368816", "time_favorited": "0", "sort_id": 253, "resolved_title": "Computer Vision Recipes: Best Practices and Examples", "resolved_url": "https://www.kdnuggets.com/computer-vision-recipes-best-practices-and-examples.html/", "excerpt": "Having recently spotlighted a similar resource from Microsoft, the Natural Language Processing Best Practices & Examples repository, today we bring to you its computer vision counterpart.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "387", "lang": "en", "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/computer-vision-recipes.jpg", "tags": {"deep-learning": {"item_id": "3099309929", "tag": "deep-learning"}, "vision": {"item_id": "3099309929", "tag": "vision"}}, "authors": {"77311567": {"item_id": "3099309929", "author_id": "77311567", "name": "Matthew Mayo", "url": "https://www.kdnuggets.com/author/matt-mayo"}}, "image": {"item_id": "3099309929", "src": "https://www.kdnuggets.com/wp-content/uploads/computer-vision-recipes.jpg", "width": "70", "height": "0"}, "images": {"1": {"item_id": "3099309929", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/uploads/computer-vision-recipes.jpg", "width": "70", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3099309929", "image_id": "2", "src": "https://i.ibb.co/xDMvNBS/cv-recipes-scenarios.jpg", "width": "100", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3099309929", "image_id": "3", "src": "https://www.kdnuggets.com/wp-content/uploads/cv-recipes-best-practices-example-folder.jpg", "width": "100", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 150}, "2780776145": {"item_id": "2780776145", "resolved_id": "2780776145", "given_url": "https://distill.pub/2019/computing-receptive-fields", "given_title": "Computing Receptive Fields of Convolutional Neural Networks", "favorite": "0", "status": "1", "time_added": "1572890440", "time_updated": "1638708525", "time_read": "1576355560", "time_favorited": "0", "sort_id": 254, "resolved_title": "Computing Receptive Fields of Convolutional Neural Networks", "resolved_url": "https://distill.pub/2019/computing-receptive-fields", "excerpt": "Mathematical derivations and open-source library to compute receptive fields of convnets, enabling the mapping of extracted features to input signals.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "5535", "lang": "en", "time_to_read": 25, "top_image_url": "https://distill.pub/2019/computing-receptive-fields/thumbnail.jpg", "tags": {"deep-learning": {"item_id": "2780776145", "tag": "deep-learning"}}, "authors": {"11099505": {"item_id": "2780776145", "author_id": "11099505", "name": "wade norris", "url": ""}, "122634326": {"item_id": "2780776145", "author_id": "122634326", "name": "Andr&eacute; Araujo", "url": ""}}, "listen_duration_estimate": 2143}, "4014968034": {"item_id": "4014968034", "resolved_id": "4014968034", "given_url": "https://github.com/MichelLutz1994/Conformal_Prediction/blob/main/paper/Conformal_Prediction_final.pdf", "given_title": "Conformal_Prediction/paper/Conformal_Prediction_final.pdf at main ¬∑ MichelL", "favorite": "0", "status": "1", "time_added": "1709518014", "time_updated": "1709597873", "time_read": "1709597873", "time_favorited": "0", "sort_id": 255, "resolved_title": "", "resolved_url": "https://github.com/MichelLutz1994/Conformal_Prediction/blob/main/paper/Conformal_Prediction_final.pdf", "excerpt": "{\"payload\":{\"allShortcutsEnabled\":false,\"fileTree\":{\"paper\":{\"items\":[{\"name\":\"fig\",\"path\":\"paper/fig\",\"contentType\":\"directory\"},{\"name\":\"Conformal prediction.zip\",\"path\":\"paper/Conformal prediction.zip\",\"contentType\":\"file\"},{\"name\":\"Conformal_Prediction_final.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "703", "lang": "", "tags": {"book": {"item_id": "4014968034", "tag": "book"}, "conformal": {"item_id": "4014968034", "tag": "conformal"}, "deep-learning": {"item_id": "4014968034", "tag": "deep-learning"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 272}, "3300876038": {"item_id": "3300876038", "resolved_id": "3300876038", "given_url": "https://techxplore.com/news/2021-04-rice-intel-optimize-ai-commodity.html", "given_title": "CPU-based algorithm trains deep neural nets up to 15 times faster than top ", "favorite": "0", "status": "1", "time_added": "1617929122", "time_updated": "1638708525", "time_read": "1617932468", "time_favorited": "0", "sort_id": 256, "resolved_title": "CPU algorithm trains deep neural nets up to 15 times faster than top GPU trainers", "resolved_url": "https://techxplore.com/news/2021-04-rice-intel-optimize-ai-commodity.html", "excerpt": "Anshumali Shrivastava is an assistant professor of computer science at Rice University.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "386", "lang": "en", "amp_url": "https://techxplore.com/news/2021-04-rice-intel-optimize-ai-commodity.amp", "top_image_url": "https://scx2.b-cdn.net/gfx/news/hires/2021/riceintelopt.jpg", "tags": {"cpus": {"item_id": "3300876038", "tag": "cpus"}, "deep-learning": {"item_id": "3300876038", "tag": "deep-learning"}, "gpus": {"item_id": "3300876038", "tag": "gpus"}, "machine-learning": {"item_id": "3300876038", "tag": "machine-learning"}}, "authors": {"1184489": {"item_id": "3300876038", "author_id": "1184489", "name": "Jade Boyd", "url": ""}}, "image": {"item_id": "3300876038", "src": "https://scx1.b-cdn.net/csz/news/800a/2021/riceintelopt.jpg", "width": "800", "height": "530"}, "images": {"1": {"item_id": "3300876038", "image_id": "1", "src": "https://scx1.b-cdn.net/csz/news/800a/2021/riceintelopt.jpg", "width": "800", "height": "530", "credit": "", "caption": ""}}, "listen_duration_estimate": 149}, "3240077566": {"item_id": "3240077566", "resolved_id": "3240077595", "given_url": "https://towardsdatascience.com/cross-topic-argument-mining-learning-how-to-classify-texts-1d9e5c00c4cc?source=rss----7f60cf5620c9---4", "given_title": "Cross-Topic Argument Mining: Learning How to Classify Texts", "favorite": "0", "status": "1", "time_added": "1611684431", "time_updated": "1638708525", "time_read": "1611746344", "time_favorited": "0", "sort_id": 257, "resolved_title": "Cross-Topic Argument Mining: Learning How to Classify Texts", "resolved_url": "https://towardsdatascience.com/cross-topic-argument-mining-learning-how-to-classify-texts-1d9e5c00c4cc", "excerpt": "Argument mining, or argumentation mining, is one of the research topics in natural language processing (NLP) and knowledge representation learning. Argumentation deals with logical reasoning and is inherent to human intelligence.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2218", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/max/1200/0*V7bXCvUPDw5rIedZ", "tags": {"classification": {"item_id": "3240077566", "tag": "classification"}, "deep-learning": {"item_id": "3240077566", "tag": "deep-learning"}, "nlp": {"item_id": "3240077566", "tag": "nlp"}, "text": {"item_id": "3240077566", "tag": "text"}}, "authors": {"143989528": {"item_id": "3240077566", "author_id": "143989528", "name": "Stephen Adhisaputra", "url": "https://stephenadhi.medium.com"}}, "image": {"item_id": "3240077566", "src": "https://miro.medium.com/max/15850/0*V7bXCvUPDw5rIedZ", "width": "7925", "height": "5286"}, "images": {"1": {"item_id": "3240077566", "image_id": "1", "src": "https://miro.medium.com/max/15850/0*V7bXCvUPDw5rIedZ", "width": "7925", "height": "5286", "credit": "Etienne Boulanger on Unsplash", "caption": ""}, "2": {"item_id": "3240077566", "image_id": "2", "src": "https://miro.medium.com/max/1984/1*aAQq-1SwdK-KorJVbM7R7Q.png", "width": "992", "height": "418", "credit": "", "caption": "Topic distribution ‚Äî Image by Author"}, "3": {"item_id": "3240077566", "image_id": "3", "src": "https://miro.medium.com/max/1044/1*Y3MpWYz5IiZ5KBaNdcDkaw.png", "width": "522", "height": "344", "credit": "", "caption": "Label distribution ‚Äî Image by Author"}, "4": {"item_id": "3240077566", "image_id": "4", "src": "https://miro.medium.com/max/3256/1*np4zvM2OrOl9z2mhvgKepA.png", "width": "1628", "height": "613", "credit": "", "caption": "Argument mining pipeline ‚Äî Image by Author"}, "5": {"item_id": "3240077566", "image_id": "5", "src": "https://miro.medium.com/max/1696/1*2Ja8WBvyQnWUCLOBH7j-5A.png", "width": "848", "height": "345", "credit": "", "caption": "Example sentences ‚Äî Image by Author"}, "6": {"item_id": "3240077566", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*BZUAUu8RU4IIVBkmfuveCw.png", "width": "700", "height": "271", "credit": "", "caption": "One-hot encoding ‚Äî Image by Author"}, "7": {"item_id": "3240077566", "image_id": "7", "src": "https://miro.medium.com/max/1262/1*QH9zQGmo2QUrQ_YvF7Bebw.png", "width": "631", "height": "442", "credit": "", "caption": "List of vocabulary ‚Äî Image by Author"}, "8": {"item_id": "3240077566", "image_id": "8", "src": "https://miro.medium.com/max/1430/1*QcG4AIgtTYyXYWd7FOIRGQ.png", "width": "715", "height": "805", "credit": "", "caption": "Word frequency distribution ‚Äî Image by Author"}, "9": {"item_id": "3240077566", "image_id": "9", "src": "https://miro.medium.com/max/1038/1*drMwgH8RLOErYpJGL-2wKQ.png", "width": "519", "height": "374", "credit": "", "caption": "Deep learning model in Tensorflow ‚Äî Image by Author"}, "10": {"item_id": "3240077566", "image_id": "10", "src": "https://miro.medium.com/max/916/1*MhDi5X0SM2usJxvDoKoO_A.png", "width": "458", "height": "211", "credit": "", "caption": "In-topic classification report‚Äî Image by Author"}, "11": {"item_id": "3240077566", "image_id": "11", "src": "https://miro.medium.com/max/904/1*VmDdCmQvQ-dFO0S72T9WWA.png", "width": "452", "height": "197", "credit": "", "caption": "Cross-topic classification report ‚Äî Image by Author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 859}, "3289249214": {"item_id": "3289249214", "resolved_id": "3289249289", "given_url": "https://towardsdatascience.com/curious-about-variational-autoencoders-vaes-start-here-ab212fc2dd54?source=rss----7f60cf5620c9---4", "given_title": "Curious about Variational Autoencoders (VAEs)? Start Here.", "favorite": "0", "status": "1", "time_added": "1616630092", "time_updated": "1673901753", "time_read": "1616661987", "time_favorited": "0", "sort_id": 258, "resolved_title": "Curious about Variational Autoencoders (VAEs)? Start Here.", "resolved_url": "https://towardsdatascience.com/curious-about-variational-autoencoders-vaes-start-here-ab212fc2dd54", "excerpt": "In recent years, GANs (generative adversarial networks) have been all the rage in the field of deep-learning generative models, leaving VAEs in relative obscurity.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "133", "lang": "en", "tags": {"autoencoders": {"item_id": "3289249214", "tag": "autoencoders"}, "deep-learning": {"item_id": "3289249214", "tag": "deep-learning"}}, "authors": {"146923948": {"item_id": "3289249214", "author_id": "146923948", "name": "Ben Huberman", "url": "https://benzbox.medium.com"}}, "image": {"item_id": "3289249214", "src": "https://miro.medium.com/fit/c/56/56/0*d9SeKmDV1vNzwzz1.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3289249214", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/0*d9SeKmDV1vNzwzz1.png", "width": "28", "height": "28", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 51}, "3245823957": {"item_id": "3245823957", "resolved_id": "3245823957", "given_url": "https://distill.pub/2020/circuits/curve-circuits", "given_title": "Curve Circuits", "favorite": "0", "status": "1", "time_added": "1612224669", "time_updated": "1638708525", "time_read": "1612377880", "time_favorited": "0", "sort_id": 259, "resolved_title": "Curve Circuits", "resolved_url": "https://distill.pub/2020/circuits/curve-circuits", "excerpt": "We reverse engineer a non-trivial learned algorithm from the weights of a neural network and use its core ideas to craft an artificial artificial neural network from scratch that reimplements it.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "599", "lang": "en", "time_to_read": 3, "top_image_url": "https://distill.pub/2020/circuits/curve-circuits/thumbnail.jpg", "tags": {"deep-learning": {"item_id": "3245823957", "tag": "deep-learning"}}, "authors": {"25865415": {"item_id": "3245823957", "author_id": "25865415", "name": "Nick Cammarata", "url": ""}, "34058231": {"item_id": "3245823957", "author_id": "34058231", "name": "Gabriel Goh", "url": ""}}, "image": {"item_id": "3245823957", "src": "https://distill.pub/2020/circuits/curve-circuits/banner-artificial.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3245823957", "image_id": "1", "src": "https://distill.pub/2020/circuits/curve-circuits/banner-artificial.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3245823957", "image_id": "2", "src": "https://distill.pub/2020/circuits/curve-circuits/banner-natural.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 232}, "3020537325": {"item_id": "3020537325", "resolved_id": "3020537325", "given_url": "https://distill.pub/2020/circuits/curve-detectors", "given_title": "Curve Detectors", "favorite": "0", "status": "1", "time_added": "1592392744", "time_updated": "1638708525", "time_read": "1592418626", "time_favorited": "0", "sort_id": 260, "resolved_title": "", "resolved_url": "https://distill.pub/2020/circuits/curve-detectors/", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"deep-learning": {"item_id": "3020537325", "tag": "deep-learning"}, "vision": {"item_id": "3020537325", "tag": "vision"}}, "listen_duration_estimate": 0}, "2985112150": {"item_id": "2985112150", "resolved_id": "2985112186", "given_url": "https://towardsdatascience.com/data-augmentation-in-yolov4-c16bd22b2617?source=rss----7f60cf5620c9---4", "given_title": "Data Augmentation in YOLOv4", "favorite": "0", "status": "1", "time_added": "1589628132", "time_updated": "1638708525", "time_read": "1591029912", "time_favorited": "0", "sort_id": 261, "resolved_title": "The ‚ÄúSecret‚Äù to YOLOv4 isn‚Äôt Architecture: It‚Äôs in Data Preparation. Note: We have also published Data Augmentation in YOLOv4 on our blog.", "resolved_url": "https://towardsdatascience.com/data-augmentation-in-yolov4-c16bd22b2617", "excerpt": "The object detection space continues to move quickly. No more than two months ago, the Google Brain team released EfficientDet for object detection, challenging YOLOv3 as the premier model for (near) realtime object detection, and pushing the boundaries of what is possible in object detection.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1292", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1136/0*jkbdj4syiIqFGvaR.png", "tags": {"deep-learning": {"item_id": "2985112150", "tag": "deep-learning"}, "object-detection": {"item_id": "2985112150", "tag": "object-detection"}, "vision": {"item_id": "2985112150", "tag": "vision"}}, "authors": {"145053877": {"item_id": "2985112150", "author_id": "145053877", "name": "Jacob Solawetz", "url": "https://jacobsolawetz.medium.com"}}, "image": {"item_id": "2985112150", "src": "https://miro.medium.com/fit/c/56/56/1*KjdQOfp6mREAOFJD9JnpTw.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2985112150", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*KjdQOfp6mREAOFJD9JnpTw.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2985112150", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*jkbdj4syiIqFGvaR.png", "width": "700", "height": "429", "credit": "Citation", "caption": ""}, "3": {"item_id": "2985112150", "image_id": "3", "src": "https://miro.medium.com/max/1200/0*fQGQyR37Mfk29mCW.gif", "width": "600", "height": "158", "credit": "", "caption": "Adjusting brightness on our platform"}, "4": {"item_id": "2985112150", "image_id": "4", "src": "https://miro.medium.com/max/1200/0*goXR99C5Q4wrSLH_.gif", "width": "600", "height": "185", "credit": "", "caption": "Flipping images on our platform"}, "5": {"item_id": "2985112150", "image_id": "5", "src": "https://miro.medium.com/max/1400/0*8Ua5bbxFK-LI1gG8.png", "width": "700", "height": "437", "credit": "Citation", "caption": ""}, "6": {"item_id": "2985112150", "image_id": "6", "src": "https://miro.medium.com/max/1400/0*9J7eZ6ujm4MO-fWC.png", "width": "700", "height": "467", "credit": "Citation", "caption": ""}, "7": {"item_id": "2985112150", "image_id": "7", "src": "https://miro.medium.com/max/1400/0*MMWEzuQbxD0GctgC.png", "width": "700", "height": "454", "credit": "Citation", "caption": ""}, "8": {"item_id": "2985112150", "image_id": "8", "src": "https://miro.medium.com/max/1400/0*CBm_F3PXphVUFKhO.png", "width": "700", "height": "676", "credit": "Citation", "caption": ""}, "9": {"item_id": "2985112150", "image_id": "9", "src": "https://miro.medium.com/max/684/0*_bse6j2icTykSdCo.png", "width": "342", "height": "565", "credit": "Citation", "caption": ""}, "10": {"item_id": "2985112150", "image_id": "10", "src": "https://miro.medium.com/max/1400/0*hJclmhf9cBewUvmP.png", "width": "700", "height": "725", "credit": "Citation", "caption": ""}, "11": {"item_id": "2985112150", "image_id": "11", "src": "https://miro.medium.com/max/1400/0*ShgLxN9VYhgYPLnv.png", "width": "700", "height": "435", "credit": "Citation", "caption": ""}, "12": {"item_id": "2985112150", "image_id": "12", "src": "https://miro.medium.com/max/1400/0*VYF0ts2Y9qV5QUpZ.png", "width": "700", "height": "430", "credit": "Citation", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 500}, "2607066834": {"item_id": "2607066834", "resolved_id": "2607066834", "given_url": "https://deepai.org/definitions", "given_title": "Data Science & AI Glossary | DeepAI", "favorite": "0", "status": "1", "time_added": "1612972399", "time_updated": "1706633668", "time_read": "1613042535", "time_favorited": "0", "sort_id": 262, "resolved_title": "Learn top data science and A.I. terms.", "resolved_url": "https://deepai.org/definitions", "excerpt": "The data science and artificial intelligence terms you need while reading the latest research", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "top_image_url": "https://deepai.org/category-pages/1178ac511fbd48e0bbaca446ee0f3724/glossary-icon.png", "tags": {"deep-learning": {"item_id": "2607066834", "tag": "deep-learning"}, "glossaries": {"item_id": "2607066834", "tag": "glossaries"}, "machine-learning": {"item_id": "2607066834", "tag": "machine-learning"}}, "listen_duration_estimate": 0}, "3308679778": {"item_id": "3308679778", "resolved_id": "3308679778", "given_url": "https://nv-tlabs.github.io/datasetGAN/", "given_title": "DatasetGAN", "favorite": "0", "status": "1", "time_added": "1621733542", "time_updated": "1638708525", "time_read": "1621858840", "time_favorited": "0", "sort_id": 263, "resolved_title": "DatasetGAN", "resolved_url": "https://nv-tlabs.github.io/datasetGAN/", "excerpt": "We introduce DatasetGAN: an automatic procedure to generate massive datasets of high-quality semantically segmented images requiring minimal human effort. Current deep networks are extremely data-hungry, benefiting from training on large-scale datasets, which are time consuming to annotate.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "183", "lang": "en", "tags": {"datasets": {"item_id": "3308679778", "tag": "datasets"}, "deep-learning": {"item_id": "3308679778", "tag": "deep-learning"}}, "listen_duration_estimate": 71}, "3659949731": {"item_id": "3659949731", "resolved_id": "3659965656", "given_url": "https://towardsdatascience.com/deep-convolutional-gan-how-to-use-a-dcgan-to-generate-images-in-python-b08afd4d124e?source=rss----7f60cf5620c9---4", "given_title": "Deep Convolutional GAN‚Ää‚Äî‚ÄäHow to Use a DCGAN to Generate Images in Python", "favorite": "0", "status": "1", "time_added": "1657743624", "time_updated": "1657762504", "time_read": "1657762431", "time_favorited": "0", "sort_id": 264, "resolved_title": "Deep Convolutional GAN‚Ää‚Äî‚ÄäHow to Use a DCGAN to Generate Images in Python", "resolved_url": "https://towardsdatascience.com/deep-convolutional-gan-how-to-use-a-dcgan-to-generate-images-in-python-b08afd4d124e", "excerpt": "Data Scientists use Generative Adversarial Networks (GANs) for a wide range of tasks, with image generation being one of the most common. A particular type of GAN known as DCGAN (Deep Convolutional GAN) has been created specifically for this.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1503", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/1200/1*YJvJEbmhYLJdn12r27Qerg.jpeg", "tags": {"deep-learning": {"item_id": "3659949731", "tag": "deep-learning"}, "gans": {"item_id": "3659949731", "tag": "gans"}, "image-generation": {"item_id": "3659949731", "tag": "image-generation"}}, "authors": {"148379686": {"item_id": "3659949731", "author_id": "148379686", "name": "Saul Dobilas", "url": "https://solclover.com"}}, "image": {"item_id": "3659949731", "src": "https://miro.medium.com/max/1400/1*YJvJEbmhYLJdn12r27Qerg.jpeg", "width": "700", "height": "459"}, "images": {"1": {"item_id": "3659949731", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*YJvJEbmhYLJdn12r27Qerg.jpeg", "width": "700", "height": "459", "credit": "", "caption": "Image by 52Hertz from Pixabay"}, "2": {"item_id": "3659949731", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*OVeduMtpBhsRKZBrc6u5Eg.gif", "width": "700", "height": "600", "credit": "", "caption": "Convolution in action. Gif image by author."}, "3": {"item_id": "3659949731", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*YwVviBiy2qAp0CwS5CDwmA.gif", "width": "700", "height": "670", "credit": "", "caption": "Transposed Convolution in action. Gif image by author."}, "4": {"item_id": "3659949731", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*SZo1GcSEnm4M5FQZZ2r_rA.png", "width": "700", "height": "837", "credit": "DCGAN", "caption": "Deep Convolutional Generative Adversarial Network"}, "5": {"item_id": "3659949731", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*vbBpBgzkIM1cGnI2oeDKIA.png", "width": "700", "height": "321", "credit": "", "caption": "Low-res images in the training data. Original image data from Caltech 101. Combined image by author."}, "6": {"item_id": "3659949731", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*1dBMmk8P58NrbG1PTJaY5w.png", "width": "700", "height": "1486", "credit": "", "caption": "Generator model diagram. Image by author."}, "7": {"item_id": "3659949731", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*z3krpS4jj5p_c5xyT1mGWQ.png", "width": "700", "height": "1353", "credit": "", "caption": "Discriminator model diagram. Image by author."}, "8": {"item_id": "3659949731", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*7-u4R8HjnSf_LQaGGlZzHQ.png", "width": "700", "height": "557", "credit": "", "caption": "DCGAN model diagram. Image by author."}, "9": {"item_id": "3659949731", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*tQl9Oyf5WJBEd6B8bbPF7w.png", "width": "700", "height": "428", "credit": "", "caption": "DCGAN generated bonsai tree images after 1000 training epochs. Image by author."}, "10": {"item_id": "3659949731", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*HZw0t9Xc928qnnm-FNPIoA.png", "width": "700", "height": "428", "credit": "", "caption": "DCGAN generated bonsai tree images after 2000 training epochs. Image by author."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 582}, "3825967033": {"item_id": "3825967033", "resolved_id": "3825967033", "given_url": "https://semiengineering.com/deep-learning-dl-applications-in-photomask-to-wafer-semiconductor-manufacturing-2/", "given_title": "Deep Learning (DL) Applications In Photomask To Wafer Semiconductor Manufac", "favorite": "0", "status": "1", "time_added": "1678878599", "time_updated": "1678881876", "time_read": "1678881876", "time_favorited": "0", "sort_id": 265, "resolved_title": "Deep Learning (DL) Applications In Photomask To Wafer Semiconductor Manufacturing", "resolved_url": "https://semiengineering.com/deep-learning-dl-applications-in-photomask-to-wafer-semiconductor-manufacturing-2/", "excerpt": "This website uses cookies to improve your experience while you navigate through the website. The cookies that are categorized as necessary are stored on your browser as they are essential for the working of basic functionalities of the website.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "130", "lang": "en", "top_image_url": "https://semiengineering.com/wp-content/uploads/wafer-AdobeStock_472655944.jpeg?fit=1200%2C825&ssl=1", "tags": {"deep-learning": {"item_id": "3825967033", "tag": "deep-learning"}, "semiconductors": {"item_id": "3825967033", "tag": "semiconductors"}}, "authors": {"87542462": {"item_id": "3825967033", "author_id": "87542462", "name": "eBeam Initiative", "url": "https://semiengineering.com/author/ebeam-initiative/"}}, "listen_duration_estimate": 50}, "3063512048": {"item_id": "3063512048", "resolved_id": "3063512048", "given_url": "https://dennybritz.com/blog/deep-learning-most-important-ideas/", "given_title": "Deep Learning's Most Important Ideas - A Brief Historical Review", "favorite": "0", "status": "1", "time_added": "1600106183", "time_updated": "1638708525", "time_read": "1604364217", "time_favorited": "0", "sort_id": 266, "resolved_title": "https://dennybritz.com/posts/deep-learning-ideas-that-stood-the-test-of-time/", "resolved_url": "https://dennybritz.com/blog/deep-learning-most-important-ideas/", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"deep-learning": {"item_id": "3063512048", "tag": "deep-learning"}}, "listen_duration_estimate": 0}, "3272805962": {"item_id": "3272805962", "resolved_id": "3272805967", "given_url": "https://www.fastcompany.com/90611504/deep-nostalgia-ai-brings-your-photos-to-life-just-like-in-the-harry-potter-movies?partner=feedburner&utm_source=feedburner&utm_medium=feed&utm_campaign=feedburner+fastcompany&utm_content=feedburner", "given_title": "Deep Nostalgia AI brings your photos to life just like in the ‚ÄòHarry Potter", "favorite": "0", "status": "1", "time_added": "1614945891", "time_updated": "1638708525", "time_read": "1615077848", "time_favorited": "0", "sort_id": 267, "resolved_title": "Deep Nostalgia AI brings your photos to life just like in the ‚ÄòHarry Potter‚Äô movies", "resolved_url": "https://www.fastcompany.com/90611504/deep-nostalgia-ai-brings-your-photos-to-life-just-like-in-the-harry-potter-movies", "excerpt": "Bring great-great-great grandma back to life using deep learning.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "466", "lang": "en", "top_image_url": "https://images.fastcompany.net/image/upload/w_1280,f_auto,q_auto,fl_lossy/wp-cms/uploads/2021/03/p-1-deep-nostalgia-ai-brings-your-photos-to-life-just-like-in-the-harry-potter-movies.jpg", "tags": {"deep-learning": {"item_id": "3272805962", "tag": "deep-learning"}, "machine-vision": {"item_id": "3272805962", "tag": "machine-vision"}, "video": {"item_id": "3272805962", "tag": "video"}}, "authors": {"38811411": {"item_id": "3272805962", "author_id": "38811411", "name": "Michael Grothaus", "url": "https://www.fastcompany.com/user/michael-grothaus"}}, "domain_metadata": {"name": "Fast Company", "logo": "https://logo.clearbit.com/fastcompany.com?size=800", "greyscale_logo": "https://logo.clearbit.com/fastcompany.com?size=800&greyscale=true"}, "listen_duration_estimate": 180}, "2899696637": {"item_id": "2899696637", "resolved_id": "2899533987", "given_url": "https://towardsdatascience.com/deep-transfer-learning-for-image-classification-f3c7e0ec1a14?source=rss----7f60cf5620c9---4", "given_title": "Deep Transfer Learning for Image Classification", "favorite": "0", "status": "1", "time_added": "1582915283", "time_updated": "1638708525", "time_read": "1583785007", "time_favorited": "0", "sort_id": 268, "resolved_title": "Deep Transfer Learning for Image Classification", "resolved_url": "https://towardsdatascience.com/deep-transfer-learning-for-image-classification-f3c7e0ec1a14", "excerpt": "The following tutorial covers how to set up a state of the art deep learning model for image classification.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3804", "lang": "en", "time_to_read": 17, "top_image_url": "https://miro.medium.com/max/450/1*EE8d_4-BxCxpurYs7dct8w.png", "tags": {"deep-learning": {"item_id": "2899696637", "tag": "deep-learning"}}, "authors": {"107756768": {"item_id": "2899696637", "author_id": "107756768", "name": "Vegard Flovik", "url": "https://medium.com/@vflovik"}}, "image": {"item_id": "2899696637", "src": "https://miro.medium.com/fit/c/56/56/1*R31RweoSbpkQccCseX0pjg.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2899696637", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*R31RweoSbpkQccCseX0pjg.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2899696637", "image_id": "2", "src": "https://miro.medium.com/max/2218/1*xGxZTiozC1ZEuERt9UGpqg.png", "width": "1109", "height": "278", "credit": "", "caption": ""}, "3": {"item_id": "2899696637", "image_id": "3", "src": "https://miro.medium.com/max/1566/1*Q4NQxril-ABNIcGbfhg8Vg.png", "width": "783", "height": "450", "credit": "", "caption": "Overview of the number of training images per class"}, "4": {"item_id": "2899696637", "image_id": "4", "src": "https://miro.medium.com/max/900/1*EE8d_4-BxCxpurYs7dct8w.png", "width": "450", "height": "577", "credit": "", "caption": "Some example images"}, "5": {"item_id": "2899696637", "image_id": "5", "src": "https://miro.medium.com/max/2436/1*iyxC5n8OvMK1cth8e0G2Ng.png", "width": "1218", "height": "596", "credit": "", "caption": "Transfer learning"}, "6": {"item_id": "2899696637", "image_id": "6", "src": "https://miro.medium.com/max/1818/1*g9cu9r6p4u3YrYvFKf1p0Q.jpeg", "width": "909", "height": "426", "credit": "", "caption": ""}, "7": {"item_id": "2899696637", "image_id": "7", "src": "https://miro.medium.com/max/1298/1*vF_andcT2tQW2WAj71BxIw.jpeg", "width": "649", "height": "231", "credit": "", "caption": ""}, "8": {"item_id": "2899696637", "image_id": "8", "src": "https://miro.medium.com/max/838/1*Xtt6icKtjIFapNbiMXXUsg.jpeg", "width": "419", "height": "134", "credit": "", "caption": "Output from running the above code block"}, "9": {"item_id": "2899696637", "image_id": "9", "src": "https://miro.medium.com/max/2430/1*dxnN_bmK5jWeZeEXdESGpw.jpeg", "width": "1215", "height": "845", "credit": "", "caption": "Output during training"}, "10": {"item_id": "2899696637", "image_id": "10", "src": "https://miro.medium.com/max/1526/1*sb7qEA-z_-dPnpS5Kh712Q.png", "width": "763", "height": "260", "credit": "", "caption": ""}, "11": {"item_id": "2899696637", "image_id": "11", "src": "https://miro.medium.com/max/1388/1*yUpv8lktOAupwX3_PNytPA.jpeg", "width": "694", "height": "711", "credit": "", "caption": ""}, "12": {"item_id": "2899696637", "image_id": "12", "src": "https://miro.medium.com/max/2580/1*1Ri2lFQeSYbczsoJ6Rgb7A.png", "width": "1290", "height": "603", "credit": "", "caption": ""}, "13": {"item_id": "2899696637", "image_id": "13", "src": "https://miro.medium.com/max/1514/1*y_LYIY15YJzti3Q43-cggQ.png", "width": "757", "height": "260", "credit": "", "caption": ""}, "14": {"item_id": "2899696637", "image_id": "14", "src": "https://miro.medium.com/max/1386/1*bvVaaGGIXkdRvMdwCV1ANw.jpeg", "width": "693", "height": "698", "credit": "", "caption": ""}, "15": {"item_id": "2899696637", "image_id": "15", "src": "https://miro.medium.com/max/794/1*j9BDbaLESuL3vKqu7ogY-Q.png", "width": "397", "height": "435", "credit": "", "caption": "Example output from classification model"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1473}, "1450303407": {"item_id": "1450303407", "resolved_id": "1450303407", "given_url": "https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap/blob/master/README.md", "given_title": "Deep-Learning-Papers-Reading-Roadmap/README.md at master ¬∑ songrotek/Deep-L", "favorite": "0", "status": "1", "time_added": "1496769582", "time_updated": "1638708525", "time_read": "1514398176", "time_favorited": "0", "sort_id": 269, "resolved_title": "songrotek/Deep-Learning-Papers-Reading-Roadmap", "resolved_url": "https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap/blob/master/README.md", "excerpt": "Here is a reading roadmap of Deep Learning papers!  You will find many papers that are quite new but really worth reading.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "2613", "lang": "en", "time_to_read": 12, "top_image_url": "https://avatars2.githubusercontent.com/u/3880963?v=3&s=400", "tags": {"deep-learning": {"item_id": "1450303407", "tag": "deep-learning"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 1011}, "3763040970": {"item_id": "3763040970", "resolved_id": "3763040973", "given_url": "https://entertainment.slashdot.org/story/22/12/10/0040219/deepmind-created-an-ai-tool-that-can-help-generate-rough-film-and-stage-scripts?utm_source=rss1.0mainlinkanon&utm_medium=feed", "given_title": "DeepMind Created An AI Tool That Can Help Generate Rough Film and Stage Scr", "favorite": "0", "status": "1", "time_added": "1670649829", "time_updated": "1706650968", "time_read": "1670683563", "time_favorited": "0", "sort_id": 270, "resolved_title": "DeepMind Created An AI Tool That Can Help Generate Rough Film and Stage Scripts", "resolved_url": "https://entertainment.slashdot.org/story/22/12/10/0040219/deepmind-created-an-ai-tool-that-can-help-generate-rough-film-and-stage-scripts", "excerpt": "Alphabet's DeepMind has built an AI tool that can help generate rough film and stage scripts Engadget's Kris Holt reports: Dramatron is a so-called \"co-writing\" tool that can generate character descriptions, plot points, location descriptions and dialogue.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "330", "lang": "en", "top_image_url": "https://a.fsdn.com/sd/topics/ai_64.png", "tags": {"deep-learning": {"item_id": "3763040970", "tag": "deep-learning"}, "generative": {"item_id": "3763040970", "tag": "generative"}, "movies-television": {"item_id": "3763040970", "tag": "movies-television"}, "storytelling": {"item_id": "3763040970", "tag": "storytelling"}}, "authors": {"47802700": {"item_id": "3763040970", "author_id": "47802700", "name": "BeauHD", "url": "https://twitter.com/BeauHD"}}, "listen_duration_estimate": 128}, "3382401960": {"item_id": "3382401960", "resolved_id": "3382401960", "given_url": "https://github.com/deepmind/alphafold", "given_title": "deepmind/alphafold: Open source code for AlphaFold.", "favorite": "0", "status": "1", "time_added": "1626460739", "time_updated": "1706620607", "time_read": "1626484714", "time_favorited": "0", "sort_id": 271, "resolved_title": "AlphaFold", "resolved_url": "https://github.com/deepmind/alphafold", "excerpt": "This package provides an implementation of the inference pipeline of AlphaFold v2.0. This is a completely new model that was entered in CASP14 and published in Nature. For simplicity, we refer to this model as AlphaFold throughout the rest of this document.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "1885", "lang": "en", "time_to_read": 9, "top_image_url": "https://opengraph.githubassets.com/aa52c2721663bf0703a5b1d47ef8e91393fad978418080e5d4ea6a75a12e6494/deepmind/alphafold", "tags": {"biology": {"item_id": "3382401960", "tag": "biology"}, "deep-learning": {"item_id": "3382401960", "tag": "deep-learning"}, "exercise-health-medicine": {"item_id": "3382401960", "tag": "exercise-health-medicine"}}, "authors": {"153763925": {"item_id": "3382401960", "author_id": "153763925", "name": "Biopython", "url": "https://biopython.org"}}, "image": {"item_id": "3382401960", "src": "https://github.com/deepmind/alphafold/blob/main/imgs/header.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3382401960", "image_id": "1", "src": "https://github.com/deepmind/alphafold/blob/main/imgs/header.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3382401960", "image_id": "2", "src": "https://github.com/deepmind/alphafold/raw/main/imgs/casp14_predictions.gif", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 730}, "2750174874": {"item_id": "2750174874", "resolved_id": "2750174874", "given_url": "https://towardsdatascience.com/a-hitchhikers-guide-to-object-detection-and-instance-segmentation-ac0146fe8e11", "given_title": "Demystifying Object Detection and Instance Segmentation for Data Scientists", "favorite": "0", "status": "1", "time_added": "1570545082", "time_updated": "1638708525", "time_read": "1576355412", "time_favorited": "0", "sort_id": 272, "resolved_title": "Demystifying Object Detection and Instance Segmentation for Data Scientists", "resolved_url": "https://towardsdatascience.com/a-hitchhikers-guide-to-object-detection-and-instance-segmentation-ac0146fe8e11", "excerpt": "And Object detection is important and does have its uses. Most common of them being self-driving cars, medical imaging and face detection. It is definitely a hard problem to solve.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3482", "lang": "en", "time_to_read": 16, "top_image_url": "https://miro.medium.com/max/1195/0*MvG68sst2o05h97G", "tags": {"deep-learning": {"item_id": "2750174874", "tag": "deep-learning"}, "object-detection": {"item_id": "2750174874", "tag": "object-detection"}}, "authors": {"144145174": {"item_id": "2750174874", "author_id": "144145174", "name": "Rahul Agarwal", "url": "https://mlwhiz.medium.com"}}, "image": {"item_id": "2750174874", "src": "https://miro.medium.com/max/2000/0*MvG68sst2o05h97G", "width": "1000", "height": "628"}, "images": {"1": {"item_id": "2750174874", "image_id": "1", "src": "https://miro.medium.com/max/2000/0*MvG68sst2o05h97G", "width": "1000", "height": "628", "credit": "", "caption": "The stage we are at and how we reached it."}, "2": {"item_id": "2750174874", "image_id": "2", "src": "https://miro.medium.com/fit/c/56/56/1*Ihl-t4w_lAH1zfqN-2THDw.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "3": {"item_id": "2750174874", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*J1qpG6TUYsq43whAqezjyg.png", "width": "700", "height": "296", "credit": "", "caption": "Source"}, "4": {"item_id": "2750174874", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*NTVoRZYBWbwRxNidyLCxPw.png", "width": "700", "height": "353", "credit": "", "caption": "Source"}, "5": {"item_id": "2750174874", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*vI_ZYi6-8dHR2C3iBmiDow.png", "width": "700", "height": "254", "credit": "", "caption": "Efficient graph-based Image Segmentation Example"}, "6": {"item_id": "2750174874", "image_id": "6", "src": "https://miro.medium.com/max/1144/1*VAgKEVCH7TA8C9iXLZXHcw.png", "width": "572", "height": "112", "credit": "", "caption": ""}, "7": {"item_id": "2750174874", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*EXmTaedvbE92jYvYltOqYQ.png", "width": "700", "height": "615", "credit": "", "caption": "The Algorithm for region Proposal used in RCNN"}, "8": {"item_id": "2750174874", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*QCzs-RFS7jFK9lawxOb8Uw.png", "width": "700", "height": "360", "credit": "", "caption": ""}, "9": {"item_id": "2750174874", "image_id": "9", "src": "https://miro.medium.com/proxy/1*fMIidAY8AMy6SVMuWu86bg.jpeg", "width": "0", "height": "0", "credit": "", "caption": "https://www.pyimagesearch.com/wp-content/uploads/2014/10/hog_object_detection_nms.jpg"}, "10": {"item_id": "2750174874", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*YJkOke1HGOGIee3t_ho8LQ.png", "width": "700", "height": "353", "credit": "", "caption": ""}, "11": {"item_id": "2750174874", "image_id": "11", "src": "https://miro.medium.com/max/940/0*nSfm_y_ODxrktHIv", "width": "470", "height": "276", "credit": "", "caption": "VGG 16 Architecture"}, "12": {"item_id": "2750174874", "image_id": "12", "src": "https://miro.medium.com/max/1400/0*vtNkjh3hB3j07z2-.png", "width": "700", "height": "394", "credit": "", "caption": "We need fixed-sized feature maps for the final classifier"}, "13": {"item_id": "2750174874", "image_id": "13", "src": "https://miro.medium.com/max/1256/1*52p9P55Ue1R4EQQcQTUzEQ.png", "width": "628", "height": "61", "credit": "", "caption": "Classification Loss + regression Loss"}, "14": {"item_id": "2750174874", "image_id": "14", "src": "https://miro.medium.com/max/1400/1*stEtEJlfxeeDTPc4Fm9VPA.png", "width": "700", "height": "433", "credit": "", "caption": "Runtime dominated by region proposals!"}, "15": {"item_id": "2750174874", "image_id": "15", "src": "https://miro.medium.com/max/1400/0*Zg6TuJz2gwA2Nyhh.png", "width": "700", "height": "628", "credit": "", "caption": ""}, "16": {"item_id": "2750174874", "image_id": "16", "src": "https://miro.medium.com/max/1400/0*URu6sPPyXHKk1dpw.png", "width": "700", "height": "525", "credit": "", "caption": "Anchor centers throughout the original image"}, "17": {"item_id": "2750174874", "image_id": "17", "src": "https://miro.medium.com/max/1400/0*Wrz9HRpdcocCwt-b.png", "width": "700", "height": "254", "credit": "", "caption": "Left: Anchors, Center: Anchor for a single point, Right: All anchors"}, "18": {"item_id": "2750174874", "image_id": "18", "src": "https://miro.medium.com/max/1276/0*s35p9gpazTYF9qUM", "width": "638", "height": "359", "credit": "", "caption": "Results on VOC Dataset for the three different approaches"}, "19": {"item_id": "2750174874", "image_id": "19", "src": "https://miro.medium.com/max/1400/0*-yYYWD5vQBbCWvDE.png", "width": "700", "height": "377", "credit": "", "caption": "Some images with masks from the paper"}, "20": {"item_id": "2750174874", "image_id": "20", "src": "https://miro.medium.com/max/2000/0*27bvIrrGKYpiUNF7.png", "width": "1000", "height": "329", "credit": "", "caption": "Source: Everything remains the same. Just one more output layer to predict masks and ROI pooling replaced by ROIAlign"}, "21": {"item_id": "2750174874", "image_id": "21", "src": "https://miro.medium.com/max/1400/0*gzaTSO9vuc4unnOq.png", "width": "700", "height": "551", "credit": "", "caption": "Source"}, "22": {"item_id": "2750174874", "image_id": "22", "src": "https://miro.medium.com/max/1400/0*PdwwH4sjOOj7q_tA", "width": "700", "height": "467", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1348}, "2962151113": {"item_id": "2962151113", "resolved_id": "2962151127", "given_url": "https://towardsdatascience.com/deploy-tensorflow-object-detection-api-on-kubernetes-with-python-flask-and-docker-7a9513dd19e4?source=rss----7f60cf5620c9---4", "given_title": "Deploy Tensorflow Object Detection API on Kubernetes with Python, Flask and", "favorite": "0", "status": "1", "time_added": "1587821380", "time_updated": "1638708525", "time_read": "1587919502", "time_favorited": "0", "sort_id": 273, "resolved_title": "Deploy Tensorflow Object Detection API on Kubernetes with Python, Flask and Docker", "resolved_url": "https://towardsdatascience.com/deploy-tensorflow-object-detection-api-on-kubernetes-with-python-flask-and-docker-7a9513dd19e4", "excerpt": "The TensorFlow Object Detection API is an open source framework built on top of TensorFlow that makes it easy to construct, train and deploy object detection models.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1629", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/1200/1*TdL7mioxFRsDd4x6pABycg.jpeg", "tags": {"deep-learning": {"item_id": "2962151113", "tag": "deep-learning"}, "object-detection": {"item_id": "2962151113", "tag": "object-detection"}}, "authors": {"154402863": {"item_id": "2962151113", "author_id": "154402863", "name": "Neeraj Krishna", "url": "https://ms-neerajkrishna.medium.com"}}, "image": {"item_id": "2962151113", "src": "https://miro.medium.com/fit/c/56/56/2*NCnZV5CUWbB6I4fOVW5Y5g.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2962151113", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*NCnZV5CUWbB6I4fOVW5Y5g.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2962151113", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*TdL7mioxFRsDd4x6pABycg.jpeg", "width": "700", "height": "468", "credit": "", "caption": "Image by Rudy and Peter Skitterians from Pixabay"}, "3": {"item_id": "2962151113", "image_id": "3", "src": "https://miro.medium.com/max/1202/1*e8u6teTHyalPejIBauj4Jw.png", "width": "601", "height": "431", "credit": "", "caption": "Docker"}, "4": {"item_id": "2962151113", "image_id": "4", "src": "https://miro.medium.com/max/800/1*x6ZPGy7StrkjP_8mvfSJSA.png", "width": "400", "height": "400", "credit": "", "caption": "Google Container Registry"}, "5": {"item_id": "2962151113", "image_id": "5", "src": "https://miro.medium.com/max/1120/1*T22Li5ZY0HcomtuirDbUrQ.png", "width": "560", "height": "496", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 631}, "2927658359": {"item_id": "2927658359", "resolved_id": "2927658359", "given_url": "https://github.com/natanielruiz/disrupting-deepfakes", "given_title": "Disrupting Deepfakes: Adversarial Attacks on Image Translation Networks (Co", "favorite": "0", "status": "1", "time_added": "1585159826", "time_updated": "1638708525", "time_read": "1585739557", "time_favorited": "0", "sort_id": 274, "resolved_title": "natanielruiz/disrupting-deepfakes : üî•üî•Defending Against Deepfakes Using Adversarial Attacks on Conditional Image Translation Networks", "resolved_url": "https://github.com/natanielruiz/disrupting-deepfakes", "excerpt": "Official PyTorch implementation of Disrupting Deepfakes (to be presented at the CVPR 2020 Workshop on Adversarial Machine Learning in Computer Vision). This repository contains code for adversarial attacks (disruptions) for (conditional) image translation networks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "811", "lang": "en", "time_to_read": 4, "top_image_url": "https://opengraph.githubassets.com/e06e7fd3ba76e29055f9f5f804c5ac1bda545941c5ac7a21100d9ce05597f255/natanielruiz/disrupting-deepfakes", "tags": {"deep-learning": {"item_id": "2927658359", "tag": "deep-learning"}, "vision": {"item_id": "2927658359", "tag": "vision"}}, "image": {"item_id": "2927658359", "src": "https://github.com/natanielruiz/disrupting-deepfakes/raw/master/imgs/demo.gif", "width": "100", "height": "0"}, "images": {"1": {"item_id": "2927658359", "image_id": "1", "src": "https://github.com/natanielruiz/disrupting-deepfakes/raw/master/imgs/demo.gif", "width": "100", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2927658359", "image_id": "2", "src": "https://github.com/natanielruiz/disrupting-deepfakes/raw/master/imgs/main_1.gif", "width": "100", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 314}, "2434838586": {"item_id": "2434838586", "resolved_id": "2434838586", "given_url": "http://d2l.ai/", "given_title": "Dive into Deep Learning ‚Äî Dive into Deep Learning 0.14.4 documentation", "favorite": "0", "status": "1", "time_added": "1658077632", "time_updated": "1658187798", "time_read": "1658187797", "time_favorited": "0", "sort_id": 275, "resolved_title": "Dive into Deep Learning ‚Äî Dive into Deep Learning 1.0.0-beta0 documentation", "resolved_url": "https://d2l.ai/", "excerpt": "You can modify the code and tune hyperparameters to get instant feedback to accumulate practical experiences in deep learning.", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "1757", "lang": "en", "time_to_read": 8, "tags": {"books": {"item_id": "2434838586", "tag": "books"}, "deep-learning": {"item_id": "2434838586", "tag": "deep-learning"}}, "listen_duration_estimate": 680}, "3255430970": {"item_id": "3255430970", "resolved_id": "3255430771", "given_url": "https://towardsdatascience.com/diving-into-different-gan-architectures-a96d05c03c5c?source=rss----7f60cf5620c9---4", "given_title": "Diving into different GAN architectures", "favorite": "0", "status": "1", "time_added": "1613164433", "time_updated": "1638708525", "time_read": "1613235536", "time_favorited": "0", "sort_id": 276, "resolved_title": "", "resolved_url": "https://towardsdatascience.com/diving-into-different-gan-architectures-a96d05c03c5c", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"deep-learning": {"item_id": "3255430970", "tag": "deep-learning"}, "gans": {"item_id": "3255430970", "tag": "gans"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3905368976": {"item_id": "3905368976", "resolved_id": "3905368976", "given_url": "https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad", "given_title": "ELI5: FlashAttention", "favorite": "0", "status": "1", "time_added": "1690067652", "time_updated": "1706235131", "time_read": "1690159036", "time_favorited": "0", "sort_id": 277, "resolved_title": "ELI5: FlashAttention", "resolved_url": "https://gordicaleksa.medium.com/eli5-flash-attention-5c44017022ad", "excerpt": "We‚Äôll start from the first principles. We‚Äôll first understand how the standard/vanilla attention is implemented and then we‚Äôll address the inefficiencies one by one ‚Äî as if we were to independently discover flash attention ourselves.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4678", "lang": "en", "time_to_read": 21, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*i4tDdwgvGtXuTIyJpFUn8A.png", "tags": {"deep-learning": {"item_id": "3905368976", "tag": "deep-learning"}, "llms": {"item_id": "3905368976", "tag": "llms"}}, "authors": {"143673938": {"item_id": "3905368976", "author_id": "143673938", "name": "Aleksa Gordiƒá", "url": "https://gordicaleksa.medium.com"}}, "image": {"item_id": "3905368976", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*iFzlYkf9g8binsKxI66few.png", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3905368976", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*iFzlYkf9g8binsKxI66few.png", "width": "44", "height": "44", "credit": "", "caption": ""}}, "listen_duration_estimate": 1811}, "3205189183": {"item_id": "3205189183", "resolved_id": "3205187243", "given_url": "https://towardsdatascience.com/everything-product-people-need-to-know-about-transformers-gpt-3-and-huggingface-6a2e8a45316a?source=rss----7f60cf5620c9---4", "given_title": "Everything Product People Need to Know About Transformers, GPT-3, and Huggi", "favorite": "0", "status": "1", "time_added": "1608310912", "time_updated": "1638708525", "time_read": "1608416310", "time_favorited": "0", "sort_id": 278, "resolved_title": "Everything Product People Need to Know About Transformers, GPT-3, and HuggingFace (", "resolved_url": "https://towardsdatascience.com/everything-product-people-need-to-know-about-transformers-gpt-3-and-huggingface-6a2e8a45316a", "excerpt": "This is Part 1 in the 3 Part Series on Transformers for Product People. Click here for Part 2. Pay attention. Natural language processing (NLP) has passed an industry-changing inflection point.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1152", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/600/1*_Yo4QbDJAlnEYJWKhiKacw.jpeg", "tags": {"deep-learning": {"item_id": "3205189183", "tag": "deep-learning"}}, "authors": {"143227320": {"item_id": "3205189183", "author_id": "143227320", "name": "Yacov Lewis", "url": "https://yacovlewis.medium.com"}}, "image": {"item_id": "3205189183", "src": "https://miro.medium.com/fit/c/56/56/1*c5N4AdwcFHUm0pyB5p6o7g.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3205189183", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*c5N4AdwcFHUm0pyB5p6o7g.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3205189183", "image_id": "2", "src": "https://miro.medium.com/max/1200/1*_Yo4QbDJAlnEYJWKhiKacw.jpeg", "width": "600", "height": "330", "credit": "", "caption": "Source: https://thehustle.co/07202020-gpt-3/"}, "3": {"item_id": "3205189183", "image_id": "3", "src": "https://miro.medium.com/max/2064/0*B7okFHE5dMSslFSw", "width": "1032", "height": "1022", "credit": "", "caption": "Source: CBInsights"}, "4": {"item_id": "3205189183", "image_id": "4", "src": "https://miro.medium.com/max/2700/1*ofzjqTGiRcuND3ugoYCeLg.png", "width": "1350", "height": "718", "credit": "", "caption": "Source: Exploring Transfer Learning with T5: the Text-To-Text Transfer Transformer"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 446}, "2989295701": {"item_id": "2989295701", "resolved_id": "2989295710", "given_url": "https://towardsdatascience.com/evolution-of-language-models-n-grams-word-embeddings-attention-transformers-a688151825d2?source=rss----7f60cf5620c9---4", "given_title": "Evolution of Language Models: N-Grams, Word Embeddings, Attention & Transfo", "favorite": "0", "status": "1", "time_added": "1589972656", "time_updated": "1638708525", "time_read": "1589992096", "time_favorited": "0", "sort_id": 279, "resolved_title": "Evolution of Language Models: N-Grams, Word Embeddings, Attention & Transformers", "resolved_url": "https://towardsdatascience.com/evolution-of-language-models-n-grams-word-embeddings-attention-transformers-a688151825d2", "excerpt": "You‚Äôd be surprised at how young this domain really is. But first and foremost, let‚Äôs lay the foundations on what a Language Model is.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1376", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/0*rWhSy2fLidHCYxPH", "tags": {"deep-learning": {"item_id": "2989295701", "tag": "deep-learning"}, "nlp": {"item_id": "2989295701", "tag": "nlp"}}, "authors": {"122128265": {"item_id": "2989295701", "author_id": "122128265", "name": "Timothy Tan", "url": "https://medium.com/@timothyguang"}}, "image": {"item_id": "2989295701", "src": "https://miro.medium.com/max/8082/0*rWhSy2fLidHCYxPH", "width": "4041", "height": "2274"}, "images": {"1": {"item_id": "2989295701", "image_id": "1", "src": "https://miro.medium.com/max/8082/0*rWhSy2fLidHCYxPH", "width": "4041", "height": "2274", "credit": "", "caption": "ImagPhoto by Johannes Plenio on Unsplash"}, "2": {"item_id": "2989295701", "image_id": "2", "src": "https://miro.medium.com/fit/c/56/56/2*gti5sGCeF7oMGhTzYTftzw.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "3": {"item_id": "2989295701", "image_id": "3", "src": "https://miro.medium.com/max/9856/0*VOcBo3hN4Og-Twm5", "width": "4928", "height": "3264", "credit": "Tim Bish on Unsplash", "caption": ""}, "4": {"item_id": "2989295701", "image_id": "4", "src": "https://miro.medium.com/max/2400/1*Jqfn9m-2wC5pfLpcwzk2Ug.png", "width": "1200", "height": "400", "credit": "RNN", "caption": "A diagram for a one-unit recurrent neural network"}, "5": {"item_id": "2989295701", "image_id": "5", "src": "https://miro.medium.com/max/2400/1*-4NZcM5LFHnf7Xp0Cyeu0Q.png", "width": "1200", "height": "534", "credit": "LSTM", "caption": "A diagram for a one-unit Long Short-Term Memory"}, "6": {"item_id": "2989295701", "image_id": "6", "src": "https://miro.medium.com/max/1192/1*Nj81Dc6OpYT9G9kgT3DOrA.png", "width": "596", "height": "509", "credit": "source", "caption": "The first neural language model by Bengio et al. 2003"}, "7": {"item_id": "2989295701", "image_id": "7", "src": "https://miro.medium.com/max/1570/1*Kv0ZBh7nCi2TDDHJbmvBBw.png", "width": "785", "height": "480", "credit": "source", "caption": "Word2Vec models. The CBOW architecture predicts the current word based on the context, and the Skip-gram predicts surrounding words given the current word. By Mikolov et al. 2013"}, "8": {"item_id": "2989295701", "image_id": "8", "src": "https://miro.medium.com/max/1544/1*kvKfEwc-Dpq6MMzoEofaxw.png", "width": "772", "height": "374", "credit": "Source", "caption": "Overall accuracy on the word analogy task Glove vs CBOW vs Skip-Gram by Pennington et al. 2014"}, "9": {"item_id": "2989295701", "image_id": "9", "src": "https://miro.medium.com/max/17656/0*_m4Ir6Z2Dtz4mOy-", "width": "8828", "height": "11092", "credit": "Science in HD on Unsplash", "caption": ""}, "10": {"item_id": "2989295701", "image_id": "10", "src": "https://miro.medium.com/max/1702/1*lpfua6ajFawoMWDCx8r4Zw.png", "width": "851", "height": "364", "credit": "white indicates the attended regions, underlines indicated the corresponding word", "caption": "Examples of attending to the correct object"}, "11": {"item_id": "2989295701", "image_id": "11", "src": "https://miro.medium.com/max/11730/0*qnvcP9ztmZrruGSF", "width": "5865", "height": "3672", "credit": "Mitchell Luo on Unsplash", "caption": ""}, "12": {"item_id": "2989295701", "image_id": "12", "src": "https://miro.medium.com/max/924/1*sOqN2gebImOhGIfpoNKsHQ.png", "width": "462", "height": "690", "credit": "source", "caption": "The Transformer ‚Äî model architecture by Vaswani et al. 2017"}, "13": {"item_id": "2989295701", "image_id": "13", "src": "https://miro.medium.com/max/960/1*h3gPsTR1A3Oa8XTQGMjG5g.gif", "width": "480", "height": "270", "credit": "source", "caption": "‚ÄúP‚Äù GIF by Sesame Street, 23 March 2016"}, "14": {"item_id": "2989295701", "image_id": "14", "src": "https://miro.medium.com/max/960/1*sdoJ3O2cZiPTrrm9WezNmQ.gif", "width": "480", "height": "320", "credit": "source", "caption": "Happy So Excited GIF By GIPHY Studios Originals, 18 November 2016"}, "15": {"item_id": "2989295701", "image_id": "15", "src": "https://miro.medium.com/max/960/1*-kEiThMHgEtKFk3w9ioJ7g.gif", "width": "480", "height": "270", "credit": "source", "caption": "Amazing Season 6 GIF By Bachelor In Paradise, 7 August 2019"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 533}, "1766030229": {"item_id": "1766030229", "resolved_id": "1766030229", "given_url": "http://blog.echen.me/2017/05/30/exploring-lstms/", "given_title": "Exploring LSTMs", "favorite": "0", "status": "1", "time_added": "1497100475", "time_updated": "1638708525", "time_read": "1514398168", "time_favorited": "0", "sort_id": 280, "resolved_title": "Exploring LSTMs", "resolved_url": "http://blog.echen.me/2017/05/30/exploring-lstms/", "excerpt": "LSTMs are behind a lot of the amazing achievements deep learning has made in the past few years, and they're a fairly simple extension to neural networks under the right view. So I'll try to present them as intuitively as possible ‚Äì in such a way that you could have discovered them yourself.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4485", "lang": "en", "time_to_read": 20, "tags": {"deep-learning": {"item_id": "1766030229", "tag": "deep-learning"}, "lstms": {"item_id": "1766030229", "tag": "lstms"}}, "authors": {"69496385": {"item_id": "1766030229", "author_id": "69496385", "name": "original paper", "url": "http://www.bioinf.jku.at/publications/older/2604.pdf"}}, "image": {"item_id": "1766030229", "src": "http://i.imgur.com/lnBi8OZ.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1766030229", "image_id": "1", "src": "http://i.imgur.com/lnBi8OZ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1766030229", "image_id": "2", "src": "http://i.imgur.com/tFMQMOn.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "1766030229", "image_id": "3", "src": "http://i.imgur.com/ifQrKRR.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "1766030229", "image_id": "4", "src": "http://i.imgur.com/vsqgLYn.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "1766030229", "image_id": "5", "src": "http://i.imgur.com/cOGzJxk.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "1766030229", "image_id": "6", "src": "http://i.imgur.com/PnWiSCf.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "1766030229", "image_id": "7", "src": "http://i.imgur.com/EGZIUuc.pngg", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "1766030229", "image_id": "8", "src": "http://i.imgur.com/szJnfAY.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "1766030229", "image_id": "9", "src": "http://i.imgur.com/EBbM9Kx.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "1766030229", "image_id": "10", "src": "http://i.imgur.com/JEIhBeh.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "1766030229", "image_id": "11", "src": "http://i.imgur.com/5DB3wnJ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "1766030229", "image_id": "12", "src": "http://i.imgur.com/yGfaCh3.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "1766030229", "image_id": "13", "src": "http://i.imgur.com/scQXaPL.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "1766030229", "image_id": "14", "src": "http://i.imgur.com/Nu504g0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "1766030229", "image_id": "15", "src": "http://i.imgur.com/iBkuAiV.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "1766030229", "image_id": "16", "src": "http://i.imgur.com/VUwMnHJ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "1766030229", "image_id": "17", "src": "http://i.imgur.com/fFs0MNm.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "1766030229", "image_id": "18", "src": "http://i.imgur.com/wmjemE1.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "1766030229", "image_id": "19", "src": "http://i.imgur.com/02ySRxl.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "1766030229", "image_id": "20", "src": "http://i.imgur.com/UfGWJ9w.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "1766030229", "image_id": "21", "src": "http://i.imgur.com/pAKw9Y2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "1766030229", "image_id": "22", "src": "http://i.imgur.com/QdQXIVu.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "23": {"item_id": "1766030229", "image_id": "23", "src": "http://i.imgur.com/ud8NjEA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "1766030229", "image_id": "24", "src": "http://i.imgur.com/PLpSocg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "1766030229", "image_id": "25", "src": "http://i.imgur.com/dO0Ai6H.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "26": {"item_id": "1766030229", "image_id": "26", "src": "http://i.imgur.com/vAMXZdN.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "27": {"item_id": "1766030229", "image_id": "27", "src": "http://i.imgur.com/eBJQLOf.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "28": {"item_id": "1766030229", "image_id": "28", "src": "http://i.imgur.com/SC4XMHr.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "29": {"item_id": "1766030229", "image_id": "29", "src": "http://i.imgur.com/fRdatTW.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "30": {"item_id": "1766030229", "image_id": "30", "src": "http://i.imgur.com/wQA8H0Q.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "31": {"item_id": "1766030229", "image_id": "31", "src": "http://i.imgur.com/1QdT0MS.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "32": {"item_id": "1766030229", "image_id": "32", "src": "http://i.imgur.com/YSVVWGp.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "33": {"item_id": "1766030229", "image_id": "33", "src": "http://i.imgur.com/rhw4lTb.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "34": {"item_id": "1766030229", "image_id": "34", "src": "http://i.imgur.com/WYVlc6w.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "35": {"item_id": "1766030229", "image_id": "35", "src": "http://i.imgur.com/DqqJZAD.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1736}, "3366151857": {"item_id": "3366151857", "resolved_id": "3366104113", "given_url": "http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:1054932", "given_title": "Face Detection Explained: State-of-the-Art Methods and Best Tools", "favorite": "0", "status": "1", "time_added": "1624661812", "time_updated": "1638708525", "time_read": "1624744701", "time_favorited": "0", "sort_id": 281, "resolved_title": "Face Detection Explained: State-of-the-Art Methods and Best Tools", "resolved_url": "https://www.datasciencecentral.com/profiles/blogs/face-detection-explained-state-of-the-art-methods-and-best-tools", "excerpt": "So many of us have used different Facebook applications to see us aging, turned into rock stars, or applied festive make-up. Such waves of facial transformations are usually accompanied by warnings not to share images of your faces ‚Äì otherwise, they will be processed and misused.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1710", "lang": "en", "time_to_read": 8, "top_image_url": "https://storage.ning.com/topology/rest/1.0/file/get/9136999481?profile=RESIZE_710x", "tags": {"deep-learning": {"item_id": "3366151857", "tag": "deep-learning"}, "face-recognition": {"item_id": "3366151857", "tag": "face-recognition"}, "machine-learning": {"item_id": "3366151857", "tag": "machine-learning"}, "machine-vision": {"item_id": "3366151857", "tag": "machine-vision"}}, "authors": {"149633473": {"item_id": "3366151857", "author_id": "149633473", "name": "Oleksandr Tyron", "url": "https://www.datasciencecentral.com/profile/OleksandrTyron"}}, "image": {"item_id": "3366151857", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9136999481?profile=RESIZE_710x", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3366151857", "image_id": "1", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9136999481?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3366151857", "image_id": "2", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9137038095?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3366151857", "image_id": "3", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9137045853?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3366151857", "image_id": "4", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9137055692?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3366151857", "image_id": "5", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9137061890?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3366151857", "image_id": "6", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9137073095?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3366151857", "image_id": "7", "src": "https://storage.ning.com/topology/rest/1.0/file/get/9137084477?profile=RESIZE_710x", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Data Science Central", "logo": "https://logo.clearbit.com/datasciencecentral.com?size=800", "greyscale_logo": "https://logo.clearbit.com/datasciencecentral.com?size=800&greyscale=true"}, "listen_duration_estimate": 662}, "2040266454": {"item_id": "2040266454", "resolved_id": "2040266454", "given_url": "https://research.fb.com/facebook-open-sources-detectron/", "given_title": "Facebook open sources Detectron ‚Äì Facebook Research", "favorite": "0", "status": "1", "time_added": "1516730041", "time_updated": "1638708525", "time_read": "1517920881", "time_favorited": "0", "sort_id": 282, "resolved_title": "Facebook open sources Detectron", "resolved_url": "https://research.fb.com/facebook-open-sources-detectron/", "excerpt": "Today, Facebook AI Research (FAIR) open sourced Detectron ‚Äî our state-of-the-art platform for object detection research. The Detectron project was started in July 2016 with the goal of creating a fast and flexible object detection system built on Caffe2, which was then in early alpha development.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "254", "lang": "en", "top_image_url": "https://research.fb.com/wp-content/uploads/2018/01/mask-detectron-post.jpg", "tags": {"deep-learning": {"item_id": "2040266454", "tag": "deep-learning"}}, "authors": {"82797883": {"item_id": "2040266454", "author_id": "82797883", "name": "Ross Girshick", "url": "https://research.fb.com/people/girshick-ross/"}}, "listen_duration_estimate": 98}, "1631388838": {"item_id": "1631388838", "resolved_id": "1631388838", "given_url": "https://github.com/facebookresearch/faiss", "given_title": "facebookresearch/faiss: A library for efficient similarity search and clust", "favorite": "1", "status": "1", "time_added": "1588510892", "time_updated": "1638708525", "time_read": "1589542054", "time_favorited": "1578753227", "sort_id": 283, "resolved_title": "Faiss", "resolved_url": "https://github.com/facebookresearch/faiss", "excerpt": "Faiss is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "636", "lang": "en", "time_to_read": 3, "top_image_url": "https://opengraph.githubassets.com/7296a6378aab4c9739b26702f060a63e69b6e3e45ccb1d30b4392ac8bf858b0f/facebookresearch/faiss", "tags": {"deep-learning": {"item_id": "1631388838", "tag": "deep-learning"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 246}, "3097075517": {"item_id": "3097075517", "resolved_id": "3097069024", "given_url": "https://towardsdatascience.com/farewell-rnns-welcome-tcns-dd76674707c8?source=rss----7f60cf5620c9---4", "given_title": "Farewell RNNs, Welcome TCNs", "favorite": "0", "status": "1", "time_added": "1598882468", "time_updated": "1638708525", "time_read": "1608290402", "time_favorited": "0", "sort_id": 284, "resolved_title": "Farewell RNNs, Welcome TCNs", "resolved_url": "https://towardsdatascience.com/farewell-rnns-welcome-tcns-dd76674707c8", "excerpt": "Farewell RNNs, Welcome TCNsHow Temporal Convolutional Networks are moving in favor of Sequence Modeling ‚Äî Stock Trend Prediction.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3697", "lang": "en", "time_to_read": 17, "top_image_url": "https://miro.medium.com/max/1200/1*j5ZGkHb3uN75QmlYlLikrg.jpeg", "tags": {"deep-learning": {"item_id": "3097075517", "tag": "deep-learning"}}, "authors": {"131344004": {"item_id": "3097075517", "author_id": "131344004", "name": "Bryan Tan", "url": "https://medium.com/@BryanJr"}}, "image": {"item_id": "3097075517", "src": "https://miro.medium.com/fit/c/56/56/2*_SeYyJ06w-fgTe5zLiYJoA.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3097075517", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*_SeYyJ06w-fgTe5zLiYJoA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3097075517", "image_id": "2", "src": "https://miro.medium.com/max/10162/1*j5ZGkHb3uN75QmlYlLikrg.jpeg", "width": "5081", "height": "3387", "credit": "Aditya Vyas on Unsplash", "caption": ""}, "3": {"item_id": "3097075517", "image_id": "3", "src": "https://miro.medium.com/max/2036/1*mqbTuP4AcCoRydB1Qnz1Vw.png", "width": "1018", "height": "228", "credit": "", "caption": "Jiayu Qiu1, Bin Wang, Changjun Zhou"}, "4": {"item_id": "3097075517", "image_id": "4", "src": "https://miro.medium.com/max/2740/1*hdYQOK9cydudM_ULGt3XgQ.png", "width": "1370", "height": "534", "credit": "source: Google Finance", "caption": "AMZN Year-to-Date prices"}, "5": {"item_id": "3097075517", "image_id": "5", "src": "https://miro.medium.com/max/3016/1*Q_ZodeTq4VsluPSA7QK7eg.png", "width": "1508", "height": "1024", "credit": "Thomas Hollis, Antoine Viscardi, Seung Eun Yi, 2018", "caption": "Shuffling techniques visualized"}, "6": {"item_id": "3097075517", "image_id": "6", "src": "https://miro.medium.com/max/2932/1*PPuFVgTOtO3DQbe8n8URaA.png", "width": "1466", "height": "344", "credit": "", "caption": "Performance comparison of shuffling methods"}, "7": {"item_id": "3097075517", "image_id": "7", "src": "https://miro.medium.com/max/2164/1*gdzEDjS5L4y0JBD_34QjEw.png", "width": "1082", "height": "212", "credit": "", "caption": ""}, "8": {"item_id": "3097075517", "image_id": "8", "src": "https://miro.medium.com/max/1644/1*4ynb-Xmv0ELQsBhNFozqgg.png", "width": "822", "height": "496", "credit": "", "caption": "A dilated causal convolution with dilation factors d = 1, 2, 4 and filter size k = 3. The receptive field is able to cover all values from the input sequence."}, "9": {"item_id": "3097075517", "image_id": "9", "src": "https://miro.medium.com/max/2144/1*o7-w3dO8t-53kWoBzooOqg.png", "width": "1072", "height": "882", "credit": "", "caption": "Illustration of the KDTCN framework"}, "10": {"item_id": "3097075517", "image_id": "10", "src": "https://miro.medium.com/max/1336/1*lmzaebuHPn2pfrnpR6cmdg.png", "width": "668", "height": "86", "credit": "", "caption": ""}, "11": {"item_id": "3097075517", "image_id": "11", "src": "https://miro.medium.com/max/1980/1*68Fk0U-CM9Thk5t8gBnpqA.png", "width": "990", "height": "518", "credit": "a", "caption": "Baseline models with different inputs. In the first column, prefix WB means word embeddings, EB means event embeddings, PV means the price vector, and KD means knowledge-driven. Note that event embedding"}, "12": {"item_id": "3097075517", "image_id": "12", "src": "https://miro.medium.com/max/1552/1*uBq7Y3BxPEQ-_9OprrFsOw.png", "width": "776", "height": "238", "credit": "", "caption": "Stock trend prediction results over the DJIA index dataset with different basic prediction models."}, "13": {"item_id": "3097075517", "image_id": "13", "src": "https://miro.medium.com/max/1636/1*TpThjHxDUIUxZ4iX4joXJQ.png", "width": "818", "height": "344", "credit": "", "caption": "Stock trend prediction results over the overall DJIA index dataset with different inputs on TCN-based models."}, "14": {"item_id": "3097075517", "image_id": "14", "src": "https://miro.medium.com/max/1636/1*av3j_IHrU1ACgDBq2NLstA.png", "width": "818", "height": "454", "credit": "", "caption": "Stock trend prediction results over the local DJIA index dataset of abrupt changes, with different model inputs."}, "15": {"item_id": "3097075517", "image_id": "15", "src": "https://miro.medium.com/max/1004/1*ACxr2y08nbScX7r9bSkBRA.png", "width": "502", "height": "138", "credit": "", "caption": ""}, "16": {"item_id": "3097075517", "image_id": "16", "src": "https://miro.medium.com/max/1336/1*7rfGXE5z9Oi1J6oEzr_yzA.png", "width": "668", "height": "86", "credit": "", "caption": ""}, "17": {"item_id": "3097075517", "image_id": "17", "src": "https://miro.medium.com/max/2208/1*VuYkkxdpwaELVdVgcQNICQ.png", "width": "1104", "height": "908", "credit": "", "caption": "Examples of event effect on stock trend prediction"}, "18": {"item_id": "3097075517", "image_id": "18", "src": "https://miro.medium.com/max/1576/1*aHcE7Kvn93y3ZFEmV53rtw.png", "width": "788", "height": "958", "credit": "", "caption": "Illustration of triples in KG linked to events"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1431}, "1892881388": {"item_id": "1892881388", "resolved_id": "1892881388", "given_url": "https://github.com/fastai/fastai/blob/master/README.md", "given_title": "fastai/README.md at master ¬∑ fastai/fastai", "favorite": "0", "status": "1", "time_added": "1582752786", "time_updated": "1706833159", "time_read": "1583785007", "time_favorited": "0", "sort_id": 285, "resolved_title": "Welcome to fastai", "resolved_url": "https://github.com/fastai/fastai/blob/master/README.md", "excerpt": "You can use fastai without any installation by using Google Colab. In fact, every page of this documentation is also available as an interactive notebook - click \"Open in colab\" at the top of any page to open it (be sure to change the Colab runtime to \"GPU\" to have it run fast!) See the fast.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "995", "lang": "en", "time_to_read": 5, "top_image_url": "https://repository-images.githubusercontent.com/102973646/f8fe2d00-ad10-11e9-87ea-0136ea4d6245", "tags": {"deep-learning": {"item_id": "1892881388", "tag": "deep-learning"}, "programming": {"item_id": "1892881388", "tag": "programming"}}, "image": {"item_id": "1892881388", "src": "https://github.com/fastai/fastai/workflows/CI/badge.svg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1892881388", "image_id": "1", "src": "https://github.com/fastai/fastai/workflows/CI/badge.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1892881388", "image_id": "2", "src": "https://camo.githubusercontent.com/cd1b7ab05e90b12a661b2971a6e6db4665e66f7cfc088b62b5bff9573da85882/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6661737461693f636f6c6f723d626c7565266c6162656c3d7079706925323076657273696f6e", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "1892881388", "image_id": "3", "src": "https://camo.githubusercontent.com/56c8bd8b4aed42cd8a89b7390ed4bff024e19d0afc82092323d6297980fcd8ac/68747470733a2f2f696d672e736869656c64732e696f2f636f6e64612f766e2f6661737461692f6661737461693f636f6c6f723d736561677265656e266c6162656c3d636f6e646125323076657273696f6e", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "1892881388", "image_id": "4", "src": "https://github.com/fastai/docker-containers/workflows/Build%20fastai%20images/badge.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "1892881388", "image_id": "5", "src": "https://github.com/fastai/fastai/workflows/docs/badge.svg", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "1892881388", "image_id": "6", "src": "https://github.com/fastai/fastai/blob/master/nbs/images/layered.png", "width": "345", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 385}, "3170259804": {"item_id": "3170259804", "resolved_id": "3170259831", "given_url": "https://towardsdatascience.com/practical-guide-to-entity-resolution-part-2-ab6e42572405?source=rss----7f60cf5620c9---4", "given_title": "Favorites", "favorite": "0", "status": "1", "time_added": "1605143156", "time_updated": "1638708525", "time_read": "1608290452", "time_favorited": "0", "sort_id": 286, "resolved_title": "Practical Guide to Entity Resolution", "resolved_url": "https://towardsdatascience.com/practical-guide-to-entity-resolution-part-2-ab6e42572405", "excerpt": "This is part 2 of a mini-series on entity resolution. Check out part 1 if you missed it Part 2 of this series will focus on the source normalization step of entity resolution, and will use the Amazon-GoogleProducts dataset obtained here as an example to illustrate ideas and implementation.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "464", "lang": "en", "top_image_url": "https://miro.medium.com/max/1200/0*xhdkyR60zzjh2AGn", "tags": {"deep-learning": {"item_id": "3170259804", "tag": "deep-learning"}, "entity-resolution": {"item_id": "3170259804", "tag": "entity-resolution"}, "vision": {"item_id": "3170259804", "tag": "vision"}}, "authors": {"142254521": {"item_id": "3170259804", "author_id": "142254521", "name": "Yifei Huang", "url": "https://yifei-huang.medium.com"}}, "image": {"item_id": "3170259804", "src": "https://miro.medium.com/fit/c/56/56/1*c01BdvUOn9xPafDWjDKy2A.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3170259804", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*c01BdvUOn9xPafDWjDKy2A.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3170259804", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*xhdkyR60zzjh2AGn", "width": "700", "height": "467", "credit": "", "caption": "Normalizing data is like forging metal ‚Äî precision and care are required. Photo by Joni Gutierrez ‚Äî Dr Joni Multimedia on Unsplash"}, "3": {"item_id": "3170259804", "image_id": "3", "src": "https://miro.medium.com/max/1400/0*3G5_Ennii315yGyC.png", "width": "700", "height": "148", "credit": "", "caption": ""}, "4": {"item_id": "3170259804", "image_id": "4", "src": "https://miro.medium.com/max/1400/0*NY6WPjiR5S3228bD.png", "width": "700", "height": "231", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 180}, "2848510220": {"item_id": "2848510220", "resolved_id": "2848510220", "given_url": "http://ieeexplore.ieee.org/document/8621059", "given_title": "Feature Boosting Network For 3D Pose Estimation", "favorite": "0", "status": "1", "time_added": "1578658294", "time_updated": "1638708525", "time_read": "1582142817", "time_favorited": "0", "sort_id": 287, "resolved_title": "Feature Boosting Network For 3D Pose Estimation", "resolved_url": "https://ieeexplore.ieee.org/document/8621059", "excerpt": "In this paper, a feature boosting network is proposed for estimating 3D hand pose and 3D body pose from a single RGB image. In this method, the features learned by the convolutional layers are boosted with a new long short-term dependence-aware (LSTD) module, which enables the intermediate convolutional feature maps to perceive the graphical long short-term dependency among different hand (or body) parts using the designed Graphical ConvLSTM. Learning a set of features that are reliable and discriminatively representative of the pose of a hand (or body) part is difficult due to the ambiguities, texture and illumination variation, and self-occlusion in the real application of 3D pose estimation. To improve the reliability of the features for representing each body part and enhance the LSTD module, we further introduce a context consistency gate (CCG) in this paper, with which the convolutional feature maps are modulated according to their consistency with the context representations. We evaluate the proposed method on challenging benchmark datasets for 3D hand pose estimation and 3D full body pose estimation. Experimental results show the effectiveness of our method that achieves state-of-the-art performance on both of the tasks.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "top_image_url": "https://ieeexplore.ieee.org/assets/img/ieee_logo_smedia_200X200.png", "tags": {"boosting": {"item_id": "2848510220", "tag": "boosting"}, "deep-learning": {"item_id": "2848510220", "tag": "deep-learning"}, "pose-estimation": {"item_id": "2848510220", "tag": "pose-estimation"}}, "authors": {"1133402": {"item_id": "2848510220", "author_id": "1133402", "name": "Jun Liu", "url": ""}, "183370692": {"item_id": "2848510220", "author_id": "183370692", "name": "Henghui Ding", "url": ""}}, "listen_duration_estimate": 0}, "2761500195": {"item_id": "2761500195", "resolved_id": "2761490070", "given_url": "http://www.datasciencecentral.com/xn/detail/6448529:BlogPost:899154", "given_title": "Federated Machine Learning - Collaborative Machine Learning without Central", "favorite": "0", "status": "1", "time_added": "1571339181", "time_updated": "1706624319", "time_read": "1571401043", "time_favorited": "0", "sort_id": 288, "resolved_title": "Federated Machine Learning - Collaborative Machine Learning without Centralised Training Data", "resolved_url": "https://www.datasciencecentral.com/profiles/blogs/federated-machine-learning-collaborative-machine-learning-without", "excerpt": "Like a failed communist state traditional machine learning centralises training of a model on a single machine. Centralising data in a single central location is not always possible for a variety of reasons such as slow network connections, and legal constraints.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1039", "lang": "en", "time_to_read": 5, "top_image_url": "https://storage.ning.com/topology/rest/1.0/file/get/3664903273?profile=RESIZE_710x", "tags": {"deep-learning": {"item_id": "2761500195", "tag": "deep-learning"}, "federated-learning": {"item_id": "2761500195", "tag": "federated-learning"}}, "authors": {"121486345": {"item_id": "2761500195", "author_id": "121486345", "name": "Brett Drury", "url": "https://www.datasciencecentral.com/profile/BrettDrury973"}}, "image": {"item_id": "2761500195", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3664903273?profile=RESIZE_710x", "width": "600", "height": "0"}, "images": {"1": {"item_id": "2761500195", "image_id": "1", "src": "https://storage.ning.com/topology/rest/1.0/file/get/3664903273?profile=RESIZE_710x", "width": "600", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Data Science Central", "logo": "https://logo.clearbit.com/datasciencecentral.com?size=800", "greyscale_logo": "https://logo.clearbit.com/datasciencecentral.com?size=800&greyscale=true"}, "listen_duration_estimate": 402}, "2848509740": {"item_id": "2848509740", "resolved_id": "2848509740", "given_url": "http://ieeexplore.ieee.org/document/8417976", "given_title": "Focal Loss for Dense Object Detection", "favorite": "0", "status": "1", "time_added": "1578658271", "time_updated": "1638708525", "time_read": "1582142817", "time_favorited": "0", "sort_id": 289, "resolved_title": "Focal Loss for Dense Object Detection", "resolved_url": "http://ieeexplore.ieee.org/document/8417976", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"deep-learning": {"item_id": "2848509740", "tag": "deep-learning"}, "object-detection": {"item_id": "2848509740", "tag": "object-detection"}}, "listen_duration_estimate": 0}, "3491988304": {"item_id": "3491988304", "resolved_id": "3491985765", "given_url": "https://towardsdatascience.com/four-deep-learning-papers-to-read-in-december-2021-e28f31e6aab4?source=rss----7f60cf5620c9---4", "given_title": "Four Deep Learning Papers to Read in December 2021", "favorite": "0", "status": "1", "time_added": "1638135360", "time_updated": "1638708525", "time_read": "1638206561", "time_favorited": "0", "sort_id": 290, "resolved_title": "Four Deep Learning Papers to Read in December 2021", "resolved_url": "https://towardsdatascience.com/four-deep-learning-papers-to-read-in-december-2021-e28f31e6aab4", "excerpt": "Welcome to the December edition of the ‚ÄöMachine-Learning-Collage‚Äò series, where I provide an overview of the different Deep Learning research streams. So what is a ML collage? Simply put, I draft one-slide visual summaries of one of my favourite recent papers. Every single week.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1277", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/1*Z5toROiPiwNvvpwOXywFoA.png", "tags": {"deep-learning": {"item_id": "3491988304", "tag": "deep-learning"}, "paperswithcode": {"item_id": "3491988304", "tag": "paperswithcode"}}, "authors": {"118495976": {"item_id": "3491988304", "author_id": "118495976", "name": "Robert Lange", "url": "https://medium.com/@RobertTLange"}}, "image": {"item_id": "3491988304", "src": "https://miro.medium.com/fit/c/56/56/1*JAheLM4qvY3oo7iY9s4Qgw.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3491988304", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*JAheLM4qvY3oo7iY9s4Qgw.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3491988304", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*Z5toROiPiwNvvpwOXywFoA.png", "width": "700", "height": "394", "credit": "", "caption": ""}, "3": {"item_id": "3491988304", "image_id": "3", "src": "https://miro.medium.com/max/2000/1*Yh0sreoXNuJTlrq2IoxRew.png", "width": "1000", "height": "564", "credit": "33/52", "caption": "ML-Collage"}, "4": {"item_id": "3491988304", "image_id": "4", "src": "https://miro.medium.com/max/2000/1*td4B0Wmt2in8Fe_iWkVZkQ.png", "width": "1000", "height": "562", "credit": "34/52", "caption": "ML-Collage"}, "5": {"item_id": "3491988304", "image_id": "5", "src": "https://miro.medium.com/max/2000/1*c5CIsrMvfGStK_TB1hHsCQ.png", "width": "1000", "height": "558", "credit": "35/52", "caption": "ML-Collage"}, "6": {"item_id": "3491988304", "image_id": "6", "src": "https://miro.medium.com/max/2000/1*q15BMGDKSfiiDrBr5CRMuA.png", "width": "1000", "height": "560", "credit": "36/52", "caption": "ML-Collage"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 494}, "3043767056": {"item_id": "3043767056", "resolved_id": "3043767056", "given_url": "https://paperswithcode.com/methods/area/general", "given_title": "General Methods | Papers With Code", "favorite": "0", "status": "1", "time_added": "1611751191", "time_updated": "1706833201", "time_read": "1611751209", "time_favorited": "0", "sort_id": 291, "resolved_title": "Papers with Code : General Methods", "resolved_url": "https://paperswithcode.com/methods/area/general", "excerpt": "Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "16", "lang": "en", "top_image_url": "https://paperswithcode.com/static/methods.jpeg", "tags": {"deep-learning": {"item_id": "3043767056", "tag": "deep-learning"}, "machine-learning": {"item_id": "3043767056", "tag": "machine-learning"}}, "listen_duration_estimate": 6}, "2633615616": {"item_id": "2633615616", "resolved_id": "2633615616", "given_url": "https://blog.floydhub.com/gans-story-so-far/", "given_title": "Generative Adversarial Networks - The Story So Far", "favorite": "0", "status": "1", "time_added": "1561239622", "time_updated": "1691366676", "time_read": "1567018788", "time_favorited": "0", "sort_id": 292, "resolved_title": "Generative Adversarial Networks - The Story So Far", "resolved_url": "https://blog.floydhub.com/gans-story-so-far/", "excerpt": "When Ian Goodfellow dreamt up the idea of Generative Adversarial Networks (GANs) over a mug of beer back in 2014, he probably didn‚Äôt expect to see the field advance so fast: In case you don‚Äôt see where I‚Äôm going here, the images you just saw were utterly, undeniably, 100% ‚Ä¶ fake.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "4227", "lang": "en", "time_to_read": 19, "amp_url": "https://blog.floydhub.com/gans-story-so-far/amp/", "top_image_url": "https://blog.floydhub.com/content/images/2019/06/benjamin-behre-429210-unsplash.jpg", "tags": {"adversarial": {"item_id": "2633615616", "tag": "adversarial"}, "deep-learning": {"item_id": "2633615616", "tag": "deep-learning"}, "gans": {"item_id": "2633615616", "tag": "gans"}}, "authors": {"110546522": {"item_id": "2633615616", "author_id": "110546522", "name": "Read More", "url": "https://blog.floydhub.com/author/ajay/"}}, "image": {"item_id": "2633615616", "src": "https://regmedia.co.uk/2018/10/01/biggan.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2633615616", "image_id": "1", "src": "https://regmedia.co.uk/2018/10/01/biggan.jpg", "width": "0", "height": "0", "credit": "", "caption": "Source"}, "2": {"item_id": "2633615616", "image_id": "2", "src": "https://paper-attachments.dropbox.com/s_D85DDA7D01FD04AEE96825C4B90F1126BC7D080CA4F2947D4A5DEC07FAD6122C_1559841150851_Map.png", "width": "0", "height": "0", "credit": "", "caption": "GAN Roadmap"}, "3": {"item_id": "2633615616", "image_id": "3", "src": "https://blog.floydhub.com/content/images/2019/06/image.png", "width": "0", "height": "0", "credit": "", "caption": "Image from paper"}, "4": {"item_id": "2633615616", "image_id": "4", "src": "https://skymind.ai/images/wiki/GANs.png", "width": "0", "height": "0", "credit": "", "caption": "Source"}, "5": {"item_id": "2633615616", "image_id": "5", "src": "https://blog.floydhub.com/content/images/2019/06/image-1.png", "width": "0", "height": "0", "credit": "", "caption": "Image from paper"}, "6": {"item_id": "2633615616", "image_id": "6", "src": "https://paper-attachments.dropbox.com/s_D85DDA7D01FD04AEE96825C4B90F1126BC7D080CA4F2947D4A5DEC07FAD6122C_1559921735372_Map2.png", "width": "0", "height": "0", "credit": "", "caption": "You're currently at the second red 'X'"}, "7": {"item_id": "2633615616", "image_id": "7", "src": "https://paper-attachments.dropbox.com/s_D85DDA7D01FD04AEE96825C4B90F1126BC7D080CA4F2947D4A5DEC07FAD6122C_1559840652472_Screenshot+2019-06-06+at+10.33.58+PM.png", "width": "0", "height": "0", "credit": "", "caption": "Image from paper"}, "8": {"item_id": "2633615616", "image_id": "8", "src": "https://images.unsplash.com/photo-1509205477838-a534e43a849f?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjI2NzI5fQ", "width": "0", "height": "0", "credit": "Anusha Barwa on Unsplash", "caption": ""}, "9": {"item_id": "2633615616", "image_id": "9", "src": "https://paper-attachments.dropbox.com/s_D85DDA7D01FD04AEE96825C4B90F1126BC7D080CA4F2947D4A5DEC07FAD6122C_1559840765144_Screenshot+2019-06-06+at+10.35.29+PM.png", "width": "0", "height": "0", "credit": "", "caption": "Source"}, "10": {"item_id": "2633615616", "image_id": "10", "src": "https://cdn-images-1.medium.com/max/1600/1*5DG4hHjxAyWTfV1J3mRH_A.png", "width": "0", "height": "0", "credit": "", "caption": "Source"}, "11": {"item_id": "2633615616", "image_id": "11", "src": "https://cdn-images-1.medium.com/max/1200/1*oZsw1JaGkKPxWKKvVUWlyg.png", "width": "0", "height": "0", "credit": "", "caption": "Source"}, "12": {"item_id": "2633615616", "image_id": "12", "src": "https://blog.floydhub.com/content/images/2019/06/68747470733a2f2f6a756e79616e7a2e6769746875622e696f2f4379636c6547414e2f696d616765732f70686f746f327061696e74696e672e6a7067.jpeg", "width": "0", "height": "0", "credit": "", "caption": "Source"}, "13": {"item_id": "2633615616", "image_id": "13", "src": "https://www.andrewszot.com/static/img/ml/voice_conversion/cyclegan.png", "width": "0", "height": "0", "credit": "", "caption": "Source"}, "14": {"item_id": "2633615616", "image_id": "14", "src": "https://blog.floydhub.com/content/images/2019/06/cogan_face-2.png", "width": "0", "height": "0", "credit": "", "caption": "Image from paper"}, "15": {"item_id": "2633615616", "image_id": "15", "src": "https://paper-attachments.dropbox.com/s_D85DDA7D01FD04AEE96825C4B90F1126BC7D080CA4F2947D4A5DEC07FAD6122C_1559833820903_CoGAN.png", "width": "0", "height": "0", "credit": "", "caption": "Source"}, "16": {"item_id": "2633615616", "image_id": "16", "src": "https://paper-attachments.dropbox.com/s_0A213C11DCFB5EF2AA80869C04C321E7C5012FF1A44CD8EA80EAEE3AC7E2E450_1552669280669_Screenshot+2019-03-15+at+18.00.57.png", "width": "0", "height": "0", "credit": "", "caption": "Image from paper"}, "17": {"item_id": "2633615616", "image_id": "17", "src": "https://paper-attachments.dropbox.com/s_D85DDA7D01FD04AEE96825C4B90F1126BC7D080CA4F2947D4A5DEC07FAD6122C_1559924418712_Screenshot+2019-06-07+at+9.50.06+PM.png", "width": "0", "height": "0", "credit": "", "caption": "Image from paper"}, "18": {"item_id": "2633615616", "image_id": "18", "src": "https://paper-attachments.dropbox.com/s_D85DDA7D01FD04AEE96825C4B90F1126BC7D080CA4F2947D4A5DEC07FAD6122C_1559924506531_Screenshot+2019-06-07+at+9.51.38+PM.png", "width": "0", "height": "0", "credit": "", "caption": "Image from paper"}, "19": {"item_id": "2633615616", "image_id": "19", "src": "https://paper-attachments.dropbox.com/s_D85DDA7D01FD04AEE96825C4B90F1126BC7D080CA4F2947D4A5DEC07FAD6122C_1559923401643_Screenshot+2019-06-07+at+9.32.54+PM.png", "width": "0", "height": "0", "credit": "", "caption": "Image from paper"}, "20": {"item_id": "2633615616", "image_id": "20", "src": "https://paper-attachments.dropbox.com/s_D85DDA7D01FD04AEE96825C4B90F1126BC7D080CA4F2947D4A5DEC07FAD6122C_1559905320679_Screenshot+2019-06-07+at+4.31.45+PM.png", "width": "0", "height": "0", "credit": "", "caption": "Image from paper"}, "21": {"item_id": "2633615616", "image_id": "21", "src": "https://cdn-images-1.medium.com/max/2600/1*Yw2KxjmIkj8yqS-ykLCQCQ.png", "width": "0", "height": "0", "credit": "", "caption": "Source"}, "22": {"item_id": "2633615616", "image_id": "22", "src": "https://blog.floydhub.com/content/images/2019/06/dogball.jpg", "width": "0", "height": "0", "credit": "", "caption": "Source"}, "23": {"item_id": "2633615616", "image_id": "23", "src": "https://paper-attachments.dropbox.com/s_0A213C11DCFB5EF2AA80869C04C321E7C5012FF1A44CD8EA80EAEE3AC7E2E450_1552669593074_Screenshot+2019-03-15+at+18.06.21.png", "width": "0", "height": "0", "credit": "", "caption": "Image from paper"}, "24": {"item_id": "2633615616", "image_id": "24", "src": "https://blog.floydhub.com/content/images/2019/06/Screenshot-2019-06-06-at-7.39.35-PM-1.png", "width": "0", "height": "0", "credit": "", "caption": "What's next?! Unexplored regions!"}}, "videos": {"1": {"item_id": "2633615616", "video_id": "1", "src": "https://www.youtube.com/embed/UBX2QQHlQ_I?feature=oembed", "width": "480", "height": "270", "type": "1", "vid": "UBX2QQHlQ_I", "length": "0"}, "2": {"item_id": "2633615616", "video_id": "2", "src": "https://www.youtube.com/embed/8UQzJaa0HPU?start=653&feature=oembed", "width": "480", "height": "270", "type": "1", "vid": "8UQzJaa0HPU", "length": "0"}}, "listen_duration_estimate": 1636}, "2121919039": {"item_id": "2121919039", "resolved_id": "1860109439", "given_url": "https://www.datasciencecentral.com/profiles/blogs/generative-adversarial-networks-gans-engine-and-applications?utm_content=buffer01dd7&utm_medium=social&utm_source=facebook.com&utm_campaign=buffer", "given_title": "Generative Adversarial Networks (GANs): Engine and Applications - Data Scie", "favorite": "0", "status": "1", "time_added": "1521561696", "time_updated": "1638708525", "time_read": "1528501240", "time_favorited": "0", "sort_id": 293, "resolved_title": "Generative Adversarial Networks (GANs): Engine and Applications", "resolved_url": "https://www.datasciencecentral.com/profiles/blogs/generative-adversarial-networks-gans-engine-and-applications", "excerpt": "GANs were ¬†introduced by Ian Goodfellow in 2014.They aren‚Äôt the only approach of neural networks in unsupervised learning. There‚Äôs also the Boltzmann machine (Geoffrey Hinton and Terry Sejnowski, 1985) and Autoencoders (Dana H. Ballard, 1987).", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "701", "lang": "en", "time_to_read": 3, "top_image_url": "https://cdn-images-1.medium.com/max/600/0*J0S58JHfF6p2xAgo.", "tags": {"deep-learning": {"item_id": "2121919039", "tag": "deep-learning"}, "gans": {"item_id": "2121919039", "tag": "gans"}}, "authors": {"77672054": {"item_id": "2121919039", "author_id": "77672054", "name": "Luba Belokon", "url": "https://www.datasciencecentral.com/profile/LubaBelokon"}}, "image": {"item_id": "2121919039", "src": "http://19359-presscdn.pagely.netdna-cdn.com/wp-content/uploads/2014/08/genuine-fake-turkey-8.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2121919039", "image_id": "1", "src": "http://19359-presscdn.pagely.netdna-cdn.com/wp-content/uploads/2014/08/genuine-fake-turkey-8.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2121919039", "image_id": "2", "src": "https://cdn-images-1.medium.com/max/800/1*L_pqMKMNJ8J-sa0Fx0qKpw.jpeg", "width": "500", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2121919039", "image_id": "3", "src": "https://cdn-images-1.medium.com/max/800/0*BuHWzAuDCIac3BQT.", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2121919039", "image_id": "4", "src": "https://cdn-images-1.medium.com/max/800/0*HIxMGxIjCaB9I1UF.?width=500", "width": "500", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2121919039", "image_id": "5", "src": "https://cdn-images-1.medium.com/max/1000/0*6DUSyhgUzbmv_QTR.?width=600", "width": "600", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2121919039", "image_id": "6", "src": "https://cdn-images-1.medium.com/max/600/0*2pq9P5-lgX3g04vO.?width=500", "width": "500", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2121919039", "image_id": "7", "src": "https://cdn-images-1.medium.com/max/800/0*1hRx-30eiCL4ZP5k.?width=500", "width": "500", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2121919039", "image_id": "8", "src": "https://cdn-images-1.medium.com/max/800/0*--g8RQpR-Hofpa8G.?width=500", "width": "500", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2121919039", "image_id": "9", "src": "https://cdn-images-1.medium.com/max/1000/0*mBizMzNID9qi6Enw.?width=600", "width": "600", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2121919039", "image_id": "10", "src": "https://cdn-images-1.medium.com/max/800/1*VczAGbJAYHYWkAy2iXXcgA.jpeg", "width": "600", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2121919039", "image_id": "11", "src": "https://cdn-images-1.medium.com/max/1000/0*FVYGxA-YUBC7q1nJ.?width=600", "width": "600", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2121919039", "image_id": "12", "src": "https://cdn-images-1.medium.com/max/800/0*2Ctb33Kyy__qf0Cu.?width=600", "width": "600", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Data Science Central", "logo": "https://logo.clearbit.com/datasciencecentral.com?size=800", "greyscale_logo": "https://logo.clearbit.com/datasciencecentral.com?size=800&greyscale=true"}, "listen_duration_estimate": 271}, "2299169531": {"item_id": "2299169531", "resolved_id": "2299169531", "given_url": "https://qz.com/1366484/give-ai-curiosity-and-it-will-watch-tv-forever", "given_title": "Give AI curiosity, and it will watch TV forever", "favorite": "0", "status": "1", "time_added": "1706793315", "time_updated": "1706801064", "time_read": "1706801064", "time_favorited": "0", "sort_id": 294, "resolved_title": "Give AI curiosity, and it will watch TV forever", "resolved_url": "https://qz.com/1366484/give-ai-curiosity-and-it-will-watch-tv-forever/", "excerpt": "AP PhotoThe noble art of watching TV.From our ObsessionMachines with BrainsHumanity‚Äôs relationship with computers is dramatically changing, but the societal and economic impact remains unclear.By Artificial intelligence reporterPublished This article is more than 2 years old.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "582", "lang": "en", "time_to_read": 3, "amp_url": "https://qz.com/1366484/give-ai-curiosity-and-it-will-watch-tv-forever/amp/", "top_image_url": "https://cms.qz.com/wp-content/uploads/2018/08/AP_4801010424-e1534959130875.jpg?quality=75&strip=all&w=1200&h=630&crop=1", "tags": {"curiosity": {"item_id": "2299169531", "tag": "curiosity"}, "deep-learning": {"item_id": "2299169531", "tag": "deep-learning"}}, "authors": {"61109938": {"item_id": "2299169531", "author_id": "61109938", "name": "Dave Gershgorn", "url": "https://qz.com/author/dgershgornqz/"}}, "image": {"item_id": "2299169531", "src": "https://cms.qz.com/wp-content/uploads/2018/08/AP_4801010424-e1534959130875.jpg?quality=75&strip=all&w=3200&h=1800", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2299169531", "image_id": "1", "src": "https://cms.qz.com/wp-content/uploads/2018/08/AP_4801010424-e1534959130875.jpg?quality=75&strip=all&w=3200&h=1800", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Quartz", "logo": "https://logo.clearbit.com/qz.com?size=800", "greyscale_logo": "https://logo.clearbit.com/qz.com?size=800&greyscale=true"}, "listen_duration_estimate": 225}, "2181236661": {"item_id": "2181236661", "resolved_id": "2181236661", "given_url": "https://www.extremetech.com/extreme/269008-google-announces-8x-faster-tpu-3-0-for-ai-machine-learning", "given_title": "Google Announces 8x Faster TPU 3.0 For AI, Machine Learning - ExtremeTech", "favorite": "0", "status": "1", "time_added": "1525972806", "time_updated": "1638708525", "time_read": "1525980746", "time_favorited": "0", "sort_id": 295, "resolved_title": "Google Announces 8x Faster TPU 3.0 For AI, Machine Learning", "resolved_url": "https://www.extremetech.com/extreme/269008-google-announces-8x-faster-tpu-3-0-for-ai-machine-learning", "excerpt": "For the past few years, Google has been building its own TPU (Tensor Processing Units) to handle various processing tasks related to artificial intelligence and machine learning. Google first announced the existence of TPUs in 2016, but said it had been using them internally for more than a year.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "429", "lang": "en", "top_image_url": "https://www.extremetech.com/wp-content/uploads/2018/02/Cloud-TPU-Feature.jpg", "tags": {"deep-learning": {"item_id": "2181236661", "tag": "deep-learning"}, "semiconductors": {"item_id": "2181236661", "tag": "semiconductors"}}, "authors": {"38621197": {"item_id": "2181236661", "author_id": "38621197", "name": "Joel Hruska", "url": "https://www.extremetech.com/author/jhruska"}}, "image": {"item_id": "2181236661", "src": "https://www.extremetech.com/wp-content/uploads/2018/02/Cloud-TPU-Feature.jpg", "width": "640", "height": "353"}, "images": {"1": {"item_id": "2181236661", "image_id": "1", "src": "https://www.extremetech.com/wp-content/uploads/2018/02/Cloud-TPU-Feature.jpg", "width": "640", "height": "353", "credit": "", "caption": ""}, "2": {"item_id": "2181236661", "image_id": "2", "src": "https://www.extremetech.com/wp-content/uploads/2018/05/TPU3.jpg", "width": "640", "height": "426", "credit": "", "caption": "Image by TechCrunch"}}, "listen_duration_estimate": 166}, "3802198384": {"item_id": "3802198384", "resolved_id": "3802198384", "given_url": "http://ai.googleblog.com/2023/02/google-research-2022-beyond-algorithms.html", "given_title": "Google Research, 2022 & beyond: Algorithms for efficient deep learning", "favorite": "0", "status": "1", "time_added": "1675799463", "time_updated": "1676023834", "time_read": "1675986165", "time_favorited": "0", "sort_id": 296, "resolved_title": "Google Research, 2022 & beyond: Algorithms for efficient deep learning", "resolved_url": "http://ai.googleblog.com/2023/02/google-research-2022-beyond-algorithms.html", "excerpt": "The explosion in deep learning a decade ago was catapulted in part by the convergence of new algorithms and architectures, a marked increase in data, and access to greater compute.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2780", "lang": "en", "time_to_read": 13, "top_image_url": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhWEHbpoo-ZRVc_Qpnqpli6x_4qb0n7Akpaelsvr8g5eoZAB6Y5JGU1ftYVuj5TH025LdIDph5Q12Mi4E9ZDElxe-vn6Oo61Ysh99HGRNbCeAr1Vvw8abDBeYRpRonppJvomYHm3Rab8O4kDE3DpkvnHaXfIMkAft9JVa3Sq3S3Olt2uGMD4lsCHlZ5mA/w1200-h630-p-k-no-nu/lockup_GoogleResearch_FullColor_Hero.jpg", "tags": {"deep-learning": {"item_id": "3802198384", "tag": "deep-learning"}}, "authors": {"149605": {"item_id": "3802198384", "author_id": "149605", "name": "Sanjiv Kumar", "url": ""}}, "image": {"item_id": "3802198384", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhWEHbpoo-ZRVc_Qpnqpli6x_4qb0n7Akpaelsvr8g5eoZAB6Y5JGU1ftYVuj5TH025LdIDph5Q12Mi4E9ZDElxe-vn6Oo61Ysh99HGRNbCeAr1Vvw8abDBeYRpRonppJvomYHm3Rab8O4kDE3DpkvnHaXfIMkAft9JVa3Sq3S3Olt2uGMD4lsCHlZ5mA/s1200/lockup_GoogleResearch_FullColor_Hero.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3802198384", "image_id": "1", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhWEHbpoo-ZRVc_Qpnqpli6x_4qb0n7Akpaelsvr8g5eoZAB6Y5JGU1ftYVuj5TH025LdIDph5Q12Mi4E9ZDElxe-vn6Oo61Ysh99HGRNbCeAr1Vvw8abDBeYRpRonppJvomYHm3Rab8O4kDE3DpkvnHaXfIMkAft9JVa3Sq3S3Olt2uGMD4lsCHlZ5mA/s1200/lockup_GoogleResearch_FullColor_Hero.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1076}, "2852367659": {"item_id": "2852367659", "resolved_id": "2852367659", "given_url": "https://www.theverge.com/2020/1/14/21065095/google-ai-weather-forecast-predictions-rainfall-research", "given_title": "Google says new AI models allow for ‚Äònearly instantaneous‚Äô weather forecast", "favorite": "0", "status": "1", "time_added": "1587666470", "time_updated": "1707064489", "time_read": "1587685518", "time_favorited": "0", "sort_id": 297, "resolved_title": "Google says new AI models allow for ‚Äònearly instantaneous‚Äô weather forecasts", "resolved_url": "https://www.theverge.com/2020/1/14/21065095/google-ai-weather-forecast-predictions-rainfall-research", "excerpt": "Weather forecasting is notoriously difficult, but in recent years experts have suggested that machine learning could better help sort the sunshine from the sleet.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "579", "lang": "en", "time_to_read": 3, "amp_url": "https://www.theverge.com/platform/amp/2020/1/14/21065095/google-ai-weather-forecast-predictions-rainfall-research", "top_image_url": "https://cdn.vox-cdn.com/thumbor/JJPsUbN4Rh6UTP4-IuUxnHXcq04=/0x403:5630x3351/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/19599985/1185354768.jpg.jpg", "tags": {"climate-weather": {"item_id": "2852367659", "tag": "climate-weather"}, "deep-learning": {"item_id": "2852367659", "tag": "deep-learning"}}, "authors": {"97592195": {"item_id": "2852367659", "author_id": "97592195", "name": "James Vincent", "url": "https://www.theverge.com/authors/james-vincent"}}, "image": {"item_id": "2852367659", "src": "https://cdn.vox-cdn.com/uploads/chorus_image/image/66097507/1185354768.jpg.0.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2852367659", "image_id": "1", "src": "https://cdn.vox-cdn.com/uploads/chorus_image/image/66097507/1185354768.jpg.0.jpg", "width": "0", "height": "0", "credit": "APU GOMES/AFP via Getty Images", "caption": "AI could be particularly useful for short-term forecasts."}, "2": {"item_id": "2852367659", "image_id": "2", "src": "https://cdn.vox-cdn.com/uploads/chorus_asset/file/19599987/WeatherPatterns.gif", "width": "0", "height": "0", "credit": "¬†NOAA,¬†NWS,¬†NSSL", "caption": "Google‚Äôs work used radar data to predict rainfall. The top image shows cloud location, while the bottom image shows rainfall."}}, "domain_metadata": {"name": "The Verge", "logo": "https://logo.clearbit.com/theverge.com?size=800", "greyscale_logo": "https://logo.clearbit.com/theverge.com?size=800&greyscale=true"}, "listen_duration_estimate": 224}, "2372493903": {"item_id": "2372493903", "resolved_id": "2372493903", "given_url": "https://github.com/google-research/bert", "given_title": "google-research/bert: TensorFlow code and pre-trained models for BERT", "favorite": "0", "status": "1", "time_added": "1584714536", "time_updated": "1638708525", "time_read": "1585739684", "time_favorited": "0", "sort_id": 298, "resolved_title": "BERT", "resolved_url": "https://github.com/google-research/bert", "excerpt": "This is a release of 24 smaller BERT models (English only, uncased, trained with WordPiece masking) referenced in Well-Read Students Learn Better: On the Importance of Pre-training Compact Models.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "6259", "lang": "en", "time_to_read": 28, "top_image_url": "https://opengraph.githubassets.com/a2aeea07f9f1ad16e1b95e2ee17846238b7786ecdfcbaed273edbe951bc8f84e/google-research/bert", "tags": {"bert": {"item_id": "2372493903", "tag": "bert"}, "deep-learning": {"item_id": "2372493903", "tag": "deep-learning"}, "nlp": {"item_id": "2372493903", "tag": "nlp"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 2423}, "3841843558": {"item_id": "3841843558", "resolved_id": "3841843558", "given_url": "https://semiengineering.com/googles-tpuv4-architecture-3-major-features/", "given_title": "Google‚Äôs TPU v4 Architecture: 3 Major Features", "favorite": "0", "status": "1", "time_added": "1680921087", "time_updated": "1680971540", "time_read": "1680971539", "time_favorited": "0", "sort_id": 299, "resolved_title": "Google‚Äôs TPU v4 Architecture: 3 Major Features", "resolved_url": "https://semiengineering.com/googles-tpuv4-architecture-3-major-features/", "excerpt": "A new technical paper titled ‚ÄúTPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings‚Äù was published by researchers at Google.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "295", "lang": "en", "top_image_url": "https://semiengineering.com/wp-content/uploads/AdobeStock_209583451-scaled.jpeg", "tags": {"deep-learning": {"item_id": "3841843558", "tag": "deep-learning"}, "semiconductors": {"item_id": "3841843558", "tag": "semiconductors"}, "tpu": {"item_id": "3841843558", "tag": "tpu"}}, "authors": {"73112018": {"item_id": "3841843558", "author_id": "73112018", "name": "Linda Christensen", "url": "https://semiengineering.com/author/linda-christensen/"}}, "listen_duration_estimate": 114}, "3113705339": {"item_id": "3113705339", "resolved_id": "3113695592", "given_url": "https://towardsdatascience.com/gpt-3-transformers-and-the-wild-world-of-nlp-9993d8bb1314?source=rss----7f60cf5620c9---4", "given_title": "GPT-3, transformers and the wild world of NLP", "favorite": "0", "status": "1", "time_added": "1600342908", "time_updated": "1671724937", "time_read": "1604364034", "time_favorited": "0", "sort_id": 300, "resolved_title": "GPT-3, transformers and the wild world of NLP", "resolved_url": "https://towardsdatascience.com/gpt-3-transformers-and-the-wild-world-of-nlp-9993d8bb1314", "excerpt": "The tech world is so full of fascinating demons. Every now and then, we get to be awed, not without a hint of horror, by a new development. The natural language processing (NLP) model GPT-3 recently developed by OpenAI is exactly a such creature.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3131", "lang": "en", "time_to_read": 14, "top_image_url": "https://miro.medium.com/max/1200/1*NdJ19yLbvv1NII7nEUJdeQ.jpeg", "tags": {"chatbots": {"item_id": "3113705339", "tag": "chatbots"}, "deep-learning": {"item_id": "3113705339", "tag": "deep-learning"}, "nlp": {"item_id": "3113705339", "tag": "nlp"}}, "authors": {"140045115": {"item_id": "3113705339", "author_id": "140045115", "name": "Lingyi", "url": "https://medium.com/@lingyi_99090"}}, "image": {"item_id": "3113705339", "src": "https://miro.medium.com/fit/c/56/56/1*RqUcf_dNPSsAou2_u4p80w.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3113705339", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*RqUcf_dNPSsAou2_u4p80w.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3113705339", "image_id": "2", "src": "https://miro.medium.com/max/2000/1*NdJ19yLbvv1NII7nEUJdeQ.jpeg", "width": "1000", "height": "328", "credit": "", "caption": "ÂÖ∞‰∫≠ÈõÜÂ∫è Image from: https://zh.wikipedia.org/wiki/%E8%98%AD%E4%BA%AD%E9%9B%86%E5%BA%8F"}, "3": {"item_id": "3113705339", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*COTw6edFBflp1-tFgZAwJA.png", "width": "700", "height": "394", "credit": "", "caption": "If you hate blurry pictures, click here to find original slides."}, "4": {"item_id": "3113705339", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*6IVEekFIZNqgCZeUAFiY0Q.jpeg", "width": "700", "height": "394", "credit": "", "caption": "If you hate blurry pictures, click here to find original slides."}, "5": {"item_id": "3113705339", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*nc4ju2hgOVrVpXwJWwCJvA.jpeg", "width": "700", "height": "394", "credit": "", "caption": "If you hate blurry pictures, click here to find original slides."}, "6": {"item_id": "3113705339", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*v0olcYtRwIaqOFK5Iyc7sQ.jpeg", "width": "700", "height": "394", "credit": "", "caption": "If you hate blurry pictures, click here to find original slides."}, "7": {"item_id": "3113705339", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*2D0wGNjPGzQoDeymyr6mDA.jpeg", "width": "700", "height": "394", "credit": "", "caption": "If you hate blurry pictures, click here to find original slides."}, "8": {"item_id": "3113705339", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*8lTURSxryeTF4rT7-I2lTA.jpeg", "width": "700", "height": "394", "credit": "", "caption": "If you hate blurry pictures, click here to find original slides."}, "9": {"item_id": "3113705339", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*KQhcK_T6w8O4el9YDBMV7g.png", "width": "700", "height": "260", "credit": "", "caption": "This is an image from Google‚Äôs paper on T5"}, "10": {"item_id": "3113705339", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*whyBi5CzQolxOkUNyX-cgQ.png", "width": "700", "height": "216", "credit": "", "caption": "XLNet, RoBERTa, ALBERT and Electra achieve on-par performance with T5‚Äì3B with much smaller architecture. If you hate blurry pictures, click here to find original slides."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1212}, "3267911475": {"item_id": "3267911475", "resolved_id": "3267911475", "given_url": "https://venturebeat.com/2021/02/27/gpt-3-were-at-the-very-beginning-of-a-new-app-ecosystem/", "given_title": "GPT-3: We‚Äôre at the very beginning of a new app ecosystem", "favorite": "0", "status": "1", "time_added": "1614466688", "time_updated": "1671724937", "time_read": "1614468059", "time_favorited": "0", "sort_id": 301, "resolved_title": "GPT-3: We‚Äôre at the very beginning of a new app ecosystem", "resolved_url": "https://venturebeat.com/2021/02/27/gpt-3-were-at-the-very-beginning-of-a-new-app-ecosystem/", "excerpt": "Elevate your enterprise data technology and strategy at Transform 2021. The most impressive thing about OpenAI‚Äôs natural language processing (NLP) model, GPT-3, is its sheer size.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1215", "lang": "en", "time_to_read": 6, "amp_url": "https://venturebeat.com/2021/02/27/gpt-3-were-at-the-very-beginning-of-a-new-app-ecosystem/amp/", "top_image_url": "https://venturebeat.com/wp-content/uploads/2021/02/gpt-3.jpg?w=1200&strip=all", "tags": {"chatbots": {"item_id": "3267911475", "tag": "chatbots"}, "deep-learning": {"item_id": "3267911475", "tag": "deep-learning"}, "nlp": {"item_id": "3267911475", "tag": "nlp"}}, "authors": {"147418404": {"item_id": "3267911475", "author_id": "147418404", "name": "YouTuber Bakz T.", "url": ""}}, "image": {"item_id": "3267911475", "src": "https://venturebeat.com/wp-content/uploads/2021/02/gpt-3.jpg?resize=1200%2C600&strip=all", "width": "1200", "height": "600"}, "images": {"1": {"item_id": "3267911475", "image_id": "1", "src": "https://venturebeat.com/wp-content/uploads/2021/02/gpt-3.jpg?resize=1200%2C600&strip=all", "width": "1200", "height": "600", "credit": "", "caption": ""}}, "domain_metadata": {"name": "VentureBeat", "logo": "https://logo.clearbit.com/venturebeat.com?size=800", "greyscale_logo": "https://logo.clearbit.com/venturebeat.com?size=800&greyscale=true"}, "listen_duration_estimate": 470}, "3429444522": {"item_id": "3429444522", "resolved_id": "3429444522", "given_url": "https://towardsdatascience.com/gpt-4-will-have-100-trillion-parameters-500x-the-size-of-gpt-3-582b98d82253", "given_title": "GPT-4 Will Have 100 Trillion Parameters ‚Äî 500x the Size of GPT-3 | by Alber", "favorite": "0", "status": "1", "time_added": "1631382547", "time_updated": "1671724968", "time_read": "1631383541", "time_favorited": "0", "sort_id": 302, "resolved_title": "GPT-4 Will Have 100 Trillion Parameters‚Ää‚Äî‚Ää500x the Size of GPT-3", "resolved_url": "https://towardsdatascience.com/gpt-4-will-have-100-trillion-parameters-500x-the-size-of-gpt-3-582b98d82253", "excerpt": "IMPORTANT: This article is outdated. Here‚Äôs the newest information. OpenAI was born to tackle the challenge of achieving artificial general intelligence (AGI) ‚Äî an AI capable of doing anything a human can do.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1331", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/0*PSxUk3lW6R325xnE", "tags": {"chatbots": {"item_id": "3429444522", "tag": "chatbots"}, "deep-learning": {"item_id": "3429444522", "tag": "deep-learning"}}, "authors": {"144430834": {"item_id": "3429444522", "author_id": "144430834", "name": "Alberto Romero", "url": "https://albertoromgar.medium.com"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 515}, "3352282942": {"item_id": "3352282942", "resolved_id": "3352282942", "given_url": "https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/", "given_title": "GPT-J-6B: 6B JAX-Based Transformer ‚Äì Aran Komatsuzaki", "favorite": "0", "status": "1", "time_added": "1625445660", "time_updated": "1638708525", "time_read": "1625486738", "time_favorited": "0", "sort_id": 303, "resolved_title": "GPT-J-6B: 6B JAX-Based Transformer", "resolved_url": "https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/", "excerpt": "Summary: We have released GPT-J-6B, 6B JAX-based (Mesh) Transformer LM (Github). GPT-J-6B performs nearly on par with 6.7B GPT-3 (or Curie) on various zero-shot down-streaming tasks. You can try out this Colab notebook or free web demo.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1215", "lang": "en", "time_to_read": 6, "amp_url": "https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/amp/", "top_image_url": "https://arankomatsuzaki.files.wordpress.com/2021/05/jax_logo.png?w=1200", "tags": {"deep-learning": {"item_id": "3352282942", "tag": "deep-learning"}, "transformers": {"item_id": "3352282942", "tag": "transformers"}}, "authors": {"93456081": {"item_id": "3352282942", "author_id": "93456081", "name": "Aran Komatsuzaki", "url": ""}}, "image": {"item_id": "3352282942", "src": "https://arankomatsuzaki.files.wordpress.com/2021/05/jax_logo.png", "width": "490", "height": "283"}, "images": {"1": {"item_id": "3352282942", "image_id": "1", "src": "https://arankomatsuzaki.files.wordpress.com/2021/05/jax_logo.png", "width": "490", "height": "283", "credit": "", "caption": ""}}, "listen_duration_estimate": 470}, "3787848372": {"item_id": "3787848372", "resolved_id": "3787848372", "given_url": "https://timdettmers.com/2023/01/16/which-gpu-for-deep-learning/", "given_title": "Hacker News", "favorite": "0", "status": "1", "time_added": "1674081856", "time_updated": "1674251456", "time_read": "1674251456", "time_favorited": "0", "sort_id": 304, "resolved_title": "Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning", "resolved_url": "https://timdettmers.com/2023/01/16/which-gpu-for-deep-learning/", "excerpt": "Deep learning is a field with intense computational requirements, and your choice of GPU will fundamentally determine your deep learning experience.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "9089", "lang": "en", "time_to_read": 41, "top_image_url": "https://timdettmers.com/wp-content/uploads/2023/01/GPUs_Ada_performance_per_dollar4.png", "tags": {"deep-learning": {"item_id": "3787848372", "tag": "deep-learning"}, "gpus": {"item_id": "3787848372", "tag": "gpus"}, "semiconductors": {"item_id": "3787848372", "tag": "semiconductors"}}, "authors": {"110561791": {"item_id": "3787848372", "author_id": "110561791", "name": "Tim Dettmers", "url": "https://timdettmers.com/author/tim-dettmers/"}}, "image": {"item_id": "3787848372", "src": "https://i0.wp.com/timdettmers.com/wp-content/uploads/2020/09/sparse_matmul.png?resize=1024%2C619&ssl=1", "width": "1024", "height": "619"}, "images": {"1": {"item_id": "3787848372", "image_id": "1", "src": "https://i0.wp.com/timdettmers.com/wp-content/uploads/2020/09/sparse_matmul.png?resize=1024%2C619&ssl=1", "width": "1024", "height": "619", "credit": "", "caption": ""}, "2": {"item_id": "3787848372", "image_id": "2", "src": "https://i0.wp.com/timdettmers.com/wp-content/uploads/2019/07/sparse_momentum.png?resize=1024%2C493&ssl=1", "width": "1024", "height": "493", "credit": "1", "caption": "Figure 3: The sparse training algorithm that I developed has three stages:"}, "3": {"item_id": "3787848372", "image_id": "3", "src": "https://i0.wp.com/timdettmers.com/wp-content/uploads/2020/09/8-bit_data_types.png?resize=869%2C268&ssl=1", "width": "869", "height": "268", "credit": "0, 0.9", "caption": "Figure 4: Low-precision deep learning 8-bit datatypes that I developed. Deep learning training benefits from highly specialized data types. My dynamic tree datatype uses a dynamic bit that indicates the beginning of a binary bisection tree that quantized the range"}, "4": {"item_id": "3787848372", "image_id": "4", "src": "https://i0.wp.com/timdettmers.com/wp-content/uploads/2020/09/4x_RTX2080Ti_desktop_extenders.jpg?resize=768%2C1024&ssl=1", "width": "768", "height": "1024", "credit": "", "caption": ""}, "5": {"item_id": "3787848372", "image_id": "5", "src": "https://i0.wp.com/timdettmers.com/wp-content/uploads/2020/09/power_limit_nvidia_smi.png?resize=1017%2C1024&ssl=1", "width": "1017", "height": "1024", "credit": "", "caption": "Figure 6: Reducing the power limit has a slight cooling effect. Reducing the RTX 2080 Ti power limit by 50-60 W decreases temperatures slightly and fans run more silent."}, "6": {"item_id": "3787848372", "image_id": "6", "src": "https://timdettmers.com/wp-content/uploads/2020/09/RTX-2080-Ti-Slowdown-vs-Power-Limit.svg", "width": "853", "height": "703", "credit": "excluding softmax layer", "caption": "Figure 7: Measured slowdown for a given power limit on an RTX 2080 Ti. Measurements taken are mean processing times for 500 mini-batches of BERT Large during inference"}, "7": {"item_id": "3787848372", "image_id": "7", "src": "https://i0.wp.com/timdettmers.com/wp-content/uploads/2023/01/LLM_int8_zeroshot_emergence.png?ssl=1", "width": "1024", "height": "828", "credit": "", "caption": ""}, "8": {"item_id": "3787848372", "image_id": "8", "src": "https://i0.wp.com/timdettmers.com/wp-content/uploads/2023/01/pythia_4bit_datatypes2.png?ssl=1", "width": "1024", "height": "773", "credit": "", "caption": ""}, "9": {"item_id": "3787848372", "image_id": "9", "src": "https://i0.wp.com/timdettmers.com/wp-content/uploads/2023/01/GPUS_Ada_raw_performance3.png?ssl=1", "width": "1024", "height": "1006", "credit": "", "caption": ""}, "10": {"item_id": "3787848372", "image_id": "10", "src": "https://i0.wp.com/timdettmers.com/wp-content/uploads/2023/01/GPUs_Ada_performance_per_dollar4.png?ssl=1", "width": "1024", "height": "1006", "credit": "", "caption": ""}, "11": {"item_id": "3787848372", "image_id": "11", "src": "https://i0.wp.com/timdettmers.com/wp-content/uploads/2023/01/gpu_recommendations_chart2.png?ssl=1", "width": "861", "height": "702", "credit": "", "caption": ""}}, "listen_duration_estimate": 3518}, "3795585300": {"item_id": "3795585300", "resolved_id": "3795585300", "given_url": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/", "given_title": "Hacker News", "favorite": "0", "status": "1", "time_added": "1675691754", "time_updated": "1675807784", "time_read": "1675807784", "time_favorited": "0", "sort_id": 305, "resolved_title": "The Transformer Family Version 2.0", "resolved_url": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/", "excerpt": "Many new Transformer architecture improvements have been proposed since my last post on ‚ÄúThe Transformer Family‚Äù about three years ago. Here I did a big refactoring and enrichment of that 2020 post ‚Äî restructure the hierarchy of sections and improve many sections with more recent papers.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "9152", "lang": "en", "time_to_read": 42, "tags": {"deep-learning": {"item_id": "3795585300", "tag": "deep-learning"}, "transformers": {"item_id": "3795585300", "tag": "transformers"}}, "authors": {"76470090": {"item_id": "3795585300", "author_id": "76470090", "name": "Lilian Weng", "url": ""}}, "image": {"item_id": "3795585300", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/multi-head-attention.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3795585300", "image_id": "1", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/multi-head-attention.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3795585300", "image_id": "2", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/transformer.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3795585300", "image_id": "3", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/sinoidual-positional-encoding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3795585300", "image_id": "4", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/RoPE.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3795585300", "image_id": "5", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/transformer-XL-training.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3795585300", "image_id": "6", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/compressive-transformer.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3795585300", "image_id": "7", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/compressive-transformer-memory.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3795585300", "image_id": "8", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/SPALM2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3795585300", "image_id": "9", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/memorizing-transformer.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3795585300", "image_id": "10", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/ALiBi-bias.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3795585300", "image_id": "11", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/ALiBi-exp.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3795585300", "image_id": "12", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/universal-transformer-loop.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3795585300", "image_id": "13", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/universal-transformer.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "3795585300", "image_id": "14", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/attention-per-head.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "3795585300", "image_id": "15", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/soft-masking-function.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "3795585300", "image_id": "16", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/depth-adaptive-classifier.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "3795585300", "image_id": "17", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/image-transformer-attention.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "3795585300", "image_id": "18", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/sparse-attention.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "3795585300", "image_id": "19", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/combined-attention.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "3795585300", "image_id": "20", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/LSH-attention-matrix.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "3795585300", "image_id": "21", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/LSH-attention.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "3795585300", "image_id": "22", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/linformer.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "23": {"item_id": "3795585300", "image_id": "23", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/RFA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "3795585300", "image_id": "24", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/performer.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "3795585300", "image_id": "25", "src": "https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/gated-transformer-XL.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 3543}, "3832449628": {"item_id": "3832449628", "resolved_id": "3832449628", "given_url": "https://johanwind.github.io/2023/03/23/rwkv_overview.html", "given_title": "Hacker News", "favorite": "1", "status": "1", "time_added": "1680186586", "time_updated": "1680276982", "time_read": "1680276982", "time_favorited": "1680276968", "sort_id": 306, "resolved_title": "The RWKV language model: An RNN with the advantages of a transformer", "resolved_url": "https://johanwind.github.io/2023/03/23/rwkv_overview.html", "excerpt": "For a while, I‚Äôve been following and contributing to the RWKV language model, an open source large language model with great potential. As ChatGPT and large language models in general have gotten a lot of attention recently, I think it‚Äôs a good time to write about RWKV.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "867", "lang": "en", "time_to_read": 4, "tags": {"deep-learning": {"item_id": "3832449628", "tag": "deep-learning"}, "nlp": {"item_id": "3832449628", "tag": "nlp"}, "rnns": {"item_id": "3832449628", "tag": "rnns"}, "transformers": {"item_id": "3832449628", "tag": "transformers"}}, "image": {"item_id": "3832449628", "src": "https://johanwind.github.io/images/rwkv_benchmark.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3832449628", "image_id": "1", "src": "https://johanwind.github.io/images/rwkv_benchmark.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 336}, "3227243147": {"item_id": "3227243147", "resolved_id": "3227243147", "given_url": "https://blog.inten.to/hardware-for-deep-learning-part-4-asic-96a542fe6a81", "given_title": "Hardware for Deep Learning. Part 4: ASIC", "favorite": "0", "status": "1", "time_added": "1610798930", "time_updated": "1638708525", "time_read": "1610832437", "time_favorited": "0", "sort_id": 307, "resolved_title": "Hardware for Deep Learning. Part 4: ASIC", "resolved_url": "https://blog.inten.to/hardware-for-deep-learning-part-4-asic-96a542fe6a81", "excerpt": "This is a part about ASICs from the ‚ÄúHardware for Deep Learning‚Äù series. The content of the series is here. Now, when every large company launches it‚Äôs own DL or AI chip, it‚Äôs impossible to be silent. So, ASICs.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "10573", "lang": "en", "time_to_read": 48, "top_image_url": "https://miro.medium.com/max/1200/0*fIsAHCkMLWi8Mwfp", "tags": {"deep-learning": {"item_id": "3227243147", "tag": "deep-learning"}, "machine-learning": {"item_id": "3227243147", "tag": "machine-learning"}, "semiconductors": {"item_id": "3227243147", "tag": "semiconductors"}}, "authors": {"144326533": {"item_id": "3227243147", "author_id": "144326533", "name": "Grigory Sapunov", "url": "https://moocaholic.medium.com"}}, "image": {"item_id": "3227243147", "src": "https://miro.medium.com/max/0/0*fIsAHCkMLWi8Mwfp", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3227243147", "image_id": "1", "src": "https://miro.medium.com/max/0/0*fIsAHCkMLWi8Mwfp", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3227243147", "image_id": "2", "src": "https://miro.medium.com/max/3000/0*gmCI3vWZZ8IPcilM", "width": "1500", "height": "762", "credit": "", "caption": "https://deepmind.com/blog/article/alphago-zero-starting-scratch"}, "3": {"item_id": "3227243147", "image_id": "3", "src": "https://miro.medium.com/max/6436/1*iOWhkTnD0uXnpQ2Y_viHdA.png", "width": "3218", "height": "1802", "credit": "", "caption": "https://www.youtube.com/watch?v=rP8CGyDbxBY&list=PLOU2XLYxmsIJ5Bl3HmuxKY5WE555cu9Uc&index=4"}, "4": {"item_id": "3227243147", "image_id": "4", "src": "https://miro.medium.com/max/1580/0*ME21757y0tfrK3f8.png", "width": "790", "height": "475", "credit": "", "caption": "Google TPU v1 printed circuit card that fits into a SATA hard disk slot for drop-in installation."}, "5": {"item_id": "3227243147", "image_id": "5", "src": "https://miro.medium.com/max/1684/1*9uNlFIx5Uic2hoC4jIV6hg.png", "width": "842", "height": "623", "credit": "", "caption": "TPU Block Diagram."}, "6": {"item_id": "3227243147", "image_id": "6", "src": "https://miro.medium.com/max/1438/1*UtQ4tN0wjK0CmiImhvdOuQ.png", "width": "719", "height": "578", "credit": "", "caption": "Floor Plan of TPU die."}, "7": {"item_id": "3227243147", "image_id": "7", "src": "https://miro.medium.com/max/1122/1*cUuejVpcWwhRd_KE2nuNkw.png", "width": "561", "height": "418", "credit": "", "caption": "Systolic data flow of the Matrix Multiply Unit"}, "8": {"item_id": "3227243147", "image_id": "8", "src": "https://miro.medium.com/max/1936/1*TRZRMm7ZisNxPZOFP7gJDQ.png", "width": "968", "height": "632", "credit": "", "caption": "The Roofline model for a single TPU die on log-log scales"}, "9": {"item_id": "3227243147", "image_id": "9", "src": "https://miro.medium.com/max/2304/1*gaBUDFMjqVZ0XOH_V4Drsg.png", "width": "1152", "height": "636", "credit": "blue", "caption": "The Roofline model for TPU"}, "10": {"item_id": "3227243147", "image_id": "10", "src": "https://miro.medium.com/max/2246/0*JN21ICSIcInGXFjz", "width": "1123", "height": "620", "credit": "", "caption": "Google TPU v2 card with 4 chips"}, "11": {"item_id": "3227243147", "image_id": "11", "src": "https://miro.medium.com/max/1376/1*oEggwcjLn6di8jykp2jmgw.png", "width": "688", "height": "336", "credit": "", "caption": "A single TPU v2 chip with two cores"}, "12": {"item_id": "3227243147", "image_id": "12", "src": "https://miro.medium.com/max/1176/1*iCoUO_fRNBxY2lk5zvhIEA.png", "width": "588", "height": "508", "credit": "", "caption": "Block diagram of a TPU v2 core"}, "13": {"item_id": "3227243147", "image_id": "13", "src": "https://miro.medium.com/max/3100/0*0Tejz4hwiUI73dKW.jpg", "width": "1550", "height": "1336", "credit": "", "caption": "TPU v2 chip floor plan"}, "14": {"item_id": "3227243147", "image_id": "14", "src": "https://miro.medium.com/max/1196/0*Py0s4S_51AwY5SVn", "width": "598", "height": "340", "credit": "", "caption": ""}, "15": {"item_id": "3227243147", "image_id": "15", "src": "https://miro.medium.com/max/1908/1*sIrmp_cXHI0rzA07acvQMg.png", "width": "954", "height": "358", "credit": "", "caption": ""}, "16": {"item_id": "3227243147", "image_id": "16", "src": "https://miro.medium.com/max/1826/1*5zT-BrkDSM1Y5uZt6CXv0Q.png", "width": "913", "height": "503", "credit": "source", "caption": ""}, "17": {"item_id": "3227243147", "image_id": "17", "src": "https://miro.medium.com/max/2042/0*w_TuijcE0JlQFnHy.jpg", "width": "1021", "height": "1015", "credit": "source", "caption": "TPUv1/v2/v3 and Volta feature comparison"}, "18": {"item_id": "3227243147", "image_id": "18", "src": "https://miro.medium.com/max/1164/1*IgTM9MTHogxvkyDBtE4IeQ.png", "width": "582", "height": "343", "credit": "source", "caption": ""}, "19": {"item_id": "3227243147", "image_id": "19", "src": "https://miro.medium.com/max/3200/0*1CWwzMxPPy4BmdyV.png", "width": "1600", "height": "941", "credit": "source", "caption": ""}, "20": {"item_id": "3227243147", "image_id": "20", "src": "https://miro.medium.com/max/2068/0*AvBgglMSIBtgweUM", "width": "1034", "height": "600", "credit": "", "caption": "The v3 TPU POD"}, "21": {"item_id": "3227243147", "image_id": "21", "src": "https://miro.medium.com/max/2044/0*EEl_1XK6lIfSGNYS.jpg", "width": "1022", "height": "738", "credit": "", "caption": "A 2D-torus topology. TPU v2 uses a 16x16 2D torus."}, "22": {"item_id": "3227243147", "image_id": "22", "src": "https://miro.medium.com/max/1176/0*tchhZPBigPBYbWRp.png", "width": "588", "height": "305", "credit": "", "caption": ""}, "23": {"item_id": "3227243147", "image_id": "23", "src": "https://miro.medium.com/max/1246/0*L0TI320WSzPbUJG6.png", "width": "623", "height": "276", "credit": "", "caption": ""}, "24": {"item_id": "3227243147", "image_id": "24", "src": "https://miro.medium.com/max/2196/1*Z7jvGn5QcXQ_C6aQ2CtBMA.png", "width": "1098", "height": "500", "credit": "", "caption": ""}, "25": {"item_id": "3227243147", "image_id": "25", "src": "https://miro.medium.com/max/1934/1*gTDtGuEOlAmi8Wzm8FyBtA.png", "width": "967", "height": "435", "credit": "", "caption": "TPU-v3 4-pod configuration where cross-pod links connect neighboring TPU-v3 pods"}, "26": {"item_id": "3227243147", "image_id": "26", "src": "https://miro.medium.com/max/2060/1*MAF2NtKSkGW-aee0vlUpiA.png", "width": "1030", "height": "1030", "credit": "", "caption": "GOYA High-level Architecture"}, "27": {"item_id": "3227243147", "image_id": "27", "src": "https://miro.medium.com/max/1920/0*SbWf9CUHNXkGgR-z.png", "width": "960", "height": "600", "credit": "", "caption": ""}, "28": {"item_id": "3227243147", "image_id": "28", "src": "https://miro.medium.com/max/3010/1*IX8l32Hmzv2dLybLvZYUPA.png", "width": "1505", "height": "865", "credit": "", "caption": "HL-100 PCIe card"}, "29": {"item_id": "3227243147", "image_id": "29", "src": "https://miro.medium.com/max/3924/1*b0QVKRh8iYEc-fXcJAZVMg.png", "width": "1962", "height": "1092", "credit": "", "caption": "GOYA Inference Platform ‚Äî Software Stack"}, "30": {"item_id": "3227243147", "image_id": "30", "src": "https://miro.medium.com/max/5008/1*ODbnd0-huIVFTeBjvsXlbA.png", "width": "2504", "height": "608", "credit": "", "caption": ""}, "31": {"item_id": "3227243147", "image_id": "31", "src": "https://miro.medium.com/max/3420/1*fSwTNw1ohh6mW2neW_SLwA.png", "width": "1710", "height": "1013", "credit": "", "caption": "Gaudi HL-205 mezzanine card"}, "32": {"item_id": "3227243147", "image_id": "32", "src": "https://miro.medium.com/max/2368/1*yAgw4s2bvnjDO9Jr6mYamA.png", "width": "1184", "height": "1150", "credit": "", "caption": "Gaudi high-level architecture"}, "33": {"item_id": "3227243147", "image_id": "33", "src": "https://miro.medium.com/max/1256/0*c-qGeao7jcfLtmjx", "width": "628", "height": "381", "credit": "", "caption": ""}, "34": {"item_id": "3227243147", "image_id": "34", "src": "https://miro.medium.com/max/1600/0*fqDvgq4dLZufgpSP", "width": "800", "height": "790", "credit": "", "caption": ""}, "35": {"item_id": "3227243147", "image_id": "35", "src": "https://miro.medium.com/max/1948/0*jJ6f_3aFX-VEwp8U", "width": "974", "height": "743", "credit": "", "caption": ""}, "36": {"item_id": "3227243147", "image_id": "36", "src": "https://miro.medium.com/max/1400/0*pvDcd6cygiBQgSPw", "width": "700", "height": "336", "credit": "", "caption": ""}, "37": {"item_id": "3227243147", "image_id": "37", "src": "https://miro.medium.com/max/3840/0*Ho0xIIc_oYOR8VbL.png", "width": "1920", "height": "1308", "credit": "", "caption": ""}, "38": {"item_id": "3227243147", "image_id": "38", "src": "https://miro.medium.com/max/880/0*IZ_IErrx75OJ3R5v.jpg", "width": "440", "height": "290", "credit": "", "caption": ""}, "39": {"item_id": "3227243147", "image_id": "39", "src": "https://miro.medium.com/max/5200/0*zrbc3zBqMJ_PXQss.png", "width": "2600", "height": "1559", "credit": "", "caption": ""}, "40": {"item_id": "3227243147", "image_id": "40", "src": "https://miro.medium.com/max/4238/1*7WC7U1ER4FA1LCzos15Zfg.png", "width": "2119", "height": "1379", "credit": "source", "caption": ""}, "41": {"item_id": "3227243147", "image_id": "41", "src": "https://miro.medium.com/max/1920/0*XCsw3yE7XzIgpcXw.jpg", "width": "960", "height": "720", "credit": "", "caption": "The IPU-M2000 is Graphcore‚Äôs IPU system"}, "42": {"item_id": "3227243147", "image_id": "42", "src": "https://miro.medium.com/max/1920/0*4q3MS5v49QIP_w-R.jpg", "width": "960", "height": "720", "credit": "", "caption": "The Graphcore IPU-POD64"}, "43": {"item_id": "3227243147", "image_id": "43", "src": "https://miro.medium.com/max/1920/0*x2CPfWK036fEjsYi.jpg", "width": "960", "height": "720", "credit": "", "caption": "Dell DSS8440"}, "44": {"item_id": "3227243147", "image_id": "44", "src": "https://miro.medium.com/max/4800/0*iydIiFOYFcMgvjJw.jpg", "width": "2400", "height": "1075", "credit": "", "caption": ""}, "45": {"item_id": "3227243147", "image_id": "45", "src": "https://miro.medium.com/max/2976/1*p-iuRoyHuh0jaSael_n4ww.png", "width": "1488", "height": "1422", "credit": "", "caption": ""}, "46": {"item_id": "3227243147", "image_id": "46", "src": "https://miro.medium.com/max/5066/1*4aiUWlbmB2UTHC8HRlQbTA.png", "width": "2533", "height": "1174", "credit": "", "caption": ""}, "47": {"item_id": "3227243147", "image_id": "47", "src": "https://miro.medium.com/max/4948/1*-YaRe_GGHpjTEGR-a26r2g.png", "width": "2474", "height": "1015", "credit": "WSE", "caption": "CS-1 Wafer Scale Engine"}, "48": {"item_id": "3227243147", "image_id": "48", "src": "https://miro.medium.com/max/5006/1*rZAxGUEwfVDdpeAcwXT6Sg.png", "width": "2503", "height": "1163", "credit": "", "caption": "From HotChips 2020 slides"}, "49": {"item_id": "3227243147", "image_id": "49", "src": "https://miro.medium.com/max/1422/0*M1niVOB4hdjos0wn.jpg", "width": "711", "height": "600", "credit": "", "caption": "CS-1 system"}, "50": {"item_id": "3227243147", "image_id": "50", "src": "https://miro.medium.com/max/5968/1*Dj4g5Iow8bWMId25-f5ulA.png", "width": "2984", "height": "544", "credit": "", "caption": "A high-level overview of the compilation process for the WSE"}, "51": {"item_id": "3227243147", "image_id": "51", "src": "https://miro.medium.com/max/5074/1*iSDuSdnmraPY0nJ7tPP_4A.png", "width": "2537", "height": "1390", "credit": "", "caption": ""}, "52": {"item_id": "3227243147", "image_id": "52", "src": "https://miro.medium.com/max/3886/1*9uVs02tElZpJUlKRy8uJCQ.png", "width": "1943", "height": "1080", "credit": "source", "caption": ""}, "53": {"item_id": "3227243147", "image_id": "53", "src": "https://miro.medium.com/max/1280/0*mqOddQuHmcs7IJBD.jpg", "width": "640", "height": "646", "credit": "source", "caption": ""}, "54": {"item_id": "3227243147", "image_id": "54", "src": "https://miro.medium.com/max/3398/1*edbeUqJz62Pp6_IyfaCJ9g.png", "width": "1699", "height": "790", "credit": "", "caption": ""}, "55": {"item_id": "3227243147", "image_id": "55", "src": "https://miro.medium.com/max/1300/0*ydw81oBsAgYkLvc7.jpg", "width": "650", "height": "488", "credit": "", "caption": ""}, "56": {"item_id": "3227243147", "image_id": "56", "src": "https://miro.medium.com/max/1300/0*owP5AO3rhSwfqI-s.png", "width": "650", "height": "488", "credit": "", "caption": ""}, "57": {"item_id": "3227243147", "image_id": "57", "src": "https://miro.medium.com/max/1300/0*wu7p_kBtjSBBspoy.png", "width": "650", "height": "488", "credit": "", "caption": "Atlas 200 Development Kit"}, "58": {"item_id": "3227243147", "image_id": "58", "src": "https://miro.medium.com/max/1300/0*PW1zrrG561OX0K68.jpg", "width": "650", "height": "488", "credit": "", "caption": ""}, "59": {"item_id": "3227243147", "image_id": "59", "src": "https://miro.medium.com/max/1300/0*McPPNylo6nSQUk6p.png", "width": "650", "height": "488", "credit": "", "caption": ""}, "60": {"item_id": "3227243147", "image_id": "60", "src": "https://miro.medium.com/max/1300/0*kIewOOQcEuacCZ9u.png", "width": "650", "height": "488", "credit": "", "caption": "Atlas 900 AI Cluster"}, "61": {"item_id": "3227243147", "image_id": "61", "src": "https://miro.medium.com/max/2858/1*FonE7k4HyxoGLwNB759DHQ.png", "width": "1429", "height": "1055", "credit": "", "caption": ""}, "62": {"item_id": "3227243147", "image_id": "62", "src": "https://miro.medium.com/max/3484/1*R7UpiQz6K4lp11kjAdPHMw.png", "width": "1742", "height": "988", "credit": "", "caption": ""}, "63": {"item_id": "3227243147", "image_id": "63", "src": "https://miro.medium.com/max/5148/1*wGXK3jr-Sxm5jeV8C4RCMg.png", "width": "2574", "height": "1389", "credit": "", "caption": ""}, "64": {"item_id": "3227243147", "image_id": "64", "src": "https://miro.medium.com/max/4970/1*ht1Es0G476Zadgv2mC6_6A.png", "width": "2485", "height": "1514", "credit": "", "caption": ""}, "65": {"item_id": "3227243147", "image_id": "65", "src": "https://miro.medium.com/max/2138/0*64aFM8wVKM7jJr_Y.png", "width": "1069", "height": "639", "credit": "", "caption": ""}, "66": {"item_id": "3227243147", "image_id": "66", "src": "https://miro.medium.com/max/2404/0*uBe5LNLH5kBJ5BgT.jpg", "width": "1202", "height": "1000", "credit": "", "caption": ""}, "67": {"item_id": "3227243147", "image_id": "67", "src": "https://miro.medium.com/max/2400/0*OKujK1NnMOkqHyCb.jpg", "width": "1200", "height": "820", "credit": "", "caption": "SC5+"}, "68": {"item_id": "3227243147", "image_id": "68", "src": "https://miro.medium.com/max/2400/0*LQUEIfKubvzuVDPY.png", "width": "1200", "height": "820", "credit": "", "caption": "Artificial Intelligence Server SA3"}, "69": {"item_id": "3227243147", "image_id": "69", "src": "https://miro.medium.com/max/2160/0*DUwCnn-HbrCvaHds.jpg", "width": "1080", "height": "980", "credit": "", "caption": ""}, "70": {"item_id": "3227243147", "image_id": "70", "src": "https://miro.medium.com/max/4500/1*M66z_fCxDR7i6zPVaWecAA.png", "width": "2250", "height": "1209", "credit": "", "caption": ""}, "71": {"item_id": "3227243147", "image_id": "71", "src": "https://miro.medium.com/max/3744/1*fWYUCRCUZhpZPQ1iAX6gdQ.png", "width": "1872", "height": "954", "credit": "", "caption": ""}, "72": {"item_id": "3227243147", "image_id": "72", "src": "https://miro.medium.com/max/3630/1*GqjTEjaW3jBcOySEotE6-A.png", "width": "1815", "height": "827", "credit": "", "caption": ""}, "73": {"item_id": "3227243147", "image_id": "73", "src": "https://miro.medium.com/max/5464/1*o4YriwWqXi9t8Qyi0QqDRQ.png", "width": "2732", "height": "1404", "credit": "", "caption": ""}, "74": {"item_id": "3227243147", "image_id": "74", "src": "https://miro.medium.com/max/2824/1*NgwO5pV4qry2zURv684T2g.png", "width": "1412", "height": "832", "credit": "", "caption": ""}, "75": {"item_id": "3227243147", "image_id": "75", "src": "https://miro.medium.com/max/4874/1*4DFEARDaXael-px23gSizg.png", "width": "2437", "height": "995", "credit": "", "caption": ""}, "76": {"item_id": "3227243147", "image_id": "76", "src": "https://miro.medium.com/max/1624/0*gxjro_q2Mx4oh4kx.png", "width": "812", "height": "597", "credit": "", "caption": ""}, "77": {"item_id": "3227243147", "image_id": "77", "src": "https://miro.medium.com/max/1780/1*s-wRzsieFABb9ioaY1xduA.png", "width": "890", "height": "550", "credit": "", "caption": "TSP conceptual diagram. Instructions flow downward through identical function units, pipelining the operations. Data flows across the processor, allowing the program to perform different operations."}, "78": {"item_id": "3227243147", "image_id": "78", "src": "https://miro.medium.com/max/3496/1*hA87QQvdXsznWWbc6yitZw.png", "width": "1748", "height": "467", "credit": "", "caption": "TSP superlane block diagram. Every superlane is bilaterally symmetric with an east side and a west side. It contains 16 lanes, each of which is 8 bits wide. Data flows from east to west and from west to east."}, "79": {"item_id": "3227243147", "image_id": "79", "src": "https://miro.medium.com/max/3506/1*pWoj4_XDs2JKiXXmHOV_3g.png", "width": "1753", "height": "894", "credit": "source", "caption": "Image recognition inference performance for ResNet-50 v2 benchmarking at small batch sizes"}, "80": {"item_id": "3227243147", "image_id": "80", "src": "https://miro.medium.com/max/960/0*X3FUS_-AXMMjalLR", "width": "480", "height": "300", "credit": "", "caption": ""}}, "listen_duration_estimate": 4093}, "2958503222": {"item_id": "2958503222", "resolved_id": "2958503222", "given_url": "https://medium.com/gsi-technology/high-performance-billion-scale-similarity-search-686b2c354ee6", "given_title": "High-Performance, Billion-Scale Similarity Search | by Pat Lasserre | GSI T", "favorite": "0", "status": "1", "time_added": "1602612791", "time_updated": "1638708525", "time_read": "1604367688", "time_favorited": "0", "sort_id": 308, "resolved_title": "High-Performance, Billion-Scale Similarity Search", "resolved_url": "https://medium.com/gsi-technology/high-performance-billion-scale-similarity-search-686b2c354ee6", "excerpt": "In Part 1 of this series, we introduced the concept of embedding vectors. In Part 2, we discussed how embedding vectors can be used in similarity search applications to provide personalized customer recommendations, which in turn create a better customer experience.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "858", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/max/366/1*GaeU1ZWN1pp1pC2yWTcwhA.png", "tags": {"deep-learning": {"item_id": "2958503222", "tag": "deep-learning"}, "gsi": {"item_id": "2958503222", "tag": "gsi"}, "search": {"item_id": "2958503222", "tag": "search"}}, "authors": {"93187984": {"item_id": "2958503222", "author_id": "93187984", "name": "Pat Lasserre", "url": "https://medium.com/@patl_94164"}}, "image": {"item_id": "2958503222", "src": "https://miro.medium.com/fit/c/96/96/1*dmbNkD5D-u45r44go_cf0g.png", "width": "48", "height": "48"}, "images": {"1": {"item_id": "2958503222", "image_id": "1", "src": "https://miro.medium.com/fit/c/96/96/1*dmbNkD5D-u45r44go_cf0g.png", "width": "48", "height": "48", "credit": "", "caption": ""}, "2": {"item_id": "2958503222", "image_id": "2", "src": "https://miro.medium.com/max/1600/1*GaeU1ZWN1pp1pC2yWTcwhA.png", "width": "366", "height": "276", "credit": "", "caption": "Figure 1 Example of dataset grouped into clusters of similar items."}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 332}, "3382848022": {"item_id": "3382848022", "resolved_id": "3382848043", "given_url": "https://towardsdatascience.com/hog-histogram-of-oriented-gradients-67ecd887675f?source=rss----7f60cf5620c9---4", "given_title": "HOG(Histogram of Oriented Gradients)", "favorite": "0", "status": "1", "time_added": "1626437627", "time_updated": "1626486554", "time_read": "1626486554", "time_favorited": "0", "sort_id": 309, "resolved_title": "HOG(Histogram of Oriented Gradients)", "resolved_url": "https://towardsdatascience.com/hog-histogram-of-oriented-gradients-67ecd887675f", "excerpt": "Histogram of Oriented Gradients, also known as HOG, is a feature descriptor like the Canny Edge Detector, SIFT (Scale Invariant and Feature Transform) . It is used in computer vision and image processing for the purpose of object detection.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "797", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/max/1200/1*FgpFKC9mu2WR5qHk08b1IQ.jpeg", "tags": {"deep-learning": {"item_id": "3382848022", "tag": "deep-learning"}, "machine-learning": {"item_id": "3382848022", "tag": "machine-learning"}, "machine-vision": {"item_id": "3382848022", "tag": "machine-vision"}}, "authors": {"153629679": {"item_id": "3382848022", "author_id": "153629679", "name": "Mrinal Tyagi", "url": "https://mrinaltyagi24.medium.com"}}, "image": {"item_id": "3382848022", "src": "https://miro.medium.com/fit/c/56/56/1*LLHJ4VcVgXW9e6YdXkikIQ.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3382848022", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*LLHJ4VcVgXW9e6YdXkikIQ.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3382848022", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*FgpFKC9mu2WR5qHk08b1IQ.jpeg", "width": "700", "height": "326", "credit": "Image by author", "caption": "Figure 1 : The image imported to get HOG features of. Figure 2 : The imported image grayscale for the process. Figure 3 : Resized and grayscale image of the imported image."}, "3": {"item_id": "3382848022", "image_id": "3", "src": "https://miro.medium.com/max/1082/1*osjvJUze_RCPSiYcFHvMzw.gif", "width": "541", "height": "20", "credit": "Image by author", "caption": "where r, c refer to rows and columns respectively."}, "4": {"item_id": "3382848022", "image_id": "4", "src": "https://miro.medium.com/max/910/1*E0YLcI7Ui1VUc2Q_R-s88w.png", "width": "455", "height": "33", "credit": "", "caption": ""}, "5": {"item_id": "3382848022", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*nR-a0e4X-ujaVobsykcAfA.png", "width": "700", "height": "520", "credit": "Image by author", "caption": "Figure 4 : Visualization of magnitude of the image. Figure 5 : Visualization of angle of the image."}, "6": {"item_id": "3382848022", "image_id": "6", "src": "https://miro.medium.com/max/800/1*T-kh04SD0ENcL4aU_aSQkQ.png", "width": "400", "height": "42", "credit": "Image by author", "caption": ""}, "7": {"item_id": "3382848022", "image_id": "7", "src": "https://miro.medium.com/max/298/1*Wbm4NwlZ4A_woVA2s7aPKQ.png", "width": "149", "height": "19", "credit": "Image by author", "caption": ""}, "8": {"item_id": "3382848022", "image_id": "8", "src": "https://miro.medium.com/max/268/1*-DW1IlCY2GBfhVHmJ4W_dA.png", "width": "134", "height": "20", "credit": "Image by author", "caption": ""}, "9": {"item_id": "3382848022", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*VgcYfGjg_WpbrX1S-ACE0Q.png", "width": "700", "height": "621", "credit": "Image by author", "caption": "Figure 6 : 8x8 blocks on the magnitude image. Figure 7 : 8x8 blocks on an angle image."}, "10": {"item_id": "3382848022", "image_id": "10", "src": "https://miro.medium.com/max/1344/1*JZwuE5wMPDMgZ8Q9pieAug.png", "width": "672", "height": "114", "credit": "j+1", "caption": "Figure 8 : Representation of a 9 bin histogram. This one single histogram will be unique for one 8x8 block made up of 64 cells. All 64 cells will add their Vj and Vj+1 value to the jth and"}, "11": {"item_id": "3382848022", "image_id": "11", "src": "https://miro.medium.com/max/324/1*b_Z1xcvIoNAb1UURK2ASqQ.png", "width": "162", "height": "135", "credit": "Image by author", "caption": ""}, "12": {"item_id": "3382848022", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*Cf9WWyN-605RWi0ZblsdGw.png", "width": "700", "height": "398", "credit": "Image by author", "caption": "Method for calculation of 9 bin histograms is illustrated in the above image."}, "13": {"item_id": "3382848022", "image_id": "13", "src": "https://miro.medium.com/max/348/1*vsZgV-CFQQO5GIjN_XYgWg.png", "width": "174", "height": "19", "credit": "Image by author", "caption": ""}, "14": {"item_id": "3382848022", "image_id": "14", "src": "https://miro.medium.com/max/796/1*ZNLQg81ZmN6TKFyLhPqilg.gif", "width": "398", "height": "576", "credit": "Image by author", "caption": "Traversing of 2x2 grid box around the image in order to make a combined fbi from 4 blocks."}, "15": {"item_id": "3382848022", "image_id": "15", "src": "https://miro.medium.com/max/288/1*0G_dlDgfNYGDt_6k6lcYBA.png", "width": "144", "height": "57", "credit": "Image by author", "caption": "Where Œµ is a small value added to the square of fb in order to avoid zero division error. In code value taken of is 1e-05."}, "16": {"item_id": "3382848022", "image_id": "16", "src": "https://miro.medium.com/max/628/1*UymIQRnu42sDlLmdsuz-Dg.png", "width": "314", "height": "78", "credit": "Image by author", "caption": ""}, "17": {"item_id": "3382848022", "image_id": "17", "src": "https://miro.medium.com/max/384/1*K67G_u5HaHrAAFIjmzVPiw.png", "width": "192", "height": "384", "credit": "Image by author", "caption": "Visualization of HOG features on the same image using skimage library."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 309}, "3094099838": {"item_id": "3094099838", "resolved_id": "3094099838", "given_url": "https://ml-jku.github.io/hopfield-layers/", "given_title": "Hopfield Networks is All You Need | hopfield-layers", "favorite": "0", "status": "1", "time_added": "1620052009", "time_updated": "1638708525", "time_read": "1620052738", "time_favorited": "0", "sort_id": 310, "resolved_title": "Hopfield Networks is All You Need", "resolved_url": "https://ml-jku.github.io/hopfield-layers/", "excerpt": "This blog post explains the paper Hopfield Networks is All You Need and the corresponding new PyTorch Hopfield layer. We introduce a new energy function and a corresponding new update rule which is guaranteed to converge to a local minimum of the energy function.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "5540", "lang": "en", "time_to_read": 25, "tags": {"deep-learning": {"item_id": "3094099838", "tag": "deep-learning"}, "hopfield": {"item_id": "3094099838", "tag": "hopfield"}}, "authors": {"117120": {"item_id": "3094099838", "author_id": "117120", "name": "Viet Tran", "url": ""}}, "image": {"item_id": "3094099838", "src": "https://ml-jku.github.io/hopfield-layers/assets/single_pat_img/homer_original.png", "width": "300", "height": "0"}, "images": {"1": {"item_id": "3094099838", "image_id": "1", "src": "https://ml-jku.github.io/hopfield-layers/assets/single_pat_img/homer_original.png", "width": "300", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3094099838", "image_id": "2", "src": "https://ml-jku.github.io/hopfield-layers/assets/single_pat_img/homer_bw.png", "width": "300", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3094099838", "image_id": "3", "src": "https://ml-jku.github.io/hopfield-layers/assets/single_pat_img/homer_bw_masked.png", "width": "300", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3094099838", "image_id": "4", "src": "https://ml-jku.github.io/hopfield-layers/assets/single_pat_img/homer_bw_masked_retrieved.png", "width": "600", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3094099838", "image_id": "5", "src": "https://ml-jku.github.io/hopfield-layers/assets/multi_pat_img/experiment_6.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3094099838", "image_id": "6", "src": "https://ml-jku.github.io/hopfield-layers/assets/multi_pat_img/experiment_12.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "3094099838", "image_id": "7", "src": "https://ml-jku.github.io/hopfield-layers/assets/multi_pat_img/experiment_115.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3094099838", "image_id": "8", "src": "https://ml-jku.github.io/hopfield-layers/assets/dense_multi_pat_img_beta1/experiment_115.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3094099838", "image_id": "9", "src": "https://ml-jku.github.io/hopfield-layers/assets/dense_multi_pat_img_beta1/experiment_with_24_patterns.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3094099838", "image_id": "10", "src": "https://ml-jku.github.io/hopfield-layers/assets/cont_multi_pat_img/homer_gray_scale.png", "width": "300", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "3094099838", "image_id": "11", "src": "https://ml-jku.github.io/hopfield-layers/assets/cont_multi_pat_img/experiment_with_24_patterns_continuous_beta8.000.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "3094099838", "image_id": "12", "src": "https://ml-jku.github.io/hopfield-layers/assets/cont_multi_pat_img/experiment_with_24_patterns_continuous_beta0.500.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "3094099838", "image_id": "13", "src": "https://ml-jku.github.io/hopfield-layers/assets/cont_multi_pat_img/reconstruction_with_different_betas.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "3094099838", "image_id": "14", "src": "https://ml-jku.github.io/hopfield-layers/assets/NNlayers.svg", "width": "500", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "3094099838", "image_id": "15", "src": "https://ml-jku.github.io/hopfield-layers/assets/hopf_layer.png", "width": "500", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "3094099838", "image_id": "16", "src": "https://ml-jku.github.io/hopfield-layers/assets/HopfieldLayer.svg", "width": "800", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "3094099838", "image_id": "17", "src": "https://ml-jku.github.io/hopfield-layers/assets/HopfieldRetrieval_homer.svg", "width": "800", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "3094099838", "image_id": "18", "src": "https://ml-jku.github.io/hopfield-layers/assets/LayerHopfieldLayer.svg", "width": "800", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "3094099838", "image_id": "19", "src": "https://ml-jku.github.io/hopfield-layers/assets/HopfieldPooling1.svg", "width": "800", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "3094099838", "image_id": "20", "src": "https://ml-jku.github.io/hopfield-layers/assets/HopfieldPooling2.svg", "width": "800", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "3094099838", "image_id": "21", "src": "https://ml-jku.github.io/hopfield-layers/assets/Figure_Overview_DeepRC.svg", "width": "800", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "3094099838", "image_id": "22", "src": "https://ml-jku.github.io/hopfield-layers/assets/deeprc_new.svg", "width": "500", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 2145}, "1946287383": {"item_id": "1946287383", "resolved_id": "1946287383", "given_url": "http://blog.ycombinator.com/how-adversarial-attacks-work/", "given_title": "How Adversarial Attacks Work", "favorite": "0", "status": "1", "time_added": "1509658006", "time_updated": "1691366676", "time_read": "1510439312", "time_favorited": "0", "sort_id": 311, "resolved_title": "How Adversarial Attacks Work", "resolved_url": "https://blog.ycombinator.com/how-adversarial-attacks-work/", "excerpt": "Emil Mikhailov is the founder of XIX.ai (YC W17). Roman Trusov is a researcher at XIX.ai.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3032", "lang": "en", "time_to_read": 14, "top_image_url": "https://ycombinator.wpengine.com/wp-content/uploads/2017/11/How-Adversarial-Attacks-Work.png", "tags": {"adversarial": {"item_id": "1946287383", "tag": "adversarial"}, "deep-learning": {"item_id": "1946287383", "tag": "deep-learning"}, "gans": {"item_id": "1946287383", "tag": "gans"}}, "authors": {"78285147": {"item_id": "1946287383", "author_id": "78285147", "name": "Emil Mikhailov", "url": "https://blog.ycombinator.com/author/emil-mikhailov/"}}, "image": {"item_id": "1946287383", "src": "https://ycombinator.wpengine.com/wp-content/uploads/2017/11/inception-v3.png", "width": "1600", "height": "598"}, "images": {"1": {"item_id": "1946287383", "image_id": "1", "src": "https://ycombinator.wpengine.com/wp-content/uploads/2017/11/inception-v3.png", "width": "1600", "height": "598", "credit": "", "caption": ""}, "2": {"item_id": "1946287383", "image_id": "2", "src": "https://ycombinator.wpengine.com/wp-content/uploads/2017/11/maps-of-adversarial.png", "width": "1017", "height": "761", "credit": "", "caption": ""}, "3": {"item_id": "1946287383", "image_id": "3", "src": "https://ycombinator.wpengine.com/wp-content/uploads/2017/11/car.png", "width": "1072", "height": "363", "credit": "", "caption": ""}, "4": {"item_id": "1946287383", "image_id": "4", "src": "https://ycombinator.wpengine.com/wp-content/uploads/2017/11/car2.png", "width": "1072", "height": "363", "credit": "", "caption": ""}, "5": {"item_id": "1946287383", "image_id": "5", "src": "https://ycombinator.wpengine.com/wp-content/uploads/2017/11/face-grid.png", "width": "557", "height": "555", "credit": "", "caption": ""}, "6": {"item_id": "1946287383", "image_id": "6", "src": "https://ycombinator.wpengine.com/wp-content/uploads/2017/11/graph.png", "width": "497", "height": "496", "credit": "", "caption": ""}, "7": {"item_id": "1946287383", "image_id": "7", "src": "https://ycombinator.wpengine.com/wp-content/uploads/2017/11/gradient-steps.png", "width": "719", "height": "373", "credit": "", "caption": ""}, "8": {"item_id": "1946287383", "image_id": "8", "src": "https://ycombinator.wpengine.com/wp-content/uploads/2017/11/stallone.png", "width": "1072", "height": "363", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Y Combinator", "logo": "https://logo.clearbit.com/ycombinator.com?size=800", "greyscale_logo": "https://logo.clearbit.com/ycombinator.com?size=800&greyscale=true"}, "listen_duration_estimate": 1174}, "2959145039": {"item_id": "2959145039", "resolved_id": "2959145039", "given_url": "https://www.amazon.science/blog/how-robots-can-adapt-to-new-tasks-quickly", "given_title": "How robots can adapt to new tasks ‚Äî quickly", "favorite": "0", "status": "1", "time_added": "1587645702", "time_updated": "1638708525", "time_read": "1587661396", "time_favorited": "0", "sort_id": 312, "resolved_title": "How robots can adapt to new tasks ‚Äî quickly", "resolved_url": "https://www.amazon.science/blog/how-robots-can-adapt-to-new-tasks-quickly", "excerpt": "Reinforcement learning (RL) is a technique in which an AI agent interacts with an environment and learns a policy based on the rewards that it receives during this interaction. Progress in RL has been dramatically demonstrated by human-level performance on games like Atari.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "676", "lang": "en", "time_to_read": 3, "top_image_url": "https://assets.amazon.science/dims4/default/1d725b6/2147483647/strip/true/crop/4000x2100+0+75/resize/1200x630!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2Fc3%2Fe9%2Fd4632cc648b7bd3c22a3a5eb80e1%2Fmql-arm.png", "tags": {"deep-learning": {"item_id": "2959145039", "tag": "deep-learning"}, "robotics": {"item_id": "2959145039", "tag": "robotics"}}, "authors": {"132625521": {"item_id": "2959145039", "author_id": "132625521", "name": "Rasool Fakoor", "url": "https://www.amazon.science/author/rasool-fakoor"}}, "image": {"item_id": "2959145039", "src": "https://assets.amazon.science/dims4/default/9c8e6c2/2147483647/strip/true/crop/4000x2250+0+0/resize/1200x675!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2Fc3%2Fe9%2Fd4632cc648b7bd3c22a3a5eb80e1%2Fmql-arm.png", "width": "1200", "height": "675"}, "images": {"1": {"item_id": "2959145039", "image_id": "1", "src": "https://assets.amazon.science/dims4/default/9c8e6c2/2147483647/strip/true/crop/4000x2250+0+0/resize/1200x675!/quality/90/?url=http%3A%2F%2Famazon-topics-brightspot.s3.amazonaws.com%2Fscience%2Fc3%2Fe9%2Fd4632cc648b7bd3c22a3a5eb80e1%2Fmql-arm.png", "width": "1200", "height": "675", "credit": "", "caption": ""}}, "listen_duration_estimate": 262}, "3124533500": {"item_id": "3124533500", "resolved_id": "3124533531", "given_url": "https://towardsdatascience.com/how-to-beat-pythons-pip-254c2635197?source=rss----7f60cf5620c9---4", "given_title": "How to beat Python‚Äôs pip", "favorite": "0", "status": "1", "time_added": "1601247555", "time_updated": "1638708525", "time_read": "1604361979", "time_favorited": "0", "sort_id": 313, "resolved_title": "", "resolved_url": "https://towardsdatascience.com/how-to-beat-pythons-pip-254c2635197", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"deep-learning": {"item_id": "3124533500", "tag": "deep-learning"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "2092443854": {"item_id": "2092443854", "resolved_id": "2092443854", "given_url": "https://tech.instacart.com/how-to-build-a-deep-learning-model-in-15-minutes-a3684c6f71e", "given_title": "How to build a deep learning model in 15 minutes ‚Äì tech-at-instacart", "favorite": "0", "status": "1", "time_added": "1520111224", "time_updated": "1638708525", "time_read": "1528501255", "time_favorited": "0", "sort_id": 314, "resolved_title": "How to build a deep learning model in 15 minutes", "resolved_url": "https://tech.instacart.com/how-to-build-a-deep-learning-model-in-15-minutes-a3684c6f71e", "excerpt": "An open source framework for configuring, building, deploying and maintaining deep learning models in Python. As Instacart has grown, we‚Äôve learned a few things the hard way.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2063", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/v2/resize:fit:1200/1*1DZImJIxInPbkqpCQpsQcA.png", "tags": {"deep-learning": {"item_id": "2092443854", "tag": "deep-learning"}}, "authors": {"84527889": {"item_id": "2092443854", "author_id": "84527889", "name": "Montana Low", "url": "https://medium.com/@montanalow"}}, "image": {"item_id": "2092443854", "src": "https://miro.medium.com/v2/resize:fill:88:88/0*c476lYnT0yMqw_RP.", "width": "44", "height": "44"}, "images": {"1": {"item_id": "2092443854", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/0*c476lYnT0yMqw_RP.", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "2092443854", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*cz16eztri2JgDrbBe6q1uA.png", "width": "24", "height": "24", "credit": "", "caption": ""}}, "listen_duration_estimate": 799}, "3646292274": {"item_id": "3646292274", "resolved_id": "3646292300", "given_url": "https://towardsdatascience.com/how-to-build-an-image-captioning-model-in-pytorch-29b9d8fe2f8c?source=rss----7f60cf5620c9---4", "given_title": "How to Build an Image-Captioning Model in Pytorch", "favorite": "0", "status": "1", "time_added": "1656013225", "time_updated": "1656013465", "time_read": "1656013465", "time_favorited": "0", "sort_id": 315, "resolved_title": "How to Build an Image-Captioning Model in Pytorch", "resolved_url": "https://towardsdatascience.com/how-to-build-an-image-captioning-model-in-pytorch-29b9d8fe2f8c", "excerpt": "In this article, I will explain how you can build an image captioning model architecture using the Pytorch deep learning library. In addition to explaining the intuition behind the model architectures, I will also provide the Pytorch code for the models.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1636", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/1200/0*9chjZxFWwGxc0gDh", "tags": {"deep-learning": {"item_id": "3646292274", "tag": "deep-learning"}, "image-classification": {"item_id": "3646292274", "tag": "image-classification"}, "pytorch": {"item_id": "3646292274", "tag": "pytorch"}}, "authors": {"145605341": {"item_id": "3646292274", "author_id": "145605341", "name": "Saketh Kotamraju", "url": "https://medium.com/@saketh.kotamraju"}}, "image": {"item_id": "3646292274", "src": "https://miro.medium.com/max/1400/0*9chjZxFWwGxc0gDh", "width": "700", "height": "1050"}, "images": {"1": {"item_id": "3646292274", "image_id": "1", "src": "https://miro.medium.com/max/1400/0*9chjZxFWwGxc0gDh", "width": "700", "height": "1050", "credit": "Adam Dutton on Unsplash", "caption": ""}, "2": {"item_id": "3646292274", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*HxBDFFqwpjShEnyb", "width": "700", "height": "467", "credit": "LyAn Voyages on Unsplash", "caption": ""}, "3": {"item_id": "3646292274", "image_id": "3", "src": "https://miro.medium.com/max/1248/1*MqsV98FA4XA99QFs7BXldg.jpeg", "width": "624", "height": "219", "credit": "", "caption": "Image by Author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 633}, "3140253273": {"item_id": "3140253273", "resolved_id": "3140253289", "given_url": "https://towardsdatascience.com/how-to-cluster-images-based-on-visual-similarity-cd6e7209fe34?source=rss----7f60cf5620c9---4", "given_title": "How to cluster images based on visual similarity", "favorite": "0", "status": "1", "time_added": "1602586790", "time_updated": "1638708525", "time_read": "1604361156", "time_favorited": "0", "sort_id": 316, "resolved_title": "How to cluster images based on visual similarity", "resolved_url": "https://towardsdatascience.com/how-to-cluster-images-based-on-visual-similarity-cd6e7209fe34", "excerpt": "In this tutorial, I'm going to walk you through using a pre-trained neural network to extract a feature vector from images and cluster the images based on how similar the feature vectors are.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1062", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/0*RARg2hIOV2DCGO-h", "tags": {"clustering": {"item_id": "3140253273", "tag": "clustering"}, "deep-learning": {"item_id": "3140253273", "tag": "deep-learning"}, "vision": {"item_id": "3140253273", "tag": "vision"}}, "authors": {"140656943": {"item_id": "3140253273", "author_id": "140656943", "name": "Gabe Flomo", "url": "https://medium.com/@gabeflomo821"}}, "image": {"item_id": "3140253273", "src": "https://miro.medium.com/fit/c/56/56/2*i_XHzhbfOqybNBQmvtK30g.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3140253273", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*i_XHzhbfOqybNBQmvtK30g.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3140253273", "image_id": "2", "src": "https://miro.medium.com/max/2000/0*RARg2hIOV2DCGO-h", "width": "1000", "height": "667", "credit": "Pietro Jeng on Unsplash", "caption": ""}, "3": {"item_id": "3140253273", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*xIIBn2Yajg4naTqJif7q1w.png", "width": "700", "height": "134", "credit": "", "caption": ""}, "4": {"item_id": "3140253273", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*wiGcYoDls0bInqoq8ixPqA.png", "width": "700", "height": "202", "credit": "", "caption": ""}, "5": {"item_id": "3140253273", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*cHlZ4tJp91n5DODlS-oZXQ.png", "width": "700", "height": "72", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 411}, "2930305743": {"item_id": "2930305743", "resolved_id": "2930305762", "given_url": "https://towardsdatascience.com/how-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489?source=rss----7f60cf5620c9---4", "given_title": "How to Get Beautiful Results with Neural Style Transfer", "favorite": "0", "status": "1", "time_added": "1585389424", "time_updated": "1638708525", "time_read": "1585579989", "time_favorited": "0", "sort_id": 317, "resolved_title": "How to Get Beautiful Results with Neural Style Transfer", "resolved_url": "https://towardsdatascience.com/how-to-get-beautiful-results-with-neural-style-transfer-75d0c05d6489", "excerpt": "I recently became interested in generating a Medium profile picture with Machine Learning. This pulled me deep into the land of Neural Style Transfer. While NST is conceptually simple to understand, generating high quality images is surprisingly difficult.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1985", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/512/1*3IdVhB62IBQhXHIJTbNeVg.png", "tags": {"deep-learning": {"item_id": "2930305743", "tag": "deep-learning"}}, "authors": {"147411860": {"item_id": "2930305743", "author_id": "147411860", "name": "Eugen Hotaj", "url": "https://eugenhotaj.medium.com"}}, "image": {"item_id": "2930305743", "src": "https://miro.medium.com/max/1024/1*esra58I1ZIpcHeUjpro_6Q.png", "width": "512", "height": "512"}, "images": {"1": {"item_id": "2930305743", "image_id": "1", "src": "https://miro.medium.com/max/1024/1*esra58I1ZIpcHeUjpro_6Q.png", "width": "512", "height": "512", "credit": "", "caption": ""}, "2": {"item_id": "2930305743", "image_id": "2", "src": "https://miro.medium.com/max/1024/1*zut4OvEX6h_1jkIX64EE0w.png", "width": "512", "height": "512", "credit": "", "caption": ""}, "3": {"item_id": "2930305743", "image_id": "3", "src": "https://miro.medium.com/max/1024/1*3IdVhB62IBQhXHIJTbNeVg.png", "width": "512", "height": "512", "credit": "", "caption": ""}, "4": {"item_id": "2930305743", "image_id": "4", "src": "https://miro.medium.com/fit/c/56/56/2*P9_lpU-n-FJDrlEOMTWe9A.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "5": {"item_id": "2930305743", "image_id": "5", "src": "https://miro.medium.com/max/2890/1*XKRk2Vr0bse4GkkWf6UNXg.png", "width": "1445", "height": "569", "credit": "Bottom Left", "caption": "Figure 1: A comparison of Neural Style Transfer quality for two different implementations."}, "6": {"item_id": "2930305743", "image_id": "6", "src": "https://miro.medium.com/max/1200/0*5Lk8jWtWkHfg0rUm.jpg", "width": "600", "height": "344", "credit": "source", "caption": "Figure 2: The VGG19 network and its layers"}, "7": {"item_id": "2930305743", "image_id": "7", "src": "https://miro.medium.com/max/2970/1*bSV2t00wFnkuYL0AP93SuQ.png", "width": "1485", "height": "319", "credit": "", "caption": "Figure 3: Visualizing what content different layers of the VGG19 network respond to. Layers further to the right are deeper in the network."}, "8": {"item_id": "2930305743", "image_id": "8", "src": "https://miro.medium.com/max/1242/1*2RGHWW3GEy_EaYq3Vd0Ing.png", "width": "621", "height": "305", "credit": "Left", "caption": "Figure 4:"}, "9": {"item_id": "2930305743", "image_id": "9", "src": "https://miro.medium.com/max/700/1*x89fDTofVmZ2PF0QLnCDCA.png", "width": "350", "height": "350", "credit": "", "caption": "Figure 5: Rotation artifacts at the top right edge of the generated image caused by aggressive data augmentation ."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 768}, "3729371649": {"item_id": "3729371649", "resolved_id": "3729371649", "given_url": "https://www.digitaltrends.com/computing/how-to-use-midjourney-to-generate-ai-images/", "given_title": "How to use Midjourney to generate AI images | Digital Trends", "favorite": "0", "status": "1", "time_added": "1680998665", "time_updated": "1681079536", "time_read": "1681079536", "time_favorited": "0", "sort_id": 318, "resolved_title": "How to use Midjourney to generate AI images", "resolved_url": "https://www.digitaltrends.com/computing/how-to-use-midjourney-to-generate-ai-images/", "excerpt": "The era of AI-generated artwork is upon us, and the internet is filled with users trying to create the perfect prompts to lead AIs to create just the right images ‚Äì or sometimes, just the wrong ones.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "772", "lang": "en", "time_to_read": 4, "amp_url": "https://www.digitaltrends.com/computing/how-to-use-midjourney-to-generate-ai-images/?amp", "top_image_url": "https://www.digitaltrends.com/wp-content/uploads/2022/10/Midjourney-River.jpg?p=1", "tags": {"deep-learning": {"item_id": "3729371649", "tag": "deep-learning"}, "image-generation": {"item_id": "3729371649", "tag": "image-generation"}}, "authors": {"67895914": {"item_id": "3729371649", "author_id": "67895914", "name": "Tyler Lacoma", "url": "https://www.digitaltrends.com/users/tylerlacoma/"}}, "image": {"item_id": "3729371649", "src": "https://www.digitaltrends.com/wp-content/uploads/2022/10/Midjourney-Join-the-Beta.jpeg?fit=720%2C720&p=1", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3729371649", "image_id": "1", "src": "https://www.digitaltrends.com/wp-content/uploads/2022/10/Midjourney-Join-the-Beta.jpeg?fit=720%2C720&p=1", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3729371649", "image_id": "2", "src": "https://www.digitaltrends.com/wp-content/uploads/2022/10/Midjourney-Accept-Invite.jpg?fit=720%2C720&p=1", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3729371649", "image_id": "3", "src": "https://www.digitaltrends.com/wp-content/uploads/2022/10/Newcomer-Rooms-in-Midjourney.jpg?fit=720%2C720&p=1", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3729371649", "image_id": "4", "src": "https://www.digitaltrends.com/wp-content/uploads/2022/10/Midjourney-Image-Options.jpg?fit=720%2C720&p=1", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3729371649", "image_id": "5", "src": "https://www.digitaltrends.com/wp-content/uploads/2022/10/Midjourney-Single-Image-Options.jpg?fit=720%2C720&p=1", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Digital Trends", "logo": "https://logo.clearbit.com/digitaltrends.com?size=800", "greyscale_logo": "https://logo.clearbit.com/digitaltrends.com?size=800&greyscale=true"}, "listen_duration_estimate": 299}, "3449750075": {"item_id": "3449750075", "resolved_id": "3449750096", "given_url": "https://towardsdatascience.com/hrnet-explained-human-pose-estimation-sematic-segmentation-and-object-detection-63f1ce79ef82?source=rss----7f60cf5620c9---4", "given_title": "HRNet explained: Human Pose Estimation, Semantic Segmentation and Object De", "favorite": "0", "status": "1", "time_added": "1633606526", "time_updated": "1633630869", "time_read": "1633630869", "time_favorited": "0", "sort_id": 319, "resolved_title": "HRNet explained: Human Pose Estimation, Sematic Segmentation and Object Detection", "resolved_url": "https://towardsdatascience.com/hrnet-explained-human-pose-estimation-sematic-segmentation-and-object-detection-63f1ce79ef82", "excerpt": "HRNet is a state-of-the-art algorithm in the field of semantic segmentation, facial landmark detection, and human pose estimation. It has shown superior results in semantic segmentation on datasets like PASCAL Context, LIP, Cityscapes, AFLW, COFW, and 300W.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1874", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/1200/1*rLhbwmHhjFF2u9NrO3iWpg.jpeg", "tags": {"deep-learning": {"item_id": "3449750075", "tag": "deep-learning"}, "machine-vision": {"item_id": "3449750075", "tag": "machine-vision"}, "pose-estimation": {"item_id": "3449750075", "tag": "pose-estimation"}, "semantic-segmentation": {"item_id": "3449750075", "tag": "semantic-segmentation"}}, "authors": {"129050273": {"item_id": "3449750075", "author_id": "129050273", "name": "Hucker Marius", "url": "https://medium.com/@hucker.marius"}}, "image": {"item_id": "3449750075", "src": "https://miro.medium.com/fit/c/56/56/2*7IaQcIIvxhB-crtlmJWGoA.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3449750075", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*7IaQcIIvxhB-crtlmJWGoA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3449750075", "image_id": "2", "src": "https://miro.medium.com/max/9036/1*rLhbwmHhjFF2u9NrO3iWpg.jpeg", "width": "4518", "height": "3011", "credit": "Christian Lue on Unsplash", "caption": ""}, "3": {"item_id": "3449750075", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*9ATXgoGvrOXukaOAgyWuCQ.png", "width": "700", "height": "317", "credit": "", "caption": "Source: http://host.robots.ox.ac.uk/pascal/VOC/voc2012/#devkit"}, "4": {"item_id": "3449750075", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*rekAeufx3gMVi3qUL3_UEw.png", "width": "700", "height": "307", "credit": "", "caption": "Source: https://learnopencv.com/face-swap-using-opencv-c-python/"}, "5": {"item_id": "3449750075", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*pcvyvpgNMuy4MCOG5ecKbw.png", "width": "700", "height": "603", "credit": "", "caption": "Source: https://arxiv.org/abs/2103.02440"}, "6": {"item_id": "3449750075", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*4U2mB9ZE46Uj2LQz989MHQ.png", "width": "700", "height": "158", "credit": "7", "caption": "Source: https://cs231n.github.io/convolutional-networks/"}, "7": {"item_id": "3449750075", "image_id": "7", "src": "https://miro.medium.com/max/1052/1*Z87z69ufkGnNolH6R_Ln_w.gif", "width": "526", "height": "384", "credit": "", "caption": "Source: https://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/"}, "8": {"item_id": "3449750075", "image_id": "8", "src": "https://miro.medium.com/max/1148/1*TCGAV3JvaWABGC34jaN4LQ.png", "width": "574", "height": "304", "credit": "7", "caption": "Source: https://cs231n.github.io/convolutional-networks/"}, "9": {"item_id": "3449750075", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*SGjMTghF8SQdD2l-DDD9vQ.png", "width": "700", "height": "115", "credit": "", "caption": "Source: https://arxiv.org/pdf/1904.04514.pdf"}, "10": {"item_id": "3449750075", "image_id": "10", "src": "https://miro.medium.com/max/928/1*BIYwJGwbm4VGQAOoazg5SQ.png", "width": "464", "height": "468", "credit": "", "caption": "Source: https://arxiv.org/pdf/1904.04514.pdf"}, "11": {"item_id": "3449750075", "image_id": "11", "src": "https://miro.medium.com/max/560/1*5lhntnXLH1YUTJKpX5-EqA.png", "width": "280", "height": "462", "credit": "", "caption": "Source: https://arxiv.org/pdf/1904.04514.pdf"}, "12": {"item_id": "3449750075", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*W2DJWlD--JgtgVLoz_03EA.png", "width": "700", "height": "65", "credit": "", "caption": "Previous CNN with serial convolution and not parallel. Source: https://arxiv.org/pdf/1904.04514.pdf"}, "13": {"item_id": "3449750075", "image_id": "13", "src": "https://miro.medium.com/max/952/1*vh1XNEWgUxn5vF0aP7BjCQ.png", "width": "476", "height": "298", "credit": "", "caption": "HRNetV1 illustration. Source: https://arxiv.org/pdf/1904.04514.pdf"}, "14": {"item_id": "3449750075", "image_id": "14", "src": "https://miro.medium.com/max/928/1*Fq-e4ExsbpZKAJxaN3sR8A.png", "width": "464", "height": "362", "credit": "", "caption": "HRNetV2 illustration. Source: https://arxiv.org/pdf/1904.04514.pdf"}, "15": {"item_id": "3449750075", "image_id": "15", "src": "https://miro.medium.com/max/960/1*keRNOE64DQXTthrITaGOOQ.png", "width": "480", "height": "360", "credit": "", "caption": "HRNetV2p illustration. Source: https://arxiv.org/pdf/1904.04514.pdf"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 725}, "930824186": {"item_id": "930824186", "resolved_id": "930824186", "given_url": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "given_title": "http://karpathy.github.io/2015/05/21/rnn-effectiveness/", "favorite": "0", "status": "1", "time_added": "1622248003", "time_updated": "1638708525", "time_read": "1622249141", "time_favorited": "0", "sort_id": 320, "resolved_title": "The Unreasonable Effectiveness of Recurrent Neural Networks", "resolved_url": "https://karpathy.github.io/2015/05/21/rnn-effectiveness/", "excerpt": "There‚Äôs something magical about Recurrent Neural Networks (RNNs). I still remember when I trained my first recurrent network for Image Captioning.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "7126", "lang": "en", "time_to_read": 32, "tags": {"deep-learning": {"item_id": "930824186", "tag": "deep-learning"}, "rnns": {"item_id": "930824186", "tag": "rnns"}}, "image": {"item_id": "930824186", "src": "https://karpathy.github.io/assets/rnn/diags.jpeg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "930824186", "image_id": "1", "src": "https://karpathy.github.io/assets/rnn/diags.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "930824186", "image_id": "2", "src": "https://karpathy.github.io/assets/rnn/charseq.jpeg", "width": "70", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "930824186", "image_id": "3", "src": "https://karpathy.github.io/assets/rnn/latex4.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "930824186", "image_id": "4", "src": "https://karpathy.github.io/assets/rnn/latex3.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "930824186", "image_id": "5", "src": "https://karpathy.github.io/assets/rnn/under1.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "930824186", "image_id": "6", "src": "https://karpathy.github.io/assets/rnn/under2.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "930824186", "image_id": "7", "src": "https://karpathy.github.io/assets/rnn/under3.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "930824186", "image_id": "8", "src": "https://karpathy.github.io/assets/rnn/under4.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 2758}, "2857734964": {"item_id": "2857734964", "resolved_id": "2857734964", "given_url": "https://blog.paperspace.com/nvidia-gaugan-introduction/", "given_title": "https://blog.paperspace.com/nvidia-gaugan-introduction/", "favorite": "0", "status": "1", "time_added": "1581181776", "time_updated": "1638708525", "time_read": "1582142466", "time_favorited": "0", "sort_id": 321, "resolved_title": "Understanding GauGAN Part 1: Unraveling Nvidia's Landscape Painting GANs", "resolved_url": "https://blog.paperspace.com/nvidia-gaugan-introduction/", "excerpt": "In this article we explain what GauGANs are, and how their architecture and objective functions work. This is part of a series on Nvidia GauGANs. One of the most interesting papers presented at CVPR in 2019 was Nvidia's Semantic Image Synthesis with Spatially-Adaptive Normalization.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2597", "lang": "en", "time_to_read": 12, "amp_url": "https://blog.paperspace.com/nvidia-gaugan-introduction/amp/", "top_image_url": "https://blog.paperspace.com/content/images/2020/01/gaugan-photo.jpg", "tags": {"deep-learning": {"item_id": "2857734964", "tag": "deep-learning"}}, "authors": {"89061737": {"item_id": "2857734964", "author_id": "89061737", "name": "Ayoosh Kathuria", "url": "https://blog.paperspace.com/author/ayoosh/"}}, "image": {"item_id": "2857734964", "src": "https://lh6.googleusercontent.com/e5ddWs9pTwcsJjLpidTdELdLpOg2wZQRAu_sYUX1noKRytE9RpHzODHoj_hxiCYLbRrbwm3jorOOn4qGx0rm9TJY-yXaQw-VefKnN2Rth-ZlCMUK4tPYG9aN9ZVq4AE3wUQM0Jjd", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2857734964", "image_id": "1", "src": "https://lh6.googleusercontent.com/e5ddWs9pTwcsJjLpidTdELdLpOg2wZQRAu_sYUX1noKRytE9RpHzODHoj_hxiCYLbRrbwm3jorOOn4qGx0rm9TJY-yXaQw-VefKnN2Rth-ZlCMUK4tPYG9aN9ZVq4AE3wUQM0Jjd", "width": "0", "height": "0", "credit": "", "caption": "GauGAN can turn doodles into lifelike images. This image, courtesy of Nvidia, demonstrates how GauGAN can produce realistic versions of different elements such as \"road,\" \"tree,\" etc."}, "2": {"item_id": "2857734964", "image_id": "2", "src": "https://lh6.googleusercontent.com/ukEqG1sR36rGRvmGgLIRc7mBnnEX3EwNzpthj0QcbF7nufrL_BV686B7oyvuVhVHHlpGvWGTGqDlW1-Dur_xXBRMzO2jFS5kJGtt92VC0wPBvh67tlZUmCNC_-bj_ehlnFGTu6X-", "width": "0", "height": "0", "credit": "left", "caption": "GauGAN takes a Semantic Segmentation Map"}, "3": {"item_id": "2857734964", "image_id": "3", "src": "https://lh3.googleusercontent.com/pNrToYKjiVaf813KcsHg8tOMajij_IuDSJWJTGb_PM4TlT6u-owhyqyfAyl8poeh3G1a1B5qK4okBhgP9y3yH1b3Pd6DGxJIJQ_HoxWn6Q0Eqd5XMsSA9RMPfUAY0llxDEiQ4Aq4", "width": "0", "height": "0", "credit": "", "caption": "Diagram illustrating how semantic maps are one-hot encoded before being sent to the generator in GauGAN"}, "4": {"item_id": "2857734964", "image_id": "4", "src": "https://lh3.googleusercontent.com/_umWygWhKYLJVItwSjxm3khQHz9TNsmTHJm6mHteV1mmBAB517YvqxkViMmP1tLRUVe88v63c7XcIZd_udrPsRi68yd4fYun9olXaM1Es0O3SX5pWhtrhzZDEyRAS7WuDmUtK23P", "width": "0", "height": "0", "credit": "", "caption": "GauGAN Generator. A miniature version of the Pix2PixHD generator has been shown for comparison. Pix2PixHD has convolutional layers, residual blocks and transpose convolutions in that order. Source: https://arxiv.org/pdf/1903.07291.pdf"}, "5": {"item_id": "2857734964", "image_id": "5", "src": "https://lh3.googleusercontent.com/JGY13318_vHN7o1AsmiyU5cJcKi93Nk1JmeykzCCE5wkzP_oeqxqMN0UH65yjUR25IumSZhbexJM4fFEEpDLDah23pWRwOUDXct6rD0u3qM14orw-bAGnhe-CG8s6CYUiiv8CU08", "width": "0", "height": "0", "credit": "", "caption": "In batch normalization, the statistics are computed over feature maps across all batches. In instance normalization, the statistics are computed over feature maps across a single image."}, "6": {"item_id": "2857734964", "image_id": "6", "src": "https://lh4.googleusercontent.com/uTrIfbzvp3B_hKcHFs4sfCFYujhukcDN1pVWS2iFdsXvpfZuyQFBa2EXXn5jNbadX4kWUdepyOMXoCJEjJnNJxdGs7f4Jo0szYOinakgvL6KHBc5FoF7Mae5gwyyNENWlKq6Je4r", "width": "0", "height": "0", "credit": "", "caption": "Design of a SPADE Unit. Note, this describes the SPADE unit in the SPADEResBlk demonstrated in the diagram above."}, "7": {"item_id": "2857734964", "image_id": "7", "src": "https://lh4.googleusercontent.com/DRpCY_bOa4D2E3NfjwammC28AeDd26wCjrPg2egA2mJxlHdPgdN5YiRD9WDQz-AGg17Ly_FkGOffjr7nw1qSRmsF7O_v1dQZdV8qg1GeE3JRGt7uX2tSARJ_xhbxxHABoNoj77BJ", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2857734964", "image_id": "8", "src": "https://lh3.googleusercontent.com/EsG7dU7Tw25uU8M1e-i95zeU5OTnDxHf4nCT7JNkWdOw_BqGrq20J1IQ3u8mLy4TVHMkHBPOjuKXlFrZOvtcPO9zcvOfP9BbMF0tdStzO8y7NLQqVymdaloCxOWoO_xrMqaSNz84", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2857734964", "image_id": "9", "src": "https://lh6.googleusercontent.com/YA9bZD9o87cRTpEsIjba0tuCCfm3anbZAoMZZpoHpzpP-aaoYeCm4VyZeucswmlENvFFjmcdozCPeAhe_8g-0eP0SOJaEiXvH7tm_MIhSTv_ujMcwXbb14NdZAeLmmPR8j8EF3ra", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2857734964", "image_id": "10", "src": "https://lh3.googleusercontent.com/oODlvkIcHeV4-zhgN0HoL-VupxZHvL7krSt_TMMnKU-TdBvTYq6BO3A5ChngwOdpuYE1U639In-wMX-YRmFK0GFz5yX1zcVoCRRlcqtThnlQBtR-Ot8CFhEcFZTW_GwnXeXlp158", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2857734964", "image_id": "11", "src": "https://lh5.googleusercontent.com/JEe1IXWhUJWGGgzoXuDVFa0z3aXwJRsveV-peuyK72isp0soNerTEVDf-2qR9bmVolinlWmgYDKWerkyCzyr-TJemeGKiUCfHo8J58E-oDt6UVKmqK8DijUlp8a6NlQt1g4hxAXP", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2857734964", "image_id": "12", "src": "https://lh6.googleusercontent.com/9JWmFsH9d5NZUFvM4lraMSX-vevZWBdC2S_Oy25V3pLeg1Wv7zAag1WBtP5WgciLRwYBvOksj7yGlFIEmCdaThHytHHpGiGvwa-tNumyGgQHgyAy8SUnfBhYao9iNbUik2lgSLTS", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1005}, "2553265441": {"item_id": "2553265441", "resolved_id": "2553265441", "given_url": "https://distill.pub/2019/gan-open-problems/", "given_title": "https://distill.pub/2019/gan-open-problems/", "favorite": "0", "status": "1", "time_added": "1554860973", "time_updated": "1691366676", "time_read": "1567116776", "time_favorited": "0", "sort_id": 322, "resolved_title": "Open Questions about Generative Adversarial Networks", "resolved_url": "https://distill.pub/2019/gan-open-problems", "excerpt": "What we‚Äôd like to find out about GANs that we don‚Äôt know yet. By some metrics, research on Generative Adversarial Networks (GANs) has progressed substantially in the past 2 years. Practical improvements to image synthesis models are being made almost too quickly to keep up with:", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3699", "lang": "en", "time_to_read": 17, "top_image_url": "https://distill.pub/2019/gan-open-problems/thumbnail.jpg", "tags": {"adversarial": {"item_id": "2553265441", "tag": "adversarial"}, "deep-learning": {"item_id": "2553265441", "tag": "deep-learning"}}, "authors": {"109167400": {"item_id": "2553265441", "author_id": "109167400", "name": "Odena et al.", "url": ""}, "109167401": {"item_id": "2553265441", "author_id": "109167401", "name": "Miyato et al.", "url": ""}}, "image": {"item_id": "2553265441", "src": "https://distill.pub/2019/gan-open-problems/images/gan-progress.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2553265441", "image_id": "1", "src": "https://distill.pub/2019/gan-open-problems/images/gan-progress.png", "width": "0", "height": "0", "credit": "Zhang et al., 2018", "caption": ""}}, "listen_duration_estimate": 1432}, "2912422231": {"item_id": "2912422231", "resolved_id": "2912422231", "given_url": "https://github.com/nandinib1999/object-detection-yolo-opencv", "given_title": "https://github.com/nandinib1999/object-detection-yolo-opencv", "favorite": "0", "status": "1", "time_added": "1583951202", "time_updated": "1638708525", "time_read": "1585739835", "time_favorited": "0", "sort_id": 323, "resolved_title": "nandinib1999/object-detection-yolo-opencv", "resolved_url": "https://github.com/nandinib1999/object-detection-yolo-opencv", "excerpt": "Object Detection using Yolo V3 and OpenCV . Contribute to nandinib1999/object-detection-yolo-opencv development by creating an account on GitHub.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "top_image_url": "https://opengraph.githubassets.com/864c25fcb0d87a42e07876a455b8932b0746d5eab4e43e16098aa5eeac56946e/nandinib1999/object-detection-yolo-opencv", "tags": {"deep-learning": {"item_id": "2912422231", "tag": "deep-learning"}, "object-detection": {"item_id": "2912422231", "tag": "object-detection"}, "opencv": {"item_id": "2912422231", "tag": "opencv"}, "vision": {"item_id": "2912422231", "tag": "vision"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "2896883391": {"item_id": "2896883391", "resolved_id": "2896883391", "given_url": "https://theaisummer.com/Deep-Learning-Algorithms/", "given_title": "https://theaisummer.com/Deep-Learning-Algorithms/", "favorite": "0", "status": "1", "time_added": "1583359979", "time_updated": "1638708525", "time_read": "1583785007", "time_favorited": "0", "sort_id": 324, "resolved_title": "Deep Learning Algorithms - The Complete Guide", "resolved_url": "https://theaisummer.com/Deep-Learning-Algorithms/", "excerpt": "Deep Learning is eating the world. The hype began around 2012 when a Neural Network achieved super human performance on Image Recognition tasks and only a few people could predict what was about to happen.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3058", "lang": "en", "time_to_read": 14, "top_image_url": "https://theaisummer.com/static/e90c0015d3a26c550664de883c3bdd18/14b42/deep-learning-algorithms.jpg", "tags": {"deep-learning": {"item_id": "2896883391", "tag": "deep-learning"}}, "authors": {"135419922": {"item_id": "2896883391", "author_id": "135419922", "name": "Sergios Karagiannakos", "url": "https://theaisummer.com/author/Sergios-Karagiannakos/"}}, "image": {"item_id": "2896883391", "src": "https://theaisummer.com/static/25ac0e7374f862841fe554de4b7a6450/4b190/neuron.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2896883391", "image_id": "1", "src": "https://theaisummer.com/static/25ac0e7374f862841fe554de4b7a6450/4b190/neuron.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2896883391", "image_id": "2", "src": "https://theaisummer.com/static/f867ca10ec93233d261116352e6bec56/c9c44/neural-network.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2896883391", "image_id": "3", "src": "https://theaisummer.com/static/2fcd242de84286b4c4be7e764b334630/167b5/convolutional-neural-network.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2896883391", "image_id": "4", "src": "https://theaisummer.com/static/5564cf7e0b865e2481dd5306d46cb402/faddd/lstm_cll.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2896883391", "image_id": "5", "src": "https://theaisummer.com/static/d57a2ae3fb095d80d99d4cca1635362c/3d2b2/autoencoder.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2896883391", "image_id": "6", "src": "https://theaisummer.com/static/0c873b5f7d8d3d46590def6f6d2972da/5aae9/restricted-boltzmann-machine.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2896883391", "image_id": "7", "src": "https://theaisummer.com/static/9dc7ade8581705de13978e14f1ff7f33/748b0/generative-adversarial-networks.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2896883391", "image_id": "8", "src": "https://theaisummer.com/static/962f8150540dda5a82b13eb77800191d/eb390/transformers.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2896883391", "image_id": "9", "src": "https://theaisummer.com/static/fd0197a92a28cba1dcc37865514f5b30/c08c5/cv_tasks.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2896883391", "image_id": "10", "src": "https://theaisummer.com/static/32bde05b2ffccf127b8a89d76dddb57d/eea4a/yolo_app.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2896883391", "image_id": "11", "src": "https://theaisummer.com/static/8b58a02198e13d2e29a41b40e7c6a035/8e1fc/semseg.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1184}, "2916558168": {"item_id": "2916558168", "resolved_id": "2916558225", "given_url": "https://towardsdatascience.com/matrix-factorization-as-a-recommender-system-727ee64683f0?source=rss----7f60cf5620c9---4", "given_title": "https://towardsdatascience.com/matrix-factorization-as-a-recommender-system", "favorite": "0", "status": "1", "time_added": "1584288374", "time_updated": "1706233547", "time_read": "1585739719", "time_favorited": "0", "sort_id": 325, "resolved_title": "Matrix Factorization as a Recommender System", "resolved_url": "https://towardsdatascience.com/matrix-factorization-as-a-recommender-system-727ee64683f0", "excerpt": "Recommender systems is one of the most industry-applicable areas of machine learning. These systems help recommend the right items to a customer to increase customer retention. There are a variety of recommender system algorithms, but one of the cleanest is matrix factorization.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1604", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/1024/0*jibyT2jB0ExPfgx3.png", "tags": {"algorithms-math": {"item_id": "2916558168", "tag": "algorithms-math"}, "deep-learning": {"item_id": "2916558168", "tag": "deep-learning"}, "machine-learning": {"item_id": "2916558168", "tag": "machine-learning"}}, "authors": {"129297771": {"item_id": "2916558168", "author_id": "129297771", "name": "Andre Ye", "url": "https://towardsdatascience.com/@andre_ye"}}, "image": {"item_id": "2916558168", "src": "https://miro.medium.com/max/2048/0*jibyT2jB0ExPfgx3.png", "width": "1024", "height": "211"}, "images": {"1": {"item_id": "2916558168", "image_id": "1", "src": "https://miro.medium.com/max/2048/0*jibyT2jB0ExPfgx3.png", "width": "1024", "height": "211", "credit": "", "caption": "Source. Image free to share and use commercially."}, "2": {"item_id": "2916558168", "image_id": "2", "src": "https://miro.medium.com/max/3298/1*TAFOBWPAffU8Izyxid7Pdg.png", "width": "1649", "height": "657", "credit": "", "caption": ""}, "3": {"item_id": "2916558168", "image_id": "3", "src": "https://miro.medium.com/max/1980/1*2fgujBbVMJ6v472eC5iLGg.png", "width": "990", "height": "378", "credit": "", "caption": ""}, "4": {"item_id": "2916558168", "image_id": "4", "src": "https://miro.medium.com/max/964/1*-tGAyQnmOWfFY4qS5nYfKQ.png", "width": "482", "height": "291", "credit": "", "caption": ""}, "5": {"item_id": "2916558168", "image_id": "5", "src": "https://miro.medium.com/max/2032/1*yBv6S2GxlosXWvS0ve_Kgg.png", "width": "1016", "height": "380", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 621}, "3719306509": {"item_id": "3719306509", "resolved_id": "3719306509", "given_url": "https://www.fastcompany.com/90793809/if-you-thought-text-to-image-ai-was-unbelievable-wait-until-you-see-how-it-compresses-images", "given_title": "If you thought text-to-image AI was unbelievable, wait until you see how it", "favorite": "0", "status": "1", "time_added": "1665244969", "time_updated": "1706830873", "time_read": "1665266978", "time_favorited": "0", "sort_id": 326, "resolved_title": "If you thought text-to-image AI was unbelievable, wait until you see how it compresses images", "resolved_url": "https://www.fastcompany.com/90793809/if-you-thought-text-to-image-ai-was-unbelievable-wait-until-you-see-how-it-compresses-images", "excerpt": "Instead of using math, a Stable Diffusion image compression engine uses a fuzzy cloud of noise to reconstruct reality with uncanny fidelity.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1033", "lang": "en", "time_to_read": 5, "top_image_url": "https://images.fastcompany.net/image/upload/w_1280,f_auto,q_auto,fl_lossy/wp-cms/uploads/2022/10/1664482063517.jpeg", "tags": {"deep-learning": {"item_id": "3719306509", "tag": "deep-learning"}, "image-compression": {"item_id": "3719306509", "tag": "image-compression"}, "stable-diffusion": {"item_id": "3719306509", "tag": "stable-diffusion"}}, "authors": {"77388198": {"item_id": "3719306509", "author_id": "77388198", "name": "Jesus Diaz", "url": "https://www.fastcompany.com/user/jesusdiaz"}}, "image": {"item_id": "3719306509", "src": "https://images.fastcompany.net/image/upload/w_596,c_limit,q_auto:best,f_auto/wp-cms/uploads/2022/10/1664525611563-457x457.jpeg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3719306509", "image_id": "1", "src": "https://images.fastcompany.net/image/upload/w_596,c_limit,q_auto:best,f_auto/wp-cms/uploads/2022/10/1664525611563-457x457.jpeg", "width": "0", "height": "0", "credit": "bottom left corner, 4.97 kilobytes", "caption": "The Stable Diffusion‚Äôs compressed image"}, "2": {"item_id": "3719306509", "image_id": "2", "src": "https://images.fastcompany.net/image/upload/w_596,c_limit,q_auto:best,f_auto/wp-cms/uploads/2022/10/1664525953379.png", "width": "0", "height": "0", "credit": "Matthias B√ºhlmann", "caption": "Latent space representation of a photo, as represented by Stable Diffusion"}, "3": {"item_id": "3719306509", "image_id": "3", "src": "https://images.fastcompany.net/image/upload/w_596,c_limit,q_auto:best,f_auto/wp-cms/uploads/2022/10/1664526203339.png", "width": "0", "height": "0", "credit": "Matthias B√ºhlmann", "caption": "Stable Diffusion‚Äôs compression on the left and center show weird features added by the AI."}, "4": {"item_id": "3719306509", "image_id": "4", "src": "https://images.fastcompany.net/image/upload/w_596,c_limit,q_auto:best,f_auto/wp-cms/uploads/2022/10/1664526301697.png", "width": "0", "height": "0", "credit": "center", "caption": "This photo of San Francisco‚Äôs skyline"}, "5": {"item_id": "3719306509", "image_id": "5", "src": "https://images.fastcompany.net/image/upload/w_596,c_limit,q_auto:best,f_auto/wp-cms/uploads/2022/10/1664526373702.png", "width": "0", "height": "0", "credit": "center and right", "caption": "Stable Diffusion‚Äôs compression"}}, "domain_metadata": {"name": "Fast Company", "logo": "https://logo.clearbit.com/fastcompany.com?size=800", "greyscale_logo": "https://logo.clearbit.com/fastcompany.com?size=800&greyscale=true"}, "listen_duration_estimate": 400}, "2998905445": {"item_id": "2998905445", "resolved_id": "2998898703", "given_url": "https://towardsdatascience.com/illustrated-guide-to-transformer-cf6969ffa067?source=rss----7f60cf5620c9---4", "given_title": "Illustrated Guide to Transformer", "favorite": "0", "status": "1", "time_added": "1590747518", "time_updated": "1638708525", "time_read": "1591029781", "time_favorited": "0", "sort_id": 327, "resolved_title": "Illustrated Guide to Transformers", "resolved_url": "https://towardsdatascience.com/illustrated-guide-to-transformer-cf6969ffa067", "excerpt": "The Transformer model is the evolution of the encoder-decoder architecture, proposed in the paper Attention is All You Need. While encoder-decoder architecture has been relying on recurrent neural networks (RNNs) to extract sequential information, the Transformer doesn‚Äôt use RNN.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2209", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/max/1200/1*R17kC9bACRkXzNeW8bSWoQ.png", "tags": {"deep-learning": {"item_id": "2998905445", "tag": "deep-learning"}}, "authors": {"141988912": {"item_id": "2998905445", "author_id": "141988912", "name": "Jingles (Hong Jing)", "url": "https://jinglesnote.medium.com"}}, "image": {"item_id": "2998905445", "src": "https://miro.medium.com/fit/c/56/56/2*kF739nhJVsf7FxWzBbN62w.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2998905445", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*kF739nhJVsf7FxWzBbN62w.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2998905445", "image_id": "2", "src": "https://miro.medium.com/max/7676/1*R17kC9bACRkXzNeW8bSWoQ.png", "width": "3838", "height": "2156", "credit": "", "caption": ""}, "3": {"item_id": "2998905445", "image_id": "3", "src": "https://miro.medium.com/max/6152/1*LeBuaSKwSR7MXgnuiXWWeA.png", "width": "3076", "height": "882", "credit": "source", "caption": "Unfolding recurrent neural network"}, "4": {"item_id": "2998905445", "image_id": "4", "src": "https://miro.medium.com/max/7564/1*BpqoXTU8LOUoX95ijwcTvw.png", "width": "3782", "height": "944", "credit": "", "caption": "Machine translation that uses encoder-decoder architecture."}, "5": {"item_id": "2998905445", "image_id": "5", "src": "https://miro.medium.com/max/5272/1*LD5wI9K0nLOY1ZktE8HW4A.png", "width": "2636", "height": "812", "credit": "", "caption": "Vanishing gradients if the input sequence is too long."}, "6": {"item_id": "2998905445", "image_id": "6", "src": "https://miro.medium.com/max/6332/1*DFiRioW203E4Ty30LHS6Nw.png", "width": "3166", "height": "1502", "credit": "source", "caption": "Long Short Term Memory"}, "7": {"item_id": "2998905445", "image_id": "7", "src": "https://miro.medium.com/max/6248/1*h7SlfXhAW8dVj_97ZkeWvQ.png", "width": "3124", "height": "1386", "credit": "", "caption": "Using a fixed-length vector to represent the input sequence."}, "8": {"item_id": "2998905445", "image_id": "8", "src": "https://miro.medium.com/max/5208/1*XRfUffxM-pIlJPr_ALOKxg.png", "width": "2604", "height": "1474", "credit": "source", "caption": "The BLEU scores of the generated translations on the test set with respect to the lengths of the sentences."}, "9": {"item_id": "2998905445", "image_id": "9", "src": "https://miro.medium.com/max/5768/1*YwLWH3PbD34vkkBjx6f6EA.png", "width": "2884", "height": "1134", "credit": "", "caption": "RNN unroll each word individually. Transformer process input in parallel."}, "10": {"item_id": "2998905445", "image_id": "10", "src": "https://miro.medium.com/max/3088/1*yhqLfM5ZXp5-mdRrD8wsEQ.png", "width": "1544", "height": "2172", "credit": "source", "caption": "The Transformer model architecture."}, "11": {"item_id": "2998905445", "image_id": "11", "src": "https://miro.medium.com/max/4508/1*HtVm0yDrfifavRJlKfo1fg.png", "width": "2254", "height": "1230", "credit": "", "caption": "Word embedding and positional encoding produce word vector with context."}, "12": {"item_id": "2998905445", "image_id": "12", "src": "https://miro.medium.com/max/2370/1*6HvlADmCAW-gFhtnmCk1hA.png", "width": "1185", "height": "404", "credit": "", "caption": "Positional encoding using multiple sine and cosine functions."}, "13": {"item_id": "2998905445", "image_id": "13", "src": "https://miro.medium.com/max/6216/1*mRUl7lG1k7QeAfyQw6dR-w.png", "width": "3108", "height": "1116", "credit": "", "caption": "Multiple attention vector normalized."}, "14": {"item_id": "2998905445", "image_id": "14", "src": "https://miro.medium.com/max/7172/1*fyBwOWImvvQIZPH5ZE5ipQ.png", "width": "3586", "height": "1136", "credit": "", "caption": "Multiple attention vector masked."}, "15": {"item_id": "2998905445", "image_id": "15", "src": "https://miro.medium.com/max/7020/1*kUCCcK3nZwzUrkWbQv_TIA.png", "width": "3510", "height": "1924", "credit": "", "caption": "Input Attention vectors into the Decoder‚Äôs Multi-Head Attention"}, "16": {"item_id": "2998905445", "image_id": "16", "src": "https://miro.medium.com/max/2160/1*rc3T7h0-KOEeZtEk8_w1wQ.gif", "width": "1080", "height": "608", "credit": "", "caption": "Translate English to French, Decoder predicts the next word."}, "17": {"item_id": "2998905445", "image_id": "17", "src": "https://miro.medium.com/max/962/1*fPTPd_WxZ4Ey7iOVElxwJQ.png", "width": "481", "height": "311", "credit": "", "caption": ""}, "18": {"item_id": "2998905445", "image_id": "18", "src": "https://miro.medium.com/max/962/1*ESxUX6V6tAqj_2ZFSr-pUw.png", "width": "481", "height": "311", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 855}, "3011329450": {"item_id": "3011329450", "resolved_id": "3011329503", "given_url": "https://towardsdatascience.com/image-augmentation-mastering-15-techniques-and-useful-functions-with-python-codes-44c3f8c1ea1f?source=rss----7f60cf5620c9---4", "given_title": "Image Augmentation Mastering: 15  Techniques and Useful Functions with Pyth", "favorite": "0", "status": "1", "time_added": "1591661968", "time_updated": "1638708525", "time_read": "1593020454", "time_favorited": "0", "sort_id": 328, "resolved_title": "Image Augmentation Mastering: 15+ Techniques and Useful Functions with Python Codes", "resolved_url": "https://towardsdatascience.com/image-augmentation-mastering-15-techniques-and-useful-functions-with-python-codes-44c3f8c1ea1f", "excerpt": "Whether we are enjoying Keras or Pytorch we have access to wonderful libraries to efficiently enhance our images. But what about those special cases where: For all these cases and many others, we must be able to master our image augmentation.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1809", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1200/1*jNwS-HWYMQqfnhkFBVf8ng.png", "tags": {"deep-learning": {"item_id": "3011329450", "tag": "deep-learning"}, "vision": {"item_id": "3011329450", "tag": "vision"}}, "authors": {"152254245": {"item_id": "3011329450", "author_id": "152254245", "name": "‚≠êAxel Thevenot", "url": "https://axel-thevenot.medium.com"}}, "image": {"item_id": "3011329450", "src": "https://miro.medium.com/fit/c/56/56/2*FObZji7hjGS6NYCI1rdY8w.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3011329450", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*FObZji7hjGS6NYCI1rdY8w.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3011329450", "image_id": "2", "src": "https://miro.medium.com/max/2540/1*jNwS-HWYMQqfnhkFBVf8ng.png", "width": "1270", "height": "748", "credit": "", "caption": ""}, "3": {"item_id": "3011329450", "image_id": "3", "src": "https://miro.medium.com/max/5080/1*jAqTra_7VQoycR9jQyqZSA.png", "width": "2540", "height": "748", "credit": "", "caption": ""}, "4": {"item_id": "3011329450", "image_id": "4", "src": "https://miro.medium.com/max/1920/1*NceyXUSU77fyoSq6EPawkw.png", "width": "960", "height": "540", "credit": "", "caption": ""}, "5": {"item_id": "3011329450", "image_id": "5", "src": "https://miro.medium.com/max/3580/1*OFQoXZBLmgaIcjt9fkQpIg.png", "width": "1790", "height": "205", "credit": "", "caption": ""}, "6": {"item_id": "3011329450", "image_id": "6", "src": "https://miro.medium.com/max/3586/1*Xn5n5Ia6VLOGU5ZZBrxp6g.png", "width": "1793", "height": "338", "credit": "", "caption": ""}, "7": {"item_id": "3011329450", "image_id": "7", "src": "https://miro.medium.com/max/2400/1*bHrhBjYNA63jv6zI7fwA3w.gif", "width": "1200", "height": "338", "credit": "", "caption": ""}, "8": {"item_id": "3011329450", "image_id": "8", "src": "https://miro.medium.com/max/2400/1*fK_ZfGDNrmwa9V4T3IhIFg.gif", "width": "1200", "height": "338", "credit": "", "caption": ""}, "9": {"item_id": "3011329450", "image_id": "9", "src": "https://miro.medium.com/max/2400/1*VXCITQ9KaOzcOW5l0Y4S9w.gif", "width": "1200", "height": "338", "credit": "", "caption": "value of center from 0 to 65."}, "10": {"item_id": "3011329450", "image_id": "10", "src": "https://miro.medium.com/max/2400/1*-TZfVtfseat6CQ9xyghwJQ.gif", "width": "1200", "height": "338", "credit": "", "caption": "kernel size from 1 to 35"}, "11": {"item_id": "3011329450", "image_id": "11", "src": "https://miro.medium.com/max/2400/1*Ij2eJ_4T3PSw6Pkv27u0zw.gif", "width": "1200", "height": "338", "credit": "", "caption": "kernel size from 1 to 35"}, "12": {"item_id": "3011329450", "image_id": "12", "src": "https://miro.medium.com/max/2400/1*V9UC_C_mtVvO2Bpq3h7N-g.gif", "width": "1200", "height": "338", "credit": "", "caption": ""}, "13": {"item_id": "3011329450", "image_id": "13", "src": "https://miro.medium.com/max/2400/1*k-vEFThmu9_g7nx_s-v2JQ.gif", "width": "1200", "height": "338", "credit": "", "caption": ""}, "14": {"item_id": "3011329450", "image_id": "14", "src": "https://miro.medium.com/max/2400/1*1pyricY3Uanu1zcwWTciHQ.gif", "width": "1200", "height": "338", "credit": "", "caption": ""}, "15": {"item_id": "3011329450", "image_id": "15", "src": "https://miro.medium.com/max/2400/1*50kSsrLM05CCh_YoqBTLqQ.gif", "width": "1200", "height": "338", "credit": "", "caption": ""}, "16": {"item_id": "3011329450", "image_id": "16", "src": "https://miro.medium.com/max/2400/1*8l-bYXw35G0d2PrVMTa9ag.gif", "width": "1200", "height": "338", "credit": "", "caption": "Combining random rotation translation shearing and scale"}, "17": {"item_id": "3011329450", "image_id": "17", "src": "https://miro.medium.com/max/2400/1*d9t9qE8Y6EUPoyhMldlwUw.gif", "width": "1200", "height": "338", "credit": "", "caption": "Cutout replacement by 0, on the whole input and cropping the target at the same time"}, "18": {"item_id": "3011329450", "image_id": "18", "src": "https://miro.medium.com/max/2400/1*br0bn7GmLE-3ctwR_30syw.gif", "width": "1200", "height": "338", "credit": "", "caption": "Cutout replacement by 1, channel size on input without cropping the target"}, "19": {"item_id": "3011329450", "image_id": "19", "src": "https://miro.medium.com/max/2400/1*sG-ygbx75S5-N2Mm6v60jA.gif", "width": "1200", "height": "338", "credit": "", "caption": ""}, "20": {"item_id": "3011329450", "image_id": "20", "src": "https://miro.medium.com/max/2400/1*lMdkvfvziGUvWkTYCiHW9Q.gif", "width": "1200", "height": "338", "credit": "", "caption": "Brightness from -100 to 100"}, "21": {"item_id": "3011329450", "image_id": "21", "src": "https://miro.medium.com/max/2400/1*7DwHkd7zSzGHr3seE7TwPw.gif", "width": "1200", "height": "338", "credit": "", "caption": "Contrasts from -100 to 100"}, "22": {"item_id": "3011329450", "image_id": "22", "src": "https://miro.medium.com/max/2400/1*vu6GiC7FXmY04tHhCR6DAQ.gif", "width": "1200", "height": "338", "credit": "", "caption": ""}, "23": {"item_id": "3011329450", "image_id": "23", "src": "https://miro.medium.com/max/2400/1*mgWhaCrkF7vNAqIUOKCbbw.gif", "width": "1200", "height": "338", "credit": "", "caption": ""}, "24": {"item_id": "3011329450", "image_id": "24", "src": "https://miro.medium.com/max/2400/1*JN-gVx1SkJ07qZk9IAVVHg.gif", "width": "1200", "height": "338", "credit": "", "caption": ""}, "25": {"item_id": "3011329450", "image_id": "25", "src": "https://miro.medium.com/max/2400/1*DHL2a28YL-CBY8Jx5dF8-w.gif", "width": "1200", "height": "338", "credit": "", "caption": ""}, "26": {"item_id": "3011329450", "image_id": "26", "src": "https://miro.medium.com/max/1912/1*eGtKKRvZfNm6mIdQlVXisA.png", "width": "956", "height": "113", "credit": "", "caption": ""}, "27": {"item_id": "3011329450", "image_id": "27", "src": "https://miro.medium.com/max/1912/1*y7Q5U2MjIji7pvt6DRzq3A.png", "width": "956", "height": "113", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 700}, "2911755133": {"item_id": "2911755133", "resolved_id": "2911755174", "given_url": "https://towardsdatascience.com/image-data-labelling-and-annotation-everything-you-need-to-know-86ede6c684b1?source=rss----7f60cf5620c9---4", "given_title": "Image Data Labelling and Annotation‚Ää‚Äî‚ÄäEverything you need to know", "favorite": "1", "status": "1", "time_added": "1583927927", "time_updated": "1638708525", "time_read": "1585739853", "time_favorited": "1583949996", "sort_id": 329, "resolved_title": "Image Data Labelling and Annotation‚Ää‚Äî‚ÄäEverything you need to know", "resolved_url": "https://towardsdatascience.com/image-data-labelling-and-annotation-everything-you-need-to-know-86ede6c684b1", "excerpt": "Data labelling is an essential step in a supervised machine learning task. Garbage In Garbage Out is a phrase commonly used in the machine learning community, which means that the quality of the training data determines the quality of the model.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1114", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/1*WE9PltBhSfl_gRPhOhyiUQ.jpeg", "tags": {"deep-learning": {"item_id": "2911755133", "tag": "deep-learning"}, "labeling": {"item_id": "2911755133", "tag": "labeling"}, "vision": {"item_id": "2911755133", "tag": "vision"}}, "authors": {"119290816": {"item_id": "2911755133", "author_id": "119290816", "name": "Sabina Pokhrel", "url": "https://medium.com/@sabinaa.pokhrel"}}, "image": {"item_id": "2911755133", "src": "https://miro.medium.com/fit/c/56/56/2*Q7OmhTLUFhxwbuoM-iyilg.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2911755133", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*Q7OmhTLUFhxwbuoM-iyilg.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2911755133", "image_id": "2", "src": "https://miro.medium.com/max/7500/1*WE9PltBhSfl_gRPhOhyiUQ.jpeg", "width": "3750", "height": "3000", "credit": "Photo by Debby Hudson on Unsplash", "caption": "Labeled bottle of blueberries"}, "3": {"item_id": "2911755133", "image_id": "3", "src": "https://miro.medium.com/max/5264/1*__7JNqqc-nQCu0-WduK6rw.png", "width": "2632", "height": "1664", "credit": "Original Photo by Patricia Jekki on Unsplash", "caption": "Bounding box for detected cars"}, "4": {"item_id": "2911755133", "image_id": "4", "src": "https://miro.medium.com/max/12000/1*GTRFOXAF5fUf853dHKgZEA.jpeg", "width": "6000", "height": "4000", "credit": "w", "caption": "Bounding Box showing co-ordinates x1, y1, x2, y2, width"}, "5": {"item_id": "2911755133", "image_id": "5", "src": "https://miro.medium.com/max/1344/1*mvAz7lcEqusO24AyXyIxLQ.png", "width": "672", "height": "1002", "credit": "", "caption": ""}, "6": {"item_id": "2911755133", "image_id": "6", "src": "https://miro.medium.com/max/1964/1*K-GgaRHr6a1QhMBBKlJ_nw.png", "width": "982", "height": "1282", "credit": "Source", "caption": "Polygonal segmentation of images from COCO dataset"}, "7": {"item_id": "2911755133", "image_id": "7", "src": "https://miro.medium.com/max/2048/1*P0NAnrDIsWSIWGkP-2M2eg.png", "width": "1024", "height": "512", "credit": "", "caption": ""}, "8": {"item_id": "2911755133", "image_id": "8", "src": "https://miro.medium.com/max/2048/1*UYNcOtnhDFTp8qHEu5nafQ.png", "width": "1024", "height": "512", "credit": "Source", "caption": "Semantic segmentation of images from Cityscapes Dataset"}, "9": {"item_id": "2911755133", "image_id": "9", "src": "https://miro.medium.com/max/12000/1*QEn9NeCy63TqxjhfCTlakA.jpeg", "width": "6000", "height": "4000", "credit": "Original Photo by Jose Carbajal on Unsplash", "caption": "3D Cuboid annotation on image"}, "10": {"item_id": "2911755133", "image_id": "10", "src": "https://miro.medium.com/max/4100/1*i7xQ1IciXpQ0XNer5hzg-g.png", "width": "2050", "height": "960", "credit": "Source", "caption": "Key-point annotation examples from COCO dataset"}, "11": {"item_id": "2911755133", "image_id": "11", "src": "https://miro.medium.com/max/10944/1*scjV5Tzr48a2H-OnXEVP7g.jpeg", "width": "5472", "height": "3648", "credit": "Original Photo by Karsten W√ºrth on Unsplash", "caption": "Line annotation on road"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 431}, "2993419586": {"item_id": "2993419586", "resolved_id": "2993419616", "given_url": "https://towardsdatascience.com/image-segmentation-with-six-lines-0f-code-acb870a462e8?source=rss----7f60cf5620c9---4", "given_title": "Image Segmentation With 5 Lines 0f Code", "favorite": "0", "status": "1", "time_added": "1590285677", "time_updated": "1638708525", "time_read": "1591029821", "time_favorited": "0", "sort_id": 330, "resolved_title": "Image Segmentation With 5 Lines 0f Code", "resolved_url": "https://towardsdatascience.com/image-segmentation-with-six-lines-0f-code-acb870a462e8", "excerpt": "Computer vision is evolving on a daily basis. Popular computer vision techniques such as image classification and object detection have been used extensively to solve a lot of computer vision problems. In image classification, an entire image is classified.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1155", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/800/1*9cLgTN_qKJusj54j2VbJrg.jpeg", "tags": {"deep-learning": {"item_id": "2993419586", "tag": "deep-learning"}, "images": {"item_id": "2993419586", "tag": "images"}, "vision": {"item_id": "2993419586", "tag": "vision"}}, "authors": {"152241588": {"item_id": "2993419586", "author_id": "152241588", "name": "Ayoola Olafenwa (she/her)", "url": "https://olafenwaayoola.medium.com"}}, "image": {"item_id": "2993419586", "src": "https://miro.medium.com/fit/c/56/56/1*PxmZHGM2czHVUMvRtJiFoA.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2993419586", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*PxmZHGM2czHVUMvRtJiFoA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2993419586", "image_id": "2", "src": "https://miro.medium.com/max/1600/1*9cLgTN_qKJusj54j2VbJrg.jpeg", "width": "800", "height": "533", "credit": "", "caption": ""}, "3": {"item_id": "2993419586", "image_id": "3", "src": "https://miro.medium.com/max/2560/1*tOTobkaJqQ3ZGuRQdxUCPQ.jpeg", "width": "1280", "height": "853", "credit": "CC0", "caption": "Source:Wikicommons.com"}, "4": {"item_id": "2993419586", "image_id": "4", "src": "https://miro.medium.com/max/2560/1*1R4gHSMLsWHlL8ehlR_R6A.jpeg", "width": "1280", "height": "853", "credit": "", "caption": "Semantic Segmentation"}, "5": {"item_id": "2993419586", "image_id": "5", "src": "https://miro.medium.com/max/2560/1*pgyg1yfWGtbDq8w-FmnR1A.jpeg", "width": "1280", "height": "853", "credit": "", "caption": "Instance Segmentation"}, "6": {"item_id": "2993419586", "image_id": "6", "src": "https://miro.medium.com/max/1140/1*RFhMuK1iVZYmgK36BFIQFg.jpeg", "width": "570", "height": "768", "credit": "CCO", "caption": "Source: pxhere.com"}, "7": {"item_id": "2993419586", "image_id": "7", "src": "https://miro.medium.com/max/1140/1*tuAi2R-hwfPD72Y66Uum7g.jpeg", "width": "570", "height": "768", "credit": "", "caption": ""}, "8": {"item_id": "2993419586", "image_id": "8", "src": "https://miro.medium.com/max/1140/1*qXk459MSvWAQBahxV1wJ7Q.jpeg", "width": "570", "height": "768", "credit": "", "caption": ""}, "9": {"item_id": "2993419586", "image_id": "9", "src": "https://miro.medium.com/max/1272/1*4lheOrxSzl4iFVHPK1_hpw.png", "width": "636", "height": "863", "credit": "", "caption": ""}, "10": {"item_id": "2993419586", "image_id": "10", "src": "https://miro.medium.com/max/1600/1*hO_md3xNtcncjAmGrTwxYA.jpeg", "width": "800", "height": "533", "credit": "CC0", "caption": "Source: wikicommons.com"}, "11": {"item_id": "2993419586", "image_id": "11", "src": "https://miro.medium.com/max/1600/1*JmVwviEBcAgkuoVC_VwdOw.jpeg", "width": "800", "height": "533", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 447}, "2819932756": {"item_id": "2819932756", "resolved_id": "2819932769", "given_url": "https://www.futurity.org/colorectal-cancer-machine-learning-2227692-2/", "given_title": "Imaging technique spots colorectal tumors with 100% accuracy", "favorite": "0", "status": "1", "time_added": "1576092955", "time_updated": "1706620607", "time_read": "1576340937", "time_favorited": "0", "sort_id": 331, "resolved_title": "Imaging technique spots colorectal tumors with 100% accuracy", "resolved_url": "https://www.futurity.org/?p=2227692", "excerpt": "A new imaging technique in development provides accurate, real-time, computer-aided diagnosis of colorectal cancer, researchers say.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "802", "lang": "en", "time_to_read": 4, "top_image_url": "https://www.futurity.org/wp/wp-content/uploads/2019/12/colorectal-cancer-colon_1600.jpg", "tags": {"deep-learning": {"item_id": "2819932756", "tag": "deep-learning"}, "exercise-health-medicine": {"item_id": "2819932756", "tag": "exercise-health-medicine"}}, "authors": {"95107193": {"item_id": "2819932756", "author_id": "95107193", "name": "Beth Miller-WUSTL", "url": "https://www.futurity.org/author/beth-miller/"}}, "image": {"item_id": "2819932756", "src": "https://www.futurity.org/wp/wp-content/uploads/2019/12/colorectal-cancer-colon_1600.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2819932756", "image_id": "1", "src": "https://www.futurity.org/wp/wp-content/uploads/2019/12/colorectal-cancer-colon_1600.jpg", "width": "0", "height": "0", "credit": "Credit: Getty Images", "caption": ""}}, "listen_duration_estimate": 310}, "2995977089": {"item_id": "2995977089", "resolved_id": "2995977103", "given_url": "https://towardsdatascience.com/implementing-deep-convolutional-generative-adversarial-networks-dcgan-573df2b63c0d?source=rss----7f60cf5620c9---4", "given_title": "Implementing Deep Convolutional Generative Adversarial Networks (DCGAN)", "favorite": "0", "status": "1", "time_added": "1590489140", "time_updated": "1638708525", "time_read": "1591030054", "time_favorited": "0", "sort_id": 332, "resolved_title": "Implementing Deep Convolutional Generative Adversarial Networks (DCGAN)", "resolved_url": "https://towardsdatascience.com/implementing-deep-convolutional-generative-adversarial-networks-dcgan-573df2b63c0d", "excerpt": "Deep Convolutional Generative Adversarial Networks or DCGANs are the ‚Äòimage version‚Äô of the most fundamental implementation of GANs.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "751", "lang": "en", "time_to_read": 3, "top_image_url": "https://miro.medium.com/freeze/max/460/1*fN-q2XG9CTii8S6Xh8SIyg.gif", "tags": {"deep-learning": {"item_id": "2995977089", "tag": "deep-learning"}}, "authors": {"142739226": {"item_id": "2995977089", "author_id": "142739226", "name": "Rohan Jagtap", "url": "https://rojagtap.medium.com"}}, "image": {"item_id": "2995977089", "src": "https://miro.medium.com/fit/c/56/56/2*gnqkz70uGsyIy7VBNrVXEQ.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2995977089", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*gnqkz70uGsyIy7VBNrVXEQ.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2995977089", "image_id": "2", "src": "https://miro.medium.com/max/920/1*fN-q2XG9CTii8S6Xh8SIyg.gif", "width": "460", "height": "460", "credit": "", "caption": "Training a DCGAN on MNIST by Author"}, "3": {"item_id": "2995977089", "image_id": "3", "src": "https://miro.medium.com/max/688/1*KGrCz7aav02KoGuO6znO0w.gif", "width": "344", "height": "386", "credit": "", "caption": "Transposed Convolution, no padding, no strides via Dumoulin et. al"}, "4": {"item_id": "2995977089", "image_id": "4", "src": "https://miro.medium.com/max/576/1*UL2JATd6ECp_aDrIXuk8Ow.png", "width": "288", "height": "288", "credit": "", "caption": "Results @50 Epochs by Author"}, "5": {"item_id": "2995977089", "image_id": "5", "src": "https://miro.medium.com/max/1228/1*rzCI1KhmY4jcNjHFWQKH1Q.png", "width": "614", "height": "596", "credit": "", "caption": "Results @100 Epochs by Author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 291}, "3840186225": {"item_id": "3840186225", "resolved_id": "3840055593", "given_url": "https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/?utm_source=twitter&utm_medium=organic_social&utm_campaign=segmentanything&utm_content=gif", "given_title": "Introducing Segment Anything: Working toward the first foundation model for", "favorite": "0", "status": "1", "time_added": "1680793754", "time_updated": "1680908481", "time_read": "1680908481", "time_favorited": "0", "sort_id": 333, "resolved_title": "Introducing Segment Anything: Working toward the first foundation model for image segmentation", "resolved_url": "https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/", "excerpt": "Segmentation ‚Äî identifying which image pixels belong to an object ‚Äî is a core task in computer vision and is used in a broad array of applications, from analyzing scientific imagery to editing photos.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1930", "lang": "en", "time_to_read": 9, "top_image_url": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/338318848_238475658638014_6444534044370711549_n.gif?_nc_cat=108&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=feCOAaD69isAX_QcqPX&_nc_ht=scontent-iad3-1.xx&oh=00_AfAEqqYcSdMMZgrdRhmFJSVeT_OV0zfbb06bX_GMnspk-w&oe=64332CE9", "tags": {"deep-learning": {"item_id": "3840186225", "tag": "deep-learning"}, "image-segmentation": {"item_id": "3840186225", "tag": "image-segmentation"}, "machine-vision": {"item_id": "3840186225", "tag": "machine-vision"}}, "image": {"item_id": "3840186225", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/338558258_1349701259095991_4358060436604292355_n.png?_nc_cat=104&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=BFL6nEDeLysAX9MbPLA&_nc_ht=scontent-iad3-1.xx&oh=00_AfBuZzxOJZfjyBhosGDZtIBnHcjsH82FjhU2K3HWnlBmDw&oe=64323D49", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3840186225", "image_id": "1", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/338558258_1349701259095991_4358060436604292355_n.png?_nc_cat=104&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=BFL6nEDeLysAX9MbPLA&_nc_ht=scontent-iad3-1.xx&oh=00_AfBuZzxOJZfjyBhosGDZtIBnHcjsH82FjhU2K3HWnlBmDw&oe=64323D49", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3840186225", "image_id": "2", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/338490494_577019134187999_95483266747832988_n.png?_nc_cat=104&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=mCgg7vGPoR4AX_c8WIw&_nc_ht=scontent-iad3-1.xx&oh=00_AfC3WeDFerrnu4DzNUjurSLTPt_wZ3M_XDULNYO1JC-zPQ&oe=6432C1BC", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3840186225", "image_id": "3", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/338713754_989652268682274_1644116157216484057_n.png?_nc_cat=108&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=r4P02ca0zPQAX-eC-Oo&_nc_ht=scontent-iad3-1.xx&oh=00_AfDOWhS0MHEhyzRpyAfH_Vy3CqPZgCmnE9ViBH-DBVeuAQ&oe=6432097F", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 747}, "1641647761": {"item_id": "1641647761", "resolved_id": "1641647761", "given_url": "http://code.flickr.net/2017/03/07/introducing-similarity-search-at-flickr/", "given_title": "Introducing Similarity Search at Flickr | code.flickr.com", "favorite": "1", "status": "1", "time_added": "1527389027", "time_updated": "1638708525", "time_read": "1527701000", "time_favorited": "1527700999", "sort_id": 334, "resolved_title": "Introducing Similarity Search at Flickr", "resolved_url": "https://code.flickr.net/2017/03/07/introducing-similarity-search-at-flickr/", "excerpt": "At Flickr, we understand that the value in our image corpus is only unlocked when our members can find photos and photographers that inspire them, so we strive to enable the discovery and appreciation of new photos. To further that effort, today we are introducing similarity search on Flickr.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2395", "lang": "en", "time_to_read": 11, "amp_url": "https://code.flickr.net/2017/03/07/introducing-similarity-search-at-flickr/amp/", "tags": {"deep-learning": {"item_id": "1641647761", "tag": "deep-learning"}, "machine-learning": {"item_id": "1641647761", "tag": "machine-learning"}}, "authors": {"64737142": {"item_id": "1641647761", "author_id": "64737142", "name": "Clayton Mellina", "url": "https://code.flickr.net/author/claytonhoo/"}}, "image": {"item_id": "1641647761", "src": "https://wp.flickr.net/wp-content/uploads/sites/3/2017/03/color_sim.png?w=800", "width": "800", "height": "343"}, "images": {"1": {"item_id": "1641647761", "image_id": "1", "src": "https://wp.flickr.net/wp-content/uploads/sites/3/2017/03/color_sim.png?w=800", "width": "800", "height": "343", "credit": "", "caption": ""}, "2": {"item_id": "1641647761", "image_id": "2", "src": "https://wp.flickr.net/wp-content/uploads/sites/3/2017/03/texture_sim.png?w=800", "width": "800", "height": "343", "credit": "", "caption": ""}, "3": {"item_id": "1641647761", "image_id": "3", "src": "https://wp.flickr.net/wp-content/uploads/sites/3/2017/03/semantic_sim.png?w=800", "width": "800", "height": "344", "credit": "", "caption": ""}, "4": {"item_id": "1641647761", "image_id": "4", "src": "https://wp.flickr.net/wp-content/uploads/sites/3/2017/03/nn_tag.png?w=800", "width": "800", "height": "230", "credit": "", "caption": ""}, "5": {"item_id": "1641647761", "image_id": "5", "src": "https://wp.flickr.net/wp-content/uploads/sites/3/2017/03/nn_feature.png?w=800", "width": "800", "height": "458", "credit": "", "caption": ""}, "6": {"item_id": "1641647761", "image_id": "6", "src": "https://wp.flickr.net/wp-content/uploads/sites/3/2017/03/retrieval.png?w=800", "width": "800", "height": "366", "credit": "", "caption": ""}, "7": {"item_id": "1641647761", "image_id": "7", "src": "https://wp.flickr.net/wp-content/uploads/sites/3/2017/03/lopq.png?w=800", "width": "800", "height": "689", "credit": "", "caption": ""}}, "listen_duration_estimate": 927}, "3086050637": {"item_id": "3086050637", "resolved_id": "3086030562", "given_url": "https://www.kdnuggets.com/2020/08/introduction-federated-learning.html", "given_title": "Introduction to Federated Learning", "favorite": "0", "status": "1", "time_added": "1597927541", "time_updated": "1706624319", "time_read": "1606680857", "time_favorited": "0", "sort_id": 335, "resolved_title": "Introduction to Federated Learning", "resolved_url": "https://www.kdnuggets.com/introduction-to-federated-learning.html/", "excerpt": "There are over 5 billion mobile device users all over the world. Such users generate massive amounts of data‚Äîvia cameras, microphones, and other sensors like accelerometers‚Äîwhich can, in turn, be used for building intelligent applications.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1893", "lang": "en", "time_to_read": 9, "top_image_url": "https://i.ibb.co/ngF03zM/gad-federated-0.jpg", "tags": {"deep-learning": {"item_id": "3086050637", "tag": "deep-learning"}, "federated-learning": {"item_id": "3086050637", "tag": "federated-learning"}}, "authors": {"85595834": {"item_id": "3086050637", "author_id": "85595834", "name": "Ahmed Gad", "url": "https://www.kdnuggets.com/author/ahmed-gad"}}, "image": {"item_id": "3086050637", "src": "https://i.ibb.co/ngF03zM/gad-federated-0.jpg", "width": "100", "height": "0"}, "images": {"1": {"item_id": "3086050637", "image_id": "1", "src": "https://i.ibb.co/ngF03zM/gad-federated-0.jpg", "width": "100", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3086050637", "image_id": "2", "src": "https://i.ibb.co/x2ZZcj5/gad-federated-1.png", "width": "70", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3086050637", "image_id": "3", "src": "https://i.ibb.co/MMQgYj6/gad-federated-2.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3086050637", "image_id": "4", "src": "https://i.ibb.co/ZKW0bQ5/gad-federated-3.jpg", "width": "100", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 733}, "3343445922": {"item_id": "3343445922", "resolved_id": "3343445935", "given_url": "https://towardsdatascience.com/introduction-to-object-detection-model-evaluation-3a789220a9bf?source=rss----7f60cf5620c9---4", "given_title": "Introduction to Object Detection Model Evaluation", "favorite": "0", "status": "1", "time_added": "1622242320", "time_updated": "1638708525", "time_read": "1622249177", "time_favorited": "0", "sort_id": 336, "resolved_title": "Introduction to Object Detection Model Evaluation", "resolved_url": "https://towardsdatascience.com/introduction-to-object-detection-model-evaluation-3a789220a9bf", "excerpt": "Evaluating object detection models is not straightforward because each image can have many objects and each object can belong to different classes. This means that we need to measure if the model found all the objects and also a way to verify if the found objects belong to the correct class.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1568", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/1200/1*wlIkpmotfZ0NGaCiEIObCw.jpeg", "tags": {"deep-learning": {"item_id": "3343445922", "tag": "deep-learning"}, "machine-learning": {"item_id": "3343445922", "tag": "machine-learning"}, "object-detection": {"item_id": "3343445922", "tag": "object-detection"}}, "authors": {"66538825": {"item_id": "3343445922", "author_id": "66538825", "name": "D√©borah Mesquita", "url": "https://medium.com/@dehhmesquita"}}, "image": {"item_id": "3343445922", "src": "https://miro.medium.com/fit/c/56/56/1*cbGf0e5_c9aAxo3zo3p4Qg.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3343445922", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*cbGf0e5_c9aAxo3zo3p4Qg.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3343445922", "image_id": "2", "src": "https://miro.medium.com/max/3840/1*wlIkpmotfZ0NGaCiEIObCw.jpeg", "width": "1920", "height": "1280", "credit": "", "caption": "Objects in supermarket shelf ‚Äî coutersy of charlesgs"}, "3": {"item_id": "3343445922", "image_id": "3", "src": "https://miro.medium.com/max/600/0*ui6Mw_piBHW1z1jY.jpg", "width": "300", "height": "225", "credit": "", "caption": "Example of bounding boxes, from wikipedia"}, "4": {"item_id": "3343445922", "image_id": "4", "src": "https://miro.medium.com/max/600/0*vZDmQzwFUDFL81wi.png", "width": "300", "height": "234", "credit": "", "caption": "How the Intersection over Union is calculated ‚Äî Wikipedia"}, "5": {"item_id": "3343445922", "image_id": "5", "src": "https://miro.medium.com/max/600/0*MDIRMyL61v-E75DC.png", "width": "300", "height": "124", "credit": "", "caption": "Some examples of IoU values ‚Äî Wikipedia"}, "6": {"item_id": "3343445922", "image_id": "6", "src": "https://miro.medium.com/max/1380/0*n57613St_lu0KJ_5.png", "width": "690", "height": "123", "credit": "", "caption": "Computing the Precision and Recall for the bounding boxes ‚Äî Image from Harshit Kumar article"}, "7": {"item_id": "3343445922", "image_id": "7", "src": "https://miro.medium.com/max/1234/1*qPN1veJJrJss-MaCnFuHXA.png", "width": "617", "height": "327", "credit": "", "caption": "TIDE Errors ‚Äî Tide: A general toolbox for identifying object detection errors"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 607}, "3691820094": {"item_id": "3691820094", "resolved_id": "3691820140", "given_url": "https://towardsdatascience.com/ivfpq-hnsw-for-billion-scale-similarity-search-89ff2f89d90e?source=rss----7f60cf5620c9---4", "given_title": "IVFPQ   HNSW for Billion-scale Similarity Search | by Peggy Chang | Towards", "favorite": "0", "status": "1", "time_added": "1661799865", "time_updated": "1665774109", "time_read": "1665774109", "time_favorited": "0", "sort_id": 337, "resolved_title": "IVFPQ + HNSW for Billion-scale Similarity Search", "resolved_url": "https://towardsdatascience.com/ivfpq-hnsw-for-billion-scale-similarity-search-89ff2f89d90e", "excerpt": "We learned about IVFPQ in the previous article, where the inverted file index (IVF) is combined with product quantization (PQ) to create an effective method for large-scale similarity search.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3819", "lang": "en", "time_to_read": 17, "top_image_url": "https://miro.medium.com/max/1200/0*5cS2Mbgb8mylgGEH", "tags": {"deep-learning": {"item_id": "3691820094", "tag": "deep-learning"}, "machine-learning": {"item_id": "3691820094", "tag": "machine-learning"}, "search": {"item_id": "3691820094", "tag": "search"}}, "authors": {"155494397": {"item_id": "3691820094", "author_id": "155494397", "name": "Peggy Chang", "url": "https://peggy1502.medium.com"}}, "image": {"item_id": "3691820094", "src": "https://miro.medium.com/max/1400/0*5cS2Mbgb8mylgGEH", "width": "700", "height": "0"}, "images": {"1": {"item_id": "3691820094", "image_id": "1", "src": "https://miro.medium.com/max/1400/0*5cS2Mbgb8mylgGEH", "width": "700", "height": "0", "credit": "Paul Talbot on Unsplash", "caption": ""}, "2": {"item_id": "3691820094", "image_id": "2", "src": "https://miro.medium.com/max/1126/1*JwTICgHIh6vs_1O011g2Ow.png", "width": "563", "height": "0", "credit": "", "caption": "All images are by the author unless otherwise specified"}, "3": {"item_id": "3691820094", "image_id": "3", "src": "https://miro.medium.com/max/1020/1*daNXIidBtHpNHyOnMo5LMA.png", "width": "510", "height": "0", "credit": "", "caption": "An example of a Delaunay graph"}, "4": {"item_id": "3691820094", "image_id": "4", "src": "https://miro.medium.com/max/764/1*VOjUe1ufbAt2YN5RgLrjkg.png", "width": "382", "height": "0", "credit": "", "caption": "Constructing an NSW graph with M=3"}, "5": {"item_id": "3691820094", "image_id": "5", "src": "https://miro.medium.com/max/766/1*mWe6b0Z82HremetXRlQV0A.png", "width": "383", "height": "0", "credit": "", "caption": "Example of an NSW graph"}, "6": {"item_id": "3691820094", "image_id": "6", "src": "https://miro.medium.com/max/1362/1*GoHviEFZ7RzyZ9yIGNnqzw.png", "width": "681", "height": "0", "credit": "Example 1", "caption": "Searching for the nearest neighbor on an NSW graph"}, "7": {"item_id": "3691820094", "image_id": "7", "src": "https://miro.medium.com/max/860/1*9vtkt5FobU6sYH_G8-2wXw.png", "width": "430", "height": "0", "credit": "Example 2", "caption": "Searching for the nearest neighbor on an NSW graph"}, "8": {"item_id": "3691820094", "image_id": "8", "src": "https://miro.medium.com/max/1138/1*063HYp53Z48c6ulA-l_mYg.png", "width": "569", "height": "0", "credit": "", "caption": "A linked list with sorted elements"}, "9": {"item_id": "3691820094", "image_id": "9", "src": "https://miro.medium.com/max/1222/1*1Gigm34wH9drlhg6Vvm6SQ.png", "width": "611", "height": "0", "credit": "", "caption": "The skip list data structure"}, "10": {"item_id": "3691820094", "image_id": "10", "src": "https://miro.medium.com/max/1226/1*xaqTzKULefkMU2RytJIqvA.png", "width": "613", "height": "0", "credit": "", "caption": "Searching for 91 on a skip list"}, "11": {"item_id": "3691820094", "image_id": "11", "src": "https://miro.medium.com/max/1004/1*CCA6dJk5JllrvbRXf3R3BA.png", "width": "502", "height": "0", "credit": "", "caption": "An example of HNSW"}, "12": {"item_id": "3691820094", "image_id": "12", "src": "https://miro.medium.com/max/862/1*YbbzXhsPjFOgzmfwrj6k_A.png", "width": "431", "height": "0", "credit": "", "caption": "The distribution of ‚Ñì from a random dataset of 500,000 vectors"}, "13": {"item_id": "3691820094", "image_id": "13", "src": "https://miro.medium.com/max/738/1*xS8hgVTs10h7pHmbUiM9gA.png", "width": "369", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "3691820094", "image_id": "14", "src": "https://miro.medium.com/max/866/1*E7aUllRqLtiE6fOskUGJaw.png", "width": "433", "height": "0", "credit": "", "caption": "Heuristic selection"}, "15": {"item_id": "3691820094", "image_id": "15", "src": "https://miro.medium.com/max/992/1*KChgy3e2F7xH6XanW_Tvgg.png", "width": "496", "height": "0", "credit": "", "caption": "Searching for the nearest neighbor on an HNSW graph"}, "16": {"item_id": "3691820094", "image_id": "16", "src": "https://miro.medium.com/max/1338/1*b17ImiEDhgheL-GS0YQkAg.png", "width": "669", "height": "0", "credit": "ms", "caption": "Average search time"}, "17": {"item_id": "3691820094", "image_id": "17", "src": "https://miro.medium.com/max/1334/1*tyr5lc7QWHRKSrQjWMwr-w.png", "width": "667", "height": "0", "credit": "", "caption": "The recall performance for 1,000 query vectors."}, "18": {"item_id": "3691820094", "image_id": "18", "src": "https://miro.medium.com/max/1086/1*1nhvbaXBDCj4a4H128eE2Q.png", "width": "543", "height": "0", "credit": "s", "caption": "Construction time"}, "19": {"item_id": "3691820094", "image_id": "19", "src": "https://miro.medium.com/max/636/1*JmOifff902s8E1yvduWUsw.png", "width": "318", "height": "0", "credit": "MB", "caption": "Index size"}, "20": {"item_id": "3691820094", "image_id": "20", "src": "https://miro.medium.com/max/1340/1*oIOZFF1JlomFUOum9AKcag.png", "width": "670", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "3691820094", "image_id": "21", "src": "https://miro.medium.com/max/1338/1*sjR27h5EyeOI7QD4y0-I-A.png", "width": "669", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "3691820094", "image_id": "22", "src": "https://miro.medium.com/max/766/1*ZrHpA--9dhkxYtjUNbYJWQ.png", "width": "383", "height": "0", "credit": "MB", "caption": "Index size"}, "23": {"item_id": "3691820094", "image_id": "23", "src": "https://miro.medium.com/max/958/1*EufbEOPOvoxO-aXCYDbgwA.png", "width": "479", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "3691820094", "image_id": "24", "src": "https://miro.medium.com/max/1104/1*1RszF_jhCG1R0o_UuntVVw.png", "width": "552", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "3691820094", "image_id": "25", "src": "https://miro.medium.com/max/1014/1*ijxlhBBmJbTysKyDymSAyw.png", "width": "507", "height": "0", "credit": "", "caption": ""}, "26": {"item_id": "3691820094", "image_id": "26", "src": "https://miro.medium.com/max/1130/1*t7ahLNz4QX8-wJFUXiv1LA.png", "width": "565", "height": "0", "credit": "", "caption": ""}, "27": {"item_id": "3691820094", "image_id": "27", "src": "https://miro.medium.com/max/1350/1*UudzimME44itTsokst2qOA.png", "width": "675", "height": "0", "credit": "", "caption": "The effect of increasing nprobe for IVF-based indexes. The green and orange bubbles move towards the top and right when nprobe increases."}, "28": {"item_id": "3691820094", "image_id": "28", "src": "https://miro.medium.com/max/1400/0*IX57wpmMDGqwRTb_", "width": "700", "height": "0", "credit": "Japheth Mast on Unsplash", "caption": ""}, "29": {"item_id": "3691820094", "image_id": "29", "src": "https://miro.medium.com/fit/c/40/40/1*4RiPT4MGaV1PUkLGaNirFQ.png", "width": "20", "height": "20", "credit": "", "caption": ""}, "30": {"item_id": "3691820094", "image_id": "30", "src": "https://miro.medium.com/fit/c/388/388/1*c0gU2CkZ880j1_pfnGS1fw.png", "width": "194", "height": "194", "credit": "", "caption": ""}, "31": {"item_id": "3691820094", "image_id": "31", "src": "https://miro.medium.com/fit/c/388/388/1*2hR-6vz3mdHIh8hS0GXanA.png", "width": "194", "height": "194", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1478}, "1519703433": {"item_id": "1519703433", "resolved_id": "1519703433", "given_url": "http://jalammar.github.io/", "given_title": "Jay Alammar ‚Äì Visualizing machine learning one concept at a time", "favorite": "0", "status": "1", "time_added": "1584704861", "time_updated": "1638708525", "time_read": "1585739647", "time_favorited": "0", "sort_id": 338, "resolved_title": "Jay Alammar ‚Äì Visualizing machine learning one concept at a time.", "resolved_url": "https://jalammar.github.io/", "excerpt": "Article: What‚Äôs the big deal with Generative AI? Is it the future or the present?", "is_article": "0", "is_index": "1", "has_video": "1", "has_image": "1", "word_count": "46", "lang": "", "tags": {"bert": {"item_id": "1519703433", "tag": "bert"}, "deep-learning": {"item_id": "1519703433", "tag": "deep-learning"}}, "authors": {"83096926": {"item_id": "1519703433", "author_id": "83096926", "name": "Jay Alammar", "url": ""}}, "image": {"item_id": "1519703433", "src": "https://jalammar.github.io/images/gen-ai-hero-image.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1519703433", "image_id": "1", "src": "https://jalammar.github.io/images/gen-ai-hero-image.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "1519703433", "video_id": "1", "src": "https://www.youtube.com/embed/AeW9r3lopp0", "width": "560", "height": "315", "type": "1", "vid": "AeW9r3lopp0", "length": "0"}, "2": {"item_id": "1519703433", "video_id": "2", "src": "https://www.youtube.com/embed/oTqG2DbXl2Y", "width": "560", "height": "315", "type": "1", "vid": "oTqG2DbXl2Y", "length": "0"}}, "listen_duration_estimate": 18}, "2629159612": {"item_id": "2629159612", "resolved_id": "2621664015", "given_url": "https://www.pyimagesearch.com/2019/06/10/keras-mask-r-cnn/?utm_source=facebook&utm_medium=ad-10-6-2019&utm_campaign=10+June+2019+BP+-+Traffic&utm_content=GIF+-+Traffic+-+Image+1&fbid_campaign=6113968903246&fbid_adset=6113968904446&utm_adset=10+June+2019+BP+-+Email+List+-+United+States+-+18%2B&fbid_ad=6113968907246&fbclid=IwAR2rlxdNju0U5dTkZepqTZKoM8CxPY_RWIjbpF11nxIyZGx07wsCcEXNIpo", "given_title": "Keras Mask R-CNN - PyImageSearch", "favorite": "0", "status": "1", "time_added": "1560778160", "time_updated": "1638708525", "time_read": "1567131457", "time_favorited": "0", "sort_id": 339, "resolved_title": "Keras Mask R-CNN", "resolved_url": "https://www.pyimagesearch.com/2019/06/10/keras-mask-r-cnn/", "excerpt": "In this tutorial, you will learn how to use Keras and Mask R-CNN to perform instance segmentation (both with and without a GPU).", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3323", "lang": "en", "time_to_read": 15, "top_image_url": "https://www.pyimagesearch.com/wp-content/uploads/2019/06/keras_mask_rcnn_featured.jpg", "tags": {"deep-learning": {"item_id": "2629159612", "tag": "deep-learning"}, "vision": {"item_id": "2629159612", "tag": "vision"}}, "authors": {"76030979": {"item_id": "2629159612", "author_id": "76030979", "name": "Adrian Rosebrock", "url": "https://www.pyimagesearch.com/author/adrian/"}}, "image": {"item_id": "2629159612", "src": "https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/keras-mask-rcnn/keras_mask_rcnn_animation.gif", "width": "600", "height": "600"}, "images": {"1": {"item_id": "2629159612", "image_id": "1", "src": "https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/keras-mask-rcnn/keras_mask_rcnn_animation.gif", "width": "600", "height": "600", "credit": "", "caption": ""}, "2": {"item_id": "2629159612", "image_id": "2", "src": "https://www.pyimagesearch.com/wp-content/uploads/2020/01/source-code-icon.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2629159612", "image_id": "3", "src": "https://pyimagesearch.com/wp-content/uploads/2018/11/mask_rcnn_arch.png", "width": "600", "height": "327", "credit": "", "caption": "Figure 1: The Mask R-CNN architecture by He et al. enables object detection and pixel-wise instance segmentation. This blog post uses Keras to work with a Mask R-CNN model trained on the COCO dataset."}, "4": {"item_id": "2629159612", "image_id": "4", "src": "https://pyimagesearch.com/wp-content/uploads/2019/06/keras_mask_rcnn_30th_birthday.jpg", "width": "424", "height": "600", "credit": "truck", "caption": "Figure 2: The Mask R-CNN model trained on COCO created a pixel-wise map of the Jurassic Park jeep"}, "5": {"item_id": "2629159612", "image_id": "5", "src": "https://pyimagesearch.com/wp-content/uploads/2019/06/keras_mask_rcnn_couch.jpg", "width": "424", "height": "600", "credit": "", "caption": "Figure 3: My dog, Janie, has been segmented from the couch and chair using a Keras and Mask R-CNN deep learning model."}, "6": {"item_id": "2629159612", "image_id": "6", "src": "https://pyimagesearch.com/wp-content/uploads/2019/06/keras_mask_rcnn_page_az.jpg", "width": "424", "height": "600", "credit": "created with Keras, TensorFlow, and Matterport‚Äôs Mask R-CNN implementation", "caption": "Figure 4: A Mask R-CNN segmented image"}, "7": {"item_id": "2629159612", "image_id": "7", "src": "https://pyimagesearch.com/wp-content/uploads/2019/06/keras_mask_rcnn_ybor_city.jpg", "width": "421", "height": "600", "credit": "", "caption": "Figure 5: Keras + Mask R-CNN with Python of a picture from Ybor City."}, "8": {"item_id": "2629159612", "image_id": "8", "src": "https://www.pyimagesearch.com/wp-content/uploads/2020/01/cta-source-guide-1.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1286}, "964205254": {"item_id": "964205254", "resolved_id": "964205254", "given_url": "https://github.com/kjw0612/awesome-rnn", "given_title": "kjw0612/awesome-rnn: Recurrent Neural Network - A curated list of resources", "favorite": "0", "status": "1", "time_added": "1527454464", "time_updated": "1638708525", "time_read": "1527461126", "time_favorited": "0", "sort_id": 340, "resolved_title": "Awesome Recurrent Neural Networks", "resolved_url": "https://github.com/kjw0612/awesome-rnn", "excerpt": "Please feel free to pull requests, email Myungsub Choi (cms6539@gmail.com) or join our chats to add links.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3623", "lang": "en", "time_to_read": 16, "top_image_url": "https://opengraph.githubassets.com/7e7a53c07055db1538e5a018a6cd910b5fca93e571e03e094aefe2394840a3e0/kjw0612/awesome-rnn", "tags": {"deep-learning": {"item_id": "964205254", "tag": "deep-learning"}, "rnns": {"item_id": "964205254", "tag": "rnns"}}, "authors": {"30972199": {"item_id": "964205254", "author_id": "30972199", "name": "Machine Learning", "url": "https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/"}}, "image": {"item_id": "964205254", "src": "https://camo.githubusercontent.com/5dbac0213da25c445bd11f168587c11a200ba153ef3014e8408e462e410169b3/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667", "width": "0", "height": "0"}, "images": {"1": {"item_id": "964205254", "image_id": "1", "src": "https://camo.githubusercontent.com/5dbac0213da25c445bd11f168587c11a200ba153ef3014e8408e462e410169b3/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 1402}, "3430179565": {"item_id": "3430179565", "resolved_id": "3430179565", "given_url": "https://laion.ai/laion-400-open-dataset/", "given_title": "Laion-400M: open-source dataset of 400M image-text pairs", "favorite": "0", "status": "1", "time_added": "1631496431", "time_updated": "1631623217", "time_read": "1631623217", "time_favorited": "0", "sort_id": 341, "resolved_title": "", "resolved_url": "https://laion.ai/laion-400-open-dataset/", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"datasets": {"item_id": "3430179565", "tag": "datasets"}, "deep-learning": {"item_id": "3430179565", "tag": "deep-learning"}}, "listen_duration_estimate": 0}, "2877516896": {"item_id": "2877516896", "resolved_id": "2877516919", "given_url": "https://www.kdnuggets.com/2020/02/large-scale-adversarial-representation-learning.html", "given_title": "Large Scale Adversarial Representation Learning", "favorite": "0", "status": "1", "time_added": "1581107500", "time_updated": "1691366676", "time_read": "1582142478", "time_favorited": "0", "sort_id": 342, "resolved_title": "Large Scale Adversarial Representation Learning", "resolved_url": "https://www.kdnuggets.com/large-scale-adversarial-representation-learning.html/", "excerpt": "This post is part of the \"superblog\" that is the collective work of the participants of the GAN workshop organized by Aggregate Intellect. This post serves as a proof of work, and covers some of the concepts covered in the workshop in addition to advanced concepts pursued by the participants.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1618", "lang": "en", "time_to_read": 7, "top_image_url": "https://aisc.ai.science/static/post-assets/gan-collaborative-post/image19.png", "tags": {"adversarial": {"item_id": "2877516896", "tag": "adversarial"}, "deep-learning": {"item_id": "2877516896", "tag": "deep-learning"}}, "authors": {"128017906": {"item_id": "2877516896", "author_id": "128017906", "name": "Most Husne Jahan", "url": ""}}, "image": {"item_id": "2877516896", "src": "https://aisc.ai.science/static/post-assets/gan-collaborative-post/image19.png", "width": "100", "height": "0"}, "images": {"1": {"item_id": "2877516896", "image_id": "1", "src": "https://aisc.ai.science/static/post-assets/gan-collaborative-post/image19.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2877516896", "image_id": "2", "src": "https://aisc.ai.science/static/post-assets/gan-collaborative-post/image16.png", "width": "80", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2877516896", "image_id": "3", "src": "https://aisc.ai.science/static/post-assets/gan-collaborative-post/image13.png", "width": "80", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2877516896", "image_id": "4", "src": "https://www.kdnuggets.com/wp-content/uploads/gan-superblog-2-table.jpg", "width": "100", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2877516896", "image_id": "5", "src": "https://aisc.ai.science/static/post-assets/gan-collaborative-post/image22.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2877516896", "image_id": "6", "src": "https://aisc.ai.science/static/post-assets/gan-collaborative-post/image17.png", "width": "90", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2877516896", "image_id": "7", "src": "https://aisc.ai.science/static/post-assets/gan-collaborative-post/image24.png", "width": "90", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2877516896", "image_id": "8", "src": "https://aisc.ai.science/static/post-assets/gan-collaborative-post/image28.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2877516896", "image_id": "9", "src": "https://aisc.ai.science/static/post-assets/gan-collaborative-post/image23.png", "width": "100", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2877516896", "image_id": "10", "src": "https://aisc.ai.science/static/post-assets/gan-collaborative-post/image25.png", "width": "100", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 626}, "2396187448": {"item_id": "2396187448", "resolved_id": "2396187448", "given_url": "https://dev.to/rosejcday/learning-the-differences-between-softmax-and-sigmoid-for-image-classification--59c", "given_title": "Learning the Differences between Softmax and Sigmoid for Image Classificati", "favorite": "0", "status": "1", "time_added": "1542898968", "time_updated": "1673901884", "time_read": "1567133190", "time_favorited": "0", "sort_id": 343, "resolved_title": "Learning the Differences between Softmax and Sigmoid for Image Classification", "resolved_url": "https://dev.to/rosejcday/learning-the-differences-between-softmax-and-sigmoid-for-image-classification--59c", "excerpt": "Happy second week of the #100DaysofCode challenge and Happy Thanksgiving, check out week one where I discussed parsing CSV rows into separate text files.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "732", "lang": "en", "time_to_read": 3, "top_image_url": "https://res.cloudinary.com/practicaldev/image/fetch/s--WfZlM2pz--/c_imagga_scale,f_auto,fl_progressive,h_500,q_auto,w_1000/https://images6.alphacoders.com/368/368992.jpg", "tags": {"activations": {"item_id": "2396187448", "tag": "activations"}, "deep-learning": {"item_id": "2396187448", "tag": "deep-learning"}, "image-classification": {"item_id": "2396187448", "tag": "image-classification"}}, "authors": {"2638393": {"item_id": "2396187448", "author_id": "2638393", "name": "work", "url": ""}, "3260078": {"item_id": "2396187448", "author_id": "3260078", "name": "Follow", "url": ""}, "3359946": {"item_id": "2396187448", "author_id": "3359946", "name": "Education", "url": ""}, "3607719": {"item_id": "2396187448", "author_id": "3607719", "name": "Rose Day", "url": ""}, "9646810": {"item_id": "2396187448", "author_id": "9646810", "name": "Joined", "url": ""}, "149114589": {"item_id": "2396187448", "author_id": "149114589", "name": "„Éª4 min read", "url": ""}, "152303384": {"item_id": "2396187448", "author_id": "152303384", "name": "Mar 7, 2018", "url": ""}, "152376551": {"item_id": "2396187448", "author_id": "152376551", "name": "Nov 22, 2018", "url": ""}, "152517871": {"item_id": "2396187448", "author_id": "152517871", "name": "Senior Engineer in Applied Data Science", "url": ""}, "152517872": {"item_id": "2396187448", "author_id": "152517872", "name": "MS in Data Science, BS in Computer Engineering", "url": ""}, "155660373": {"item_id": "2396187448", "author_id": "155660373", "name": "Love working on data science, software engineering and documentation. My interests include IoT, gree", "url": ""}}, "image": {"item_id": "2396187448", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--xNpTNR1i--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://images6.alphacoders.com/368/368992.jpg", "width": "1000", "height": "420"}, "images": {"1": {"item_id": "2396187448", "image_id": "1", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--xNpTNR1i--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://images6.alphacoders.com/368/368992.jpg", "width": "1000", "height": "420", "credit": "", "caption": ""}, "2": {"item_id": "2396187448", "image_id": "2", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--axbIW3Ez--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://latex.codecogs.com/svg.latex%3F%255CLarge%26space%3By%255E%257B%28i%29%257D%2520%255Cin%2520%255Cleft%2520%255C%257B%2520%25201%2C%2520...%2520k%2520%255Cright%2520%255C%257D", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The Practical Dev", "logo": "https://logo.clearbit.com/dev.to?size=800", "greyscale_logo": "https://logo.clearbit.com/dev.to?size=800&greyscale=true"}, "listen_duration_estimate": 283}, "2882841415": {"item_id": "2882841415", "resolved_id": "2882841415", "given_url": "http://ai.googleblog.com/2020/02/learning-to-see-transparent-objects.html", "given_title": "Learning to See Transparent Objects", "favorite": "0", "status": "1", "time_added": "1582807635", "time_updated": "1638708525", "time_read": "1583785007", "time_favorited": "0", "sort_id": 344, "resolved_title": "Learning to See Transparent Objects", "resolved_url": "http://ai.googleblog.com/2020/02/learning-to-see-transparent-objects.html", "excerpt": "Optical 3D range sensors, like RGB-D cameras and LIDAR, have found widespread use in robotics to generate rich and accurate 3D maps of the environment, from self-driving cars to autonomous manipulators.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "1347", "lang": "en", "time_to_read": 6, "top_image_url": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png", "tags": {"deep-learning": {"item_id": "2882841415", "tag": "deep-learning"}, "vision": {"item_id": "2882841415", "tag": "vision"}}, "authors": {"83475403": {"item_id": "2882841415", "author_id": "83475403", "name": "Shreeyak Sajjan", "url": ""}}, "image": {"item_id": "2882841415", "src": "https://1.bp.blogspot.com/-VNB-xPguois/XkQ7sqF3VWI/AAAAAAAAFRc/ek6wUpjOGNw0u9vALnnW9zXCZ8VsWTjcACLcBGAsYHQ/s1600/image3.png", "width": "640", "height": "174"}, "images": {"1": {"item_id": "2882841415", "image_id": "1", "src": "https://1.bp.blogspot.com/-VNB-xPguois/XkQ7sqF3VWI/AAAAAAAAFRc/ek6wUpjOGNw0u9vALnnW9zXCZ8VsWTjcACLcBGAsYHQ/s1600/image3.png", "width": "640", "height": "174", "credit": "", "caption": ""}, "2": {"item_id": "2882841415", "image_id": "2", "src": "https://1.bp.blogspot.com/-mcdDuutDw5Q/XkQ7ssTGUvI/AAAAAAAAFRg/OIyqAa7Qbgs1yGWB7vFKL2E90hCPXiuYACEwYBhgL/s640/image2.gif", "width": "640", "height": "268", "credit": "", "caption": "Transparent objects often fail to be detected by optical 3D sensors. Top, Right: For instance, glass bottles do not show up in the 3D depth imagery captured from an Intel¬Æ RealSense‚Ñ¢ D415 RGB-D camera. Bottom: A 3D visualization via point clouds constructed from the depth image."}, "3": {"item_id": "2882841415", "image_id": "3", "src": "https://1.bp.blogspot.com/-oncutBVkLQU/XkQ7rQz4zLI/AAAAAAAAFSI/Y1dSYj38GkgDTtw-P-UaP1e7pRzmC6izgCEwYBhgL/s1600/image11.png", "width": "640", "height": "232", "credit": "", "caption": "Some example data of transparent objects from the ClearGrasp synthetic dataset."}, "4": {"item_id": "2882841415", "image_id": "4", "src": "https://1.bp.blogspot.com/-QcyTESfw4AM/XkQ7rJaGdVI/AAAAAAAAFR8/CUPvkzCJuygr6xw9S36vYIQ1r0wfi3rogCEwYBhgL/s1600/image10.jpg", "width": "400", "height": "226", "credit": "", "caption": "Specular reflections on transparent objects create distinct features that vary based on the object shape and provide strong visual cues for estimating surface normals."}, "5": {"item_id": "2882841415", "image_id": "5", "src": "https://1.bp.blogspot.com/-xbiK9-km_BE/XkQ7rJmME0I/AAAAAAAAFSA/2kRSqd3DvlcOpv6ql4qILwn3HdmmryfBACEwYBhgL/s1600/image1.png", "width": "640", "height": "202", "credit": "", "caption": "Overview of our method. The point cloud was generated using the output depth and is colored with its surface normals."}, "6": {"item_id": "2882841415", "image_id": "6", "src": "https://1.bp.blogspot.com/-QBobUQ2ssow/XkQ7txFy4gI/AAAAAAAAFSI/wIR43QtxSd48ghg9bEOAyN617pqIfvsPwCEwYBhgL/s1600/image7.png", "width": "640", "height": "202", "credit": "MP+SN), b) our synthetic dataset only, and c", "caption": "Surface Normal estimation on real images when trained on a) Matterport3D and ScanNet only"}, "7": {"item_id": "2882841415", "image_id": "7", "src": "https://1.bp.blogspot.com/-iaTKEeKdlTA/XkQ7u6Mv6gI/AAAAAAAAFSE/_59HIFZptyoP9tDllG_0WVy2HKD4edPcwCEwYBhgL/s1600/image9.png", "width": "640", "height": "242", "credit": "", "caption": "Qualitative results on real images. Top two rows: results on known objects. Bottom two rows: results on novel objects. The point clouds, colored with their surface normals, are generated from the corresponding depth images."}, "8": {"item_id": "2882841415", "image_id": "8", "src": "https://1.bp.blogspot.com/-fHSXEBQAp_8/XkQ7uzz9jzI/AAAAAAAAFSI/FKoaYnuntS8vA9IhQCUduBrRyrEnjtVhQCEwYBhgL/s640/image8.gif", "width": "640", "height": "360", "credit": "the patterns of light that occur when light rays are reflected or refracted from a surface", "caption": "Manipulation of novel transparent objects using ClearGrasp. Note the challenging conditions: textureless background, complex object shapes and the directional light causing confusing shadows and caustics"}}, "videos": {"1": {"item_id": "2882841415", "video_id": "1", "src": "https://www.youtube.com/embed/lbmklphGgGE?rel=0&feature=player_embedded", "width": "640", "height": "360", "type": "1", "vid": "lbmklphGgGE", "length": "0"}}, "listen_duration_estimate": 521}, "2183227282": {"item_id": "2183227282", "resolved_id": "2183227282", "given_url": "https://techcrunch.com/2018/05/11/lighttag/", "given_title": "LightTag is a text annotation platform for data scientists creating AI trai", "favorite": "0", "status": "1", "time_added": "1526038553", "time_updated": "1638708525", "time_read": "1526039394", "time_favorited": "0", "sort_id": 345, "resolved_title": "LightTag is a text annotation platform for data scientists creating AI training data", "resolved_url": "https://techcrunch.com/2018/05/11/lighttag/", "excerpt": "LightTag, a newly launched startup from a former NLP researcher at Citi, has built a ‚Äútext annotation platform‚Äù designed to assist data scientists who need to quickly create training data for their AI systems.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "540", "lang": "en", "amp_url": "https://techcrunch.com/2018/05/11/lighttag/amp/", "top_image_url": "https://techcrunch.com/wp-content/uploads/2018/05/img_0118.jpg?w=461", "tags": {"deep-learning": {"item_id": "2183227282", "tag": "deep-learning"}, "machine-learning": {"item_id": "2183227282", "tag": "machine-learning"}, "text": {"item_id": "2183227282", "tag": "text"}}, "authors": {"87041035": {"item_id": "2183227282", "author_id": "87041035", "name": "Steve O'Hear", "url": "https://techcrunch.com/author/steve-o-hear/"}}, "image": {"item_id": "2183227282", "src": "https://techcrunch.com/wp-content/uploads/2018/05/img_0118.jpg?w=461", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2183227282", "image_id": "1", "src": "https://techcrunch.com/wp-content/uploads/2018/05/img_0118.jpg?w=461", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2183227282", "image_id": "2", "src": "https://techcrunch.com/wp-content/uploads/2018/05/lighttag-box.gif", "width": "692", "height": "357", "credit": "", "caption": ""}, "3": {"item_id": "2183227282", "image_id": "3", "src": "https://techcrunch.com/wp-content/uploads/2018/05/lighttag.gif", "width": "1024", "height": "361", "credit": "", "caption": ""}}, "domain_metadata": {"name": "TechCrunch", "logo": "https://logo.clearbit.com/techcrunch.com?size=800", "greyscale_logo": "https://logo.clearbit.com/techcrunch.com?size=800&greyscale=true"}, "listen_duration_estimate": 209}, "2927601837": {"item_id": "2927601837", "resolved_id": "2927601876", "given_url": "https://towardsdatascience.com/limitations-of-graph-neural-networks-2412fffe677?source=rss----7f60cf5620c9---4", "given_title": "Limitations of Graph Neural Networks", "favorite": "0", "status": "1", "time_added": "1585152034", "time_updated": "1638708525", "time_read": "1585740100", "time_favorited": "0", "sort_id": 346, "resolved_title": "Limitations of Graph Neural Networks", "resolved_url": "https://towardsdatascience.com/limitations-of-graph-neural-networks-2412fffe677", "excerpt": "There are two paradigms for graph representations: graph kernels and graph neural networks. Graph kernels typically create an embedding of a graph, based on decomposition, in an unsupervised manner.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1757", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1200/1*jd2KplvadkJqnPyYM4G88Q.jpeg", "tags": {"deep-learning": {"item_id": "2927601837", "tag": "deep-learning"}, "graphs": {"item_id": "2927601837", "tag": "graphs"}}, "authors": {"147967875": {"item_id": "2927601837", "author_id": "147967875", "name": "Sergei Ivanov", "url": "https://sergei-ivanov.medium.com"}}, "image": {"item_id": "2927601837", "src": "https://miro.medium.com/fit/c/56/56/2*a9JCJJmE65jaga8ZuKC3Tg.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2927601837", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*a9JCJJmE65jaga8ZuKC3Tg.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2927601837", "image_id": "2", "src": "https://miro.medium.com/max/14296/1*jd2KplvadkJqnPyYM4G88Q.jpeg", "width": "7148", "height": "4501", "credit": "", "caption": "On the way to more powerful GNN. Source."}, "3": {"item_id": "2927601837", "image_id": "3", "src": "https://miro.medium.com/max/1144/1*5IsFL7yatJI8iTyrKRHydQ.png", "width": "572", "height": "202", "credit": "", "caption": "All graphlets of size 4. Counting the number of each graphlet among all quadruples in a graph will result in a graphlet kernel. Source: Efficient graphlet kernels for large graph comparison"}, "4": {"item_id": "2927601837", "image_id": "4", "src": "https://miro.medium.com/max/4340/1*4snvfVctcSCdxD2zdtpIig.png", "width": "2170", "height": "724", "credit": "", "caption": ""}, "5": {"item_id": "2927601837", "image_id": "5", "src": "https://miro.medium.com/max/2632/1*1A2e9sioxQBIAqGerPK_8w.png", "width": "1316", "height": "440", "credit": "left to right", "caption": "Injective, bijective, and surjective mappings"}, "6": {"item_id": "2927601837", "image_id": "6", "src": "https://miro.medium.com/max/3612/1*Ibqkur3qd6IHsjkbTZ87ow.png", "width": "1806", "height": "486", "credit": "", "caption": ""}, "7": {"item_id": "2927601837", "image_id": "7", "src": "https://miro.medium.com/max/2152/1*HUsLVzfKLQqwiPuYyG-OQQ.png", "width": "1076", "height": "296", "credit": "", "caption": ""}, "8": {"item_id": "2927601837", "image_id": "8", "src": "https://miro.medium.com/max/840/1*yyDASzL3sAG8z1x2h6tqag.png", "width": "420", "height": "292", "credit": "embeddings correspond to different colors here", "caption": "Mean aggregation of embeddings"}, "9": {"item_id": "2927601837", "image_id": "9", "src": "https://miro.medium.com/max/2360/1*Ar_0ZhGmksoJQ_J6_AUFDw.png", "width": "1180", "height": "122", "credit": "", "caption": ""}, "10": {"item_id": "2927601837", "image_id": "10", "src": "https://miro.medium.com/max/2356/1*6Tq9l7FsOPmrcM2ZtuDw0Q.png", "width": "1178", "height": "176", "credit": "", "caption": ""}, "11": {"item_id": "2927601837", "image_id": "11", "src": "https://miro.medium.com/max/1436/1*3t9AjNZOlz3er_FjLFitBA.png", "width": "718", "height": "100", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 680}, "2781404601": {"item_id": "2781404601", "resolved_id": "2781404601", "given_url": "https://jfpettit.github.io/blog/2019/11/03/fundamentals-of-reinforcement-learning", "given_title": "Looking at the Fundamentals of Reinforcement Learning", "favorite": "0", "status": "1", "time_added": "1573151327", "time_updated": "1638708525", "time_read": "1573151337", "time_favorited": "0", "sort_id": 347, "resolved_title": "Looking at the Fundamentals of Reinforcement Learning", "resolved_url": "https://jfpettit.github.io/blog/2019/11/03/fundamentals-of-reinforcement-learning", "excerpt": "In this post, we‚Äôll get into the weeds with some of the fundamentals of reinforcement learning.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3500", "lang": "en", "time_to_read": 16, "tags": {"deep-learning": {"item_id": "2781404601", "tag": "deep-learning"}, "reinforcement-learning": {"item_id": "2781404601", "tag": "reinforcement-learning"}}, "authors": {"74984196": {"item_id": "2781404601", "author_id": "74984196", "name": "Where  is", "url": ""}}, "image": {"item_id": "2781404601", "src": "https://jfpettit.github.io/assets/imgs/github_logo.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2781404601", "image_id": "1", "src": "https://jfpettit.github.io/assets/imgs/github_logo.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2781404601", "image_id": "2", "src": "https://jfpettit.github.io/assets/imgs/twitter_logo.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2781404601", "image_id": "3", "src": "https://jfpettit.github.io/assets/imgs/svbtle_logo.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2781404601", "image_id": "4", "src": "https://jfpettit.github.io/assets/imgs/email_logo.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2781404601", "image_id": "5", "src": "https://www.kdnuggets.com/images/reinforcement-learning-fig1-700.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2781404601", "image_id": "6", "src": "https://miro.medium.com/max/1454/1*G3q-q9gEiDc2fD8sPXHBpQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2781404601", "image_id": "7", "src": "https://lilianweng.github.io/lil-log/assets/images/MC_control.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1355}, "1847534625": {"item_id": "1847534625", "resolved_id": "1847534625", "given_url": "https://github.com/LouieYang/deep-photo-styletransfer-tf", "given_title": "LouieYang/deep-photo-styletransfer-tf: Tensorflow (Python API) implementati", "favorite": "0", "status": "1", "time_added": "1519321521", "time_updated": "1638708525", "time_read": "1528501272", "time_favorited": "0", "sort_id": 348, "resolved_title": "deep-photo-styletransfer-tf", "resolved_url": "https://github.com/LouieYang/deep-photo-styletransfer-tf", "excerpt": "This implementation support L-BFGS-B (which is what the original authors used) and Adam in case the ScipyOptimizerInterface incompatible when Tensorflow upgrades to higher version. Additionally, there is no dependency on MATLAB thanks to another repository computing Matting Laplacian Sparse Matrix.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "645", "lang": "en", "time_to_read": 3, "top_image_url": "https://opengraph.githubassets.com/e1fe2ecba5f764951b9607795b239d3141d6c186eab888ac78c045dccdecc786/LouieYang/deep-photo-styletransfer-tf", "tags": {"deep-learning": {"item_id": "1847534625", "tag": "deep-learning"}, "vision": {"item_id": "1847534625", "tag": "vision"}}, "image": {"item_id": "1847534625", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/some_results/best5.png", "width": "512", "height": "0"}, "images": {"1": {"item_id": "1847534625", "image_id": "1", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/some_results/best5.png", "width": "512", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1847534625", "image_id": "2", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/readme_examples/intar5.png", "width": "290", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "1847534625", "image_id": "3", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/input/in6.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "4": {"item_id": "1847534625", "image_id": "4", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/style/tar6.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "5": {"item_id": "1847534625", "image_id": "5", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/final_results/best6_t_1000.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "6": {"item_id": "1847534625", "image_id": "6", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/some_results/best6.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "7": {"item_id": "1847534625", "image_id": "7", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/input/in7.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "8": {"item_id": "1847534625", "image_id": "8", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/style/tar7.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "9": {"item_id": "1847534625", "image_id": "9", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/final_results/best7_t_1000.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "10": {"item_id": "1847534625", "image_id": "10", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/some_results/best7.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "11": {"item_id": "1847534625", "image_id": "11", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/input/in8.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "12": {"item_id": "1847534625", "image_id": "12", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/style/tar8.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "13": {"item_id": "1847534625", "image_id": "13", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/final_results/best8_t_1000.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "14": {"item_id": "1847534625", "image_id": "14", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/some_results/best8.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "15": {"item_id": "1847534625", "image_id": "15", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/input/in9.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "16": {"item_id": "1847534625", "image_id": "16", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/style/tar9.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "17": {"item_id": "1847534625", "image_id": "17", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/final_results/best9_t_1000.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "18": {"item_id": "1847534625", "image_id": "18", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/some_results/best9.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "19": {"item_id": "1847534625", "image_id": "19", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/input/in10.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "20": {"item_id": "1847534625", "image_id": "20", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/style/tar10.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "21": {"item_id": "1847534625", "image_id": "21", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/final_results/best10_t_1000.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "22": {"item_id": "1847534625", "image_id": "22", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/some_results/best10.png", "width": "210", "height": "140", "credit": "", "caption": ""}, "23": {"item_id": "1847534625", "image_id": "23", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/input/in11.png", "width": "210", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "1847534625", "image_id": "24", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/style/tar11.png", "width": "210", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "1847534625", "image_id": "25", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/examples/final_results/best11_t_1000.png", "width": "210", "height": "0", "credit": "", "caption": ""}, "26": {"item_id": "1847534625", "image_id": "26", "src": "https://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/some_results/best11.png", "width": "210", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 250}, "2478897343": {"item_id": "2478897343", "resolved_id": "2478897359", "given_url": "https://drive.google.com/file/d/1XhngKISDpQgwGlvU-hjXWZb_qfyIYjqN/view", "given_title": "Luminovo - Deep Learning Toolset.pdf - Google Drive", "favorite": "0", "status": "1", "time_added": "1581276974", "time_updated": "1706833159", "time_read": "1582142455", "time_favorited": "0", "sort_id": 349, "resolved_title": "Luminovo - Deep Learning Toolset.pdf", "resolved_url": "https://drive.google.com/file/d/1XhngKISDpQgwGlvU-hjXWZb_qfyIYjqN/view?usp=embed_facebook&usp=embed_facebook&usp=embed_facebook&usp=embed_facebook", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"deep-learning": {"item_id": "2478897343", "tag": "deep-learning"}, "programming": {"item_id": "2478897343", "tag": "programming"}}, "domain_metadata": {"name": "Google Drive", "logo": "https://logo.clearbit.com/drive.google.com?size=800", "greyscale_logo": "https://logo.clearbit.com/drive.google.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3540668786": {"item_id": "3540668786", "resolved_id": "3540668786", "given_url": "https://www.accel.ai/anthology/2022/1/24/machine-learning-algorithms-cheat-sheet", "given_title": "Machine Learning Algorithms Cheat Sheet ‚Äî Accel.AI", "favorite": "0", "status": "1", "time_added": "1645366341", "time_updated": "1706233547", "time_read": "1645366989", "time_favorited": "0", "sort_id": 350, "resolved_title": "Machine Learning Algorithms Cheat Sheet ‚Äî Accel.AI", "resolved_url": "https://www.accel.ai/anthology/2022/1/24/machine-learning-algorithms-cheat-sheet", "excerpt": "One daily usage can be when e-commerce makes a product recommendation to its customers. Applying DBSCAN on the data of products the user has bought before.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1912", "lang": "en", "time_to_read": 9, "top_image_url": "http://static1.squarespace.com/static/58dc1a1ee4fcb51cbb80a096/t/61ef129567e39b6aaebaae65/1643057857237/ML-CheatSheet-en.png?format=1500w", "tags": {"algorithms-math": {"item_id": "3540668786", "tag": "algorithms-math"}, "deep-learning": {"item_id": "3540668786", "tag": "deep-learning"}, "machine-learning": {"item_id": "3540668786", "tag": "machine-learning"}}, "authors": {"162981132": {"item_id": "3540668786", "author_id": "162981132", "name": "Anthony Barrios", "url": "https://www.accel.ai/anthology?author=61e0ca339cbeac55efa18dc5"}}, "image": {"item_id": "3540668786", "src": "https://images.squarespace-cdn.com/content/v1/58dc1a1ee4fcb51cbb80a096/24c2f0fb-e667-42d6-a6fb-b2c4ad79ed41/ML-CheatSheet-en.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3540668786", "image_id": "1", "src": "https://images.squarespace-cdn.com/content/v1/58dc1a1ee4fcb51cbb80a096/24c2f0fb-e667-42d6-a6fb-b2c4ad79ed41/ML-CheatSheet-en.png", "width": "0", "height": "0", "credit": "", "caption": "Machine Learning Algorithms Cheat Sheet by LatinX in AI‚Ñ¢. Download the pdf: https://github.com/latinxinai/AI-Educational-Resources/raw/master/CheatSheets/Machine%20Learning%20Cheat%20Sheet.pdf"}, "2": {"item_id": "3540668786", "image_id": "2", "src": "https://images.squarespace-cdn.com/content/v1/58dc1a1ee4fcb51cbb80a096/09c7a4d1-d70a-49ac-9210-5d80dfc4163a/pca-ex.png", "width": "0", "height": "0", "credit": "wordpress.com", "caption": "Image source: What is principal component analysis? | Bits of DNA"}, "3": {"item_id": "3540668786", "image_id": "3", "src": "https://images.squarespace-cdn.com/content/v1/58dc1a1ee4fcb51cbb80a096/bf695af4-c161-43e6-8f69-fc49e5f1c7ce/svd-ex.png", "width": "0", "height": "0", "credit": "analyticsvidhya.com", "caption": "Compression of an image with a given number of components. Source: Singular Value Decomposition | SVD in Python"}, "4": {"item_id": "3540668786", "image_id": "4", "src": "https://images.squarespace-cdn.com/content/v1/58dc1a1ee4fcb51cbb80a096/6f129ad6-7648-4e17-973d-b8c2f7efd68f/lda-ex.png", "width": "0", "height": "0", "credit": "classes", "caption": "Distribution of 170 face images of five subjects"}, "5": {"item_id": "3540668786", "image_id": "5", "src": "https://images.squarespace-cdn.com/content/v1/58dc1a1ee4fcb51cbb80a096/4ef3af3e-7c21-4f66-9e9e-bc4b7ce20af7/eps-ex.png", "width": "0", "height": "0", "credit": "", "caption": "Source: Tracking down the Villains: Outlier Detection at Netflix | by Netflix Technology Blog | Netflix TechBlog"}}, "listen_duration_estimate": 740}, "3156392066": {"item_id": "3156392066", "resolved_id": "3156392066", "given_url": "https://embracethered.com/blog/posts/2020/husky-ai-image-rescaling-attacks/", "given_title": "Machine Learning Attack Series: Image Scaling Attacks ¬∑ wunderwuzzi blog", "favorite": "0", "status": "1", "time_added": "1603980827", "time_updated": "1638708525", "time_read": "1604187210", "time_favorited": "0", "sort_id": 351, "resolved_title": "Machine Learning Attack Series: Image Scaling Attacks", "resolved_url": "https://embracethered.com/blog/posts/2020/husky-ai-image-rescaling-attacks/", "excerpt": "This post is part of a series about machine learning and artificial intelligence. Click on the blog tag ‚Äúhuskyai‚Äù to see related posts. The basic idea is to hide a smaller image inside a larger image (it should be about 5-10x the size). The attack is easy to explain actually:", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "463", "lang": "en", "tags": {"deep-learning": {"item_id": "3156392066", "tag": "deep-learning"}, "vision": {"item_id": "3156392066", "tag": "vision"}}, "image": {"item_id": "3156392066", "src": "https://embracethered.com/blog/images/2020/image-rescale-attack.gif", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3156392066", "image_id": "1", "src": "https://embracethered.com/blog/images/2020/image-rescale-attack.gif", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3156392066", "image_id": "2", "src": "https://embracethered.com/blog/images/2020/image-rescaling-attack-schoenbrunn.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3156392066", "image_id": "3", "src": "https://embracethered.com/blog/images/2020/image-rescaling-attack.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 179}, "1840287059": {"item_id": "1840287059", "resolved_id": "1840287059", "given_url": "https://www.google.com/search?q=machine+learning+benchmarks&oq=machine+learning+benchmarks&aqs=chrome..69i57.7070j0j7&sourceid=chrome&ie=UTF-8", "given_title": "machine learning benchmarks - Google Search", "favorite": "0", "status": "1", "time_added": "1501515359", "time_updated": "1638708525", "time_read": "1514398107", "time_favorited": "0", "sort_id": 352, "resolved_title": "machine learning benchmarks", "resolved_url": "https://www.google.com/search?q=machine+learning+benchmarks&oq=machine+learning+benchmarks&aqs=chrome..69i57.7070j0j7&sourceid=chrome&ie=UTF-8", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"benchmarks": {"item_id": "1840287059", "tag": "benchmarks"}, "deep-learning": {"item_id": "1840287059", "tag": "deep-learning"}}, "domain_metadata": {"name": "Google", "logo": "https://logo.clearbit.com/google.com?size=800", "greyscale_logo": "https://logo.clearbit.com/google.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "1950743425": {"item_id": "1950743425", "resolved_id": "1950743425", "given_url": "https://technology.condenast.com/story/handbag-brand-and-color-detection", "given_title": "Machine Learning: Handbag Brand and Color Detection using Deep Neural Netwo", "favorite": "0", "status": "1", "time_added": "1510156068", "time_updated": "1638708525", "time_read": "1510184940", "time_favorited": "0", "sort_id": 353, "resolved_title": "Machine Learning at Cond√© Nast, Part 2: Handbag Brand and Color Detection", "resolved_url": "https://technology.condenast.com/story/handbag-brand-and-color-detection", "excerpt": "For a primer on Neural Network concepts, please visit our first post in this series. Over the past few years, we here at Cond√© Nast have invested heavily in building Machine Learning (ML) tools to help us understand our content and how our users interact with it.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1595", "lang": "en", "time_to_read": 7, "amp_url": "https://technology.condenast.com/story/handbag-brand-and-color-detection/amp", "top_image_url": "https://media.condenast.io/photos/59fcc07c5faf870879f21f0a/master/pass/jacobs_hm.png", "tags": {"deep-learning": {"item_id": "1950743425", "tag": "deep-learning"}, "ecommerce": {"item_id": "1950743425", "tag": "ecommerce"}, "machine-learning": {"item_id": "1950743425", "tag": "machine-learning"}, "vision": {"item_id": "1950743425", "tag": "vision"}}, "authors": {"78104804": {"item_id": "1950743425", "author_id": "78104804", "name": "Johan Edvinsson", "url": "https://technology.condenast.com/contributor/johan-edvinsson"}}, "listen_duration_estimate": 617}, "2848509913": {"item_id": "2848509913", "resolved_id": "2848509913", "given_url": "http://ieeexplore.ieee.org/document/8372616", "given_title": "Mask R-CNN", "favorite": "0", "status": "1", "time_added": "1578658278", "time_updated": "1638708525", "time_read": "1582142817", "time_favorited": "0", "sort_id": 354, "resolved_title": "Mask R-CNN : IEEE Journals & Magazine", "resolved_url": "http://ieeexplore.ieee.org/document/8372616", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"deep-learning": {"item_id": "2848509913", "tag": "deep-learning"}}, "listen_duration_estimate": 0}, "2972103631": {"item_id": "2972103631", "resolved_id": "2972103667", "given_url": "https://towardsdatascience.com/master-the-coco-dataset-for-semantic-image-segmentation-part-1-of-2-732712631047?source=rss----7f60cf5620c9---4", "given_title": "Master the COCO Dataset for Semantic Image Segmentation", "favorite": "0", "status": "1", "time_added": "1588614655", "time_updated": "1638708525", "time_read": "1589542049", "time_favorited": "0", "sort_id": 355, "resolved_title": "Master the COCO Dataset for Semantic Image Segmentation", "resolved_url": "https://towardsdatascience.com/master-the-coco-dataset-for-semantic-image-segmentation-part-1-of-2-732712631047", "excerpt": ", being one of the most popular image datasets out there, with appliations like object detection, segmentation, and captioning - it is quite surprising how few comprehensive but simple, end-to-end tutorials exist. When I first started out with this dataset, I was quite lost and intimidated.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1339", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/1*taqoyoo-5DlTvktWYM21tQ.jpeg", "tags": {"deep-learning": {"item_id": "2972103631", "tag": "deep-learning"}, "vision": {"item_id": "2972103631", "tag": "vision"}}, "authors": {"133317569": {"item_id": "2972103631", "author_id": "133317569", "name": "Viraf", "url": "https://medium.com/@virafpatrawala"}}, "image": {"item_id": "2972103631", "src": "https://miro.medium.com/fit/c/56/56/2*R04h_eboCIBsrrwArUc5aA.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2972103631", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*R04h_eboCIBsrrwArUc5aA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2972103631", "image_id": "2", "src": "https://miro.medium.com/max/12000/1*taqoyoo-5DlTvktWYM21tQ.jpeg", "width": "6000", "height": "4000", "credit": "Original photo by Ylanite Koppens from Pexels", "caption": "Did you mean COCOA?"}, "3": {"item_id": "2972103631", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*vP5WkxR8oY2Iz0Ox0tXW1w.jpeg", "width": "700", "height": "213", "credit": "", "caption": "The COCO Dataset"}, "4": {"item_id": "2972103631", "image_id": "4", "src": "https://miro.medium.com/max/1000/1*ShJDpj-tEmuxJ0BdvsvIOw.png", "width": "500", "height": "375", "credit": "", "caption": "An example image from the dataset."}, "5": {"item_id": "2972103631", "image_id": "5", "src": "https://miro.medium.com/max/608/1*QZd5XQXNiy9EnL1BXzSXXw.png", "width": "304", "height": "231", "credit": "", "caption": "A sample image containing the filtered output classes."}, "6": {"item_id": "2972103631", "image_id": "6", "src": "https://miro.medium.com/max/608/1*C0BP5dLinScCUjH3DrNhNA.png", "width": "304", "height": "231", "credit": "", "caption": "Annotations for filtered classes neatly drawn out."}, "7": {"item_id": "2972103631", "image_id": "7", "src": "https://miro.medium.com/max/660/1*VIBddw3Pj29rATNbc4rk9g.png", "width": "330", "height": "252", "credit": "", "caption": "A normal 2-channel mask for semantic segmentation."}, "8": {"item_id": "2972103631", "image_id": "8", "src": "https://miro.medium.com/max/660/1*DlLjP-00rEHjVMNhvE1wPQ.png", "width": "330", "height": "252", "credit": "", "caption": "A binary semantic segmentation mask. Yellow represents pixel value 1, violet represents pixel value 0."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 518}, "2973971072": {"item_id": "2973971072", "resolved_id": "2973971128", "given_url": "https://towardsdatascience.com/master-the-coco-dataset-for-semantic-image-segmentation-part-2-of-2-c0d1f593096a?source=rss----7f60cf5620c9---4", "given_title": "Master the COCO Dataset for Semantic Image Segmentation", "favorite": "0", "status": "1", "time_added": "1588764125", "time_updated": "1638708525", "time_read": "1589542035", "time_favorited": "0", "sort_id": 356, "resolved_title": "Master the COCO Dataset for Semantic Image Segmentation", "resolved_url": "https://towardsdatascience.com/master-the-coco-dataset-for-semantic-image-segmentation-part-2-of-2-c0d1f593096a", "excerpt": "For new readers, you can find Part 1 of this series here. I strongly recommend going through it to better understand the following article.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1462", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/1200/1*hki1s4QtFbvYmQV_TrvWAQ.jpeg", "tags": {"deep-learning": {"item_id": "2973971072", "tag": "deep-learning"}, "vision": {"item_id": "2973971072", "tag": "vision"}}, "authors": {"133317569": {"item_id": "2973971072", "author_id": "133317569", "name": "Viraf", "url": "https://medium.com/@virafpatrawala"}}, "image": {"item_id": "2973971072", "src": "https://miro.medium.com/max/1400/1*hki1s4QtFbvYmQV_TrvWAQ.jpeg", "width": "700", "height": "467"}, "images": {"1": {"item_id": "2973971072", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*hki1s4QtFbvYmQV_TrvWAQ.jpeg", "width": "700", "height": "467", "credit": "Original photo by Craig Adderley from Pexels", "caption": "Have you gone COCOnuts?!"}, "2": {"item_id": "2973971072", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*lmHKDnlqSML3mrNo6WVKHg.png", "width": "700", "height": "342", "credit": "", "caption": "Visualization of the images generated by the generator for mask_type=‚Äôbinary‚Äô."}, "3": {"item_id": "2973971072", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*FX-sdv4ZJiYbty_xThD8qw.png", "width": "700", "height": "342", "credit": "", "caption": "Visualization of the images generated by the generator for mask_type=‚Äônormal‚Äô."}, "4": {"item_id": "2973971072", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*kxJ9729dpVC-4RNuWjrD7A.png", "width": "700", "height": "342", "credit": "", "caption": "Visualization of the images generated by the augmentations generator for mask_type=‚Äôbinary‚Äô."}, "5": {"item_id": "2973971072", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*lrjlS18mS2qALnfI-d_Uow.png", "width": "700", "height": "342", "credit": "", "caption": "Visualization of the images generated by the augmentations generator for mask_type=‚Äônormal‚Äô."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 566}, "3048421057": {"item_id": "3048421057", "resolved_id": "3048421057", "given_url": "https://paperswithcode.com/methods/category/activation-functions", "given_title": "Math | Obviously Awesome", "favorite": "0", "status": "1", "time_added": "1612406187", "time_updated": "1673901884", "time_read": "1612406200", "time_favorited": "0", "sort_id": 357, "resolved_title": "An Overview of Activation Functions", "resolved_url": "https://paperswithcode.com/methods/category/activation-functions", "excerpt": "Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "16", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/method_collections/Screen_Shot_2020-07-06_at_12.49.45_PM.png", "tags": {"activations": {"item_id": "3048421057", "tag": "activations"}, "deep-learning": {"item_id": "3048421057", "tag": "deep-learning"}}, "listen_duration_estimate": 6}, "1679897830": {"item_id": "1679897830", "resolved_id": "1679897830", "given_url": "https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0", "given_title": "Math | Obviously Awesome", "favorite": "0", "status": "1", "time_added": "1612406206", "time_updated": "1673901884", "time_read": "1612406217", "time_favorited": "0", "sort_id": 358, "resolved_title": "Understanding Activation Functions in Neural Networks", "resolved_url": "https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0", "excerpt": "Recently, a colleague of mine asked me a few questions like ‚Äúwhy do we have so many activation functions?‚Äù, ‚Äúwhy is that one works better than the other?‚Äù, ‚Äùhow do we know which one to use?‚Äù, ‚Äúis it hardcore maths?‚Äù and so on.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2062", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/325/0*8U8_aa9hMsGmzMY2.", "tags": {"activations": {"item_id": "1679897830", "tag": "activations"}, "deep-learning": {"item_id": "1679897830", "tag": "deep-learning"}}, "authors": {"65929789": {"item_id": "1679897830", "author_id": "65929789", "name": "Avinash Sharma V", "url": "https://medium.com/@avinashsharmav91"}}, "image": {"item_id": "1679897830", "src": "https://miro.medium.com/max/1600/1*vGj29ZBD1kH1kDlGQspPxA.png", "width": "440", "height": "94"}, "images": {"1": {"item_id": "1679897830", "image_id": "1", "src": "https://miro.medium.com/max/1600/1*vGj29ZBD1kH1kDlGQspPxA.png", "width": "440", "height": "94", "credit": "", "caption": ""}, "2": {"item_id": "1679897830", "image_id": "2", "src": "https://miro.medium.com/max/1600/0*8U8_aa9hMsGmzMY2.", "width": "325", "height": "244", "credit": "", "caption": ""}, "3": {"item_id": "1679897830", "image_id": "3", "src": "https://miro.medium.com/max/1600/1*DHN75JRJ_EQgGc0spfqLtQ.png", "width": "224", "height": "96", "credit": "", "caption": ""}, "4": {"item_id": "1679897830", "image_id": "4", "src": "https://miro.medium.com/max/1600/0*5euYS7InCmDP08ir.", "width": "600", "height": "400", "credit": "", "caption": ""}, "5": {"item_id": "1679897830", "image_id": "5", "src": "https://miro.medium.com/max/1600/0*YJ27cYXmTAUFZc9Z.", "width": "400", "height": "300", "credit": "", "caption": ""}, "6": {"item_id": "1679897830", "image_id": "6", "src": "https://miro.medium.com/max/1600/1*WNTLbBRWFiHPoXvyZ6s9eg.png", "width": "644", "height": "120", "credit": "", "caption": ""}, "7": {"item_id": "1679897830", "image_id": "7", "src": "https://miro.medium.com/max/1600/1*U-677uRd-StXbAgrAnX2hw.png", "width": "616", "height": "96", "credit": "", "caption": ""}, "8": {"item_id": "1679897830", "image_id": "8", "src": "https://miro.medium.com/max/1600/0*vGJq0cIuvTB9dvf5.", "width": "311", "height": "210", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 798}, "1866345387": {"item_id": "1866345387", "resolved_id": "1866345387", "given_url": "https://medium.com/@matelabs_ai/secret-sauce-behind-the-beauty-of-deep-learning-beginners-guide-to-activation-functions-a8e23a57d046", "given_title": "Math | Obviously Awesome", "favorite": "0", "status": "1", "time_added": "1612406224", "time_updated": "1673901884", "time_read": "1612438321", "time_favorited": "0", "sort_id": 359, "resolved_title": "Secret Sauce behind the beauty of Deep Learning: Beginners guide to Activation Functions", "resolved_url": "https://medium.com/@matelabs_ai/secret-sauce-behind-the-beauty-of-deep-learning-beginners-guide-to-activation-functions-a8e23a57d046", "excerpt": "Activation functions are functions which take an input signal and convert it to an output signal. Activation functions introduce non-linearity to the networks that is why we call them non-linearities.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "1062", "lang": "en", "time_to_read": 5, "top_image_url": "https://cdn-images-1.medium.com/max/1200/1*zwp7ZQLR4cXgLjI2qrMOKQ.png", "tags": {"activations": {"item_id": "1866345387", "tag": "activations"}, "deep-learning": {"item_id": "1866345387", "tag": "deep-learning"}}, "authors": {"67550525": {"item_id": "1866345387", "author_id": "67550525", "name": "Mate Labs", "url": "https://medium.com/@matelabs_ai"}}, "image": {"item_id": "1866345387", "src": "https://cdn-images-1.medium.com/max/2000/1*zwp7ZQLR4cXgLjI2qrMOKQ.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1866345387", "image_id": "1", "src": "https://cdn-images-1.medium.com/max/2000/1*zwp7ZQLR4cXgLjI2qrMOKQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1866345387", "image_id": "2", "src": "https://cdn-images-1.medium.com/max/1600/1*gklL4_EwFpXPSzFC4sPT1g.png", "width": "0", "height": "0", "credit": "", "caption": "Equation for Identity or Linear activation function"}, "3": {"item_id": "1866345387", "image_id": "3", "src": "https://cdn-images-1.medium.com/max/1600/1*x0lkaiCj7i8ut6Dis2O6rg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "1866345387", "image_id": "4", "src": "https://cdn-images-1.medium.com/max/1600/1*LfKVxBfSYSFyUwEw5YInFg.png", "width": "0", "height": "0", "credit": "0 or 1, high or¬†low", "caption": "Equation for Heaveside/Binary Step Function"}, "5": {"item_id": "1866345387", "image_id": "5", "src": "https://cdn-images-1.medium.com/max/1600/1*lZMnAj3RbuHGMLC68Av1Sw.png", "width": "0", "height": "0", "credit": "", "caption": "Source‚Ää‚Äî‚Äähttps://en.wikipedia.org/wiki/Heaviside_step_function"}, "6": {"item_id": "1866345387", "image_id": "6", "src": "https://cdn-images-1.medium.com/max/1600/1*Bhzlu8WmM1UFo8TltoRHOQ.png", "width": "0", "height": "0", "credit": "", "caption": "Sigmoid or Logistic activation function"}, "7": {"item_id": "1866345387", "image_id": "7", "src": "https://cdn-images-1.medium.com/max/1600/1*Q_fCmWPcz4F8IoNXm9tqcg.png", "width": "0", "height": "0", "credit": "", "caption": "Derivative of the sigmoid¬†function"}, "8": {"item_id": "1866345387", "image_id": "8", "src": "https://cdn-images-1.medium.com/max/1600/1*g1aJzppuf9eoC2Ojwr7myw.png", "width": "0", "height": "0", "credit": "", "caption": "Source‚Ää‚Äî‚Äähttps://en.wikipedia.org/wiki/Logistic_function"}, "9": {"item_id": "1866345387", "image_id": "9", "src": "https://cdn-images-1.medium.com/max/1600/1*lKk5Q2arktxQ0m1hJYZqTA.png", "width": "0", "height": "0", "credit": "", "caption": "Source‚Ää‚Äî‚Äähttps://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions"}, "10": {"item_id": "1866345387", "image_id": "10", "src": "https://cdn-images-1.medium.com/max/1600/1*rACT-asoF6gANDE2fW07IQ.png", "width": "0", "height": "0", "credit": "TanH", "caption": "Equation for Hyperbolic Tangent"}, "11": {"item_id": "1866345387", "image_id": "11", "src": "https://cdn-images-1.medium.com/max/1600/1*RtVgvbjI7v8CuUcAC2QM8Q.png", "width": "0", "height": "0", "credit": "", "caption": "Source‚Ää‚Äî‚Äähttps://commons.wikimedia.org/wiki/File:Hyperbolic_Tangent.svg"}, "12": {"item_id": "1866345387", "image_id": "12", "src": "https://cdn-images-1.medium.com/max/1600/1*ZH-D-NXMq82joIHyJocZ3w.png", "width": "0", "height": "0", "credit": "ReLU", "caption": "Equation for Rectified Linear Unit"}, "13": {"item_id": "1866345387", "image_id": "13", "src": "https://cdn-images-1.medium.com/max/1600/1*w275Sin5bKAIaWBaJ6zXcA.png", "width": "0", "height": "0", "credit": "neural_networks", "caption": "Source‚Ää‚Äî‚Äähttps://en.wikipedia.org/wiki/Rectifier_"}, "14": {"item_id": "1866345387", "image_id": "14", "src": "https://cdn-images-1.medium.com/max/1600/1*BQeReUpqHQgVOTjLHpeyLQ.png", "width": "0", "height": "0", "credit": "", "caption": "From Andrej Karpathy‚Äôs CS231n¬†course"}, "15": {"item_id": "1866345387", "image_id": "15", "src": "https://cdn-images-1.medium.com/max/1600/1*qVrYlFchG7YiTX5WWx1r7A.png", "width": "0", "height": "0", "credit": "Leaky ReLU", "caption": "Equation for Leaky Rectified Linear Unit"}, "16": {"item_id": "1866345387", "image_id": "16", "src": "https://cdn-images-1.medium.com/max/1600/1*W6BURQnUE62qyxJxMDpdnA.png", "width": "0", "height": "0", "credit": "Leaky ReLU", "caption": "Leaky Rectified Linear Unit"}, "17": {"item_id": "1866345387", "image_id": "17", "src": "https://cdn-images-1.medium.com/max/1600/1*pZ5_JgEGDHEWsTFoVfK_2g.png", "width": "0", "height": "0", "credit": "PReLU", "caption": "Equation for Parametric Rectified Linear Unit"}, "18": {"item_id": "1866345387", "image_id": "18", "src": "https://cdn-images-1.medium.com/max/1600/1*NwoeUo9Nn85fzUfr9s5tlA.png", "width": "0", "height": "0", "credit": "RReLU", "caption": "Randomized Leaky Rectified Linear Unit"}, "19": {"item_id": "1866345387", "image_id": "19", "src": "https://cdn-images-1.medium.com/max/1600/1*2hEeawGNKs0WwGz9I0JqAg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "1866345387", "image_id": "20", "src": "https://cdn-images-1.medium.com/max/1600/1*rc2g2ZIm4lRCNt8gWMhjyA.png", "width": "0", "height": "0", "credit": "ELU", "caption": "Exponential Linear Unit¬†"}, "21": {"item_id": "1866345387", "image_id": "21", "src": "https://cdn-images-1.medium.com/max/1600/1*gfEr6eAKDZT8hHf2t7u7Lw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "1866345387", "image_id": "22", "src": "https://cdn-images-1.medium.com/max/1600/1*BJS-0XHaB_BSjqMDIPeUJQ.png", "width": "0", "height": "0", "credit": "SELU", "caption": "Scaled Exponential Linear Unit"}, "23": {"item_id": "1866345387", "image_id": "23", "src": "https://cdn-images-1.medium.com/max/1600/1*u35Rsj78T6nOoZJheODMRQ.png", "width": "0", "height": "0", "credit": "", "caption": "S-shaped Rectified Linear Activation Unit"}, "24": {"item_id": "1866345387", "image_id": "24", "src": "https://cdn-images-1.medium.com/max/1600/1*NNuE0OdrkeRDVADeARq4Pw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "1866345387", "image_id": "25", "src": "https://cdn-images-1.medium.com/max/1600/1*EyVsonpsBRp5fdNa-djnBw.png", "width": "0", "height": "0", "credit": "", "caption": "Softplus"}, "26": {"item_id": "1866345387", "image_id": "26", "src": "https://cdn-images-1.medium.com/max/1600/1*D3YKEgImpixP1lst0_uljQ.png", "width": "0", "height": "0", "credit": "", "caption": "Derivative of the softplus¬†function"}, "27": {"item_id": "1866345387", "image_id": "27", "src": "https://cdn-images-1.medium.com/max/1600/1*Vsfd4_mfx5SA7TdHrCZhww.png", "width": "0", "height": "0", "credit": "", "caption": "Bent Identity"}, "28": {"item_id": "1866345387", "image_id": "28", "src": "https://cdn-images-1.medium.com/max/1600/1*XipIlq5eCmQMUDxr4PNH_g.png", "width": "0", "height": "0", "credit": "", "caption": "Equation for Softmax¬†function"}}, "videos": {"1": {"item_id": "1866345387", "video_id": "1", "src": "https://medium.com/media/7ccc375a11ef548386b2ce5b1a6488ba?postId=a8e23a57d046", "width": "700", "height": "420", "type": "7", "vid": "", "length": "0"}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 411}, "3468277057": {"item_id": "3468277057", "resolved_id": "3468277057", "given_url": "https://paperswithcode.com/dataset/medmnist-v2", "given_title": "MedMNIST v2 Dataset | Papers With Code", "favorite": "0", "status": "1", "time_added": "1635518542", "time_updated": "1635531868", "time_read": "1635531868", "time_favorited": "0", "sort_id": 360, "resolved_title": "MedMNIST v2 Dataset", "resolved_url": "https://paperswithcode.com/dataset/medmnist-v2", "excerpt": "MedMNIST v2 is a large-scale MNIST-like collection of standardized biomedical images, including 12 datasets for 2D and 6 datasets for 3D.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "151", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/datasets/cc67083f-1439-4eb9-a436-82ad80808515.png", "tags": {"datasets": {"item_id": "3468277057", "tag": "datasets"}, "deep-learning": {"item_id": "3468277057", "tag": "deep-learning"}, "machine-learning": {"item_id": "3468277057", "tag": "machine-learning"}}, "listen_duration_estimate": 58}, "3992586315": {"item_id": "3992586315", "resolved_id": "3992586315", "given_url": "https://www.marktechpost.com/2024/01/11/meet-neograd-a-deep-learning-framework-created-from-scratch-using-python-and-numpy-with-automatic-differentiation-capabilities/", "given_title": "Meet neograd: A Deep Learning Framework Created from Scratch Using Python a", "favorite": "0", "status": "1", "time_added": "1704975709", "time_updated": "1705475403", "time_read": "1705475403", "time_favorited": "0", "sort_id": 361, "resolved_title": "Meet neograd: A Deep Learning Framework Created from Scratch Using Python and NumPy with Automatic Differentiation Capabilities", "resolved_url": "https://www.marktechpost.com/2024/01/11/meet-neograd-a-deep-learning-framework-created-from-scratch-using-python-and-numpy-with-automatic-differentiation-capabilities/", "excerpt": "Understanding how convolutional neural networks (CNNs) operate is essential in deep learning. However, implementing these networks, especially convolutions and gradient calculations, can be challenging.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "388", "lang": "en", "amp_url": "https://www.marktechpost.com/2024/01/11/meet-neograd-a-deep-learning-framework-created-from-scratch-using-python-and-numpy-with-automatic-differentiation-capabilities/?amp", "top_image_url": "https://www.marktechpost.com/wp-content/uploads/2024/01/ng.png", "tags": {"deep-learning": {"item_id": "3992586315", "tag": "deep-learning"}, "numpy": {"item_id": "3992586315", "tag": "numpy"}, "python": {"item_id": "3992586315", "tag": "python"}}, "authors": {"177644645": {"item_id": "3992586315", "author_id": "177644645", "name": "Niharika Singh", "url": "https://www.marktechpost.com/author/niharika98678/"}}, "image": {"item_id": "3992586315", "src": "https://www.marktechpost.com/wp-content/uploads/2024/01/ng.png", "width": "502", "height": "502"}, "images": {"1": {"item_id": "3992586315", "image_id": "1", "src": "https://www.marktechpost.com/wp-content/uploads/2024/01/ng.png", "width": "502", "height": "502", "credit": "", "caption": "https://github.com/pranftw/neograd"}}, "listen_duration_estimate": 150}, "3813438729": {"item_id": "3813438729", "resolved_id": "3813438729", "given_url": "https://arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/", "given_title": "Meta unveils a new large language model that can run on a single GPU", "favorite": "0", "status": "1", "time_added": "1677275847", "time_updated": "1677353638", "time_read": "1677353638", "time_favorited": "0", "sort_id": 362, "resolved_title": "Meta unveils a new large language model that can run on a single GPU [Updated]", "resolved_url": "https://arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/", "excerpt": "On Friday, Meta announced a new AI-powered large language model (LLM) called LLaMA-13B that it claims can outperform OpenAI's GPT-3 model despite being \"10x smaller.\" Smaller-sized AI models could lead to running ChatGPT-style language assistants locally on devices such as PCs and smartphones.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "621", "lang": "", "amp_url": "https://arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/amp/", "top_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/meta_llm_hero_1-640x360.jpg", "tags": {"chatgpt": {"item_id": "3813438729", "tag": "chatgpt"}, "deep-learning": {"item_id": "3813438729", "tag": "deep-learning"}, "generative": {"item_id": "3813438729", "tag": "generative"}, "nlp": {"item_id": "3813438729", "tag": "nlp"}}, "authors": {"171668034": {"item_id": "3813438729", "author_id": "171668034", "name": "Benj Edwards", "url": "https://arstechnica.com/author/benjedwards/"}}, "image": {"item_id": "3813438729", "src": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/meta_llm_hero_1-800x450.jpg", "width": "640", "height": "360"}, "images": {"1": {"item_id": "3813438729", "image_id": "1", "src": "https://cdn.arstechnica.net/wp-content/uploads/2023/02/meta_llm_hero_1-800x450.jpg", "width": "640", "height": "360", "credit": "Benj Edwards / Ars Technica", "caption": "Benj Edwards / Ars Technica"}}, "domain_metadata": {"name": "Ars Technica", "logo": "https://logo.clearbit.com/arstechnica.com?size=800", "greyscale_logo": "https://logo.clearbit.com/arstechnica.com?size=800&greyscale=true"}, "listen_duration_estimate": 240}, "2483790070": {"item_id": "2483790070", "resolved_id": "2483790070", "given_url": "https://paperswithcode.com/task/transfer-learning", "given_title": "Methodology | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572937", "time_updated": "1638708525", "time_read": "1608572947", "time_favorited": "0", "sort_id": 363, "resolved_title": "Transfer Learning", "resolved_url": "https://paperswithcode.com/task/transfer-learning", "excerpt": "Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "16", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/Screenshot_2019-11-29_at_17.29.44_aF1ljIX.png", "tags": {"deep-learning": {"item_id": "2483790070", "tag": "deep-learning"}, "transfer-learning": {"item_id": "2483790070", "tag": "transfer-learning"}}, "listen_duration_estimate": 6}, "2490491560": {"item_id": "2490491560", "resolved_id": "2490491560", "given_url": "https://paperswithcode.com/task/representation-learning", "given_title": "Methodology | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572916", "time_updated": "1638708525", "time_read": "1608572930", "time_favorited": "0", "sort_id": 364, "resolved_title": "Representation Learning", "resolved_url": "https://paperswithcode.com/task/representation-learning", "excerpt": "Representation Learning is a process in machine learning where algorithms extract meaningful patterns from raw data to create representations that are easier to understand and process.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "203", "lang": "en", "top_image_url": "https://production-media.paperswithcode.com/tasks/representation-learning_Rkb0arA.jpeg", "tags": {"deep-learning": {"item_id": "2490491560", "tag": "deep-learning"}, "representation-learning": {"item_id": "2490491560", "tag": "representation-learning"}}, "listen_duration_estimate": 79}, "2590463839": {"item_id": "2590463839", "resolved_id": "2590463839", "given_url": "https://paperswithcode.com/task/bayesian-inference", "given_title": "Methodology | Papers With Code", "favorite": "0", "status": "1", "time_added": "1608572963", "time_updated": "1638708525", "time_read": "1608572975", "time_favorited": "0", "sort_id": 365, "resolved_title": "Bayesian Inference", "resolved_url": "https://paperswithcode.com/task/bayesian-inference", "excerpt": "Or, discuss a change on Slack. Bayesian Inference is a methodology that employs Bayes Rule to estimate parameters (and their full posterior).", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "508", "lang": "en", "top_image_url": "https://paperswithcode.com/media/tasks/bayes-rule_0tW9Y9M.png", "tags": {"bayes": {"item_id": "2590463839", "tag": "bayes"}, "deep-learning": {"item_id": "2590463839", "tag": "deep-learning"}}, "image": {"item_id": "2590463839", "src": "https://paperswithcode.com/static/frameworks/torch.3a4c06fb45f1.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2590463839", "image_id": "1", "src": "https://paperswithcode.com/static/frameworks/torch.3a4c06fb45f1.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 197}, "2776499268": {"item_id": "2776499268", "resolved_id": "2776499268", "given_url": "https://github.com/milvus-io/milvus", "given_title": "milvus - An open source embedding vector similarity search engine powered b", "favorite": "0", "status": "1", "time_added": "1620993273", "time_updated": "1638708525", "time_read": "1621357115", "time_favorited": "0", "sort_id": 366, "resolved_title": "milvus-io/milvus", "resolved_url": "https://github.com/milvus-io/milvus", "excerpt": "What is Milvus? Milvus is an open-source vector database built to power AI applications and embedding similarity search. Milvus makes unstructured data search more accessible, and provides a consistent user experience regardless of the deployment environment.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "758", "lang": "en", "time_to_read": 3, "top_image_url": "https://repository-images.githubusercontent.com/208728772/03862e80-d34d-11eb-9030-15519da6dc8f", "tags": {"deep-learning": {"item_id": "2776499268", "tag": "deep-learning"}, "search": {"item_id": "2776499268", "tag": "search"}}, "image": {"item_id": "2776499268", "src": "https://camo.githubusercontent.com/39babe0486379545c8ba9cf5bfc37a66faf34f591822146596ff1229a1c4090b/68747470733a2f2f7a696c6c697a73746f726167652e626c6f622e636f72652e77696e646f77732e6e65742f7a696c6c697a2d6173736574732f7a696c6c697a2d6173736574732f6173736574732f726561646d655f656e5f366335623361313436362e706e67", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2776499268", "image_id": "1", "src": "https://camo.githubusercontent.com/39babe0486379545c8ba9cf5bfc37a66faf34f591822146596ff1229a1c4090b/68747470733a2f2f7a696c6c697a73746f726167652e626c6f622e636f72652e77696e646f77732e6e65742f7a696c6c697a2d6173736574732f7a696c6c697a2d6173736574732f6173736574732f726561646d655f656e5f366335623361313436362e706e67", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2776499268", "image_id": "2", "src": "https://camo.githubusercontent.com/519b2c5e8823f3fcb61656016815b923b8d2ccd5e47f81578099aba586b3ab7c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4a6f696e2d536c61636b2d6f72616e6765", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2776499268", "image_id": "3", "src": "https://camo.githubusercontent.com/752b4774cfd165a79c9a60ce99a3f8d4a8fdf32a812140db7c0d5ed1262e7832/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d696c7675732d696f2f6d696c767573", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2776499268", "image_id": "4", "src": "https://camo.githubusercontent.com/1c43e8844e10f0aa3cc090008162bac679bb930988a762d5b1aa36e8f2114d3d/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f70756c6c732f6d696c76757364622f6d696c767573", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2776499268", "image_id": "5", "src": "https://camo.githubusercontent.com/d7f7c9888e93284493a3c11e7fbee49df5a114e522a189c1d097143d346606d6/68747470733a2f2f696e7465726e616c2e7a696c6c697a2e636f6d3a31383038302f6a656e6b696e732f6a6f622f6d696c7675732d68612d63692f6a6f622f6d61737465722f62616467652f69636f6e", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2776499268", "image_id": "6", "src": "https://camo.githubusercontent.com/870aed02ba682dacc46be2ad2c3f32e113f01a39a98d184de191d09e5feeedd6/68747470733a2f2f626573747072616374696365732e636f7265696e6672617374727563747572652e6f72672f70726f6a656374732f333536332f6261646765", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2776499268", "image_id": "7", "src": "https://camo.githubusercontent.com/4110e294bf9a46dde489f3e4fffc4b5e7abf9eed144240606d51b940ef6a0d3f/68747470733a2f2f636f6465636f762e696f2f67682f6d696c7675732d696f2f6d696c7675732f6272616e63682f6d61737465722f67726170682f62616467652e737667", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2776499268", "image_id": "8", "src": "https://camo.githubusercontent.com/2d7e94f1820e7c3f5e9a1ca6c5146c05a97f15de0618b1313719239d0bd2802a/68747470733a2f2f6170692e636f646163792e636f6d2f70726f6a6563742f62616467652f47726164652f6334626232636366623531623437663939653433626664313730356564643935", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2776499268", "image_id": "9", "src": "https://camo.githubusercontent.com/4eceaf64f4f67b2ab71dacd60717b1723e2ba4f4cd83f8ebb201897fdd3a7d30/68747470733a2f2f7a696c6c697a73746f726167652e626c6f622e636f72652e77696e646f77732e6e65742f7a696c6c697a2d6173736574732f7a696c6c697a2d6173736574732f6173736574732f696d6167655f7365617263685f353961363465346632322e676966", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2776499268", "image_id": "10", "src": "https://camo.githubusercontent.com/61ac1b2149ce0039e57fc6d3da4231f3d07c83c782c3a2ef44d103d622eb6068/68747470733a2f2f7a696c6c697a73746f726167652e626c6f622e636f72652e77696e646f77732e6e65742f7a696c6c697a2d6173736574732f7a696c6c697a2d6173736574732f6173736574732f71615f646635656537626438332e676966", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2776499268", "image_id": "11", "src": "https://camo.githubusercontent.com/df85bd88b6eb45501a578929e77580309394879d2cc277031e215b358b69b033/68747470733a2f2f7a696c6c697a73746f726167652e626c6f622e636f72652e77696e646f77732e6e65742f7a696c6c697a2d6173736574732f7a696c6c697a2d6173736574732f6173736574732f6d6f6c655f7365617263685f373666383334303537322e676966", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2776499268", "image_id": "12", "src": "https://camo.githubusercontent.com/4eb39c5c3350a7599d9051109baa449df639fc454a73254a01c22b63160a3cc6/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616c6c2d2d636f6e7472696275746f72732d3133382d6f72616e6765", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "2776499268", "image_id": "13", "src": "https://avatars.githubusercontent.com/u/24547351?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "2776499268", "image_id": "14", "src": "https://avatars.githubusercontent.com/u/9635216?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "2776499268", "image_id": "15", "src": "https://avatars.githubusercontent.com/u/12489985?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "2776499268", "image_id": "16", "src": "https://avatars.githubusercontent.com/u/40494761?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "2776499268", "image_id": "17", "src": "https://avatars.githubusercontent.com/u/54123439?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "2776499268", "image_id": "18", "src": "https://avatars.githubusercontent.com/u/53458891?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "2776499268", "image_id": "19", "src": "https://avatars.githubusercontent.com/u/40255591?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "2776499268", "image_id": "20", "src": "https://avatars.githubusercontent.com/u/3909908?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "2776499268", "image_id": "21", "src": "https://avatars.githubusercontent.com/u/34762375?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "2776499268", "image_id": "22", "src": "https://avatars.githubusercontent.com/u/4417873?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "23": {"item_id": "2776499268", "image_id": "23", "src": "https://avatars.githubusercontent.com/u/31589260?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "2776499268", "image_id": "24", "src": "https://avatars.githubusercontent.com/u/64460989?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "2776499268", "image_id": "25", "src": "https://avatars.githubusercontent.com/u/8857059?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "26": {"item_id": "2776499268", "image_id": "26", "src": "https://avatars.githubusercontent.com/u/15663612?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "27": {"item_id": "2776499268", "image_id": "27", "src": "https://avatars.githubusercontent.com/u/55842817?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "28": {"item_id": "2776499268", "image_id": "28", "src": "https://avatars.githubusercontent.com/u/50101579?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "29": {"item_id": "2776499268", "image_id": "29", "src": "https://avatars.githubusercontent.com/u/40229765?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "30": {"item_id": "2776499268", "image_id": "30", "src": "https://avatars.githubusercontent.com/u/57477222?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "31": {"item_id": "2776499268", "image_id": "31", "src": "https://avatars.githubusercontent.com/u/35055583?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "32": {"item_id": "2776499268", "image_id": "32", "src": "https://avatars.githubusercontent.com/u/17645053?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "33": {"item_id": "2776499268", "image_id": "33", "src": "https://avatars.githubusercontent.com/u/2274405?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "34": {"item_id": "2776499268", "image_id": "34", "src": "https://avatars.githubusercontent.com/u/53512883?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "35": {"item_id": "2776499268", "image_id": "35", "src": "https://avatars.githubusercontent.com/u/33142505?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "36": {"item_id": "2776499268", "image_id": "36", "src": "https://avatars.githubusercontent.com/u/64019322?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "37": {"item_id": "2776499268", "image_id": "37", "src": "https://avatars.githubusercontent.com/u/81553353?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "38": {"item_id": "2776499268", "image_id": "38", "src": "https://avatars.githubusercontent.com/u/47274057?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "39": {"item_id": "2776499268", "image_id": "39", "src": "https://avatars.githubusercontent.com/u/64403786?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "40": {"item_id": "2776499268", "image_id": "40", "src": "https://avatars.githubusercontent.com/u/5410298?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "41": {"item_id": "2776499268", "image_id": "41", "src": "https://avatars.githubusercontent.com/u/57280231?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "42": {"item_id": "2776499268", "image_id": "42", "src": "https://avatars.githubusercontent.com/u/9876551?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "43": {"item_id": "2776499268", "image_id": "43", "src": "https://avatars.githubusercontent.com/u/29282370?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "44": {"item_id": "2776499268", "image_id": "44", "src": "https://avatars.githubusercontent.com/u/4702509?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "45": {"item_id": "2776499268", "image_id": "45", "src": "https://avatars.githubusercontent.com/u/10348819?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "46": {"item_id": "2776499268", "image_id": "46", "src": "https://avatars.githubusercontent.com/u/36157116?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "47": {"item_id": "2776499268", "image_id": "47", "src": "https://avatars.githubusercontent.com/u/27288593?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "48": {"item_id": "2776499268", "image_id": "48", "src": "https://avatars.githubusercontent.com/u/41352919?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "49": {"item_id": "2776499268", "image_id": "49", "src": "https://avatars.githubusercontent.com/u/11934432?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "50": {"item_id": "2776499268", "image_id": "50", "src": "https://avatars.githubusercontent.com/u/20420181?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "51": {"item_id": "2776499268", "image_id": "51", "src": "https://avatars.githubusercontent.com/u/39627130?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "52": {"item_id": "2776499268", "image_id": "52", "src": "https://avatars.githubusercontent.com/u/51370125?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "53": {"item_id": "2776499268", "image_id": "53", "src": "https://avatars.githubusercontent.com/u/48198922?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "54": {"item_id": "2776499268", "image_id": "54", "src": "https://avatars.githubusercontent.com/u/48044391?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "55": {"item_id": "2776499268", "image_id": "55", "src": "https://avatars.githubusercontent.com/u/36330442?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "56": {"item_id": "2776499268", "image_id": "56", "src": "https://avatars.githubusercontent.com/u/2356895?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "57": {"item_id": "2776499268", "image_id": "57", "src": "https://avatars.githubusercontent.com/u/50362613?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "58": {"item_id": "2776499268", "image_id": "58", "src": "https://avatars.githubusercontent.com/u/56624819?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "59": {"item_id": "2776499268", "image_id": "59", "src": "https://avatars.githubusercontent.com/u/42060877?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "60": {"item_id": "2776499268", "image_id": "60", "src": "https://avatars.githubusercontent.com/u/30914966?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "61": {"item_id": "2776499268", "image_id": "61", "src": "https://avatars.githubusercontent.com/u/83755740?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "62": {"item_id": "2776499268", "image_id": "62", "src": "https://avatars.githubusercontent.com/u/24309515?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "63": {"item_id": "2776499268", "image_id": "63", "src": "https://avatars.githubusercontent.com/u/2993941?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "64": {"item_id": "2776499268", "image_id": "64", "src": "https://avatars.githubusercontent.com/u/2155120?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "65": {"item_id": "2776499268", "image_id": "65", "src": "https://avatars.githubusercontent.com/u/2233492?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "66": {"item_id": "2776499268", "image_id": "66", "src": "https://avatars.githubusercontent.com/u/23704769?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "67": {"item_id": "2776499268", "image_id": "67", "src": "https://avatars.githubusercontent.com/u/84113973?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "68": {"item_id": "2776499268", "image_id": "68", "src": "https://avatars.githubusercontent.com/u/39671710?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "69": {"item_id": "2776499268", "image_id": "69", "src": "https://avatars.githubusercontent.com/u/653101?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "70": {"item_id": "2776499268", "image_id": "70", "src": "https://avatars.githubusercontent.com/u/3992404?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "71": {"item_id": "2776499268", "image_id": "71", "src": "https://avatars.githubusercontent.com/u/83751452?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "72": {"item_id": "2776499268", "image_id": "72", "src": "https://avatars.githubusercontent.com/u/26356194?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "73": {"item_id": "2776499268", "image_id": "73", "src": "https://avatars.githubusercontent.com/u/59249785?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "74": {"item_id": "2776499268", "image_id": "74", "src": "https://avatars.githubusercontent.com/u/24242249?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "75": {"item_id": "2776499268", "image_id": "75", "src": "https://avatars.githubusercontent.com/u/41563853?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "76": {"item_id": "2776499268", "image_id": "76", "src": "https://avatars.githubusercontent.com/u/56623710?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "77": {"item_id": "2776499268", "image_id": "77", "src": "https://avatars.githubusercontent.com/u/1488134?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "78": {"item_id": "2776499268", "image_id": "78", "src": "https://avatars.githubusercontent.com/u/14878830?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "79": {"item_id": "2776499268", "image_id": "79", "src": "https://avatars.githubusercontent.com/u/64584368?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "80": {"item_id": "2776499268", "image_id": "80", "src": "https://avatars.githubusercontent.com/u/25433850?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "81": {"item_id": "2776499268", "image_id": "81", "src": "https://avatars.githubusercontent.com/u/64510805?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "82": {"item_id": "2776499268", "image_id": "82", "src": "https://avatars.githubusercontent.com/u/81822489?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "83": {"item_id": "2776499268", "image_id": "83", "src": "https://avatars.githubusercontent.com/u/49153041?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "84": {"item_id": "2776499268", "image_id": "84", "src": "https://avatars.githubusercontent.com/u/4769989?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "85": {"item_id": "2776499268", "image_id": "85", "src": "https://avatars.githubusercontent.com/u/67679556?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "86": {"item_id": "2776499268", "image_id": "86", "src": "https://avatars.githubusercontent.com/u/14368181?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "87": {"item_id": "2776499268", "image_id": "87", "src": "https://avatars.githubusercontent.com/u/56617657?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "88": {"item_id": "2776499268", "image_id": "88", "src": "https://avatars.githubusercontent.com/u/8500564?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "89": {"item_id": "2776499268", "image_id": "89", "src": "https://avatars.githubusercontent.com/u/53246671?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "90": {"item_id": "2776499268", "image_id": "90", "src": "https://avatars.githubusercontent.com/u/52496626?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "91": {"item_id": "2776499268", "image_id": "91", "src": "https://avatars.githubusercontent.com/u/528003?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "92": {"item_id": "2776499268", "image_id": "92", "src": "https://avatars.githubusercontent.com/u/64533877?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "93": {"item_id": "2776499268", "image_id": "93", "src": "https://avatars.githubusercontent.com/u/86251631?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "94": {"item_id": "2776499268", "image_id": "94", "src": "https://avatars.githubusercontent.com/u/24581746?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "95": {"item_id": "2776499268", "image_id": "95", "src": "https://avatars.githubusercontent.com/u/52057195?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "96": {"item_id": "2776499268", "image_id": "96", "src": "https://avatars.githubusercontent.com/u/34296482?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "97": {"item_id": "2776499268", "image_id": "97", "src": "https://avatars.githubusercontent.com/u/31717785?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "98": {"item_id": "2776499268", "image_id": "98", "src": "https://avatars.githubusercontent.com/u/9720105?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "99": {"item_id": "2776499268", "image_id": "99", "src": "https://avatars.githubusercontent.com/u/15364733?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "100": {"item_id": "2776499268", "image_id": "100", "src": "https://avatars.githubusercontent.com/u/26682620?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "101": {"item_id": "2776499268", "image_id": "101", "src": "https://avatars.githubusercontent.com/u/5290110?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "102": {"item_id": "2776499268", "image_id": "102", "src": "https://avatars.githubusercontent.com/u/183388?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "103": {"item_id": "2776499268", "image_id": "103", "src": "https://avatars.githubusercontent.com/u/95194?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "104": {"item_id": "2776499268", "image_id": "104", "src": "https://avatars.githubusercontent.com/u/22544815?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "105": {"item_id": "2776499268", "image_id": "105", "src": "https://avatars.githubusercontent.com/u/37039827?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "106": {"item_id": "2776499268", "image_id": "106", "src": "https://avatars.githubusercontent.com/u/5696721?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "107": {"item_id": "2776499268", "image_id": "107", "src": "https://avatars.githubusercontent.com/u/20559208?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "108": {"item_id": "2776499268", "image_id": "108", "src": "https://avatars.githubusercontent.com/u/1751024?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "109": {"item_id": "2776499268", "image_id": "109", "src": "https://avatars.githubusercontent.com/u/34152706?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "110": {"item_id": "2776499268", "image_id": "110", "src": "https://avatars.githubusercontent.com/u/5617677?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "111": {"item_id": "2776499268", "image_id": "111", "src": "https://avatars.githubusercontent.com/u/14035577?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "112": {"item_id": "2776499268", "image_id": "112", "src": "https://avatars.githubusercontent.com/u/11576622?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "113": {"item_id": "2776499268", "image_id": "113", "src": "https://avatars.githubusercontent.com/u/51972064?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "114": {"item_id": "2776499268", "image_id": "114", "src": "https://avatars.githubusercontent.com/u/26035292?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "115": {"item_id": "2776499268", "image_id": "115", "src": "https://avatars.githubusercontent.com/u/3996622?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "116": {"item_id": "2776499268", "image_id": "116", "src": "https://avatars.githubusercontent.com/u/12595343?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "117": {"item_id": "2776499268", "image_id": "117", "src": "https://avatars.githubusercontent.com/u/33335490?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "118": {"item_id": "2776499268", "image_id": "118", "src": "https://avatars.githubusercontent.com/u/185051?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "119": {"item_id": "2776499268", "image_id": "119", "src": "https://avatars.githubusercontent.com/u/46514371?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "120": {"item_id": "2776499268", "image_id": "120", "src": "https://avatars.githubusercontent.com/u/49774184?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "121": {"item_id": "2776499268", "image_id": "121", "src": "https://avatars.githubusercontent.com/u/39143280?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "122": {"item_id": "2776499268", "image_id": "122", "src": "https://avatars.githubusercontent.com/u/53459423?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "123": {"item_id": "2776499268", "image_id": "123", "src": "https://avatars.githubusercontent.com/u/26541600?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "124": {"item_id": "2776499268", "image_id": "124", "src": "https://avatars.githubusercontent.com/u/19733683?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "125": {"item_id": "2776499268", "image_id": "125", "src": "https://avatars.githubusercontent.com/u/56469371?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "126": {"item_id": "2776499268", "image_id": "126", "src": "https://avatars.githubusercontent.com/u/10708326?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "127": {"item_id": "2776499268", "image_id": "127", "src": "https://avatars.githubusercontent.com/u/9817127?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "128": {"item_id": "2776499268", "image_id": "128", "src": "https://avatars.githubusercontent.com/u/83750738?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "129": {"item_id": "2776499268", "image_id": "129", "src": "https://avatars.githubusercontent.com/u/17634030?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "130": {"item_id": "2776499268", "image_id": "130", "src": "https://avatars.githubusercontent.com/u/24822588?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "131": {"item_id": "2776499268", "image_id": "131", "src": "https://avatars.githubusercontent.com/u/56624359?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "132": {"item_id": "2776499268", "image_id": "132", "src": "https://avatars.githubusercontent.com/u/13817362?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "133": {"item_id": "2776499268", "image_id": "133", "src": "https://avatars.githubusercontent.com/u/26307815?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "134": {"item_id": "2776499268", "image_id": "134", "src": "https://avatars.githubusercontent.com/u/13234561?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "135": {"item_id": "2776499268", "image_id": "135", "src": "https://avatars.githubusercontent.com/u/27938020?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "136": {"item_id": "2776499268", "image_id": "136", "src": "https://avatars.githubusercontent.com/u/48882296?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "137": {"item_id": "2776499268", "image_id": "137", "src": "https://avatars.githubusercontent.com/u/46207236?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "138": {"item_id": "2776499268", "image_id": "138", "src": "https://avatars.githubusercontent.com/u/20124155?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "139": {"item_id": "2776499268", "image_id": "139", "src": "https://avatars.githubusercontent.com/u/35444753?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "140": {"item_id": "2776499268", "image_id": "140", "src": "https://avatars.githubusercontent.com/u/10089260?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "141": {"item_id": "2776499268", "image_id": "141", "src": "https://avatars.githubusercontent.com/u/82361606?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "142": {"item_id": "2776499268", "image_id": "142", "src": "https://avatars.githubusercontent.com/u/2282099?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "143": {"item_id": "2776499268", "image_id": "143", "src": "https://avatars.githubusercontent.com/u/23047684?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "144": {"item_id": "2776499268", "image_id": "144", "src": "https://avatars.githubusercontent.com/u/9016120?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "145": {"item_id": "2776499268", "image_id": "145", "src": "https://avatars.githubusercontent.com/u/62009483?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "146": {"item_id": "2776499268", "image_id": "146", "src": "https://avatars.githubusercontent.com/u/11961641?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "147": {"item_id": "2776499268", "image_id": "147", "src": "https://avatars.githubusercontent.com/u/57790060?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "148": {"item_id": "2776499268", "image_id": "148", "src": "https://avatars.githubusercontent.com/u/51948620?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "149": {"item_id": "2776499268", "image_id": "149", "src": "https://avatars.githubusercontent.com/u/15153901?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "150": {"item_id": "2776499268", "image_id": "150", "src": "https://avatars.githubusercontent.com/u/29620478?v=4", "width": "40", "height": "0", "credit": "", "caption": ""}, "151": {"item_id": "2776499268", "image_id": "151", "src": "https://camo.githubusercontent.com/fd5fe91d7bb437abfa40b0fbf6b5dc79f9d80be62b98810d85ef5285c91be5bc/68747470733a2f2f7a696c6c697a73746f726167652e626c6f622e636f72652e77696e646f77732e6e65742f7a696c6c697a2d6173736574732f7a696c6c697a2d6173736574732f6173736574732f726561646d655f736c61636b5f346130376334633932662e706e67", "width": "500", "height": "150", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 293}, "3651162538": {"item_id": "3651162538", "resolved_id": "3651162538", "given_url": "http://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html", "given_title": "Minerva: Solving Quantitative Reasoning Problems with Language Models", "favorite": "0", "status": "1", "time_added": "1656617557", "time_updated": "1657065526", "time_read": "1657065525", "time_favorited": "0", "sort_id": 367, "resolved_title": "Minerva: Solving Quantitative Reasoning Problems with Language Models", "resolved_url": "http://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html", "excerpt": "Language models have demonstrated remarkable performance on a variety of natural language tasks ‚Äî indeed, a general lesson from many works, including BERT, GPT-3, Gopher, and PaLM, has been that neural networks trained on diverse data at large scale in an unsupervised way can perform well on a var", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1026", "lang": "en", "time_to_read": 5, "top_image_url": "http://2.bp.blogspot.com/-qRz-hnwUdY4/WulXSQ6Rv4I/AAAAAAAATvQ/shk7KsphA0c3E3nUMsDVASqYaH0PhLPNwCK4BGAYYCw/s1600/GoogleAI_logo_horizontal_color_rgb.png", "tags": {"deep-learning": {"item_id": "3651162538", "tag": "deep-learning"}, "nlp": {"item_id": "3651162538", "tag": "nlp"}}, "image": {"item_id": "3651162538", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgpHov9BD2yiBEDrAWZUQxDYWRIuofmpbWVJaJPDPrE-2BbT3B_15-R4n22yNnDVs_8Vkea-Y-ykOHaB6mCKwkLYkBDBoS1r8NX2u4KsCpNC53GAM_8seK6L_90CJCmhC4ML9SSVY03lErXDQd6Pp-ysGsANdvNcqur7lMARO7h4RtDtf6Y7UlNYuEjjQ/s1999/image5.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3651162538", "image_id": "1", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgpHov9BD2yiBEDrAWZUQxDYWRIuofmpbWVJaJPDPrE-2BbT3B_15-R4n22yNnDVs_8Vkea-Y-ykOHaB6mCKwkLYkBDBoS1r8NX2u4KsCpNC53GAM_8seK6L_90CJCmhC4ML9SSVY03lErXDQd6Pp-ysGsANdvNcqur7lMARO7h4RtDtf6Y7UlNYuEjjQ/s1999/image5.png", "width": "0", "height": "0", "credit": "", "caption": "Solving a multi-step problem: A question from the MATH dataset and Minerva‚Äôs solution. The model writes down a line equation, simplifies it, substitutes a variable, and solves for y."}, "2": {"item_id": "3651162538", "image_id": "2", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjIOaSDE8P-ubM5OvUkbjEFtEvs21SKAI3F3dwa4dbRuKKiq1cQPG1unZGyJrtxJFLiG8mfViwz2vDd2BrHd-E8UFKTOf2WB5r4L-EpO3BQY-zu5Z4yW1EfVmSrFvNzYfKXSruQgdPTiwgeZGUNdPUHKFSUIMUGCxWBRsV_KWO72PqlFPDUBFe_MLBgBg/s2272/image.png", "width": "0", "height": "0", "credit": "left", "caption": "Example questions from the Joint Entrance Examination Main Math 2020 exam taken each year by almost 2M Indian high-school students intended to study engineering and similar fields"}, "3": {"item_id": "3651162538", "image_id": "3", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEivwDKms-EUCz7cz8H0c8Q5KHe97juJHfPWbuTf1y6hdCMS8xE1mLs3-x1znGaMPzrvjj87k750VhmDZYen3U056ou78Sn2ENZ0Zxv-aRBQ3doXpDZpIpY7D-yLgc4Vvi_-FagkBYy8IioKWPwV61Ri9l2B3LZu7mSVPuGnoC626f0tyZnTrT0iiGuM7Q/s1999/image1.png", "width": "0", "height": "0", "credit": "", "caption": "A dataset for quantitative reasoning: Careful data processing preserves mathematical information, allowing the model to learn mathematics at a higher level."}, "4": {"item_id": "3651162538", "image_id": "4", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgTupKiVyR5dIslWNgdzXAVJcGJXFmQCPD2Md23ceVdLwcIYtGODTrEE0Jj_cM7NLt-4pR9Yk47WjvbWWJJBroqYxRvWKciUTk-1AWJZXGdnUuXQzMq41nDJFFdhwXq73Gi2T880waPoqTxX6N9B444DM4u6Hwo6Ygt2NPT2nOMr8chsx1q2YhSl3NmyQ/s1896/image2.png", "width": "0", "height": "0", "credit": "", "caption": "Evaluation results on MATH and MMLU-STEM, which include high school and college level questions covering a range of STEM topics."}, "5": {"item_id": "3651162538", "image_id": "5", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjbE_3M_iZVTPpV-fM6rnv2T0k48RiTXWVtQIan4NEm953gsIuZXNc6t59_WABUjTZD1NHM2SDXQ-4gFCQrou3ekA3Ly3US4LYVO5Qfqkj0FfNMMucP97Omr1Taq9fdRL0x_VbsTih3oyMwave84GPjddFPtadp1fgcNkcTeGolfIBvjLj2SsIfJ9vs9A/s1999/image8.png", "width": "0", "height": "0", "credit": "", "caption": "Calculation mistake: The model incorrectly cancels the square root on both sides of the equation."}, "6": {"item_id": "3651162538", "image_id": "6", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg0hsddb9-V6t0H2wSDN0UPNY--wVNwZYKUEpAroQVs0Zlb-UW5w60anhm-S8--hk1E7Ht6Gb-3QzQD70h3RQQDIR8OBgq8CW3dKnmHamLlZKH3CYCV2TeLB9PAI84UMKBP8l-eiI-SafFGbqlTy9OAYspIP240hKD8It73Gnx1I0RdSdElS7jj4l267A/s1999/image3.png", "width": "0", "height": "0", "credit": "", "caption": "Reasoning mistake: The model computes the number of free throws at the fourth practice, but then uses this number as the final answer for the first practice."}, "7": {"item_id": "3651162538", "image_id": "7", "src": "https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgjB2ctso8XO1RgQdVp5f5OVCxxTqaCL23tGnHaLcxU5JgemoNYFwHYKPsAXmqhu3Ht4mBaC8m_DGap1w1bNwfqd7eAQAGzx21M6kRTleyCmCI_1QYS5BM3X01HZ2PGkIA11shPHAOEvJO7n6yi7nAiTTLhoENdxom9ITom8pp5DNQBoI7PJdqc78T1Zg/s1999/image6.png", "width": "0", "height": "0", "credit": "", "caption": "Solving a problem using calculus and trigonometry: A question from the MATH dataset asking for the speed of a particle in circular motion. Minerva finds a correct step-by-step solution. In the process, Minerva computes a time derivative and applies a trigonometric identity."}}, "listen_duration_estimate": 397}, "3224867250": {"item_id": "3224867250", "resolved_id": "3224867275", "given_url": "https://towardsdatascience.com/model-compression-a-look-into-reducing-model-size-8251683c338e?source=rss----7f60cf5620c9---4", "given_title": "Model Compression: A Look into Reducing Model Size", "favorite": "0", "status": "1", "time_added": "1610215520", "time_updated": "1638708525", "time_read": "1610311470", "time_favorited": "0", "sort_id": 368, "resolved_title": "Model Compression with TensorFlow Lite: A Look into Reducing Model Size", "resolved_url": "https://towardsdatascience.com/model-compression-a-look-into-reducing-model-size-8251683c338e", "excerpt": "A significant problem in the arms race to produce more accurate models is complexity, which leads to the problem of size. These models are usually huge and resource-intensive, which leads to greater space and time consumption.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2156", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/max/1200/1*Em_pmyl1YhE5FwiIxKGyfQ.jpeg", "tags": {"deep-learning": {"item_id": "3224867250", "tag": "deep-learning"}, "machine-learning": {"item_id": "3224867250", "tag": "machine-learning"}, "model-compression": {"item_id": "3224867250", "tag": "model-compression"}, "tensorflow": {"item_id": "3224867250", "tag": "tensorflow"}}, "authors": {"143995228": {"item_id": "3224867250", "author_id": "143995228", "name": "Cawin Chan", "url": "https://cawin-chan.medium.com"}}, "image": {"item_id": "3224867250", "src": "https://miro.medium.com/fit/c/56/56/1*ujyAtDrVIt3uT4uTX2DTXg.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3224867250", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*ujyAtDrVIt3uT4uTX2DTXg.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3224867250", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*Em_pmyl1YhE5FwiIxKGyfQ.jpeg", "width": "700", "height": "730", "credit": "John Cameron on Unsplash", "caption": ""}, "3": {"item_id": "3224867250", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*tWvofX1zZZnIHyHs-nKAfA.png", "width": "700", "height": "592", "credit": "Image by Govind Bhattacharjee on Science Reporter", "caption": "Artificial Neural Network"}, "4": {"item_id": "3224867250", "image_id": "4", "src": "https://miro.medium.com/max/1038/1*dSe3tHRp5tX--KhPe1s3kQ.png", "width": "519", "height": "206", "credit": "", "caption": ""}, "5": {"item_id": "3224867250", "image_id": "5", "src": "https://miro.medium.com/max/1230/1*-tP5wAcnO9ZNiE3xqasyWQ.png", "width": "615", "height": "284", "credit": "", "caption": "Model Architecture Size Comparison and Model Accuracy Chart by Author"}, "6": {"item_id": "3224867250", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*4bdzw3lO1bgmcEG4olUTIw.png", "width": "700", "height": "276", "credit": "", "caption": "Average Accuracy Chart by Author"}, "7": {"item_id": "3224867250", "image_id": "7", "src": "https://miro.medium.com/max/768/1*rq7yYw1Qc_iAcUtyIa8yTA.png", "width": "384", "height": "92", "credit": "", "caption": ""}, "8": {"item_id": "3224867250", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*zp3pgLarHDokJE3_r3BSYw.png", "width": "700", "height": "263", "credit": "", "caption": "Average Accuracy Table and Chart by Author"}, "9": {"item_id": "3224867250", "image_id": "9", "src": "https://miro.medium.com/max/896/1*MS9CurWu7d9-jY8VtwvZgw.png", "width": "448", "height": "264", "credit": "", "caption": "Original Model Benchmark Table by Author"}, "10": {"item_id": "3224867250", "image_id": "10", "src": "https://miro.medium.com/max/2000/1*qqyw_eO4yOt3Fij4Z9k_bw.png", "width": "1000", "height": "491", "credit": "", "caption": ""}, "11": {"item_id": "3224867250", "image_id": "11", "src": "https://miro.medium.com/max/2000/1*DEPl-Saa6877mUZiLnXDFA.png", "width": "1000", "height": "424", "credit": "", "caption": "Images by Raziel Alverez from TensorFlow"}, "12": {"item_id": "3224867250", "image_id": "12", "src": "https://miro.medium.com/max/2878/1*9zlVmTRHs91sa7BlHiSEig.png", "width": "1439", "height": "289", "credit": "", "caption": ""}, "13": {"item_id": "3224867250", "image_id": "13", "src": "https://miro.medium.com/max/1352/1*4n7E3daJ6QnRq-yUgkwQ5w.png", "width": "676", "height": "109", "credit": "Table and Chart", "caption": "Results of Different Model Compression Tools"}, "14": {"item_id": "3224867250", "image_id": "14", "src": "https://miro.medium.com/max/1192/1*71eCH4F8k_RcuH-nuZvNXg.png", "width": "596", "height": "264", "credit": "", "caption": "TFLite Model Benchmark Table Comparison by Author"}, "15": {"item_id": "3224867250", "image_id": "15", "src": "https://miro.medium.com/max/2000/1*wBXAUgeb1qbfjnrxGqolfA.png", "width": "1000", "height": "551", "credit": "", "caption": "Images by Raziel Alverez from TensorFlow"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 835}, "2749835414": {"item_id": "2749835414", "resolved_id": "2749835414", "given_url": "https://github.com/MrSyee/pg-is-all-you-need", "given_title": "MrSyee/pg-is-all-you-need: Policy Gradient is all you need! A step-by-step ", "favorite": "0", "status": "1", "time_added": "1570503860", "time_updated": "1638708525", "time_read": "1576355404", "time_favorited": "0", "sort_id": 369, "resolved_title": "PG is all you need!", "resolved_url": "https://github.com/MrSyee/pg-is-all-you-need", "excerpt": "PG is all you need! This is a step-by-step tutorial for Policy Gradient algorithms from A2C to SAC, including learning acceleration methods using demonstrations for treating real applications with sparse rewards.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "428", "lang": "en", "top_image_url": "https://opengraph.githubassets.com/87fcc101c22001f008eee32094a10014807c52f01c6904f756b04ae958eb7fd9/MrSyee/pg-is-all-you-need", "tags": {"deep-learning": {"item_id": "2749835414", "tag": "deep-learning"}, "policy-gradients": {"item_id": "2749835414", "tag": "policy-gradients"}}, "authors": {"112381369": {"item_id": "2749835414", "author_id": "112381369", "name": "emoji key", "url": "https://allcontributors.org/docs/en/emoji-key"}}, "image": {"item_id": "2749835414", "src": "https://camo.githubusercontent.com/3f29481ce9ea7caed48cceaa0255584ec5519f38b00fec3f5aaf7d9aff3cb5c8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616c6c5f636f6e7472696275746f72732d342d6f72616e67652e7376673f7374796c653d666c61742d737175617265", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2749835414", "image_id": "1", "src": "https://camo.githubusercontent.com/3f29481ce9ea7caed48cceaa0255584ec5519f38b00fec3f5aaf7d9aff3cb5c8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f616c6c5f636f6e7472696275746f72732d342d6f72616e67652e7376673f7374796c653d666c61742d737175617265", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2749835414", "image_id": "2", "src": "https://user-images.githubusercontent.com/17582508/76502245-0bd39680-6487-11ea-8f59-cbde1b841af9.gif", "width": "200", "height": "140", "credit": "", "caption": ""}, "3": {"item_id": "2749835414", "image_id": "3", "src": "https://avatars3.githubusercontent.com/u/17582508?v=4", "width": "100", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2749835414", "image_id": "4", "src": "https://avatars3.githubusercontent.com/u/14961526?v=4", "width": "100", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2749835414", "image_id": "5", "src": "https://avatars0.githubusercontent.com/u/43226417?v=4", "width": "100", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2749835414", "image_id": "6", "src": "https://avatars0.githubusercontent.com/u/37307369?v=4", "width": "100", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 166}, "2799205818": {"item_id": "2799205818", "resolved_id": "2799205861", "given_url": "https://www.kdnuggets.com/2019/11/all-about-autoencoders.html", "given_title": "Neural Networks 201: All About Autoencoders", "favorite": "0", "status": "1", "time_added": "1574431023", "time_updated": "1673901753", "time_read": "1576355687", "time_favorited": "0", "sort_id": 370, "resolved_title": "Neural Networks 201: All About Autoencoders", "resolved_url": "https://www.kdnuggets.com/neural-networks-201-all-about-autoencoders.html/", "excerpt": "Autoencoders can be a very powerful tool for leveraging unlabeled data to solve a variety of problems, such as learning a \"feature extractor\" that helps build powerful classifiers, finding anomalies, or doing a Missing Value Imputation. By Zak Jost, Research Scientist at Amazon Web Services.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "334", "lang": "en", "tags": {"autoencoders": {"item_id": "2799205818", "tag": "autoencoders"}, "deep-learning": {"item_id": "2799205818", "tag": "deep-learning"}}, "image": {"item_id": "2799205818", "src": "http://img.youtube.com/vi/3jmcHZq3A5s/0.jpg", "width": "480", "height": "360"}, "images": {"1": {"item_id": "2799205818", "image_id": "1", "src": "http://img.youtube.com/vi/3jmcHZq3A5s/0.jpg", "width": "480", "height": "360", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "2799205818", "video_id": "1", "src": "https://www.youtube.com/embed/3jmcHZq3A5s?feature=oembed", "width": "600", "height": "338", "type": "1", "vid": "3jmcHZq3A5s", "length": "0"}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 129}, "3248106227": {"item_id": "3248106227", "resolved_id": "0", "given_url": "http://localhost:4000/pdfs/math/neural-net-cheatsheet.pdf", "given_title": "neural-net-cheatsheet.pdf", "favorite": "0", "status": "1", "time_added": "1612436913", "time_updated": "1691366676", "time_read": "1612436926", "time_favorited": "0", "sort_id": 371, "tags": {"adversarial": {"item_id": "3248106227", "tag": "adversarial"}, "deep-learning": {"item_id": "3248106227", "tag": "deep-learning"}}, "listen_duration_estimate": 0}, "3155793407": {"item_id": "3155793407", "resolved_id": "3155793407", "given_url": "https://spectrum.ieee.org/tech-talk/robotics/artificial-intelligence/new-ai-inferencing-records?fbclid=IwAR2d9DLYUNeYmCnKNm9VoQkdWQHkFQBedMaSpLu6pDnKTpqV_Mkir0AD2qA", "given_title": "New AI Inferencing Records - IEEE Spectrum", "favorite": "0", "status": "1", "time_added": "1603900196", "time_updated": "1638708525", "time_read": "1604187428", "time_favorited": "0", "sort_id": 372, "resolved_title": "Full Page Reload", "resolved_url": "https://spectrum.ieee.org/tech-talk/robotics/artificial-intelligence/new-ai-inferencing-records?fbclid=IwAR2d9DLYUNeYmCnKNm9VoQkdWQHkFQBedMaSpLu6pDnKTpqV_Mkir0AD2qA", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"deep-learning": {"item_id": "3155793407", "tag": "deep-learning"}, "semiconductors": {"item_id": "3155793407", "tag": "semiconductors"}}, "domain_metadata": {"name": "IEEE", "logo": "https://logo.clearbit.com/ieee.org?size=800", "greyscale_logo": "https://logo.clearbit.com/ieee.org?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3278175081": {"item_id": "3278175081", "resolved_id": "3278175081", "given_url": "https://thenextweb.com/neural/2021/03/11/ai-detects-deepfakes-analyzing-light-reflections-in-the-cornea-eyes-gans-thispersondoesnotexist/", "given_title": "New AI tool detects Deepfakes by analyzing light reflections in the eyes", "favorite": "0", "status": "1", "time_added": "1615720596", "time_updated": "1638708525", "time_read": "1615720629", "time_favorited": "0", "sort_id": 373, "resolved_title": "AI tool detects Deepfakes by analyzing light reflections in the eyes", "resolved_url": "https://thenextweb.com/neural/2021/03/11/ai-detects-deepfakes-analyzing-light-reflections-in-the-cornea-eyes-gans-thispersondoesnotexist/", "excerpt": "Writer at Neural by TNW ‚Äî Thomas covers AI in all its iterations. Likes Werner Herzog films and Arsenal FC.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "437", "lang": "en", "amp_url": "https://thenextweb.com/news/ai-detects-deepfakes-analyzing-light-reflections-in-the-cornea-eyes-gans-thispersondoesnotexist/amp", "top_image_url": "https://img-cdn.tnwcdn.com/image/neural?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2021%2F03%2Fimage-2-1.jpg&signature=dda76292883900c4239ddfdb05eb5045", "tags": {"deep-learning": {"item_id": "3278175081", "tag": "deep-learning"}, "deepfakes": {"item_id": "3278175081", "tag": "deepfakes"}, "gans": {"item_id": "3278175081", "tag": "gans"}, "machine-vision": {"item_id": "3278175081", "tag": "machine-vision"}}, "authors": {"28642972": {"item_id": "3278175081", "author_id": "28642972", "name": "Thomas Macaulay", "url": ""}}, "image": {"item_id": "3278175081", "src": "https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2021/03/Screenshot-2021-03-11-at-16.15.55.png", "width": "982", "height": "634"}, "images": {"1": {"item_id": "3278175081", "image_id": "1", "src": "https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2021/03/Screenshot-2021-03-11-at-16.15.55.png", "width": "982", "height": "634", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The Next Web", "logo": "https://logo.clearbit.com/thenextweb.com?size=800", "greyscale_logo": "https://logo.clearbit.com/thenextweb.com?size=800&greyscale=true"}, "listen_duration_estimate": 169}, "3098126871": {"item_id": "3098126871", "resolved_id": "3098126892", "given_url": "https://towardsdatascience.com/new-approaches-to-object-detection-f5cbc925e00e?source=rss----7f60cf5620c9---4", "given_title": "New Approaches to Object Detection", "favorite": "0", "status": "1", "time_added": "1598988620", "time_updated": "1638708525", "time_read": "1599011208", "time_favorited": "0", "sort_id": 374, "resolved_title": "New Approaches to Object Detection", "resolved_url": "https://towardsdatascience.com/new-approaches-to-object-detection-f5cbc925e00e", "excerpt": "I will start with a short introduction of different approaches to object detection. After both traditional and newer approaches are presented, you can read about the most important parts of CenterNet and TTFNet. Many ideas in both models are similar, therefore they will be introduced together.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1205", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/1*_ssXB-7gYmIwif0mxjncYg.jpeg", "tags": {"deep-learning": {"item_id": "3098126871", "tag": "deep-learning"}, "vision": {"item_id": "3098126871", "tag": "vision"}}, "authors": {"152215953": {"item_id": "3098126871", "author_id": "152215953", "name": "Libor Vanek", "url": "https://libor-vanek.medium.com"}}, "image": {"item_id": "3098126871", "src": "https://miro.medium.com/fit/c/56/56/1*YUYMuqs815KxE1iR6QtVJQ.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3098126871", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*YUYMuqs815KxE1iR6QtVJQ.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3098126871", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*_ssXB-7gYmIwif0mxjncYg.jpeg", "width": "700", "height": "394", "credit": "", "caption": "source: pexels.com"}, "3": {"item_id": "3098126871", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*QSdw1M6FkmarZXbD0PQs_A.jpeg", "width": "700", "height": "333", "credit": "", "caption": "source: pexels.com"}, "4": {"item_id": "3098126871", "image_id": "4", "src": "https://miro.medium.com/max/4400/1*60ROU3IyeI3U8ryAUXs-2A.png", "width": "2200", "height": "617", "credit": "Yellow: convolutional layer, red: max pooling, blue: upsampling.", "caption": "Simplified visualization of CenterNet with ResNet18, using upsampling and concatenation."}, "5": {"item_id": "3098126871", "image_id": "5", "src": "https://miro.medium.com/max/1084/1*lVma1W94MGETfUVaGEpF0g.png", "width": "542", "height": "256", "credit": "left", "caption": "A heatmap for CenterNet"}, "6": {"item_id": "3098126871", "image_id": "6", "src": "https://miro.medium.com/max/1084/1*khKe6aSlYkjjzUaCzRbhVw.png", "width": "542", "height": "238", "credit": "", "caption": "Selection of values for standard vs deformable convolution.FI"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 466}, "3840267465": {"item_id": "3840267465", "resolved_id": "3840267465", "given_url": "https://www.nvidia.com/en-us/lp/ai-data-science/large-language-models-ebook/", "given_title": "New Ebook: A Beginner‚Äôs Guide to Large Language Models", "favorite": "0", "status": "1", "time_added": "1680721352", "time_updated": "1681439189", "time_read": "1681439189", "time_favorited": "0", "sort_id": 375, "resolved_title": "An Enterprise Guide to Large Language Models", "resolved_url": "https://www.nvidia.com/en-us/lp/ai-data-science/large-language-models-ebook/", "excerpt": "What Are Large Language Models and How Do They Work? Learn about the evolution of LLMs, the role of foundation models, and how the underlying technologies have come together to unlock the power of LLMs for the enterprise.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "38", "lang": "en", "top_image_url": "https://www.nvidia.com/content/dam/en-zz/Solutions/lp/large-language-models-ebook/nvidia-llm-ebook-og.jpg", "tags": {"deep-learning": {"item_id": "3840267465", "tag": "deep-learning"}, "llms": {"item_id": "3840267465", "tag": "llms"}}, "listen_duration_estimate": 15}, "2861345665": {"item_id": "2861345665", "resolved_id": "2861345665", "given_url": "https://ankane.org/new-ml-gems", "given_title": "New Machine Learning Gems for Ruby", "favorite": "0", "status": "1", "time_added": "1624194631", "time_updated": "1706833159", "time_read": "1624215013", "time_favorited": "0", "sort_id": 376, "resolved_title": "16 New ML Gems for Ruby", "resolved_url": "https://ankane.org/new-ml-gems", "excerpt": "In August, I set out to improve the machine learning ecosystem for Ruby and wasn‚Äôt sure where it would go. Over the next 5 months, I ended up releasing 16 libraries and learned a lot along the way.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1125", "lang": "en", "time_to_read": 5, "top_image_url": "https://ankane.org/images/ml-gems-2.png", "tags": {"deep-learning": {"item_id": "2861345665", "tag": "deep-learning"}, "machine-learning": {"item_id": "2861345665", "tag": "machine-learning"}, "programming": {"item_id": "2861345665", "tag": "programming"}, "ruby": {"item_id": "2861345665", "tag": "ruby"}}, "image": {"item_id": "2861345665", "src": "https://ankane.org/images/ml-gems-2.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2861345665", "image_id": "1", "src": "https://ankane.org/images/ml-gems-2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2861345665", "image_id": "2", "src": "https://ankane.org/images/ann-benchmarks.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 435}, "2781201017": {"item_id": "2781201017", "resolved_id": "2781201017", "given_url": "https://medium.com/@jonathan_hui/nlp-bert-transformer-7f0ac397f524", "given_title": "NLP ‚Äî BERT & Transformer - Jonathan Hui - Medium", "favorite": "0", "status": "1", "time_added": "1584720501", "time_updated": "1638708525", "time_read": "1585739932", "time_favorited": "0", "sort_id": 377, "resolved_title": "NLP", "resolved_url": "https://medium.com/@jonathan_hui/nlp-bert-transformer-7f0ac397f524", "excerpt": "Google published an article ‚ÄúUnderstanding searches better than ever before‚Äù and positioned BERT as one of the most important updates to the searching algorithms in recent years. BERT is a language representation model with impressive accuracy for many NLP tasks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4170", "lang": "en", "time_to_read": 19, "top_image_url": "https://miro.medium.com/max/792/1*AaRWGD95loQWAHq_ulm2LA.jpeg", "tags": {"bert": {"item_id": "2781201017", "tag": "bert"}, "deep-learning": {"item_id": "2781201017", "tag": "deep-learning"}}, "authors": {"84948079": {"item_id": "2781201017", "author_id": "84948079", "name": "Jonathan Hui", "url": "https://medium.com/@jonathan_hui"}}, "image": {"item_id": "2781201017", "src": "https://miro.medium.com/max/1600/1*AaRWGD95loQWAHq_ulm2LA.jpeg", "width": "792", "height": "1236"}, "images": {"1": {"item_id": "2781201017", "image_id": "1", "src": "https://miro.medium.com/max/1600/1*AaRWGD95loQWAHq_ulm2LA.jpeg", "width": "792", "height": "1236", "credit": "", "caption": ""}, "2": {"item_id": "2781201017", "image_id": "2", "src": "https://miro.medium.com/max/4600/1*pE0lYanFGi80ILtK1HF11g.jpeg", "width": "2300", "height": "1066", "credit": "After using BERT in understanding the query", "caption": "Source"}, "3": {"item_id": "2781201017", "image_id": "3", "src": "https://miro.medium.com/max/3200/1*3q4gK4QGQNEkUC3bH5vOqA.jpeg", "width": "1600", "height": "492", "credit": "", "caption": ""}, "4": {"item_id": "2781201017", "image_id": "4", "src": "https://miro.medium.com/max/3000/1*1CHs3Ks21h6mC2Ox6aA_1Q.jpeg", "width": "1500", "height": "316", "credit": "sfgate", "caption": "Source"}, "5": {"item_id": "2781201017", "image_id": "5", "src": "https://miro.medium.com/max/3200/1*QN-E59RG9lx1ip0DDxVh_w.jpeg", "width": "1600", "height": "341", "credit": "", "caption": ""}, "6": {"item_id": "2781201017", "image_id": "6", "src": "https://miro.medium.com/max/3200/1*8-xB4DkHZ0Q8Ujzty6VFDw.jpeg", "width": "1600", "height": "602", "credit": "", "caption": "Source"}, "7": {"item_id": "2781201017", "image_id": "7", "src": "https://miro.medium.com/max/3600/1*pA6yCuy_gqFNThpbEoYwTA.jpeg", "width": "1800", "height": "712", "credit": "", "caption": "Source"}, "8": {"item_id": "2781201017", "image_id": "8", "src": "https://miro.medium.com/max/3200/1*cIzH9iLI0waqBe2dh9DEbQ.jpeg", "width": "1600", "height": "504", "credit": "", "caption": ""}, "9": {"item_id": "2781201017", "image_id": "9", "src": "https://miro.medium.com/max/2800/1*VTf_wyCYPHsiAq-SV_48jQ.jpeg", "width": "1400", "height": "366", "credit": "", "caption": ""}, "10": {"item_id": "2781201017", "image_id": "10", "src": "https://miro.medium.com/max/4000/1*Jcb-PSnPu4xIUXGhnRCLAQ.jpeg", "width": "2000", "height": "1136", "credit": "", "caption": ""}, "11": {"item_id": "2781201017", "image_id": "11", "src": "https://miro.medium.com/max/2800/1*z6xuvSl7Ux1STg3ZOxfV7A.jpeg", "width": "1400", "height": "470", "credit": "", "caption": ""}, "12": {"item_id": "2781201017", "image_id": "12", "src": "https://miro.medium.com/max/2800/1*MKSm7LhIxptKJ0pb4kMLLQ.jpeg", "width": "1400", "height": "204", "credit": "", "caption": ""}, "13": {"item_id": "2781201017", "image_id": "13", "src": "https://miro.medium.com/max/2402/1*CMaY1EKl9lozV1M4B01mZg.jpeg", "width": "1201", "height": "519", "credit": "", "caption": ""}, "14": {"item_id": "2781201017", "image_id": "14", "src": "https://miro.medium.com/max/2800/1*X8zlN5UYdiPMZiqDWw7-Rg.jpeg", "width": "1400", "height": "46", "credit": "", "caption": ""}, "15": {"item_id": "2781201017", "image_id": "15", "src": "https://miro.medium.com/max/2800/1*zLmlAv-9kyTqEjY00-08pg.jpeg", "width": "1400", "height": "175", "credit": "", "caption": ""}, "16": {"item_id": "2781201017", "image_id": "16", "src": "https://miro.medium.com/max/2400/1*EC04ZMiCnLBT3IG0tdU33g.jpeg", "width": "1200", "height": "908", "credit": "", "caption": ""}, "17": {"item_id": "2781201017", "image_id": "17", "src": "https://miro.medium.com/max/2800/1*0J_Uz5QzwdbqSPlzONik5A.jpeg", "width": "1400", "height": "335", "credit": "", "caption": ""}, "18": {"item_id": "2781201017", "image_id": "18", "src": "https://miro.medium.com/max/2536/1*jqHNZAZKjxuMN3YNrcajbw.jpeg", "width": "1268", "height": "158", "credit": "", "caption": ""}, "19": {"item_id": "2781201017", "image_id": "19", "src": "https://miro.medium.com/max/4136/1*bG8a8c0kA4Ffb2wn7t9w1A.png", "width": "2068", "height": "654", "credit": "", "caption": ""}, "20": {"item_id": "2781201017", "image_id": "20", "src": "https://miro.medium.com/max/2536/1*ac9xOeKoJJttz5RFr2Sluw.jpeg", "width": "1268", "height": "187", "credit": "", "caption": ""}, "21": {"item_id": "2781201017", "image_id": "21", "src": "https://miro.medium.com/max/2536/1*ZRwTZbXQ9xdsld3zd8-f6A.jpeg", "width": "1268", "height": "226", "credit": "", "caption": ""}, "22": {"item_id": "2781201017", "image_id": "22", "src": "https://miro.medium.com/max/2536/1*QeZiuWDYeTSMIDsQY-44zQ.jpeg", "width": "1268", "height": "284", "credit": "", "caption": ""}, "23": {"item_id": "2781201017", "image_id": "23", "src": "https://miro.medium.com/max/3200/1*kw05m2_KwI9ekqU95j3Ryg.jpeg", "width": "1600", "height": "972", "credit": "", "caption": ""}, "24": {"item_id": "2781201017", "image_id": "24", "src": "https://miro.medium.com/max/3000/1*63vv9pbICaRAIWF2me-efA.jpeg", "width": "1500", "height": "1216", "credit": "", "caption": ""}, "25": {"item_id": "2781201017", "image_id": "25", "src": "https://miro.medium.com/max/3200/1*B2iaba-bqVEPTjs-y907WA.jpeg", "width": "1600", "height": "532", "credit": "", "caption": ""}, "26": {"item_id": "2781201017", "image_id": "26", "src": "https://miro.medium.com/max/3528/1*DrZdbl8snUCD_oCC7NbVAw.png", "width": "1764", "height": "742", "credit": "", "caption": "Source"}, "27": {"item_id": "2781201017", "image_id": "27", "src": "https://miro.medium.com/max/3200/1*7FhaUqzKV6xT_dCKuAORrg.jpeg", "width": "1600", "height": "368", "credit": "", "caption": ""}, "28": {"item_id": "2781201017", "image_id": "28", "src": "https://miro.medium.com/max/2800/1*rLH9-CWTRPuGkFr8U8xP7w.jpeg", "width": "1400", "height": "335", "credit": "", "caption": ""}, "29": {"item_id": "2781201017", "image_id": "29", "src": "https://miro.medium.com/max/3800/1*N47fOTE9ICW39I8Mvm8nKA.jpeg", "width": "1900", "height": "544", "credit": "", "caption": ""}, "30": {"item_id": "2781201017", "image_id": "30", "src": "https://miro.medium.com/max/3000/1*b_IsDblR33SlVL12EU8p1g.jpeg", "width": "1500", "height": "1216", "credit": "", "caption": ""}, "31": {"item_id": "2781201017", "image_id": "31", "src": "https://miro.medium.com/max/3200/1*dqM06R1D2pTkVFmhKOz0tg.jpeg", "width": "1600", "height": "680", "credit": "", "caption": ""}, "32": {"item_id": "2781201017", "image_id": "32", "src": "https://miro.medium.com/max/2800/1*crFmOScMM5yCpen_rVvilg.jpeg", "width": "1400", "height": "820", "credit": "", "caption": ""}, "33": {"item_id": "2781201017", "image_id": "33", "src": "https://miro.medium.com/max/2992/1*Jy2jwbdduzZvbn8CslJoyQ.jpeg", "width": "1496", "height": "309", "credit": "", "caption": ""}, "34": {"item_id": "2781201017", "image_id": "34", "src": "https://miro.medium.com/max/3400/1*ls1Ua-UO_CjyTwGl2oI5xA.jpeg", "width": "1700", "height": "700", "credit": "", "caption": "Source"}, "35": {"item_id": "2781201017", "image_id": "35", "src": "https://miro.medium.com/max/3200/1*gdBbR42XSqfjMuOoB1XTvQ.jpeg", "width": "1600", "height": "442", "credit": "", "caption": "Source"}, "36": {"item_id": "2781201017", "image_id": "36", "src": "https://miro.medium.com/max/3556/1*svuP-COnnPZcsdFd-DT1Hw.png", "width": "1778", "height": "902", "credit": "", "caption": ""}, "37": {"item_id": "2781201017", "image_id": "37", "src": "https://miro.medium.com/max/4800/1*WTLf9hY4WyarZy9Ra7o4zQ.jpeg", "width": "2400", "height": "907", "credit": "", "caption": ""}, "38": {"item_id": "2781201017", "image_id": "38", "src": "https://miro.medium.com/max/3200/1*EjW_CHsjZaK0VuwQUozTdQ.jpeg", "width": "1600", "height": "907", "credit": "", "caption": ""}, "39": {"item_id": "2781201017", "image_id": "39", "src": "https://miro.medium.com/max/2480/1*OiCqb9YrwekKSYzG0RcuFg.png", "width": "1240", "height": "1276", "credit": "", "caption": ""}, "40": {"item_id": "2781201017", "image_id": "40", "src": "https://miro.medium.com/max/3304/1*OiEXFC4isOSOEIFkRcXx1g.jpeg", "width": "1652", "height": "820", "credit": "", "caption": ""}, "41": {"item_id": "2781201017", "image_id": "41", "src": "https://miro.medium.com/max/2404/1*R6_u8qGXKUyyGaHb9-mMDw.jpeg", "width": "1202", "height": "990", "credit": "", "caption": ""}, "42": {"item_id": "2781201017", "image_id": "42", "src": "https://miro.medium.com/max/3000/1*UE-hjfG4dB9GWTg1gjHrVg.jpeg", "width": "1500", "height": "1160", "credit": "", "caption": ""}, "43": {"item_id": "2781201017", "image_id": "43", "src": "https://miro.medium.com/max/3250/1*in3wK8ex2fZJLsoZgKCQAQ.jpeg", "width": "1625", "height": "614", "credit": "", "caption": ""}, "44": {"item_id": "2781201017", "image_id": "44", "src": "https://miro.medium.com/max/2392/1*uYWI6BIt7aCE_hvw3DhUOg.jpeg", "width": "1196", "height": "1482", "credit": "", "caption": ""}, "45": {"item_id": "2781201017", "image_id": "45", "src": "https://miro.medium.com/max/3036/1*AOC4wYxISiMW-rPHYvtWyA.png", "width": "1518", "height": "1292", "credit": "", "caption": ""}, "46": {"item_id": "2781201017", "image_id": "46", "src": "https://miro.medium.com/max/2800/1*I-VlqUAk23uHVVcxbrqTHA.jpeg", "width": "1400", "height": "662", "credit": "", "caption": ""}, "47": {"item_id": "2781201017", "image_id": "47", "src": "https://miro.medium.com/max/4414/1*oWqHKkITyafyC6UeUQyajA.jpeg", "width": "2207", "height": "1047", "credit": "SQuAD", "caption": "Source"}, "48": {"item_id": "2781201017", "image_id": "48", "src": "https://miro.medium.com/max/2100/1*SD6y5bhQ4i0_KGZm3YPFpw.png", "width": "1050", "height": "558", "credit": "", "caption": "Source"}, "49": {"item_id": "2781201017", "image_id": "49", "src": "https://miro.medium.com/max/3516/1*cDlhkuE8b8IBadV9vONOmg.png", "width": "1758", "height": "694", "credit": "", "caption": "Source"}, "50": {"item_id": "2781201017", "image_id": "50", "src": "https://miro.medium.com/max/3796/1*zj729Q7E3Lx1_io7dz-xCw.png", "width": "1898", "height": "458", "credit": "", "caption": "Source"}, "51": {"item_id": "2781201017", "image_id": "51", "src": "https://miro.medium.com/max/3600/1*gO2JP4iWhuC0hLZrPGsTmQ.jpeg", "width": "1800", "height": "982", "credit": "", "caption": "Source"}, "52": {"item_id": "2781201017", "image_id": "52", "src": "https://miro.medium.com/max/3600/1*71lj0YoM5fkZB229XKAFrA.jpeg", "width": "1800", "height": "1300", "credit": "", "caption": "Source"}, "53": {"item_id": "2781201017", "image_id": "53", "src": "https://miro.medium.com/max/3200/1*D0_sVWpmOSaGCvm6gk9aHA.jpeg", "width": "1600", "height": "486", "credit": "", "caption": "Modified from source"}, "54": {"item_id": "2781201017", "image_id": "54", "src": "https://miro.medium.com/max/3140/1*yTk92fAvqPDlabJJqkM4rw.png", "width": "1570", "height": "1384", "credit": "", "caption": ""}, "55": {"item_id": "2781201017", "image_id": "55", "src": "https://miro.medium.com/max/3508/1*tqvpanBOuVxoPlZ0X47V7g.png", "width": "1754", "height": "168", "credit": "", "caption": ""}, "56": {"item_id": "2781201017", "image_id": "56", "src": "https://miro.medium.com/max/2936/1*zlNaJtkkpg2UaKl7ibKOyQ.png", "width": "1468", "height": "1070", "credit": "", "caption": ""}, "57": {"item_id": "2781201017", "image_id": "57", "src": "https://miro.medium.com/max/4124/1*LdK3uwUZq3bAm5ZcSjccKw.png", "width": "2062", "height": "202", "credit": "", "caption": "Source"}, "58": {"item_id": "2781201017", "image_id": "58", "src": "https://miro.medium.com/max/2508/1*UvFUs9afyoIGKj9F5qTIxw.png", "width": "1254", "height": "922", "credit": "", "caption": ""}, "59": {"item_id": "2781201017", "image_id": "59", "src": "https://miro.medium.com/max/2616/1*TT1uyr3LF0HBW71dA5516g.png", "width": "1308", "height": "1282", "credit": "", "caption": "Source"}, "60": {"item_id": "2781201017", "image_id": "60", "src": "https://miro.medium.com/max/4600/1*k90kkTbwAJsdxweru-oPUQ.jpeg", "width": "2300", "height": "261", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 1614}, "3141820159": {"item_id": "3141820159", "resolved_id": "3141820159", "given_url": "https://www.microsoft.com/en-us/research/blog/novel-object-captioning-surpasses-human-performance-on-benchmarks/", "given_title": "Novel object captioning surpasses human performance on benchmarks", "favorite": "0", "status": "1", "time_added": "1602753845", "time_updated": "1638708525", "time_read": "1604361029", "time_favorited": "0", "sort_id": 378, "resolved_title": "Novel object captioning surpasses human performance on benchmarks", "resolved_url": "https://www.microsoft.com/en-us/research/blog/novel-object-captioning-surpasses-human-performance-on-benchmarks/", "excerpt": "Consider for a moment what it takes to visually identify and describe something to another person. Now imagine that the other person can‚Äôt see the object or image, so every detail matters.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1463", "lang": "en", "time_to_read": 7, "top_image_url": "https://www.microsoft.com/en-us/research/uploads/prod/2020/10/1200x627_NoCaps_WithLogo_Still.png", "tags": {"deep-learning": {"item_id": "3141820159", "tag": "deep-learning"}, "object-detection": {"item_id": "3141820159", "tag": "object-detection"}, "vision": {"item_id": "3141820159", "tag": "vision"}}, "authors": {"141349258": {"item_id": "3141820159", "author_id": "141349258", "name": "Kevin Lin", "url": "https://www.microsoft.com/en-us/research/people/keli/"}}, "image": {"item_id": "3141820159", "src": "https://www.microsoft.com/en-us/research/uploads/prod/2020/10/NOCAPS_Figure1.png", "width": "624", "height": "361"}, "images": {"1": {"item_id": "3141820159", "image_id": "1", "src": "https://www.microsoft.com/en-us/research/uploads/prod/2020/10/NOCAPS_Figure1.png", "width": "624", "height": "361", "credit": "", "caption": ""}, "2": {"item_id": "3141820159", "image_id": "2", "src": "https://www.microsoft.com/en-us/research/uploads/prod/2020/10/Nocaps_figure2_updateres-1024x579.jpg", "width": "1024", "height": "579", "credit": "", "caption": ""}, "3": {"item_id": "3141820159", "image_id": "3", "src": "https://www.microsoft.com/en-us/research/uploads/prod/2020/07/MSR_WebinarCollage1400x788.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3141820159", "image_id": "4", "src": "https://www.microsoft.com/en-us/research/uploads/prod/2020/10/Nocaps_figre-3_updatedres-1024x652.jpg", "width": "1024", "height": "652", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Microsoft", "logo": "https://logo.clearbit.com/microsoft.com?size=800", "greyscale_logo": "https://logo.clearbit.com/microsoft.com?size=800&greyscale=true"}, "listen_duration_estimate": 566}, "3581824922": {"item_id": "3581824922", "resolved_id": "3581824922", "given_url": "https://hothardware.com/news/nvidia-nerf-ai-renders-3d-scenes-2d-photos-milliseconds", "given_title": "NVIDIA NeRF AI Renders Amazingly Realistic 3D Scenes From 2D Photos In Just", "favorite": "0", "status": "1", "time_added": "1648233694", "time_updated": "1654559376", "time_read": "1648303175", "time_favorited": "0", "sort_id": 379, "resolved_title": "NVIDIA NeRF AI Renders Amazingly Realistic 3D Scenes From 2D Photos In Just Milliseconds", "resolved_url": "https://hothardware.com/news/nvidia-nerf-ai-renders-3d-scenes-2d-photos-milliseconds", "excerpt": "It takes a human being around 0.1 to 0.4 seconds to blink. In even less time, an AI-based inverse rendering process developed by NVIDIA can generate a realistic three-dimensional scene from a series of two-dimensional photographs taken from different angles.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "453", "lang": "en", "amp_url": "https://amp.hothardware.com/news/nvidia-nerf-ai-renders-3d-scenes-2d-photos-milliseconds", "top_image_url": "https://images.hothardware.com/contentimages/newsitem/58082/content/small_nvidia_nerf_thumbnail.jpg", "tags": {"deep-learning": {"item_id": "3581824922", "tag": "deep-learning"}, "image-generation": {"item_id": "3581824922", "tag": "image-generation"}, "machine-vision": {"item_id": "3581824922", "tag": "machine-vision"}}, "authors": {"68870047": {"item_id": "3581824922", "author_id": "68870047", "name": "Paul Lilly", "url": "https://hothardware.com/author/Paul-Lilly"}}, "listen_duration_estimate": 175}, "2675562336": {"item_id": "2675562336", "resolved_id": "2675562336", "given_url": "https://venturebeat.com/2019/07/30/nvidias-gaugan-has-been-used-to-create-500000-images/", "given_title": "Nvidia‚Äôs GauGAN has been used to create 500,000 images", "favorite": "0", "status": "1", "time_added": "1564492430", "time_updated": "1691366676", "time_read": "1565015274", "time_favorited": "0", "sort_id": 380, "resolved_title": "Nvidia‚Äôs GauGAN has been used to create 500,000 images", "resolved_url": "https://venturebeat.com/2019/07/30/nvidias-gaugan-has-been-used-to-create-500000-images/", "excerpt": "Where does your enterprise stand on the AI adoption curve? Take our AI survey to find out.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "639", "lang": "en", "time_to_read": 3, "amp_url": "https://venturebeat.com/2019/07/30/nvidias-gaugan-has-been-used-to-create-500000-images/amp/", "top_image_url": "https://venturebeat.com/wp-content/uploads/2019/03/nvidia-gaugan.jpg?w=1200&strip=all", "tags": {"adversarial": {"item_id": "2675562336", "tag": "adversarial"}, "deep-learning": {"item_id": "2675562336", "tag": "deep-learning"}, "gans": {"item_id": "2675562336", "tag": "gans"}, "image-generation": {"item_id": "2675562336", "tag": "image-generation"}}, "authors": {"89415017": {"item_id": "2675562336", "author_id": "89415017", "name": "Kyle Wiggers", "url": "https://venturebeat.com/author/kylewiggers/"}}, "image": {"item_id": "2675562336", "src": "https://venturebeat.com/wp-content/uploads/2019/03/nvidia-gaugan.jpg?resize=1200%2C600&strip=all", "width": "1200", "height": "600"}, "images": {"1": {"item_id": "2675562336", "image_id": "1", "src": "https://venturebeat.com/wp-content/uploads/2019/03/nvidia-gaugan.jpg?resize=1200%2C600&strip=all", "width": "1200", "height": "600", "credit": "", "caption": "Image Credit: Khari Johnson / VentureBeat"}, "2": {"item_id": "2675562336", "image_id": "2", "src": "https://venturebeat.com/wp-content/uploads/2019/07/GauGAN-photo-2-labeled.png?w=800&resize=800%2C500&strip=all", "width": "800", "height": "500", "credit": "", "caption": ""}, "3": {"item_id": "2675562336", "image_id": "3", "src": "https://venturebeat.com/wp-content/uploads/2019/07/GauGAN-photo-1-labeled.png?w=800&resize=800%2C418&strip=all", "width": "800", "height": "418", "credit": "", "caption": ""}}, "domain_metadata": {"name": "VentureBeat", "logo": "https://logo.clearbit.com/venturebeat.com?size=800", "greyscale_logo": "https://logo.clearbit.com/venturebeat.com?size=800&greyscale=true"}, "listen_duration_estimate": 247}, "2929127429": {"item_id": "2929127429", "resolved_id": "2929127446", "given_url": "https://towardsdatascience.com/object-detection-face-recognition-algorithms-146fec385205?source=rss----7f60cf5620c9---4", "given_title": "Object detection & Face recognition algorithms", "favorite": "0", "status": "1", "time_added": "1585268447", "time_updated": "1638708525", "time_read": "1585580042", "time_favorited": "0", "sort_id": 381, "resolved_title": "Object detection & Face recognition algorithms", "resolved_url": "https://towardsdatascience.com/object-detection-face-recognition-algorithms-146fec385205", "excerpt": "Convolutional neural networks are widely used in addressing image-based problems, such as object/character detection and face recognition. In this article, we will focus on the most famous architectures from LeNet to Siamese networks, having for most of them the following architecture:", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1423", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/1*_0Cu63U3TlJCoJ3kZcgNoA.jpeg", "tags": {"deep-learning": {"item_id": "2929127429", "tag": "deep-learning"}}, "authors": {"146980681": {"item_id": "2929127429", "author_id": "146980681", "name": "Ismail Mebsout", "url": "https://ismail-mebsout.medium.com"}}, "image": {"item_id": "2929127429", "src": "https://miro.medium.com/max/1400/1*_0Cu63U3TlJCoJ3kZcgNoA.jpeg", "width": "700", "height": "455"}, "images": {"1": {"item_id": "2929127429", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*_0Cu63U3TlJCoJ3kZcgNoA.jpeg", "width": "700", "height": "455", "credit": "Skitterphoto downloaded from Pexels", "caption": ""}, "2": {"item_id": "2929127429", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*YejW73f36BGhNGhrtbz67g.png", "width": "700", "height": "235", "credit": "", "caption": "Image by Author"}, "3": {"item_id": "2929127429", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*_2vT_c5s6j42lcZXpdKvjg.png", "width": "700", "height": "30", "credit": "", "caption": ""}, "4": {"item_id": "2929127429", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*yM8owtQiNu6alT552V24yA.png", "width": "700", "height": "70", "credit": "", "caption": ""}, "5": {"item_id": "2929127429", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*nTOu65y3r1rcKMHk2WwjQw.png", "width": "700", "height": "59", "credit": "", "caption": ""}, "6": {"item_id": "2929127429", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*NOnMXgFljE4Aj3ce2Y8mew.png", "width": "700", "height": "267", "credit": "", "caption": "Official paper of LeNet"}, "7": {"item_id": "2929127429", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*_5QP3edJot_b8fneDFx4ug.png", "width": "700", "height": "210", "credit": "", "caption": "Official paper of AlexNet"}, "8": {"item_id": "2929127429", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*gtXfhZkxl8Glp2fNsIIMpg.png", "width": "700", "height": "446", "credit": "", "caption": "Official paper of VGG-16"}, "9": {"item_id": "2929127429", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*VTYYiB76ph_2dYMlQvfNJg.png", "width": "700", "height": "213", "credit": "", "caption": ""}, "10": {"item_id": "2929127429", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*0jrU9w72-s1lsmYKaTp3lw.png", "width": "700", "height": "308", "credit": "", "caption": "Image by Author"}, "11": {"item_id": "2929127429", "image_id": "11", "src": "https://miro.medium.com/max/1400/1*L4Z61qSoZlHa0-GLhjmkAA.png", "width": "700", "height": "76", "credit": "", "caption": ""}, "12": {"item_id": "2929127429", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*W0s7wnejxgJLgWxFuBnkxw.png", "width": "700", "height": "170", "credit": "", "caption": "Image by Author"}, "13": {"item_id": "2929127429", "image_id": "13", "src": "https://miro.medium.com/max/1400/1*aiac-6PBHAVCFcK9seiuYQ.png", "width": "700", "height": "150", "credit": "", "caption": ""}, "14": {"item_id": "2929127429", "image_id": "14", "src": "https://miro.medium.com/max/1400/1*GeVmBAiWFbQYRg3ul9gNEA.png", "width": "700", "height": "212", "credit": "", "caption": "Image by Author"}, "15": {"item_id": "2929127429", "image_id": "15", "src": "https://miro.medium.com/max/1400/1*ljtQSkJt0AffTsp3rNRqAw.png", "width": "700", "height": "36", "credit": "", "caption": ""}, "16": {"item_id": "2929127429", "image_id": "16", "src": "https://miro.medium.com/max/1400/1*YpDX85SxAFN3v5NvPzsj3Q.png", "width": "700", "height": "278", "credit": "", "caption": "Image by Author"}, "17": {"item_id": "2929127429", "image_id": "17", "src": "https://miro.medium.com/max/1400/1*XrEI7gvxhTKRAmL-Tr_X5Q.png", "width": "700", "height": "36", "credit": "", "caption": ""}, "18": {"item_id": "2929127429", "image_id": "18", "src": "https://miro.medium.com/max/1400/1*4jqvNSpQW6qY6fKCqQMR0A.png", "width": "700", "height": "319", "credit": "", "caption": "Image by Author"}, "19": {"item_id": "2929127429", "image_id": "19", "src": "https://miro.medium.com/max/1400/1*bczwvOkReF6InX4b3psCWw.png", "width": "700", "height": "39", "credit": "", "caption": ""}, "20": {"item_id": "2929127429", "image_id": "20", "src": "https://miro.medium.com/max/1400/1*cvNFuzu_RkT4f8QTivAfew.png", "width": "700", "height": "58", "credit": "", "caption": ""}, "21": {"item_id": "2929127429", "image_id": "21", "src": "https://miro.medium.com/max/1400/1*5OXF91UZQeky5ljepgnyyw.png", "width": "700", "height": "31", "credit": "", "caption": ""}, "22": {"item_id": "2929127429", "image_id": "22", "src": "https://miro.medium.com/max/1400/1*29PBSsI88Z9uMuxke-me3A.png", "width": "700", "height": "31", "credit": "", "caption": ""}, "23": {"item_id": "2929127429", "image_id": "23", "src": "https://miro.medium.com/max/1400/1*LZX9-s8l6-GMSrAr-0cESw.png", "width": "700", "height": "224", "credit": "", "caption": "Image by Author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 551}, "3409982141": {"item_id": "3409982141", "resolved_id": "3409982141", "given_url": "https://neptune.ai/blog/object-detection-algorithms-and-libraries", "given_title": "Object Detection Algorithms and Libraries - neptune.ai", "favorite": "0", "status": "1", "time_added": "1629666972", "time_updated": "1638708525", "time_read": "1629796875", "time_favorited": "0", "sort_id": 382, "resolved_title": "Object Detection Algorithms and Libraries", "resolved_url": "https://neptune.ai/blog/object-detection-algorithms-and-libraries", "excerpt": "Object detection finds and identifies things in images, and it‚Äôs one of the biggest accomplishments of deep learning and image processing. One of the common approaches to creating localizations for objects is with the help of bounding boxes.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3892", "lang": "en", "time_to_read": 18, "amp_url": "https://neptune.ai/blog/object-detection-algorithms-and-libraries/amp", "top_image_url": "https://neptune.ai/wp-content/uploads/Object-detection-algorithms-libraries.jpg", "tags": {"deep-learning": {"item_id": "3409982141", "tag": "deep-learning"}, "machine-vision": {"item_id": "3409982141", "tag": "machine-vision"}, "object-detection": {"item_id": "3409982141", "tag": "object-detection"}}, "image": {"item_id": "3409982141", "src": "https://i2.wp.com/neptune.ai/wp-content/uploads/HOG-object-detection-algorithm.png?resize=1024%2C354&ssl=1", "width": "1024", "height": "354"}, "images": {"1": {"item_id": "3409982141", "image_id": "1", "src": "https://i2.wp.com/neptune.ai/wp-content/uploads/HOG-object-detection-algorithm.png?resize=1024%2C354&ssl=1", "width": "1024", "height": "354", "credit": "", "caption": ""}, "2": {"item_id": "3409982141", "image_id": "2", "src": "https://i0.wp.com/neptune.ai/wp-content/uploads/RCNN-object-detection-algorithm.png?resize=1024%2C303&ssl=1", "width": "1024", "height": "303", "credit": "", "caption": ""}, "3": {"item_id": "3409982141", "image_id": "3", "src": "https://i0.wp.com/neptune.ai/wp-content/uploads/Faster-RCNN-object-detection-algorithm.png?resize=1024%2C570&ssl=1", "width": "1024", "height": "570", "credit": "", "caption": ""}, "4": {"item_id": "3409982141", "image_id": "4", "src": "https://i2.wp.com/neptune.ai/wp-content/uploads/SSD-object-detection-algorithm.png?resize=1024%2C345&ssl=1", "width": "1024", "height": "345", "credit": "", "caption": ""}, "5": {"item_id": "3409982141", "image_id": "5", "src": "https://i2.wp.com/neptune.ai/wp-content/uploads/YOLO-object-detection-algorithm.png?resize=1024%2C402&ssl=1", "width": "1024", "height": "402", "credit": "", "caption": ""}, "6": {"item_id": "3409982141", "image_id": "6", "src": "https://i2.wp.com/neptune.ai/wp-content/uploads/RetinaNet-object-detection-algorithm.png?resize=1024%2C278&ssl=1", "width": "1024", "height": "278", "credit": "", "caption": ""}}, "listen_duration_estimate": 1507}, "2910367561": {"item_id": "2910367561", "resolved_id": "2910357773", "given_url": "https://towardsdatascience.com/object-detection-using-yolov3-and-opencv-19ee0792a420?source=rss----7f60cf5620c9---4", "given_title": "Object Detection using YoloV3 and OpenCV", "favorite": "0", "status": "1", "time_added": "1583795188", "time_updated": "1638708525", "time_read": "1585739876", "time_favorited": "0", "sort_id": 383, "resolved_title": "Object Detection using YoloV3 and OpenCV", "resolved_url": "https://towardsdatascience.com/object-detection-using-yolov3-and-opencv-19ee0792a420", "excerpt": "Computer Vision has always been a topic of fascination for me. In layman's terms, computer vision is all about replicating the complexity of the human vision and his understanding of his surroundings. It is emerging to be one of the most powerful fields of application of AI.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1141", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/1*pOBd3QvpLL88gurjZ8g_GQ.jpeg", "tags": {"deep-learning": {"item_id": "2910367561", "tag": "deep-learning"}, "object-detection": {"item_id": "2910367561", "tag": "object-detection"}, "vision": {"item_id": "2910367561", "tag": "vision"}}, "authors": {"152894092": {"item_id": "2910367561", "author_id": "152894092", "name": "Nandini Bansal", "url": "https://nandinibansal1811.medium.com"}}, "image": {"item_id": "2910367561", "src": "https://miro.medium.com/fit/c/56/56/0*et5WzdK_dJ0FhQSg.jpg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2910367561", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/0*et5WzdK_dJ0FhQSg.jpg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2910367561", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*pOBd3QvpLL88gurjZ8g_GQ.jpeg", "width": "700", "height": "394", "credit": "", "caption": "Object Detection using YoloV3 and OpenCV"}, "3": {"item_id": "2910367561", "image_id": "3", "src": "https://miro.medium.com/max/1160/1*C_9fyPCt15vw0tjUZuu7lQ.jpeg", "width": "580", "height": "418", "credit": "", "caption": "Object Detection with Multiple Bounding Boxes"}, "4": {"item_id": "2910367561", "image_id": "4", "src": "https://miro.medium.com/max/1160/1*AlCFUk7x4ZJbZocVrWiNzw.jpeg", "width": "580", "height": "418", "credit": "", "caption": "Final Output"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 442}, "3098605006": {"item_id": "3098605006", "resolved_id": "3098600472", "given_url": "https://towardsdatascience.com/oil-storage-tanks-volume-occupancy-on-satellite-imagery-using-yolov3-3cf251362d9d?source=rss----7f60cf5620c9---4", "given_title": "Oil Storage Tank‚Äôs Volume Occupancy On Satellite Imagery Using YoloV3", "favorite": "0", "status": "1", "time_added": "1599042450", "time_updated": "1638708525", "time_read": "1599042960", "time_favorited": "0", "sort_id": 384, "resolved_title": "Oil Storage Tank‚Äôs Volume Occupancy On Satellite Imagery Using YoloV3", "resolved_url": "https://towardsdatascience.com/oil-storage-tanks-volume-occupancy-on-satellite-imagery-using-yolov3-3cf251362d9d", "excerpt": "Oil Storage Tank‚Äôs Volume Occupancy On Satellite Imagery Using YoloV3Recognition of Oil Storage Tanks in satellite images using the Yolov3 object detection model from scratch using Tensorflow 2.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3704", "lang": "en", "time_to_read": 17, "top_image_url": "https://miro.medium.com/max/1200/1*hJSg0vEbU2MRs4a9UPOsKg.jpeg", "tags": {"deep-learning": {"item_id": "3098605006", "tag": "deep-learning"}, "vision": {"item_id": "3098605006", "tag": "vision"}}, "authors": {"137650792": {"item_id": "3098605006", "author_id": "137650792", "name": "Md. Mubasir", "url": "https://medium.com/@talk2mubasir0587"}}, "image": {"item_id": "3098605006", "src": "https://miro.medium.com/fit/c/56/56/1*4vTf4g_Jp4R1_DT4ZWu0Jg.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3098605006", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*4vTf4g_Jp4R1_DT4ZWu0Jg.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3098605006", "image_id": "2", "src": "https://miro.medium.com/max/9590/1*hJSg0vEbU2MRs4a9UPOsKg.jpeg", "width": "4795", "height": "1502", "credit": "", "caption": "source"}, "3": {"item_id": "3098605006", "image_id": "3", "src": "https://miro.medium.com/max/1400/0*jtf7E2TfLJ6Pzjve", "width": "700", "height": "466", "credit": "NASA on Unsplash", "caption": ""}, "4": {"item_id": "3098605006", "image_id": "4", "src": "https://miro.medium.com/max/1210/1*62qgv4v-X-fK_VmC6Z4n_Q.png", "width": "605", "height": "251", "credit": "", "caption": "source"}, "5": {"item_id": "3098605006", "image_id": "5", "src": "https://miro.medium.com/max/878/1*AhQhu34KcnU-VOSzqnKumg.png", "width": "439", "height": "419", "credit": "", "caption": "source"}, "6": {"item_id": "3098605006", "image_id": "6", "src": "https://miro.medium.com/max/1356/1*y7PZzHVzz_eVsjfhVi3big.png", "width": "678", "height": "313", "credit": "", "caption": "source"}, "7": {"item_id": "3098605006", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*8MgEQLskukMGjhJXbZgVtw.jpeg", "width": "700", "height": "115", "credit": "", "caption": "source"}, "8": {"item_id": "3098605006", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*4Yk1CKX8fktt3GLcW83d1A.png", "width": "700", "height": "543", "credit": "", "caption": "source"}, "9": {"item_id": "3098605006", "image_id": "9", "src": "https://miro.medium.com/max/2000/1*vfYEhTl820FF_9uEvoGf7Q.png", "width": "1000", "height": "414", "credit": "", "caption": "source"}, "10": {"item_id": "3098605006", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*TLE1XuWsJT0F1OuffOaeTA.png", "width": "700", "height": "712", "credit": "", "caption": ""}, "11": {"item_id": "3098605006", "image_id": "11", "src": "https://miro.medium.com/max/1172/1*5V7kKiWgWHXE9_Dc_etxsw.png", "width": "586", "height": "767", "credit": "", "caption": "Image by author"}, "12": {"item_id": "3098605006", "image_id": "12", "src": "https://miro.medium.com/max/2000/1*DHXkTEXQQWXHO4PiFiSkfw.png", "width": "1000", "height": "365", "credit": "", "caption": "Image by author"}, "13": {"item_id": "3098605006", "image_id": "13", "src": "https://miro.medium.com/max/1174/1*j0cLsyYFS4Mid75fGiwBUw.png", "width": "587", "height": "218", "credit": "", "caption": "Image by author"}, "14": {"item_id": "3098605006", "image_id": "14", "src": "https://miro.medium.com/max/2000/1*8lnJQIE_bpaK6R5B2BALyQ.png", "width": "1000", "height": "442", "credit": "", "caption": "Image by author"}, "15": {"item_id": "3098605006", "image_id": "15", "src": "https://miro.medium.com/max/1400/1*eENhWw9vTYuwgg8k-J5GtQ.png", "width": "700", "height": "268", "credit": "", "caption": "Image by author"}, "16": {"item_id": "3098605006", "image_id": "16", "src": "https://miro.medium.com/max/1400/1*TpzoU_2gJnbKT7OxnnTw8A.png", "width": "700", "height": "343", "credit": "", "caption": "Image by author"}, "17": {"item_id": "3098605006", "image_id": "17", "src": "https://miro.medium.com/max/1400/1*lnwrh8kBQCEOPJA03at3aQ.png", "width": "700", "height": "492", "credit": "", "caption": ""}, "18": {"item_id": "3098605006", "image_id": "18", "src": "https://miro.medium.com/max/2000/1*1ZovyQgriyXdPmKG_JqYNw.png", "width": "1000", "height": "351", "credit": "", "caption": "Image by author"}, "19": {"item_id": "3098605006", "image_id": "19", "src": "https://miro.medium.com/max/1068/1*TQnV__vNvwqQoydzfQ6IuA.png", "width": "534", "height": "347", "credit": "", "caption": "source"}, "20": {"item_id": "3098605006", "image_id": "20", "src": "https://miro.medium.com/max/1304/1*nLHXhLJAd0lfDPPQMbNORg.png", "width": "652", "height": "123", "credit": "", "caption": "Image by author"}, "21": {"item_id": "3098605006", "image_id": "21", "src": "https://miro.medium.com/max/1170/1*cQRtTqqkui65KCqZ9_TGDg.png", "width": "585", "height": "127", "credit": "", "caption": "Image by author"}, "22": {"item_id": "3098605006", "image_id": "22", "src": "https://miro.medium.com/max/1400/1*yXzL7jVZfJ9Lpdu31biq9Q.png", "width": "700", "height": "324", "credit": "", "caption": "Image by author"}, "23": {"item_id": "3098605006", "image_id": "23", "src": "https://miro.medium.com/max/1400/1*-twOa0WG507U0wchAwsRcA.png", "width": "700", "height": "325", "credit": "", "caption": "Image by author"}, "24": {"item_id": "3098605006", "image_id": "24", "src": "https://miro.medium.com/max/2000/1*ij5Trvv_xxWCrH95zQN7Uw.png", "width": "1000", "height": "1000", "credit": "", "caption": "Image by author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1434}, "2307233876": {"item_id": "2307233876", "resolved_id": "2307233876", "given_url": "https://www.nextplatform.com/2018/08/30/one-deep-learning-benchmark-to-rule-them-all/", "given_title": "One Deep Learning Benchmark to Rule Them All", "favorite": "0", "status": "1", "time_added": "1535660104", "time_updated": "1638708525", "time_read": "1535672701", "time_favorited": "0", "sort_id": 385, "resolved_title": "One Deep Learning Benchmark to Rule Them All", "resolved_url": "https://www.nextplatform.com/2018/08/30/one-deep-learning-benchmark-to-rule-them-all/", "excerpt": "Over the last few years we have detailed the explosion in new machine learning systems with the influx of novel architectures from deep learning chip startups to efforts from vendors and hyperscalers alike.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1185", "lang": "en", "time_to_read": 5, "amp_url": "https://www.nextplatform.com/2018/08/30/one-deep-learning-benchmark-to-rule-them-all/amp/", "top_image_url": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2016/05/TPU_main2-1024x1024.jpg", "tags": {"benchmarks": {"item_id": "2307233876", "tag": "benchmarks"}, "deep-learning": {"item_id": "2307233876", "tag": "deep-learning"}}, "authors": {"58691955": {"item_id": "2307233876", "author_id": "58691955", "name": "Nicole Hemsoth", "url": "https://www.nextplatform.com/author/nicole/"}}, "image": {"item_id": "2307233876", "src": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2016/05/TPU_main2-1030x438.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2307233876", "image_id": "1", "src": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2016/05/TPU_main2-1030x438.jpg", "width": "0", "height": "0", "credit": "", "caption": "Current v0.5 training suite elements in MLperf."}, "2": {"item_id": "2307233876", "image_id": "2", "src": "http://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2018/08/MLperfNearFinal.png", "width": "965", "height": "527", "credit": "", "caption": ""}, "3": {"item_id": "2307233876", "image_id": "3", "src": "http://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2018/08/MLPerfFinal.png", "width": "942", "height": "539", "credit": "", "caption": ""}}, "listen_duration_estimate": 459}, "2025482866": {"item_id": "2025482866", "resolved_id": "2025482866", "given_url": "https://blog.acolyer.org/2018/01/12/one-model-to-learn-them-all/", "given_title": "One model to learn them all", "favorite": "0", "status": "1", "time_added": "1515751513", "time_updated": "1638708525", "time_read": "1515768973", "time_favorited": "0", "sort_id": 386, "resolved_title": "One model to learn them all", "resolved_url": "https://blog.acolyer.org/2018/01/12/one-model-to-learn-them-all/", "excerpt": "You almost certainly have an abstract conception of a banana in your head. Suppose you ask me if I‚Äôd like anything to eat.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1364", "lang": "en", "time_to_read": 6, "tags": {"deep-learning": {"item_id": "2025482866", "tag": "deep-learning"}}, "authors": {"136059453": {"item_id": "2025482866", "author_id": "136059453", "name": "Adrian Colyer", "url": "https://blog.acolyer.org/author/adriancolyer/"}}, "image": {"item_id": "2025482866", "src": "https://blog.acolyer.org/wp-content/uploads/2018/01/one-model-fig-1.jpeg?w=640", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2025482866", "image_id": "1", "src": "https://blog.acolyer.org/wp-content/uploads/2018/01/one-model-fig-1.jpeg?w=640", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2025482866", "image_id": "2", "src": "https://blog.acolyer.org/wp-content/uploads/2018/01/one-model-fig-2.jpeg?w=640", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2025482866", "image_id": "3", "src": "https://blog.acolyer.org/wp-content/uploads/2018/01/one-model-fig-3.jpeg?w=640", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2025482866", "image_id": "4", "src": "https://blog.acolyer.org/wp-content/uploads/2018/01/one-model-table-1.jpeg?w=480", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2025482866", "image_id": "5", "src": "https://blog.acolyer.org/wp-content/uploads/2018/01/one-model-table-2.jpeg?w=480", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2025482866", "image_id": "6", "src": "https://blog.acolyer.org/wp-content/uploads/2018/01/one-model-table-4.jpeg?w=480", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"logo": "https://logo.clearbit.com/acolyer.org?size=800", "greyscale_logo": "https://logo.clearbit.com/acolyer.org?size=800&greyscale=true"}, "listen_duration_estimate": 528}, "2678881770": {"item_id": "2678881770", "resolved_id": "2678881770", "given_url": "https://blog.floydhub.com/n-shot-learning/", "given_title": "One-Shot Learning: Learning More with Less Data", "favorite": "0", "status": "1", "time_added": "1564838211", "time_updated": "1638708525", "time_read": "1564849277", "time_favorited": "0", "sort_id": 387, "resolved_title": "N-Shot Learning: Learning More with Less Data", "resolved_url": "https://blog.floydhub.com/n-shot-learning/", "excerpt": "If AI is the new electricity, then data is the new coal. Unfortunately, just as we‚Äôve seen a hazardous depletion in the amount of available coal, many AI applications have little or no data accessible to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3423", "lang": "en", "time_to_read": 16, "amp_url": "https://blog.floydhub.com/n-shot-learning/amp/", "top_image_url": "https://blog.floydhub.com/content/images/2019/08/photo-1452611545118-2b35b308caf5.jpeg", "tags": {"deep-learning": {"item_id": "2678881770", "tag": "deep-learning"}, "machine-learning": {"item_id": "2678881770", "tag": "machine-learning"}}, "authors": {"128385676": {"item_id": "2678881770", "author_id": "128385676", "name": "Naren Thiagarajan", "url": "https://blog.floydhub.com/author/naren/"}}, "image": {"item_id": "2678881770", "src": "https://blog.floydhub.com/content/images/2019/08/cassiopea.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2678881770", "image_id": "1", "src": "https://blog.floydhub.com/content/images/2019/08/cassiopea.jpg", "width": "0", "height": "0", "credit": "", "caption": "Constellation of Cassiopeia in the night sky. Source"}, "2": {"item_id": "2678881770", "image_id": "2", "src": "https://lh5.googleusercontent.com/dM2dhO5xN_JAAtPZy4Ns5x1rBuKU-bGZl8Hj6bO71qIP-F48nsCgmaqKVtotqEmunEoyLJIUZWQ2P7l1YqglZ3_XArvZ1yyOmicJdMJ48Bzw9k9jAvRTKL4cHDpHREEM97CwDkES", "width": "0", "height": "0", "credit": "dark circles", "caption": "A diagram of the function of the prototypical network. An encoder maps an image into a vector in the embedding space"}, "3": {"item_id": "2678881770", "image_id": "3", "src": "https://lh3.googleusercontent.com/D1r0cQ9QlrF3b-v4PlM1T_8kmdo7adxrTak5JcDZbhPxucxcdME9nHZsvC1qOtjIpj5SqcYVvw8NRrjBj9ryl6deOPJWPlOJqNnwMHM24hSOUIPgh1TkA4ZhGZTosr_PVNPk_lOj", "width": "0", "height": "0", "credit": "$X$", "caption": "Few-shot prototypes $C_k$ are computed as the mean of embedded support examples for each class. The encoder maps new image"}, "4": {"item_id": "2678881770", "image_id": "4", "src": "https://lh4.googleusercontent.com/dupE1e1OLDG1tTrwP11axUduhgYs8jTa81rRahH9MVEIDCp67lNqSOC_q3AG1c3-fi89-fZUkH5-yfz8vYB-NNlFeET5dqCZBie__KhBGFFi52JCsw2TnEAGU8l0k1UhY1NAuJ0s", "width": "0", "height": "0", "credit": "", "caption": "Image2vector CNN architecture used in the paper."}, "5": {"item_id": "2678881770", "image_id": "5", "src": "https://lh6.googleusercontent.com/yES2Ka08Hwqe59qPnmOWSyq0wdXT3s09a-g2y4RR-isjgpOCK53Wcimsqt6Leo2N8pEcKc_eblStlAyAJ9mCtNEYR1wbH_yXveCrqjdvOptjRF9qFG2Zep1iPxMKbHpXKT1zjs7Y", "width": "0", "height": "0", "credit": "", "caption": "The working of negative log-likelihood. Source."}, "6": {"item_id": "2678881770", "image_id": "6", "src": "https://lh5.googleusercontent.com/tA94V2yK45UQpL6JNiWqDEVqmvpzj9dajcmFrLzO1ng6OE8hNa6A1z8vaA5e9vjhZ76Cztcvy0WOuVoEhju-eMmkd0ZB47H6Be7CJ3uFCXQ_MVTTNGcm4Qs-gM3RaCD7ex-8Ipe4", "width": "0", "height": "0", "credit": "", "caption": "A few classes of images in Omniglot dataset. Source."}, "7": {"item_id": "2678881770", "image_id": "7", "src": "https://lh3.googleusercontent.com/pKUM6kIafLtbYhEd5ByNeHWsQ6YzucSqnuhuGa6uad6XZn_jj1Bv73EmxTtGXGHRZshQw5prYNTyMPjxQPBIMvWnJ9BIQLk__rKB57d4l8r9K8sypt3snt4bMhBQKRdmuK3n9YDM", "width": "0", "height": "0", "credit": "", "caption": "Overview of the Network. Source."}, "8": {"item_id": "2678881770", "image_id": "8", "src": "https://lh4.googleusercontent.com/34Km3uovz5Khb_On7AtmmUu1QTXQZ9sO9ekEzmMpcmD_t72RgBkkEFF3MBFXzx0Sd147s8jJLWEOBIAGjRiyJgmQ6Mff8pnNS4ZSQdGLoITuuVuAmJX3Xzj9NYgytZiAcHIIIYSJ", "width": "0", "height": "0", "credit": "", "caption": "Centroid calculation in the Network. Source."}}, "listen_duration_estimate": 1325}, "2302178486": {"item_id": "2302178486", "resolved_id": "2132141089", "given_url": "https://medium.com/machine-learning-in-practice/over-150-of-the-best-machine-learning-nlp-and-python-tutorials-ive-found-ffce2939bd78#hn", "given_title": "Over 150 of the Best Machine Learning, NLP, and Python Tutorials I‚Äôve Found", "favorite": "1", "status": "1", "time_added": "1582773536", "time_updated": "1638708525", "time_read": "1583785007", "time_favorited": "1582773706", "sort_id": 388, "resolved_title": "Over 150 of the Best Machine Learning, NLP, and Python Tutorials I‚Äôve Found", "resolved_url": "https://medium.com/machine-learning-in-practice/over-150-of-the-best-machine-learning-nlp-and-python-tutorials-ive-found-ffce2939bd78", "excerpt": "While machine learning has a rich history dating back to 1959, the field is evolving at an unprecedented rate. In a recent article, I discussed why the broader artificial intelligence field is booming and likely will for some time to come.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1673", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1200/1*R8bEkSHE65EpgwmA_H0ABA.png", "tags": {"deep-learning": {"item_id": "2302178486", "tag": "deep-learning"}, "machine-learning": {"item_id": "2302178486", "tag": "machine-learning"}, "nlp": {"item_id": "2302178486", "tag": "nlp"}}, "authors": {"143598617": {"item_id": "2302178486", "author_id": "143598617", "name": "Robbie Allen", "url": "https://robbieallen.medium.com"}}, "image": {"item_id": "2302178486", "src": "https://miro.medium.com/fit/c/96/96/2*pMKzIh-dW5etk_Gfrh0tXw.jpeg", "width": "48", "height": "48"}, "images": {"1": {"item_id": "2302178486", "image_id": "1", "src": "https://miro.medium.com/fit/c/96/96/2*pMKzIh-dW5etk_Gfrh0tXw.jpeg", "width": "48", "height": "48", "credit": "", "caption": ""}, "2": {"item_id": "2302178486", "image_id": "2", "src": "https://miro.medium.com/max/2548/1*R8bEkSHE65EpgwmA_H0ABA.png", "width": "1274", "height": "1043", "credit": "", "caption": "Einstein‚Äôs desk a few hours after his death. Source: LIFE Magazine"}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 648}, "3798480471": {"item_id": "3798480471", "resolved_id": "3798478728", "given_url": "https://towardsdatascience.com/paper-review-a-deep-dive-into-imagen-4e5b4092af13?source=rss----7f60cf5620c9---4", "given_title": "Paper Review: A Deep Dive into Imagen", "favorite": "0", "status": "1", "time_added": "1675298739", "time_updated": "1706830866", "time_read": "1675465538", "time_favorited": "0", "sort_id": 389, "resolved_title": "Paper Review: A Deep Dive into Imagen", "resolved_url": "https://towardsdatascience.com/paper-review-a-deep-dive-into-imagen-4e5b4092af13", "excerpt": "Text-to-image synthesis is a research direction within the field of multimodal learning which has been the subject of many recent advancements [1‚Äì4]. This review will focus on the article, ‚ÄòPhotorealistic Text-to-Image Diffusion Models with Deep Language Understanding‚Äô [1].", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "2783", "lang": "en", "time_to_read": 13, "top_image_url": "https://miro.medium.com/max/1200/0*Nkyo43aZ1FtnpmHv", "tags": {"deep-learning": {"item_id": "3798480471", "tag": "deep-learning"}, "generative": {"item_id": "3798480471", "tag": "generative"}, "image-generation": {"item_id": "3798480471", "tag": "image-generation"}}, "authors": {"147271896": {"item_id": "3798480471", "author_id": "147271896", "name": "Jamie McGowan", "url": "https://j-w-mcgowan18.medium.com"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1077}, "3141124232": {"item_id": "3141124232", "resolved_id": "3141124256", "given_url": "https://towardsdatascience.com/papers-with-code-arxiv-reproducible-organized-research-f5404eb6a22e?source=rss----7f60cf5620c9---4", "given_title": "Papers with Code   arXiv = Reproducible, Organized Research", "favorite": "0", "status": "1", "time_added": "1602635012", "time_updated": "1638708525", "time_read": "1604367662", "time_favorited": "0", "sort_id": 390, "resolved_title": "Papers with Code + arXiv = Reproducible, Organized Research", "resolved_url": "https://towardsdatascience.com/papers-with-code-arxiv-reproducible-organized-research-f5404eb6a22e", "excerpt": "Millions of scientific articles are shared openly via arXiv, a Cornell-powered website that focuses on open access to research. The Papers with Code website hosts academic papers that also share their backing software so that experiments can be faithfully reproduced.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1052", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1133/1*S0qI3tDpftQAFSQKSNbI9Q.png", "tags": {"deep-learning": {"item_id": "3141124232", "tag": "deep-learning"}}, "authors": {"143974644": {"item_id": "3141124232", "author_id": "143974644", "name": "Anthony Agnone", "url": "https://anthonyagnone.medium.com"}}, "image": {"item_id": "3141124232", "src": "https://miro.medium.com/max/1400/1*S0qI3tDpftQAFSQKSNbI9Q.png", "width": "700", "height": "504"}, "images": {"1": {"item_id": "3141124232", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*S0qI3tDpftQAFSQKSNbI9Q.png", "width": "700", "height": "504", "credit": "", "caption": "Easily browse state-of-the-art machine learning code on Papers with Code"}, "2": {"item_id": "3141124232", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*TataFDIVOB1ZGCwpYfeb5g.png", "width": "700", "height": "362", "credit": "", "caption": "A high-level view of Paperscape‚Äôs interaction visualization of arXiv articles."}, "3": {"item_id": "3141124232", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*8plAOW0IawdV7rxeljnGyA.png", "width": "700", "height": "533", "credit": "", "caption": "A few of the highest-rated repositories on Papers with Code."}, "4": {"item_id": "3141124232", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*iRVI06JYCqK81fQ7zXSeng.png", "width": "700", "height": "609", "credit": "", "caption": "Time-based trends of framework usage and paper code availability, managed by Papers with Code."}, "5": {"item_id": "3141124232", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*Sy1LJW_t97A_xkrwQHtphw.png", "width": "700", "height": "390", "credit": "", "caption": "A preview of the EfficientNet arXiv page with links to Papers with Code."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 407}, "2544930772": {"item_id": "2544930772", "resolved_id": "2544930772", "given_url": "https://medium.com/@andersasac/the-end-of-anchors-improving-object-detection-models-and-annotations-73828c7b39f6", "given_title": "Pocket - Anchor Boxes‚Ää‚Äî‚ÄäThe key to quality object detection", "favorite": "0", "status": "1", "time_added": "1609622758", "time_updated": "1638708525", "time_read": "1609624934", "time_favorited": "0", "sort_id": 391, "resolved_title": "The End of Anchors‚Ää‚Äî‚ÄäImproving Object Detection Models and Annotations", "resolved_url": "https://medium.com/@andersasac/the-end-of-anchors-improving-object-detection-models-and-annotations-73828c7b39f6", "excerpt": "If you have ever needed to tinker with anchor boxes, you were probably frustrated, confused and saying to yourself, ‚ÄúThere must be another way!‚Äù Well now it appears that there is another way.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "878", "lang": "en", "time_to_read": 4, "top_image_url": "https://cdn-images-1.medium.com/max/1200/1*lSA4IYkqrIgpM1SyuQE4Dg.png", "tags": {"deep-learning": {"item_id": "2544930772", "tag": "deep-learning"}, "object-detection": {"item_id": "2544930772", "tag": "object-detection"}}, "authors": {"77706152": {"item_id": "2544930772", "author_id": "77706152", "name": "Anders Christiansen", "url": "https://medium.com/@andersasac"}}, "image": {"item_id": "2544930772", "src": "https://cdn-images-1.medium.com/max/1600/1*lSA4IYkqrIgpM1SyuQE4Dg.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2544930772", "image_id": "1", "src": "https://cdn-images-1.medium.com/max/1600/1*lSA4IYkqrIgpM1SyuQE4Dg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2544930772", "image_id": "2", "src": "https://cdn-images-1.medium.com/max/1600/1*gXOdLx6KYnSXMVjjC7g92Q.png", "width": "0", "height": "0", "credit": "COCO", "caption": "Examples from the Common Objects in Context"}, "3": {"item_id": "2544930772", "image_id": "3", "src": "https://cdn-images-1.medium.com/max/1600/1*HN3y5Il7TeRj06bpksmXOA.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2544930772", "image_id": "4", "src": "https://cdn-images-1.medium.com/max/1600/1*AjkLoASqjP7M3lir2lHGVg.gif", "width": "0", "height": "0", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 340}, "3170451341": {"item_id": "3170451341", "resolved_id": "3170451362", "given_url": "https://towardsdatascience.com/practical-guide-to-entity-resolution-part-5-5ecdd0005470?source=rss----7f60cf5620c9---4", "given_title": "Practical Guide to Entity Resolution‚Ää‚Äî‚Ääpart 5", "favorite": "0", "status": "1", "time_added": "1605137900", "time_updated": "1638708525", "time_read": "1608290449", "time_favorited": "0", "sort_id": 392, "resolved_title": "Practical Guide to Entity Resolution", "resolved_url": "https://towardsdatascience.com/practical-guide-to-entity-resolution-part-5-5ecdd0005470", "excerpt": "This is part 5 of a mini-series on entity resolution. Check out part 1, part 2, part 3, part 4 if you missed it In most real world ER use cases, there is no ground truth on which candidate pair should match and which should not match.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "967", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/max/1200/0*0qWXV_wUH8mA_S8n", "tags": {"deep-learning": {"item_id": "3170451341", "tag": "deep-learning"}, "entity-resolution": {"item_id": "3170451341", "tag": "entity-resolution"}, "vision": {"item_id": "3170451341", "tag": "vision"}}, "authors": {"142254521": {"item_id": "3170451341", "author_id": "142254521", "name": "Yifei Huang", "url": "https://yifei-huang.medium.com"}}, "image": {"item_id": "3170451341", "src": "https://miro.medium.com/fit/c/56/56/1*c01BdvUOn9xPafDWjDKy2A.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3170451341", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*c01BdvUOn9xPafDWjDKy2A.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3170451341", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*0qWXV_wUH8mA_S8n", "width": "700", "height": "472", "credit": "Laura Ockel on Unsplash", "caption": ""}, "3": {"item_id": "3170451341", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*yRokOvNUlhS1pv13lrOMwQ.png", "width": "700", "height": "238", "credit": "", "caption": "score iteration learning loop"}, "4": {"item_id": "3170451341", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*XT8AslWjcIVoYeYHP4Q5ug.png", "width": "700", "height": "420", "credit": "", "caption": "Example outputs from the sampled candidate pairs"}, "5": {"item_id": "3170451341", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*_ilNg_Z_iEmWmpP1k6HInA.png", "width": "700", "height": "313", "credit": "", "caption": "Sampled output with modeled based match probability"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 374}, "2965073012": {"item_id": "2965073012", "resolved_id": "2965073012", "given_url": "https://opensource.facebook.com/projects", "given_title": "Projects", "favorite": "0", "status": "1", "time_added": "1620162633", "time_updated": "1706833159", "time_read": "1620581722", "time_favorited": "0", "sort_id": 393, "resolved_title": "Projects", "resolved_url": "https://opensource.facebook.com/projects", "excerpt": "Detectron2 is FAIR's next-generation platform for object detection and segmentation. An Android library for managing images and the memory they use.", "is_article": "0", "is_index": "1", "has_video": "0", "has_image": "1", "word_count": "610", "lang": "en", "time_to_read": 3, "tags": {"deep-learning": {"item_id": "2965073012", "tag": "deep-learning"}, "machine-learning": {"item_id": "2965073012", "tag": "machine-learning"}, "programming": {"item_id": "2965073012", "tag": "programming"}}, "image": {"item_id": "2965073012", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/35329452_250930248986413_8511224269714227200_n.svg?_nc_cat=100&_nc_sid=ad8a9d&_nc_ohc=T0dvXYo3Ke8AX-K8vES&_nc_ht=scontent-iad3-1.xx&oh=0780336b0bb756128d01f9661bf44f87&oe=5F25F603", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2965073012", "image_id": "1", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/35329452_250930248986413_8511224269714227200_n.svg?_nc_cat=100&_nc_sid=ad8a9d&_nc_ohc=T0dvXYo3Ke8AX-K8vES&_nc_ht=scontent-iad3-1.xx&oh=0780336b0bb756128d01f9661bf44f87&oe=5F25F603", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2965073012", "image_id": "2", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/35265463_178426236171462_7159795342395834368_n.svg?_nc_cat=111&_nc_sid=ad8a9d&_nc_ohc=mLzcPVv6jbwAX_tD37Z&_nc_ht=scontent-iad3-1.xx&oh=6b71ef3b0707dd50245c79ee7da22044&oe=5F2633D8", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2965073012", "image_id": "3", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/35265203_240118960081362_6038662097632493568_n.svg?_nc_cat=100&_nc_sid=ad8a9d&_nc_ohc=eRPcFyzOoYAAX94_ACH&_nc_ht=scontent-iad3-1.xx&oh=0c5502e6ffb7e099d6065b1c5a2f7bb0&oe=5F25F645", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2965073012", "image_id": "4", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/80927290_915557595505003_2335302211371794432_n.svg?_nc_cat=100&_nc_sid=ad8a9d&_nc_ohc=uo5mayko3AQAX8C8L1E&_nc_ht=scontent-iad3-1.xx&oh=9e29d4b6d36f0b4ec53228e51c9a1f17&oe=5F23F742", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2965073012", "image_id": "5", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/70054325_2542097379144485_8906474579363364864_n.jpg?_nc_cat=108&_nc_sid=ad8a9d&_nc_ohc=11gFj4YRlFkAX-cYXzE&_nc_ht=scontent-iad3-1.xx&oh=f23d715911ef1f86935d1b95e1569d43&oe=5F25E559", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2965073012", "image_id": "6", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/35389316_383922622118123_8759049191273005056_n.svg?_nc_cat=101&_nc_sid=ad8a9d&_nc_ohc=7vEciAWr5PIAX-DwpyH&_nc_ht=scontent-iad3-1.xx&oh=52262ddc9705740d530b2048c48f82f0&oe=5F253C83", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2965073012", "image_id": "7", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/35330260_209390496345536_3498915062104457216_n.svg?_nc_cat=105&_nc_sid=ad8a9d&_nc_ohc=nGE17g8mVg0AX-ApERx&_nc_ht=scontent-iad3-1.xx&oh=ae94ce5f5f259b02738fbc966337e9c9&oe=5F259A74", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2965073012", "image_id": "8", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/35387767_773312829724328_1989297017486049280_n.svg?_nc_cat=105&_nc_sid=ad8a9d&_nc_ohc=2X0Kl8Pvfi0AX9prB08&_nc_ht=scontent-iad3-1.xx&oh=0ebb1b415552d5e2b7747eec74bfdfcd&oe=5F236784", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2965073012", "image_id": "9", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/35417120_1037737653031121_9038772607305908224_n.svg?_nc_cat=109&_nc_sid=ad8a9d&_nc_ohc=EFloQ0jcobgAX_c0_Sg&_nc_ht=scontent-iad3-1.xx&oh=6fe556e7498b6d6eac89b4c6a847ac7d&oe=5F233573", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2965073012", "image_id": "10", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/62461071_545420359319886_6709966340695785472_n.svg?_nc_cat=104&_nc_sid=ad8a9d&_nc_ohc=eI3SsIB_Wr8AX_9uKrr&_nc_ht=scontent-iad3-1.xx&oh=f3aadb6bc06b62ce1d0ded4bd71cc7e3&oe=5F25B609", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2965073012", "image_id": "11", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/35307500_253837245199191_6425232037858246656_n.svg?_nc_cat=110&_nc_sid=ad8a9d&_nc_ohc=whdPLDKladIAX-7U6ex&_nc_ht=scontent-iad3-1.xx&oh=92668ec6548bd3e75f140435e8a3b635&oe=5F23B4B5", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2965073012", "image_id": "12", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/43580957_926063297594839_698293512608677888_n.svg?_nc_cat=104&_nc_sid=ad8a9d&_nc_ohc=T-_fDVN48ewAX9fiss4&_nc_ht=scontent-iad3-1.xx&oh=1aeb196aca02e70f421964e0f08b348b&oe=5F2269F2", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "2965073012", "image_id": "13", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/44646694_278168366372060_7441621531467186176_n.svg?_nc_cat=106&_nc_sid=ad8a9d&_nc_ohc=-fOP0uSyjgoAX_5e_OC&_nc_ht=scontent-iad3-1.xx&oh=d21dbfd6849f9e81d082f1decc9ac000&oe=5F24E919", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "2965073012", "image_id": "14", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/48172328_260206981338538_2187933147482554368_n.svg?_nc_cat=105&_nc_sid=ad8a9d&_nc_ohc=Zfh8Zkgcgk0AX-zYXQe&_nc_ht=scontent-iad3-1.xx&oh=f1cd295eea03a1a6f61554bc6514e031&oe=5F262669", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "2965073012", "image_id": "15", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/47741939_275346893179505_8248798293300084736_n.svg?_nc_cat=105&_nc_sid=ad8a9d&_nc_ohc=C5daeRHjvyoAX9gdMNz&_nc_ht=scontent-iad3-1.xx&oh=b8eb717fea24c5724b0cd29aac908f59&oe=5F22BBA2", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "2965073012", "image_id": "16", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/47946553_309108866610501_1074285420830785536_n.svg?_nc_cat=104&_nc_sid=ad8a9d&_nc_ohc=PY5BJY4pMbkAX_iXErJ&_nc_ht=scontent-iad3-1.xx&oh=efac562a24fd25f5687de3c4a4fdce8c&oe=5F241EAF", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "2965073012", "image_id": "17", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/47960215_348933492568111_5355030207507988480_n.svg?_nc_cat=106&_nc_sid=ad8a9d&_nc_ohc=AqPZiwAyDkgAX_TYS6r&_nc_ht=scontent-iad3-1.xx&oh=db1425aaa24fb272a4dbbadb5f66312a&oe=5F225E8C", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "2965073012", "image_id": "18", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/47947430_789506281399725_5385993288169816064_n.svg?_nc_cat=106&_nc_sid=ad8a9d&_nc_ohc=o16bjeRfCxkAX_tCb4U&_nc_ht=scontent-iad3-1.xx&oh=cb05a9d95cf674e5834553622380732f&oe=5F230E7A", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "2965073012", "image_id": "19", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/47740953_125066908414036_8246943395709190144_n.svg?_nc_cat=109&_nc_sid=ad8a9d&_nc_ohc=7J2Bd13xfAUAX9tLD37&_nc_ht=scontent-iad3-1.xx&oh=df039b434cb3a43652243492a596c770&oe=5F235CFD", "width": "0", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "2965073012", "image_id": "20", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/55670231_341340656485699_2287242068495433728_n.png?_nc_cat=102&_nc_sid=ad8a9d&_nc_ohc=pwDo4iek_lEAX-Bb-Rf&_nc_ht=scontent-iad3-1.xx&oh=87b21b73ac46a74bb2e19ab5f08a5025&oe=5F2439A7", "width": "0", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "2965073012", "image_id": "21", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/47963403_2276942729207149_7966349449934929920_n.svg?_nc_cat=111&_nc_sid=ad8a9d&_nc_ohc=DyTFh6SwNRcAX_peweD&_nc_ht=scontent-iad3-1.xx&oh=1e3b26fd22095b311667e08209a538b6&oe=5F254FA2", "width": "0", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "2965073012", "image_id": "22", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/47941804_2413794235328271_1342302100339556352_n.svg?_nc_cat=107&_nc_sid=ad8a9d&_nc_ohc=JXY1BlsrMyUAX8swGz6&_nc_ht=scontent-iad3-1.xx&oh=97533cabbed8023125331291b753f333&oe=5F25CAC5", "width": "0", "height": "0", "credit": "", "caption": ""}, "23": {"item_id": "2965073012", "image_id": "23", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/47931515_2043615319051361_3173396716191744_n.svg?_nc_cat=105&_nc_sid=ad8a9d&_nc_ohc=qa14U4ObsCkAX-7gKnD&_nc_ht=scontent-iad3-1.xx&oh=19f86be77634ef20a5b7897b589a2521&oe=5F24585D", "width": "0", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "2965073012", "image_id": "24", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/43523794_2092076324165044_5313300550073188352_n.png?_nc_cat=109&_nc_sid=ad8a9d&_nc_ohc=NOEnQuZIlqMAX_HVRBr&_nc_ht=scontent-iad3-1.xx&oh=c9dcffeca6689342b1c0fafa68b046c2&oe=5F23A627", "width": "0", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "2965073012", "image_id": "25", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/48083288_375412483207654_6549512667529216000_n.svg?_nc_cat=106&_nc_sid=ad8a9d&_nc_ohc=ti6QpMv2980AX9Z3bWI&_nc_ht=scontent-iad3-1.xx&oh=10d6d3b44161a0396b317cebf6b8f87e&oe=5F246D29", "width": "0", "height": "0", "credit": "", "caption": ""}, "26": {"item_id": "2965073012", "image_id": "26", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/47943985_534918970313751_4748803626741268480_n.svg?_nc_cat=110&_nc_sid=ad8a9d&_nc_ohc=hLfF8YXvwiwAX-cgjng&_nc_ht=scontent-iad3-1.xx&oh=d13f73aad0096d8d64b016416fc689db&oe=5F228C0A", "width": "0", "height": "0", "credit": "", "caption": ""}, "27": {"item_id": "2965073012", "image_id": "27", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/47740098_385271725375800_1159603047790280704_n.svg?_nc_cat=102&_nc_sid=ad8a9d&_nc_ohc=TqZAq6oyFa8AX-ZkMx6&_nc_ht=scontent-iad3-1.xx&oh=be1494702210cd0458917c72f494c1b1&oe=5F2306D5", "width": "0", "height": "0", "credit": "", "caption": ""}, "28": {"item_id": "2965073012", "image_id": "28", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/47741776_433420583859515_4648563075782279168_n.svg?_nc_cat=111&_nc_sid=ad8a9d&_nc_ohc=mUUE4KsBSOwAX8HM6SL&_nc_ht=scontent-iad3-1.xx&oh=69f465b61bf8f55f7ef646363f7cbeae&oe=5F22EAAD", "width": "0", "height": "0", "credit": "", "caption": ""}, "29": {"item_id": "2965073012", "image_id": "29", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/47938364_222999701926858_1990645130410852352_n.svg?_nc_cat=101&_nc_sid=ad8a9d&_nc_ohc=RQmhc6PCchwAX9EMVT4&_nc_ht=scontent-iad3-1.xx&oh=628a41bee0f9a9474df36ca515bfc57b&oe=5F260C79", "width": "0", "height": "0", "credit": "", "caption": ""}, "30": {"item_id": "2965073012", "image_id": "30", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/47952313_1211585938989573_1154188111937273856_n.svg?_nc_cat=106&_nc_sid=ad8a9d&_nc_ohc=kVFsqZ0wYh0AX-d0ig9&_nc_ht=scontent-iad3-1.xx&oh=e1217aa7afebf7da97047ae8347ba458&oe=5F241CA8", "width": "0", "height": "0", "credit": "", "caption": ""}, "31": {"item_id": "2965073012", "image_id": "31", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/47741324_2067321323332035_4636875301538758656_n.svg?_nc_cat=111&_nc_sid=ad8a9d&_nc_ohc=b5em1fHiBhEAX-gMOkl&_nc_ht=scontent-iad3-1.xx&oh=51275489b9e4e42d3461a23fef8673c5&oe=5F240332", "width": "0", "height": "0", "credit": "", "caption": ""}, "32": {"item_id": "2965073012", "image_id": "32", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/34929128_2542370199321677_3462617962773479424_n.png?_nc_cat=108&_nc_sid=ad8a9d&_nc_ohc=n049xd0pxIYAX_goNYP&_nc_ht=scontent-iad3-1.xx&oh=090aef3a5dc356484800ddaf02284f4d&oe=5F2436D2", "width": "0", "height": "0", "credit": "", "caption": ""}, "33": {"item_id": "2965073012", "image_id": "33", "src": "https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/34747737_1440020432811296_5160914217057910784_n.png?_nc_cat=103&_nc_sid=ad8a9d&_nc_ohc=G0_oIhRUtxQAX_RErEP&_nc_ht=scontent-iad3-1.xx&oh=fc8c9bafbb9bc3d7e9a940c93aa8fb1f&oe=5F23C1B2", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 236}, "1898569116": {"item_id": "1898569116", "resolved_id": "1898569116", "given_url": "https://pymol.org/2/", "given_title": "PyMOL | pymol.org", "favorite": "0", "status": "1", "time_added": "1626546387", "time_updated": "1706833159", "time_read": "1626575043", "time_favorited": "0", "sort_id": 394, "resolved_title": "pymol.org", "resolved_url": "https://pymol.org/2/", "excerpt": "(Installation instructions) For previous versions, see here. These bundles include Python 3.7.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "11", "lang": "en", "tags": {"biology": {"item_id": "1898569116", "tag": "biology"}, "deep-learning": {"item_id": "1898569116", "tag": "deep-learning"}, "programming": {"item_id": "1898569116", "tag": "programming"}, "python": {"item_id": "1898569116", "tag": "python"}, "visualization": {"item_id": "1898569116", "tag": "visualization"}}, "listen_duration_estimate": 4}, "2965485019": {"item_id": "2965485019", "resolved_id": "2965485019", "given_url": "https://towardsdatascience.com/python-libraries-for-natural-language-processing-be0e5a35dd64", "given_title": "Python Libraries for Natural Language Processing - Towards Data Science", "favorite": "0", "status": "1", "time_added": "1588088451", "time_updated": "1638708525", "time_read": "1588089112", "time_favorited": "0", "sort_id": 395, "resolved_title": "Python Libraries for Natural Language Processing", "resolved_url": "https://towardsdatascience.com/python-libraries-for-natural-language-processing-be0e5a35dd64", "excerpt": "Claire D. Costa Python is one of the hottest programming languages in the world right now because of how gracefully it integrates with other programming languages and fits perfectly into most new project ideas as the preferred programming language of choice.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1733", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1200/1*PIpjPTlcrDyXLl2fDv34bA.png", "tags": {"deep-learning": {"item_id": "2965485019", "tag": "deep-learning"}, "nlp": {"item_id": "2965485019", "tag": "nlp"}, "python": {"item_id": "2965485019", "tag": "python"}}, "authors": {"137500960": {"item_id": "2965485019", "author_id": "137500960", "name": "Claire D. Costa", "url": "https://medium.com/@harish_6956"}}, "image": {"item_id": "2965485019", "src": "https://miro.medium.com/fit/c/56/56/2*8UE9VXSUAfwXmaMsVg_3dw.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2965485019", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*8UE9VXSUAfwXmaMsVg_3dw.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2965485019", "image_id": "2", "src": "https://miro.medium.com/max/2974/1*PIpjPTlcrDyXLl2fDv34bA.png", "width": "1487", "height": "645", "credit": "", "caption": "Python Libraries for Natural Language Processing"}, "3": {"item_id": "2965485019", "image_id": "3", "src": "https://miro.medium.com/max/752/1*yGIAhBw_KgwBIaU6j-fJJA.png", "width": "376", "height": "134", "credit": "source", "caption": "Spacy"}, "4": {"item_id": "2965485019", "image_id": "4", "src": "https://miro.medium.com/max/1556/1*y8NHPVoA8RMpgPdzIlLggw.png", "width": "778", "height": "304", "credit": "source", "caption": "NLTK ‚Äî Tokenize and tag some text"}, "5": {"item_id": "2965485019", "image_id": "5", "src": "https://miro.medium.com/max/1564/1*AuzOxOTA6gsjNwLMtepUOg.png", "width": "782", "height": "206", "credit": "source", "caption": "NLTK ‚Äî Identify Named Entities"}, "6": {"item_id": "2965485019", "image_id": "6", "src": "https://miro.medium.com/max/2290/1*bMF6V6I7dgg87MowKArI4g.png", "width": "1145", "height": "349", "credit": "source", "caption": "Google Trends ‚Äî Pattern"}, "7": {"item_id": "2965485019", "image_id": "7", "src": "https://miro.medium.com/max/1180/1*-mMgSBLeWuZiKgGd8bFQVw.jpeg", "width": "590", "height": "430", "credit": "source", "caption": "Textblob"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 671}, "2907866502": {"item_id": "2907866502", "resolved_id": "728603", "given_url": "https://pytorch-lightning.readthedocs.io/en/latest/", "given_title": "PyTorch Lightning Documentation ‚Äî PyTorch Lightning 1.3.0dev documentation", "favorite": "0", "status": "1", "time_added": "1615923456", "time_updated": "1638708525", "time_read": "1616192077", "time_favorited": "0", "sort_id": 396, "resolved_title": "Let‚Äôs build from here", "resolved_url": "https://github.com/", "excerpt": "Skip to content Sign in Sign in Sign up You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session.", "is_article": "0", "is_index": "1", "has_video": "1", "has_image": "1", "word_count": "59", "lang": "en", "top_image_url": "https://github.githubassets.com/assets/campaign-social-031d6161fa10.png", "tags": {"deep-learning": {"item_id": "2907866502", "tag": "deep-learning"}, "pytorch": {"item_id": "2907866502", "tag": "pytorch"}}, "image": {"item_id": "2907866502", "src": "https://github.githubassets.com/assets/shape-0-df97fa6b0c27.svg", "width": "626", "height": "626"}, "images": {"1": {"item_id": "2907866502", "image_id": "1", "src": "https://github.githubassets.com/assets/shape-0-df97fa6b0c27.svg", "width": "626", "height": "626", "credit": "", "caption": ""}, "2": {"item_id": "2907866502", "image_id": "2", "src": "https://github.githubassets.com/assets/shape-1-c219318e479a.svg", "width": "584", "height": "584", "credit": "", "caption": ""}, "3": {"item_id": "2907866502", "image_id": "3", "src": "https://github.githubassets.com/assets/shape-2-f30dcc9bd35c.svg", "width": "595", "height": "595", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "2907866502", "video_id": "1", "src": "https://github.githubassets.com/assets/globe-900.hevc-58019d77b21c.mp4", "width": "916", "height": "918", "type": "5", "vid": "", "length": "0"}, "2": {"item_id": "2907866502", "video_id": "2", "src": "https://github.githubassets.com/assets/globe-500.hevc-42032a395ff1.mp4", "width": "0", "height": "0", "type": "5", "vid": "", "length": "0"}, "3": {"item_id": "2907866502", "video_id": "3", "src": "https://github.githubassets.com/assets/aurora.h264-25af1afc4e69.mp4", "width": "0", "height": "0", "type": "5", "vid": "", "length": "0"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 23}, "2908761563": {"item_id": "2908761563", "resolved_id": "2908493691", "given_url": "https://towardsdatascience.com/q-learning-a4f1bcec58be?source=rss----7f60cf5620c9---4", "given_title": "Q-Learning", "favorite": "0", "status": "1", "time_added": "1583664883", "time_updated": "1638708525", "time_read": "1583784804", "time_favorited": "0", "sort_id": 397, "resolved_title": "Q-Learning", "resolved_url": "https://towardsdatascience.com/q-learning-a4f1bcec58be", "excerpt": "Welcome to my column on reinforcement learning, where I spend some time going over some very interesting concepts revolving around the nature of learning with a computational approach.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "753", "lang": "en", "time_to_read": 3, "top_image_url": "https://miro.medium.com/max/543/1*CD2E94bMwI68SPYE3tkH7Q.png", "tags": {"deep-learning": {"item_id": "2908761563", "tag": "deep-learning"}}, "authors": {"126531483": {"item_id": "2908761563", "author_id": "126531483", "name": "Reuben Kavalov", "url": "https://medium.com/@reubena.kavalov"}}, "image": {"item_id": "2908761563", "src": "https://miro.medium.com/fit/c/56/56/2*oiWZB798SzqPgjr6VkFt2g.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2908761563", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*oiWZB798SzqPgjr6VkFt2g.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2908761563", "image_id": "2", "src": "https://miro.medium.com/max/754/1*aZ9_q_TLXwBZDop3mwahNw.png", "width": "377", "height": "67", "credit": "", "caption": ""}, "3": {"item_id": "2908761563", "image_id": "3", "src": "https://miro.medium.com/max/982/1*JjExhPaTkB4LGWSPbmnRvA.png", "width": "491", "height": "165", "credit": "", "caption": ""}, "4": {"item_id": "2908761563", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*00GnaYEjVHQbea6Ul_27vQ.png", "width": "700", "height": "314", "credit": "", "caption": ""}, "5": {"item_id": "2908761563", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*qgEKefbQww0-ADFrcJ7mOg.png", "width": "700", "height": "286", "credit": "", "caption": "http://incompleteideas.net/book/RLbook2018.pdf"}, "6": {"item_id": "2908761563", "image_id": "6", "src": "https://miro.medium.com/max/1000/1*CD2E94bMwI68SPYE3tkH7Q.png", "width": "500", "height": "243", "credit": "", "caption": ""}, "7": {"item_id": "2908761563", "image_id": "7", "src": "https://miro.medium.com/max/2488/1*lGX_9byWoTJWHlYB2xZ3oQ.png", "width": "1244", "height": "680", "credit": "", "caption": ""}, "8": {"item_id": "2908761563", "image_id": "8", "src": "https://miro.medium.com/max/2520/1*swCZ6h66Cj3nxUQxw6e_qg.png", "width": "1260", "height": "684", "credit": "", "caption": ""}, "9": {"item_id": "2908761563", "image_id": "9", "src": "https://miro.medium.com/max/2552/1*4XTx5V_4c0urOPjt0oguOA.png", "width": "1276", "height": "680", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 291}, "3134859480": {"item_id": "3134859480", "resolved_id": "3134859507", "given_url": "https://towardsdatascience.com/qrnn-a-potential-competitor-to-the-transformer-86b5aef6c137?source=rss----7f60cf5620c9---4", "given_title": "QRNN: A Potential Competitor to the Transformer", "favorite": "0", "status": "1", "time_added": "1602092019", "time_updated": "1638708525", "time_read": "1604367779", "time_favorited": "0", "sort_id": 398, "resolved_title": "QRNN: A Potential Competitor to the Transformer", "resolved_url": "https://towardsdatascience.com/qrnn-a-potential-competitor-to-the-transformer-86b5aef6c137", "excerpt": "Recurrent Neural Networks (RNNs) have been in the sequence modeling business for a long time. But RNNs are slow; they process one token at a time. Moreover, the recurrent architecture adds a limitation of fixed-length encoding vectors for the complete sequence.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1259", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/0*gotH4l-64DRir1Gw", "tags": {"deep-learning": {"item_id": "3134859480", "tag": "deep-learning"}}, "authors": {"142739226": {"item_id": "3134859480", "author_id": "142739226", "name": "Rohan Jagtap", "url": "https://rojagtap.medium.com"}}, "image": {"item_id": "3134859480", "src": "https://miro.medium.com/fit/c/56/56/2*gnqkz70uGsyIy7VBNrVXEQ.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3134859480", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*gnqkz70uGsyIy7VBNrVXEQ.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3134859480", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*gotH4l-64DRir1Gw", "width": "700", "height": "467", "credit": "Braden Collum on Unsplash", "caption": ""}, "3": {"item_id": "3134859480", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*DM5T5S6S1ebno9zw4iQqxQ.png", "width": "700", "height": "433", "credit": "", "caption": "LSTM via QRNN Paper"}, "4": {"item_id": "3134859480", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*j9p1wMowqJwXweHGmG3_9g.png", "width": "700", "height": "436", "credit": "", "caption": "CNN via QRNN Paper"}, "5": {"item_id": "3134859480", "image_id": "5", "src": "https://miro.medium.com/max/1388/1*3-Tg-Sd_ABkPk0DtWHxtwg.png", "width": "694", "height": "434", "credit": "", "caption": "QRNN via QRNN Paper"}, "6": {"item_id": "3134859480", "image_id": "6", "src": "https://miro.medium.com/max/1354/1*3VZ9hSFeNlmq_hnb66RZPw.gif", "width": "677", "height": "521", "credit": "", "caption": "Masked-Convolution Animation by Author"}, "7": {"item_id": "3134859480", "image_id": "7", "src": "https://miro.medium.com/max/1136/1*23rVFZAFqytWqvwwjzcvNA.png", "width": "568", "height": "260", "credit": "", "caption": "Outputs of Convolution Component via QRNN Paper"}, "8": {"item_id": "3134859480", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*aSiOzyQmzVEn-4vUlB8OhQ.png", "width": "700", "height": "252", "credit": "", "caption": "LSTM-like Outputs via QRNN Paper"}, "9": {"item_id": "3134859480", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*MjYpO562T-vt8kfV7oOhmg.png", "width": "700", "height": "112", "credit": "f-pooling", "caption": "Dynamic Average Pooling"}, "10": {"item_id": "3134859480", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*6IGkNubITahcK2EOnkjyfQ.png", "width": "700", "height": "144", "credit": "", "caption": "fo-pooling via QRNN Paper"}, "11": {"item_id": "3134859480", "image_id": "11", "src": "https://miro.medium.com/max/1348/1*tclUIPrZfeC_pMC8doPAvA.png", "width": "674", "height": "164", "credit": "", "caption": "ifo-pooling via QRNN Paper"}, "12": {"item_id": "3134859480", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*yYuxOfvN2AvTbCLjC5ol3g.png", "width": "700", "height": "85", "credit": "", "caption": "Dropout via QRNN Paper"}, "13": {"item_id": "3134859480", "image_id": "13", "src": "https://miro.medium.com/max/1400/1*PUbHoG3_xWT8pniTdf-YzA.png", "width": "700", "height": "508", "credit": "", "caption": "DenseNet via DenseNet Paper"}, "14": {"item_id": "3134859480", "image_id": "14", "src": "https://miro.medium.com/max/2000/1*3KESexGEFrgIwOokF3RULA.png", "width": "1000", "height": "495", "credit": "", "caption": "QRNN seq2seq via QRNN Paper"}, "15": {"item_id": "3134859480", "image_id": "15", "src": "https://miro.medium.com/max/1400/1*R21SM_dWEU247MLcoImU5Q.png", "width": "700", "height": "248", "credit": "", "caption": "Decoder Layer via QRNN Paper"}, "16": {"item_id": "3134859480", "image_id": "16", "src": "https://miro.medium.com/max/1400/1*oDLy2jA69LbJCX0HLuJr1A.png", "width": "700", "height": "336", "credit": "", "caption": "Attention in QRNN via QRNN Paper"}, "17": {"item_id": "3134859480", "image_id": "17", "src": "https://miro.medium.com/max/2000/1*87ZEY6a6f1br1SwExn-9PQ.png", "width": "1000", "height": "292", "credit": "", "caption": "Speed Comparison via QRNN Paper"}, "18": {"item_id": "3134859480", "image_id": "18", "src": "https://miro.medium.com/max/1280/0*lWP8_xD9nQJ47H6J.png", "width": "640", "height": "398", "credit": "", "caption": "pQRNN vs BERT via Google AI Blog"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 487}, "2909956296": {"item_id": "2909956296", "resolved_id": "2909931118", "given_url": "https://towardsdatascience.com/quick-introduction-to-sentiment-analysis-74bd3dfb536c?source=rss----7f60cf5620c9---4", "given_title": "Quick Introduction to Sentiment Analysis", "favorite": "0", "status": "1", "time_added": "1583770651", "time_updated": "1638708525", "time_read": "1583784758", "time_favorited": "0", "sort_id": 399, "resolved_title": "Quick Introduction to Sentiment Analysis", "resolved_url": "https://towardsdatascience.com/quick-introduction-to-sentiment-analysis-74bd3dfb536c", "excerpt": "Sentiment analysis is the automated process of determining whether a text expresses a positive, negative, or neutral opinion about a product or topic.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1421", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/1*TUqC3XRqvzErhnFC4h1Rcw@2x.png", "tags": {"deep-learning": {"item_id": "2909956296", "tag": "deep-learning"}, "nlp": {"item_id": "2909956296", "tag": "nlp"}, "sentiment-analysis": {"item_id": "2909956296", "tag": "sentiment-analysis"}}, "authors": {"153833261": {"item_id": "2909956296", "author_id": "153833261", "name": "Rachel Wolff", "url": "https://medium.com/@rachel_39895"}}, "image": {"item_id": "2909956296", "src": "https://miro.medium.com/max/1400/1*TUqC3XRqvzErhnFC4h1Rcw@2x.png", "width": "700", "height": "438"}, "images": {"1": {"item_id": "2909956296", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*TUqC3XRqvzErhnFC4h1Rcw@2x.png", "width": "700", "height": "438", "credit": "", "caption": "Source: MonkeyLearn"}, "2": {"item_id": "2909956296", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*w6FMzraZmFZw3lje", "width": "700", "height": "633", "credit": "", "caption": "Source: MonkeyLearn"}, "3": {"item_id": "2909956296", "image_id": "3", "src": "https://miro.medium.com/max/1400/0*PM18NL-TxTCy5yZ_", "width": "700", "height": "230", "credit": "", "caption": "Source: MonkeyLearn"}, "4": {"item_id": "2909956296", "image_id": "4", "src": "https://miro.medium.com/max/1400/0*8Ne8nPky1tTS9_N7", "width": "700", "height": "361", "credit": "", "caption": "Source: MonkeyLearn"}, "5": {"item_id": "2909956296", "image_id": "5", "src": "https://miro.medium.com/max/830/0*oZ_z0MIWiSm0gv7L", "width": "415", "height": "456", "credit": "", "caption": "Source: MonkeyLearn"}, "6": {"item_id": "2909956296", "image_id": "6", "src": "https://miro.medium.com/max/1400/0*_8OBKlSD9VaNewn2", "width": "700", "height": "479", "credit": "", "caption": "Source: MonkeyLearn"}, "7": {"item_id": "2909956296", "image_id": "7", "src": "https://miro.medium.com/max/1400/0*TS_ilhnJOnvuMJf-", "width": "700", "height": "467", "credit": "", "caption": "Source: MonkeyLearn"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 550}, "3640839133": {"item_id": "3640839133", "resolved_id": "3640839148", "given_url": "https://towardsdatascience.com/recipe-cuisine-classification-278ea0837c94?source=rss----7f60cf5620c9---4", "given_title": "Recipe Cuisine Classification", "favorite": "0", "status": "1", "time_added": "1655334368", "time_updated": "1656015817", "time_read": "1656015817", "time_favorited": "0", "sort_id": 400, "resolved_title": "Recipe Cuisine Classification", "resolved_url": "https://towardsdatascience.com/recipe-cuisine-classification-278ea0837c94", "excerpt": "Several model architectures can be used to perform cuisine classification. Some of the most popular, in increasing order of complexity, are SVMs (Pouladzadeh et al., 2015), BERT (Devlin et al., 2018), RoBERTa (Liu et al., 2019) or GPT-3 (Brown et al., 2020) models.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1314", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/650/1*6UxlAXJ97ifHaxSAbWKFww.png", "tags": {"classification": {"item_id": "3640839133", "tag": "classification"}, "deep-learning": {"item_id": "3640839133", "tag": "deep-learning"}, "food-drink": {"item_id": "3640839133", "tag": "food-drink"}}, "authors": {"158644747": {"item_id": "3640839133", "author_id": "158644747", "name": "Lu√≠s Rita", "url": "https://luisdrita.com"}}, "image": {"item_id": "3640839133", "src": "https://miro.medium.com/max/1400/0*8fjRr9KZfNll6OVI", "width": "700", "height": "456"}, "images": {"1": {"item_id": "3640839133", "image_id": "1", "src": "https://miro.medium.com/max/1400/0*8fjRr9KZfNll6OVI", "width": "700", "height": "456", "credit": "S O C I A L . C U T on Unsplash", "caption": ""}, "2": {"item_id": "3640839133", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*OrU587pmaHqnZfLstCo09A.png", "width": "700", "height": "210", "credit": "on the left", "caption": "Figure 1 Permillage of existing interactions between drugs"}, "3": {"item_id": "3640839133", "image_id": "3", "src": "https://miro.medium.com/max/904/1*M37K7wOFtmNsK8abRpEe_g.png", "width": "452", "height": "288", "credit": "", "caption": "Figure 2 Recipe distribution in Kaggle & Nature dataset accordingly to the number of ingredients"}, "4": {"item_id": "3640839133", "image_id": "4", "src": "https://miro.medium.com/max/392/1*fGpJ83DpxyvSEqNd_1hjbQ.png", "width": "196", "height": "268", "credit": "", "caption": "Figure 3 Number of recipes per cuisine in Kaggle & Nature dataset."}, "5": {"item_id": "3640839133", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*1Za2hO7PAz9zV1jSFEZCkA.png", "width": "700", "height": "324", "credit": "", "caption": "Table 1 Model classification accuracy ‚Äî precision, recall and f1-score were detailed to every cuisine in the training dataset"}, "6": {"item_id": "3640839133", "image_id": "6", "src": "https://miro.medium.com/max/1300/1*6UxlAXJ97ifHaxSAbWKFww.png", "width": "650", "height": "330", "credit": "", "caption": "Figure 4 Latin American cuisine has the lowest number of negative interactions with neurological drugs ‚Äî AD. Western European shows the best results for anti-infective drugs ‚Äî COVID-19."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 509}, "2960579777": {"item_id": "2960579777", "resolved_id": "2960568943", "given_url": "https://towardsdatascience.com/recsys-series-part-5-neural-matrix-factorization-for-collaborative-filtering-a0aebfe15883?source=rss----7f60cf5620c9---4", "given_title": "RecSys Series Part 5: Neural Matrix Factorization for Collaborative Filteri", "favorite": "0", "status": "1", "time_added": "1587721548", "time_updated": "1638708525", "time_read": "1587744166", "time_favorited": "0", "sort_id": 401, "resolved_title": "Recommendation System Series Part 5: The 5 Variants of Multi-Layer Perceptron for Collaborative Filtering", "resolved_url": "https://towardsdatascience.com/recsys-series-part-5-neural-matrix-factorization-for-collaborative-filtering-a0aebfe15883", "excerpt": "Update: This article is part of a series where I explore recommendation systems in academia and industry. Check out the full series: Part 1, Part 2, Part 3, Part 4, Part 5, and Part 6. Collaborative Filtering algorithms are most commonly used in the applications of Recommendation Systems.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "3499", "lang": "en", "time_to_read": 16, "top_image_url": "https://miro.medium.com/max/1200/1*lrj-BgrJWKUuIUQu8ZFDCg.png", "tags": {"deep-learning": {"item_id": "2960579777", "tag": "deep-learning"}, "machine-learning": {"item_id": "2960579777", "tag": "machine-learning"}, "recommenders": {"item_id": "2960579777", "tag": "recommenders"}}, "authors": {"143561470": {"item_id": "2960579777", "author_id": "143561470", "name": "James Le", "url": "https://le-james94.medium.com"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1354}, "1863447707": {"item_id": "1863447707", "resolved_id": "1863447707", "given_url": "https://blog.deepsense.ai/region-of-interest-pooling-explained/", "given_title": "Region of interest pooling explained", "favorite": "1", "status": "1", "time_added": "1517098871", "time_updated": "1638708525", "time_read": "1517594931", "time_favorited": "1517594930", "sort_id": 402, "resolved_title": "Region of interest pooling explained", "resolved_url": "https://blog.deepsense.ai/region-of-interest-pooling-explained/", "excerpt": "Region of interest pooling (also known as RoI pooling) is an operation widely used in object detection tasks using convolutional neural networks. For example, to detect multiple cars and pedestrians in a single image.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1228", "lang": "en", "time_to_read": 6, "top_image_url": "https://blog.deepsense.ai/wp-content/uploads/2017/02/region-of-interest-pooling-explained.jpg", "tags": {"deep-learning": {"item_id": "1863447707", "tag": "deep-learning"}, "vision": {"item_id": "1863447707", "tag": "vision"}}, "authors": {"74242860": {"item_id": "1863447707", "author_id": "74242860", "name": "Tomasz Grel", "url": "https://blog.deepsense.ai/author/tomasz-grel/"}}, "image": {"item_id": "1863447707", "src": "https://blog.deepsense.ai/wp-content/uploads/2017/02/region_proposal_cat.png", "width": "300", "height": "300"}, "images": {"1": {"item_id": "1863447707", "image_id": "1", "src": "https://blog.deepsense.ai/wp-content/uploads/2017/02/region_proposal_cat.png", "width": "300", "height": "300", "credit": "", "caption": ""}, "2": {"item_id": "1863447707", "image_id": "2", "src": "https://blog.deepsense.ai/wp-content/uploads/2017/02/1.jpg", "width": "800", "height": "600", "credit": "", "caption": ""}, "3": {"item_id": "1863447707", "image_id": "3", "src": "https://blog.deepsense.ai/wp-content/uploads/2017/02/2.jpg", "width": "800", "height": "600", "credit": "", "caption": ""}, "4": {"item_id": "1863447707", "image_id": "4", "src": "https://blog.deepsense.ai/wp-content/uploads/2017/02/3.jpg", "width": "800", "height": "600", "credit": "", "caption": ""}, "5": {"item_id": "1863447707", "image_id": "5", "src": "https://blog.deepsense.ai/wp-content/uploads/2017/02/output.jpg", "width": "200", "height": "200", "credit": "", "caption": ""}}, "listen_duration_estimate": 475}, "3097075503": {"item_id": "3097075503", "resolved_id": "3097075523", "given_url": "https://towardsdatascience.com/reinforcement-learning-an-introduction-chapter-1-4bff46d8c6e6?source=rss----7f60cf5620c9---4", "given_title": "Reinforcement Learning‚Ää‚Äî‚ÄäAn Introduction | Chapter 1", "favorite": "0", "status": "1", "time_added": "1598882495", "time_updated": "1638708525", "time_read": "1604368900", "time_favorited": "0", "sort_id": 403, "resolved_title": "", "resolved_url": "https://towardsdatascience.com/reinforcement-learning-an-introduction-chapter-1-4bff46d8c6e6", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "en", "tags": {"deep-learning": {"item_id": "3097075503", "tag": "deep-learning"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "3224867213": {"item_id": "3224867213", "resolved_id": "3224867235", "given_url": "https://towardsdatascience.com/reinforcement-learning-explained-visually-part-6-policy-gradients-step-by-step-f9f448e73754?source=rss----7f60cf5620c9---4", "given_title": "Reinforcement Learning Explained Visually (Part 6): Policy Gradients, step-", "favorite": "0", "status": "1", "time_added": "1610215533", "time_updated": "1638708525", "time_read": "1610731441", "time_favorited": "0", "sort_id": 404, "resolved_title": "Reinforcement Learning Explained Visually (Part 6): Policy Gradients, step-by-step", "resolved_url": "https://towardsdatascience.com/reinforcement-learning-explained-visually-part-6-policy-gradients-step-by-step-f9f448e73754", "excerpt": "This is the sixth article in my series on Reinforcement Learning (RL). We now have a good understanding of the concepts that form the building blocks of an RL problem, and the techniques used to solve them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2062", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/737/1*hGNwjytdKtWFY69SFSMwwg.png", "tags": {"deep-learning": {"item_id": "3224867213", "tag": "deep-learning"}, "reinforcement-learning": {"item_id": "3224867213", "tag": "reinforcement-learning"}}, "authors": {"142118215": {"item_id": "3224867213", "author_id": "142118215", "name": "Ketan Doshi", "url": "https://ketanhdoshi.medium.com"}}, "image": {"item_id": "3224867213", "src": "https://miro.medium.com/fit/c/56/56/1*ZpFBF1tIJfdXWqSjIk1DKg.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3224867213", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*ZpFBF1tIJfdXWqSjIk1DKg.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3224867213", "image_id": "2", "src": "https://miro.medium.com/max/2000/0*DiqznIUhtrhHOq-J", "width": "1000", "height": "786", "credit": "Michael Dziedzic on Unsplash", "caption": ""}, "3": {"item_id": "3224867213", "image_id": "3", "src": "https://miro.medium.com/max/1338/1*_qQ5Sf39P4ZusDspO6WGpQ.png", "width": "669", "height": "201", "credit": "Image by Author", "caption": ""}, "4": {"item_id": "3224867213", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*ekQLwlQzVIeWJujJTB59Wg.png", "width": "700", "height": "286", "credit": "Image by Author", "caption": ""}, "5": {"item_id": "3224867213", "image_id": "5", "src": "https://miro.medium.com/max/2000/1*C4hMehBY9u0i02hom9hF1g.png", "width": "1000", "height": "341", "credit": "Image by Author", "caption": ""}, "6": {"item_id": "3224867213", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*37xQ9X8M2DDRfAJ-WaELaw.png", "width": "700", "height": "240", "credit": "Image by Author", "caption": ""}, "7": {"item_id": "3224867213", "image_id": "7", "src": "https://miro.medium.com/max/1258/1*ADZ_txGODUd0suwrWRmnKA.png", "width": "629", "height": "394", "credit": "Image by Author", "caption": ""}, "8": {"item_id": "3224867213", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*vGx4z8W3ToJnE6PBGK1L_w.png", "width": "700", "height": "248", "credit": "Image by Author", "caption": ""}, "9": {"item_id": "3224867213", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*JDpofIMGWCOOMjTCcd7kpg.png", "width": "700", "height": "322", "credit": "Image by Author", "caption": ""}, "10": {"item_id": "3224867213", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*DeDoQtoiUBqiXrlcOU7kzw.png", "width": "700", "height": "255", "credit": "Image by Author", "caption": ""}, "11": {"item_id": "3224867213", "image_id": "11", "src": "https://miro.medium.com/max/1082/1*e_Lo_JBc6YbKRZw6Z3m-kw.png", "width": "541", "height": "246", "credit": "Image by Author", "caption": ""}, "12": {"item_id": "3224867213", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*fr7h0lRmfK8oKz1z96_KDw.png", "width": "700", "height": "349", "credit": "Image by Author", "caption": ""}, "13": {"item_id": "3224867213", "image_id": "13", "src": "https://miro.medium.com/max/1324/1*tzEfqfMVxjNKUYdkV6fYVg.png", "width": "662", "height": "408", "credit": "Image by Author", "caption": ""}, "14": {"item_id": "3224867213", "image_id": "14", "src": "https://miro.medium.com/max/1400/1*hGNwjytdKtWFY69SFSMwwg.png", "width": "700", "height": "385", "credit": "Image by Author", "caption": ""}, "15": {"item_id": "3224867213", "image_id": "15", "src": "https://miro.medium.com/max/1400/1*5FLTkAHoTcj4ZJ-KBXVnSA.png", "width": "700", "height": "312", "credit": "Image by Author", "caption": ""}, "16": {"item_id": "3224867213", "image_id": "16", "src": "https://miro.medium.com/max/1368/1*Jb2mIgmxIyFeASIWJvyXmQ.png", "width": "684", "height": "448", "credit": "Image by Author", "caption": ""}, "17": {"item_id": "3224867213", "image_id": "17", "src": "https://miro.medium.com/max/1220/1*kFydYqArwGgvnHn3CGckhQ.png", "width": "610", "height": "320", "credit": "Image by Author", "caption": ""}, "18": {"item_id": "3224867213", "image_id": "18", "src": "https://miro.medium.com/max/2000/1*CW3LpQFtwLJUakp6m1YTgw.png", "width": "1000", "height": "335", "credit": "Image by Author", "caption": ""}, "19": {"item_id": "3224867213", "image_id": "19", "src": "https://miro.medium.com/max/2000/1*Rj0A1QGDECrnexDeduXtaQ.png", "width": "1000", "height": "284", "credit": "Image by Author", "caption": ""}, "20": {"item_id": "3224867213", "image_id": "20", "src": "https://miro.medium.com/max/1400/1*BeAmOjXP4PeJ0vTJmaGmmA.png", "width": "700", "height": "373", "credit": "Image by Author", "caption": ""}, "21": {"item_id": "3224867213", "image_id": "21", "src": "https://miro.medium.com/max/1400/1*oXhrjtq2GWxhD9x4OKSLgg.png", "width": "700", "height": "354", "credit": "Image by Author", "caption": ""}, "22": {"item_id": "3224867213", "image_id": "22", "src": "https://miro.medium.com/max/2000/1*1zG8cmkKZ4EBjyPhXcAn0g.png", "width": "1000", "height": "507", "credit": "Image by Author", "caption": ""}, "23": {"item_id": "3224867213", "image_id": "23", "src": "https://miro.medium.com/max/956/1*pb9a5NDAdyhbJBDyoBiG-Q.png", "width": "478", "height": "288", "credit": "Image by Author", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 798}, "3124716047": {"item_id": "3124716047", "resolved_id": "3124716069", "given_url": "https://towardsdatascience.com/reinforcement-learning-frameworks-e349de4f645a?source=rss----7f60cf5620c9---4", "given_title": "Reinforcement Learning frameworks", "favorite": "0", "status": "1", "time_added": "1601247459", "time_updated": "1638708525", "time_read": "1604361985", "time_favorited": "0", "sort_id": 405, "resolved_title": "Reinforcement Learning frameworks", "resolved_url": "https://towardsdatascience.com/reinforcement-learning-frameworks-e349de4f645a", "excerpt": "Welcome to this 20th post that concludes the series that presents a practical approach to getting started in the exciting world of Deep Reinforcement Learning.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3170", "lang": "en", "time_to_read": 14, "top_image_url": "https://miro.medium.com/max/1200/1*LDhcpkgdzkisARJU93i5xw.png", "tags": {"deep-learning": {"item_id": "3124716047", "tag": "deep-learning"}}, "authors": {"64797080": {"item_id": "3124716047", "author_id": "64797080", "name": "Ion Stoica", "url": "https://people.eecs.berkeley.edu/~istoica/"}}, "image": {"item_id": "3124716047", "src": "https://miro.medium.com/fit/c/56/56/1*chzC6PH4tky5FdrG3B_spA.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3124716047", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*chzC6PH4tky5FdrG3B_spA.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3124716047", "image_id": "2", "src": "https://miro.medium.com/max/2800/1*LDhcpkgdzkisARJU93i5xw.png", "width": "1400", "height": "419", "credit": "", "caption": ""}, "3": {"item_id": "3124716047", "image_id": "3", "src": "https://miro.medium.com/max/1242/1*u5R7-jCyQQL4pV55T4gpiA.png", "width": "621", "height": "198", "credit": "source: docs.ray.io", "caption": "Software stack of RLlib"}, "4": {"item_id": "3124716047", "image_id": "4", "src": "https://miro.medium.com/max/1680/1*stBWj1KUV23u60nRkVyndA.png", "width": "840", "height": "354", "credit": "", "caption": "Before training"}, "5": {"item_id": "3124716047", "image_id": "5", "src": "https://miro.medium.com/max/1768/1*-UM3E9i0A61mINcMnHHlJA.png", "width": "884", "height": "352", "credit": "", "caption": "After training"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1227}, "3292486832": {"item_id": "3292486832", "resolved_id": "3292486832", "given_url": "https://venturebeat.com/2021/03/28/reinforcement-learning-the-next-great-ai-tech-moving-from-the-lab-to-the-real-world/", "given_title": "Reinforcement learning: The next great AI tech moving from the lab to the r", "favorite": "0", "status": "1", "time_added": "1616954171", "time_updated": "1638708525", "time_read": "1617138532", "time_favorited": "0", "sort_id": 406, "resolved_title": "Reinforcement learning: The next great AI tech moving from the lab to the real world", "resolved_url": "https://venturebeat.com/2021/03/28/reinforcement-learning-the-next-great-ai-tech-moving-from-the-lab-to-the-real-world/", "excerpt": "Elevate your enterprise data technology and strategy at Transform 2021.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1440", "lang": "en", "time_to_read": 7, "amp_url": "https://venturebeat.com/2021/03/28/reinforcement-learning-the-next-great-ai-tech-moving-from-the-lab-to-the-real-world/amp/", "top_image_url": "https://venturebeat.com/wp-content/uploads/2021/03/ai-4.jpg?w=1200&strip=all", "tags": {"deep-learning": {"item_id": "3292486832", "tag": "deep-learning"}, "reinforcement-learning": {"item_id": "3292486832", "tag": "reinforcement-learning"}}, "image": {"item_id": "3292486832", "src": "https://venturebeat.com/wp-content/uploads/2021/03/ai-4.jpg?resize=1200%2C600&strip=all", "width": "1200", "height": "600"}, "images": {"1": {"item_id": "3292486832", "image_id": "1", "src": "https://venturebeat.com/wp-content/uploads/2021/03/ai-4.jpg?resize=1200%2C600&strip=all", "width": "1200", "height": "600", "credit": "", "caption": "Image Credit: gremlin/Getty Images"}}, "domain_metadata": {"name": "VentureBeat", "logo": "https://logo.clearbit.com/venturebeat.com?size=800", "greyscale_logo": "https://logo.clearbit.com/venturebeat.com?size=800&greyscale=true"}, "listen_duration_estimate": 557}, "2797977736": {"item_id": "2797977736", "resolved_id": "2797977736", "given_url": "https://heartbeat.fritz.ai/research-guide-model-distillation-techniques-for-deep-learning-4a100801c0eb", "given_title": "Research Guide: Model Distillation Techniques for Deep Learning", "favorite": "0", "status": "1", "time_added": "1574291145", "time_updated": "1638708525", "time_read": "1576355684", "time_favorited": "0", "sort_id": 407, "resolved_title": "Research Guide: Model Distillation Techniques for Deep Learning", "resolved_url": "https://heartbeat.fritz.ai/research-guide-model-distillation-techniques-for-deep-learning-4a100801c0eb", "excerpt": "Knowledge distillation is a model compression technique whereby a small network (student) is taught by a larger trained neural network (teacher). The smaller network is trained to behave like the large neural network.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1661", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1200/1*Xoll0HT4YUfF_DhJZqiiuA.jpeg", "tags": {"compression-encoding": {"item_id": "2797977736", "tag": "compression-encoding"}, "deep-learning": {"item_id": "2797977736", "tag": "deep-learning"}}, "authors": {"143986085": {"item_id": "2797977736", "author_id": "143986085", "name": "Derrick Mwiti", "url": "https://mwitiderrick.medium.com"}}, "image": {"item_id": "2797977736", "src": "https://miro.medium.com/max/5000/1*Xoll0HT4YUfF_DhJZqiiuA.jpeg", "width": "2500", "height": "1667"}, "images": {"1": {"item_id": "2797977736", "image_id": "1", "src": "https://miro.medium.com/max/5000/1*Xoll0HT4YUfF_DhJZqiiuA.jpeg", "width": "2500", "height": "1667", "credit": "", "caption": "Image Source"}, "2": {"item_id": "2797977736", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*V8HART7mTUfVm95QCVnL2A.png", "width": "700", "height": "179", "credit": "", "caption": "source"}, "3": {"item_id": "2797977736", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*K3smDf1qq9MxHVDScxCRyg.png", "width": "700", "height": "331", "credit": "", "caption": "source"}, "4": {"item_id": "2797977736", "image_id": "4", "src": "https://miro.medium.com/max/992/1*2MF0F1EynML3tPCi022IeQ.png", "width": "496", "height": "622", "credit": "", "caption": "source"}, "5": {"item_id": "2797977736", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*LOyJ7xI2ubEpqAlnBYXvsA.png", "width": "700", "height": "418", "credit": "", "caption": "source"}, "6": {"item_id": "2797977736", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*bCfTnjcbO-YUxq_CQyOh6g.png", "width": "700", "height": "212", "credit": "", "caption": "source"}, "7": {"item_id": "2797977736", "image_id": "7", "src": "https://miro.medium.com/max/1242/1*LAGuIW5T-5BgG2mRkk9sYg.png", "width": "621", "height": "301", "credit": "", "caption": "source"}, "8": {"item_id": "2797977736", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*6KgACRX6W76WMGs0AmGX2A.png", "width": "700", "height": "176", "credit": "", "caption": "source"}, "9": {"item_id": "2797977736", "image_id": "9", "src": "https://miro.medium.com/max/908/1*DvStcoanxP8S8Gj8HNvOfQ.png", "width": "454", "height": "517", "credit": "", "caption": "source"}, "10": {"item_id": "2797977736", "image_id": "10", "src": "https://miro.medium.com/max/1118/1*II6njeoWehDHo1vafLIf9Q.png", "width": "559", "height": "387", "credit": "", "caption": "source"}, "11": {"item_id": "2797977736", "image_id": "11", "src": "https://miro.medium.com/max/1400/1*crh8XurNHrYwmOXiMNhoFQ.png", "width": "700", "height": "287", "credit": "", "caption": "source"}, "12": {"item_id": "2797977736", "image_id": "12", "src": "https://miro.medium.com/max/1142/1*W1Vet3fBdi0NDNSHkqbaaw.png", "width": "571", "height": "640", "credit": "", "caption": "source"}, "13": {"item_id": "2797977736", "image_id": "13", "src": "https://miro.medium.com/max/1106/1*xHd4cXTJZIh5_jxOiVUGSA.png", "width": "553", "height": "351", "credit": "", "caption": "source"}, "14": {"item_id": "2797977736", "image_id": "14", "src": "https://miro.medium.com/max/1192/1*c8RAMjjxFLgZFPkqdMbsRg.png", "width": "596", "height": "488", "credit": "", "caption": "source"}, "15": {"item_id": "2797977736", "image_id": "15", "src": "https://miro.medium.com/max/1400/1*zQ9kUQJW2OM3Qi8KevIlog.png", "width": "700", "height": "258", "credit": "", "caption": ""}, "16": {"item_id": "2797977736", "image_id": "16", "src": "https://miro.medium.com/max/784/1*qDoXqbfyJDW9XbRlcF_8bA.png", "width": "392", "height": "595", "credit": "", "caption": "source"}, "17": {"item_id": "2797977736", "image_id": "17", "src": "https://miro.medium.com/max/1400/1*kJCi_RVoNn7UNaLS55b4Bw.png", "width": "700", "height": "283", "credit": "", "caption": "source"}, "18": {"item_id": "2797977736", "image_id": "18", "src": "https://miro.medium.com/max/1400/1*DZ9xLvGBcxQ_HVQtyc7fGg.png", "width": "700", "height": "398", "credit": "", "caption": "source"}}, "listen_duration_estimate": 643}, "2918769630": {"item_id": "2918769630", "resolved_id": "2918769630", "given_url": "https://venturebeat.com/2020/03/17/researchers-detail-trojai-a-framework-for-hardening-ai-models-against-adversarial-attacks/", "given_title": "Researchers detail TrojAI, a framework for hardening AI models against adve", "favorite": "0", "status": "1", "time_added": "1584459861", "time_updated": "1691366676", "time_read": "1584552705", "time_favorited": "0", "sort_id": 408, "resolved_title": "Researchers detail TrojAI, a framework for hardening AI models against adversarial attacks", "resolved_url": "https://venturebeat.com/2020/03/17/researchers-detail-trojai-a-framework-for-hardening-ai-models-against-adversarial-attacks/", "excerpt": "The Transform Technology Summits start October 13th with Low-Code/No Code: Enabling Enterprise Agility. Register now!", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "618", "lang": "en", "time_to_read": 3, "amp_url": "https://venturebeat.com/2020/03/17/researchers-detail-trojai-a-framework-for-hardening-ai-models-against-adversarial-attacks/amp/", "top_image_url": "https://venturebeat.com/wp-content/uploads/2018/01/cyber-attack-shutterstock_690087028.jpg?w=1200&strip=all", "tags": {"adversarial": {"item_id": "2918769630", "tag": "adversarial"}, "deep-learning": {"item_id": "2918769630", "tag": "deep-learning"}}, "authors": {"89415017": {"item_id": "2918769630", "author_id": "89415017", "name": "Kyle Wiggers", "url": "https://venturebeat.com/author/kylewiggers/"}}, "image": {"item_id": "2918769630", "src": "https://venturebeat.com/wp-content/uploads/2018/01/cyber-attack-shutterstock_690087028.jpg?fit=750%2C500&strip=all", "width": "750", "height": "500"}, "images": {"1": {"item_id": "2918769630", "image_id": "1", "src": "https://venturebeat.com/wp-content/uploads/2018/01/cyber-attack-shutterstock_690087028.jpg?fit=750%2C500&strip=all", "width": "750", "height": "500", "credit": "", "caption": "Image Credit: Shutterstock"}}, "domain_metadata": {"name": "VentureBeat", "logo": "https://logo.clearbit.com/venturebeat.com?size=800", "greyscale_logo": "https://logo.clearbit.com/venturebeat.com?size=800&greyscale=true"}, "listen_duration_estimate": 239}, "2448445664": {"item_id": "2448445664", "resolved_id": "2448445664", "given_url": "https://learnk8s.io/blog/scaling-machine-learning-with-kubeflow-tensorflow", "given_title": "Scaling Jupyter notebooks with Kubernetes and Tensorflow", "favorite": "0", "status": "1", "time_added": "1547178486", "time_updated": "1660827285", "time_read": "1567119261", "time_favorited": "0", "sort_id": 409, "resolved_title": "Scaling Jupyter notebooks with Kubernetes and Tensorflow", "resolved_url": "https://learnk8s.io/blog/scaling-machine-learning-with-kubeflow-tensorflow", "excerpt": "Gathering facts and data to understand better the world we live in has become the new norm. From self-driving cars to smart personal assistants, data and data science is everywhere.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1862", "lang": "en", "time_to_read": 8, "top_image_url": "https://learnk8s.io/a/25578661c4220a43040ebfb385ea44e9.png", "tags": {"deep-learning": {"item_id": "2448445664", "tag": "deep-learning"}, "devops": {"item_id": "2448445664", "tag": "devops"}, "kubernetes": {"item_id": "2448445664", "tag": "kubernetes"}, "tensorflow": {"item_id": "2448445664", "tag": "tensorflow"}}, "authors": {"78178920": {"item_id": "2448445664", "author_id": "78178920", "name": "learnk8s", "url": ""}}, "image": {"item_id": "2448445664", "src": "https://learnk8s.io/a/d52338abe54f841e8419a403ad6c4690.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2448445664", "image_id": "1", "src": "https://learnk8s.io/a/d52338abe54f841e8419a403ad6c4690.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2448445664", "image_id": "2", "src": "https://learnk8s.io/a/daff15054db49d2906807a151d5fc733.gif", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 721}, "3116588515": {"item_id": "3116588515", "resolved_id": "3116588547", "given_url": "https://towardsdatascience.com/self-organizing-maps-for-dimension-reduction-data-visualization-and-clustering-ff966edd311c?source=rss----7f60cf5620c9---4", "given_title": "Self-Organizing Maps for Dimension Reduction, Data Visualization, and Clust", "favorite": "0", "status": "1", "time_added": "1600536534", "time_updated": "1638708525", "time_read": "1600548918", "time_favorited": "0", "sort_id": 410, "resolved_title": "A Brief Introduction to Self-Organizing Maps", "resolved_url": "https://towardsdatascience.com/self-organizing-maps-for-dimension-reduction-data-visualization-and-clustering-ff966edd311c", "excerpt": "Self-Organizing Map (SOM) is one of the common unsupervised neural network models. SOM has been widely used for clustering, dimension reduction, and feature detection. SOM was first introduced by Professor Kohonen. For this reason, SOM also called Kohonen Map.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1029", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/624/1*ktXCJAPfQocwEel7313eOw.png", "tags": {"deep-learning": {"item_id": "3116588515", "tag": "deep-learning"}}, "authors": {"155058233": {"item_id": "3116588515", "author_id": "155058233", "name": "Thought Partner for Data", "url": "https://masum-math8065.medium.com"}}, "image": {"item_id": "3116588515", "src": "https://miro.medium.com/fit/c/56/56/0*NrIVeI7xeeyB9B4_.jpg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3116588515", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/0*NrIVeI7xeeyB9B4_.jpg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3116588515", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*v1Hobqkj6AZLUXlf", "width": "700", "height": "466", "credit": "Andrew Stutesman on Unsplash", "caption": ""}, "3": {"item_id": "3116588515", "image_id": "3", "src": "https://miro.medium.com/max/1248/1*ktXCJAPfQocwEel7313eOw.png", "width": "624", "height": "350", "credit": "", "caption": "process of computing winner neuron"}, "4": {"item_id": "3116588515", "image_id": "4", "src": "https://miro.medium.com/max/760/1*WbehSv621GAoOWMm5nGWDg.png", "width": "380", "height": "107", "credit": "", "caption": "exponential decay function for finding the neighbor size"}, "5": {"item_id": "3116588515", "image_id": "5", "src": "https://miro.medium.com/max/1248/1*2oi-5CAyMZp2bz6VmikftA.png", "width": "624", "height": "264", "credit": "", "caption": "shrinking of the radius of the neighborhood of the BMU"}, "6": {"item_id": "3116588515", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*LKFIFtCfAjv_8vkpVZJBHg.png", "width": "700", "height": "97", "credit": "", "caption": "the equation for updating neurons weights"}, "7": {"item_id": "3116588515", "image_id": "7", "src": "https://miro.medium.com/max/804/1*SgOUaqkF58lwN7a5EO8DxQ.png", "width": "402", "height": "141", "credit": "", "caption": "the equation of learning rate"}, "8": {"item_id": "3116588515", "image_id": "8", "src": "https://miro.medium.com/max/1162/1*8O1C8Rak5U5VuXiNyc7TyA.png", "width": "581", "height": "187", "credit": "", "caption": "the equation for influence rate"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 398}, "3189740136": {"item_id": "3189740136", "resolved_id": "3189740171", "given_url": "https://towardsdatascience.com/semantic-hand-segmentation-using-pytorch-3e7a0a0386fa?source=rss----7f60cf5620c9---4", "given_title": "Semantic hand segmentation using Pytorch", "favorite": "0", "status": "1", "time_added": "1606909319", "time_updated": "1638708525", "time_read": "1608254890", "time_favorited": "0", "sort_id": 411, "resolved_title": "Semantic hand segmentation using Pytorch", "resolved_url": "https://towardsdatascience.com/semantic-hand-segmentation-using-pytorch-3e7a0a0386fa", "excerpt": "Semantic segmentation is the task of predicting the class of each pixel in an image. This problem is more difficult than object detection, where you have to predict a box around the object.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1179", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/freeze/max/600/1*J_ZxnuUMcCQt_fxoG4ffOQ.gif", "tags": {"deep-learning": {"item_id": "3189740136", "tag": "deep-learning"}, "pytorch": {"item_id": "3189740136", "tag": "pytorch"}, "vision": {"item_id": "3189740136", "tag": "vision"}}, "authors": {"143511438": {"item_id": "3189740136", "author_id": "143511438", "name": "Saurabh Kumar", "url": "https://saurabhk660.medium.com"}}, "image": {"item_id": "3189740136", "src": "https://miro.medium.com/fit/c/56/56/1*Kv-dyWlyTEb_KEHs8a8zlA.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3189740136", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*Kv-dyWlyTEb_KEHs8a8zlA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3189740136", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*aNkDoJu9EkH_15f1v3Pdcg.png", "width": "700", "height": "303", "credit": "", "caption": "A sample of semantic hand segmentation. (images from HOF dataset[1])"}, "3": {"item_id": "3189740136", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*CPtuThn8l44a6jj0wcXeog.png", "width": "700", "height": "219", "credit": "", "caption": "Outputs : 1. Hands prediction mask 2. No-hands prediction mask 3. Mask generated after comparing"}, "4": {"item_id": "3189740136", "image_id": "4", "src": "https://miro.medium.com/max/1200/1*J_ZxnuUMcCQt_fxoG4ffOQ.gif", "width": "600", "height": "532", "credit": "", "caption": "Sample hand segmentation"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 456}, "1444374332": {"item_id": "1444374332", "resolved_id": "1444374332", "given_url": "http://semiengineering.com/making-waves-in-deep-learning/", "given_title": "Semiconductor Engineering .:. Making Waves In Deep Learning", "favorite": "0", "status": "1", "time_added": "1476308541", "time_updated": "1638708872", "time_read": "1476313324", "time_favorited": "0", "sort_id": 412, "resolved_title": "Making Waves In Deep Learning", "resolved_url": "https://semiengineering.com/making-waves-in-deep-learning/", "excerpt": "A little more than two and a half years ago I wrote Making Waves in Low-Power Design, an article about a company (at the time) called Wave Semiconductor.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "710", "lang": "", "top_image_url": "http://semiengineering.com/wp-content/uploads/2016/10/Wave_Chip.png", "tags": {"deep-learning": {"item_id": "1444374332", "tag": "deep-learning"}, "gpus": {"item_id": "1444374332", "tag": "gpus"}, "semiconductors": {"item_id": "1444374332", "tag": "semiconductors"}}, "authors": {"79059418": {"item_id": "1444374332", "author_id": "79059418", "name": "Barry Pangrle", "url": "https://semiengineering.com/author/barry-pangrle/"}}, "image": {"item_id": "1444374332", "src": "https://i0.wp.com/semiengineering.com/wp-content/uploads/2016/10/Wave_Chip.png", "width": "824", "height": "828"}, "images": {"1": {"item_id": "1444374332", "image_id": "1", "src": "https://i0.wp.com/semiengineering.com/wp-content/uploads/2016/10/Wave_Chip.png", "width": "824", "height": "828", "credit": "", "caption": ""}, "2": {"item_id": "1444374332", "image_id": "2", "src": "https://i2.wp.com/semiengineering.com/wp-content/uploads/2016/10/Wave_PE_Cluster.png", "width": "1034", "height": "422", "credit": "", "caption": ""}, "3": {"item_id": "1444374332", "image_id": "3", "src": "https://i1.wp.com/semiengineering.com/wp-content/uploads/2016/10/Wave_Flow.png", "width": "1241", "height": "695", "credit": "", "caption": ""}}, "listen_duration_estimate": 275}, "3344104739": {"item_id": "3344104739", "resolved_id": "3344104739", "given_url": "https://towardsdatascience.com/sentiment-analysis-comparing-3-common-approaches-naive-bayes-lstm-and-vader-ab561f834f89", "given_title": "Sentiment Analysis‚Ää‚Äî‚ÄäComparing 3 Common Approaches: Naive Bayes, LSTM, and ", "favorite": "0", "status": "1", "time_added": "1622320672", "time_updated": "1638708525", "time_read": "1622498987", "time_favorited": "0", "sort_id": 413, "resolved_title": "Sentiment Analysis", "resolved_url": "https://towardsdatascience.com/sentiment-analysis-comparing-3-common-approaches-naive-bayes-lstm-and-vader-ab561f834f89", "excerpt": "Sentiment Analysis, or Opinion Mining, is a subfield of NLP (Natural Language Processing) that aims to extract attitudes, appraisals, opinions, and emotions from text. Inspired by the rapid migration of customer interactions to digital formats e.g.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2155", "lang": "en", "time_to_read": 10, "top_image_url": "https://miro.medium.com/max/974/1*8RZ-43p0vFmdOBu1SHjyDg.png", "tags": {"deep-learning": {"item_id": "3344104739", "tag": "deep-learning"}, "machine-learning": {"item_id": "3344104739", "tag": "machine-learning"}, "nlp": {"item_id": "3344104739", "tag": "nlp"}, "sentiment-analysis": {"item_id": "3344104739", "tag": "sentiment-analysis"}}, "authors": {"141706727": {"item_id": "3344104739", "author_id": "141706727", "name": "Kevin C Lee", "url": "https://kevin-c-lee26.medium.com"}}, "image": {"item_id": "3344104739", "src": "https://miro.medium.com/fit/c/56/56/2*vB0XEUj0jbXkeAPZV5dovA.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3344104739", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*vB0XEUj0jbXkeAPZV5dovA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3344104739", "image_id": "2", "src": "https://miro.medium.com/max/1948/1*8RZ-43p0vFmdOBu1SHjyDg.png", "width": "974", "height": "489", "credit": "image by Author", "caption": "Sentiment Analysis"}, "3": {"item_id": "3344104739", "image_id": "3", "src": "https://miro.medium.com/max/3236/1*BDMmQjXmClWpyziFcgGjBQ.png", "width": "1618", "height": "562", "credit": "", "caption": "Strengths and Weaknesses Analysis"}, "4": {"item_id": "3344104739", "image_id": "4", "src": "https://miro.medium.com/max/3168/1*IkEIL4puSqD9odOnWbQsxw.png", "width": "1584", "height": "334", "credit": "", "caption": "Original Data"}, "5": {"item_id": "3344104739", "image_id": "5", "src": "https://miro.medium.com/max/1508/1*rnCFjyv4ZymoLHgpWVPC_w.png", "width": "754", "height": "378", "credit": "", "caption": "VADER Calculations"}, "6": {"item_id": "3344104739", "image_id": "6", "src": "https://miro.medium.com/max/3512/1*sGs41qiaBU8HB_y1bO5bNQ.png", "width": "1756", "height": "764", "credit": "", "caption": "Machine Learning NLP Text Classification Process"}, "7": {"item_id": "3344104739", "image_id": "7", "src": "https://miro.medium.com/max/3004/1*SgQRncVp-2WgSftO5_2AUw.png", "width": "1502", "height": "506", "credit": "Weighted Frequency Count", "caption": "Naive Bayes Data Preprocessing Pipeline"}, "8": {"item_id": "3344104739", "image_id": "8", "src": "https://miro.medium.com/max/2996/1*LH-edargGLbjeOrzHJQkpA.png", "width": "1498", "height": "560", "credit": "", "caption": "Word Embedding + LSTM Data Preprocessing Pipeline"}, "9": {"item_id": "3344104739", "image_id": "9", "src": "https://miro.medium.com/max/2376/1*u5VwJdg9dDTpo6NHVAHfxA.png", "width": "1188", "height": "546", "credit": "", "caption": "Word Embedding LSTM Architecture"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 834}, "153656807": {"item_id": "153656807", "resolved_id": "153656807", "given_url": "http://www.slaney.org/malcolm/yahoo/Slaney2008-LSHTutorial.pdf", "given_title": "Slaney2008-LSHTutorial.pdf", "favorite": "0", "status": "1", "time_added": "1500839426", "time_updated": "1638708525", "time_read": "1528501623", "time_favorited": "0", "sort_id": 414, "resolved_title": "", "resolved_url": "http://www.slaney.org/malcolm/yahoo/Slaney2008-LSHTutorial.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"deep-learning": {"item_id": "153656807", "tag": "deep-learning"}}, "listen_duration_estimate": 0}, "2945247373": {"item_id": "2945247373", "resolved_id": "2945247373", "given_url": "https://arstechnica.com/features/2020/04/some-shirts-hide-you-from-cameras-but-will-anyone-wear-them/", "given_title": "Some shirts hide you from cameras‚Äîbut will anyone wear them?", "favorite": "0", "status": "1", "time_added": "1586711575", "time_updated": "1638708525", "time_read": "1587120358", "time_favorited": "0", "sort_id": 415, "resolved_title": "Some shirts hide you from cameras‚Äîbut will anyone wear them?", "resolved_url": "https://arstechnica.com/features/2020/04/some-shirts-hide-you-from-cameras-but-will-anyone-wear-them/", "excerpt": "Right now, you're more than likely spending the vast majority of your time at home. Someday, however, we will all be able to leave the house once again and emerge, blinking, into society to work, travel, eat, play, and congregate in all of humanity's many bustling crowds.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3511", "lang": "en", "time_to_read": 16, "amp_url": "https://arstechnica.com/features/2020/04/some-shirts-hide-you-from-cameras-but-will-anyone-wear-them/amp/", "top_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2020/03/adversarial-fashion-shoot-640x360.jpg", "tags": {"deep-learning": {"item_id": "2945247373", "tag": "deep-learning"}, "public-policy": {"item_id": "2945247373", "tag": "public-policy"}, "vision": {"item_id": "2945247373", "tag": "vision"}}, "authors": {"114573933": {"item_id": "2945247373", "author_id": "114573933", "name": "Kate Cox", "url": "https://arstechnica.com/author/katecox/"}}, "image": {"item_id": "2945247373", "src": "https://cdn.arstechnica.net/wp-content/uploads/2020/03/adversarial-fashion-shoot-800x450.jpg", "width": "640", "height": "360"}, "images": {"1": {"item_id": "2945247373", "image_id": "1", "src": "https://cdn.arstechnica.net/wp-content/uploads/2020/03/adversarial-fashion-shoot-800x450.jpg", "width": "640", "height": "360", "credit": "Aurich Lawson / Getty", "caption": "Aurich Lawson / Getty"}, "2": {"item_id": "2945247373", "image_id": "2", "src": "https://cdn.arstechnica.net/wp-content/uploads/2020/03/goldstein_shirt.png", "width": "640", "height": "285", "credit": "Tom Goldstein | University of Maryland", "caption": "Enlarge / The bright adversarial pattern, which a human viewer can darn-near see from space, renders the wearer invisible to the software looking at him."}, "3": {"item_id": "2945247373", "image_id": "3", "src": "https://cdn.arstechnica.net/wp-content/uploads/2020/03/bertash_fashion.png", "width": "640", "height": "394", "credit": "", "caption": "Enlarge / A slide from Bertash's 2019 Defcon presentation showing how the ALPR-foiling fabric works."}}, "domain_metadata": {"name": "Ars Technica", "logo": "https://logo.clearbit.com/arstechnica.com?size=800", "greyscale_logo": "https://logo.clearbit.com/arstechnica.com?size=800&greyscale=true"}, "listen_duration_estimate": 1359}, "3610344525": {"item_id": "3610344525", "resolved_id": "3610344525", "given_url": "https://towardsdatascience.com/sparse-autoencoder-neural-networks-how-to-utilise-sparsity-for-robust-information-encoding-6aa9ff542bc9", "given_title": "Sparse Autoencoder Neural Networks‚Ää‚Äî‚ÄäHow to Utilise Sparsity for Robust Inf", "favorite": "0", "status": "1", "time_added": "1651619509", "time_updated": "1673901753", "time_read": "1651678041", "time_favorited": "0", "sort_id": 416, "resolved_title": "Sparse Autoencoder Neural Networks‚Ää‚Äî‚ÄäHow to Utilise Sparsity for Robust Information Encoding", "resolved_url": "https://towardsdatascience.com/sparse-autoencoder-neural-networks-how-to-utilise-sparsity-for-robust-information-encoding-6aa9ff542bc9", "excerpt": "Autoencoders enable us to distil information by utilising a neural network architecture composed of an encoder and decoder. There are multiple types of autoencoders that vary based on their structure or the problems they are designed to solve. The four most commons ones are:", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1158", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/940/1*1-gz-jCEEnE4XALIUUKVEQ.png", "tags": {"autoencoders": {"item_id": "3610344525", "tag": "autoencoders"}, "deep-learning": {"item_id": "3610344525", "tag": "deep-learning"}, "python": {"item_id": "3610344525", "tag": "python"}}, "authors": {"148379686": {"item_id": "3610344525", "author_id": "148379686", "name": "Saul Dobilas", "url": "https://solclover.com"}}, "image": {"item_id": "3610344525", "src": "https://miro.medium.com/max/1400/1*1-gz-jCEEnE4XALIUUKVEQ.png", "width": "700", "height": "587"}, "images": {"1": {"item_id": "3610344525", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*1-gz-jCEEnE4XALIUUKVEQ.png", "width": "700", "height": "587", "credit": "SAE", "caption": "Sparse Autoencoder"}, "2": {"item_id": "3610344525", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*0gDmxAoBF6k3hltZvS76fg.png", "width": "700", "height": "571", "credit": "", "caption": "Undercomplete Autoencoder architecture. Image by author, created using AlexNail‚Äôs NN-SVG tool."}, "3": {"item_id": "3610344525", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*cs1t0PLZF4tsnRcY9GTFKA.png", "width": "700", "height": "618", "credit": "SAE", "caption": "Sparse Autoencoder"}, "4": {"item_id": "3610344525", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*5gEa1BA4Ce864MxMOKHtnA.png", "width": "700", "height": "387", "credit": "", "caption": "The first ten digits of the MNIST dataset. Image by author."}, "5": {"item_id": "3610344525", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*ZoC6_q8_25E22L5xQ4ZIPg.png", "width": "700", "height": "435", "credit": "", "caption": "Undercomplete AE model summary. Image by author."}, "6": {"item_id": "3610344525", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*1qLGWSwmIOqAJJRRUOW1dw.png", "width": "700", "height": "402", "credit": "", "caption": "Undercomplete AE model loss chart. Image by author."}, "7": {"item_id": "3610344525", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*ZaYCahTJ8zLNpftBVesSLw.png", "width": "700", "height": "475", "credit": "", "caption": "Sparse AE model summary. Image by author."}, "8": {"item_id": "3610344525", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*iRl-pL0L6FKFNzL9Pa4kLw.png", "width": "700", "height": "400", "credit": "", "caption": "Sparse AE model loss chart. Image by author."}, "9": {"item_id": "3610344525", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*M64UApv47JmN7mXlsG4lbg.png", "width": "700", "height": "319", "credit": "", "caption": "The selected ten digits for model comparison. Image by author."}, "10": {"item_id": "3610344525", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*EBv3Ykqwa42RxELQ8DBf4w.png", "width": "700", "height": "349", "credit": "", "caption": "Neuron activations in the two AE models. Image by author."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 448}, "2954887640": {"item_id": "2954887640", "resolved_id": "2954887655", "given_url": "https://towardsdatascience.com/stacked-auto-encoder-as-a-recommendation-system-for-movie-rating-prediction-33842386338?source=rss----7f60cf5620c9---4", "given_title": "Stacked Auto-encoder as a Recommendation System for Movie Rating Prediction", "favorite": "0", "status": "1", "time_added": "1587284727", "time_updated": "1638708525", "time_read": "1587748135", "time_favorited": "0", "sort_id": 417, "resolved_title": "Intuitive Introduction to Stacked Auto-encoder and Creation as Movie Rating System", "resolved_url": "https://towardsdatascience.com/stacked-auto-encoder-as-a-recommendation-system-for-movie-rating-prediction-33842386338", "excerpt": "In the previous article, we created a Restricted Boltzmann Machine model for movie review prediction: like or not. Now, I will walk through how to build an auto-encoder model for movie rating prediction from 0 to 5. It is split into 6 parts. üì£üì£ This is a technical-driven article.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1906", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/601/1*DOl_zca_7nRuOdKGw6ZLYg.png", "tags": {"deep-learning": {"item_id": "2954887640", "tag": "deep-learning"}, "machine-learning": {"item_id": "2954887640", "tag": "machine-learning"}, "recommenders": {"item_id": "2954887640", "tag": "recommenders"}}, "authors": {"142287966": {"item_id": "2954887640", "author_id": "142287966", "name": "Luke Sun", "url": "https://lukesun.medium.com"}}, "image": {"item_id": "2954887640", "src": "https://miro.medium.com/fit/c/56/56/2*ihJqqRYBAp1BLQcfZU5RfA.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2954887640", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*ihJqqRYBAp1BLQcfZU5RfA.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2954887640", "image_id": "2", "src": "https://miro.medium.com/max/1202/1*DOl_zca_7nRuOdKGw6ZLYg.png", "width": "601", "height": "407", "credit": "", "caption": "Img adapted from unsplash via link"}, "3": {"item_id": "2954887640", "image_id": "3", "src": "https://miro.medium.com/max/774/1*DNagOJAKtUUxk_WvS0ZIeQ.png", "width": "387", "height": "296", "credit": "Img created by Author", "caption": "Fig.1 Auto-encoder model diagram"}, "4": {"item_id": "2954887640", "image_id": "4", "src": "https://miro.medium.com/max/978/1*38tzKSidK3XDLfpJsLzXOA.png", "width": "489", "height": "278", "credit": "Img created by Author", "caption": "Fig.2 Stacked auto-encoder model diagram"}, "5": {"item_id": "2954887640", "image_id": "5", "src": "https://miro.medium.com/max/804/1*LPHmZk8glcWtLaCv4IC3eQ.png", "width": "402", "height": "349", "credit": "", "caption": "Fig.3 Snippet of the source data"}, "6": {"item_id": "2954887640", "image_id": "6", "src": "https://miro.medium.com/max/1004/1*b40AwXK9K76ih2-Uiaq1tQ.png", "width": "502", "height": "308", "credit": "", "caption": "Fig.4 Snippet of training and test sets"}, "7": {"item_id": "2954887640", "image_id": "7", "src": "https://miro.medium.com/max/1204/1*WjCNG3iY0x4L26W6UEsD6A.png", "width": "602", "height": "269", "credit": "", "caption": "Fig.5 Snippet of final training set"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 738}, "3197583013": {"item_id": "3197583013", "resolved_id": "3197583013", "given_url": "https://duckduckgo.com/?q=storytelling+arxiv+paperswithcode&t=canonical&ia=web", "given_title": "storytelling arxiv paperswithcode at DuckDuckGo", "favorite": "0", "status": "1", "time_added": "1607598221", "time_updated": "1638708525", "time_read": "1607598236", "time_favorited": "0", "sort_id": 418, "resolved_title": "storytelling arxiv paperswithcode at DuckDuckGo", "resolved_url": "https://duckduckgo.com/?q=storytelling+arxiv+paperswithcode&t=canonical&ia=web", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"deep-learning": {"item_id": "3197583013", "tag": "deep-learning"}, "ideas": {"item_id": "3197583013", "tag": "ideas"}, "storytelling": {"item_id": "3197583013", "tag": "storytelling"}}, "domain_metadata": {"name": "DuckDuckGo", "logo": "https://logo.clearbit.com/duckduckgo.com?size=800", "greyscale_logo": "https://logo.clearbit.com/duckduckgo.com?size=800&greyscale=true"}, "listen_duration_estimate": 0}, "2844724045": {"item_id": "2844724045", "resolved_id": "2844724045", "given_url": "https://nanonets.com/blog/table-extraction-deep-learning/", "given_title": "Table Detection and Extraction Using Deep Learning", "favorite": "0", "status": "1", "time_added": "1579687034", "time_updated": "1638708525", "time_read": "1582142665", "time_favorited": "0", "sort_id": 419, "resolved_title": "Table OCR for Detecting & Extracting Tabular Information", "resolved_url": "https://nanonets.com/blog/table-extraction-deep-learning/", "excerpt": "The amount of data being collected is drastically increasing day-by-day with lots of applications, tools, and online platforms booming in the present technological era. To handle and access this humongous data productively, it‚Äôs necessary to develop valuable information extraction tools.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "5849", "lang": "en", "time_to_read": 27, "amp_url": "https://nanonets.com/blog/table-extraction-deep-learning/amp/", "top_image_url": "https://nanonets.com/blog/content/images/2020/01/Comp-5-1.gif", "tags": {"deep-learning": {"item_id": "2844724045", "tag": "deep-learning"}, "text": {"item_id": "2844724045", "tag": "text"}, "vision": {"item_id": "2844724045", "tag": "vision"}}, "authors": {"120397522": {"item_id": "2844724045", "author_id": "120397522", "name": "Vihar Kurama", "url": "https://nanonets.com/blog/author/vihar/"}}, "image": {"item_id": "2844724045", "src": "https://lh4.googleusercontent.com/Ru-0lxAfURZR7yiRDXkcK5poCPAwZ7h-Q2o3SUixphuu1YuVqeA-GfAH0cjsDlTyyurVZA8ak15lmKpI73mK_LGijTLd2ATV1wU7fye7tLYh1V9Nqlu7zZozNNgWbfoZMWdabXGe", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2844724045", "image_id": "1", "src": "https://lh4.googleusercontent.com/Ru-0lxAfURZR7yiRDXkcK5poCPAwZ7h-Q2o3SUixphuu1YuVqeA-GfAH0cjsDlTyyurVZA8ak15lmKpI73mK_LGijTLd2ATV1wU7fye7tLYh1V9Nqlu7zZozNNgWbfoZMWdabXGe", "width": "0", "height": "0", "credit": "", "caption": "Source: Patrick Tomasso, Unsplash"}, "2": {"item_id": "2844724045", "image_id": "2", "src": "https://lh6.googleusercontent.com/vYJJ-9MnJGCYEWv-HpumDwpa9s7HcF4xgHO-poAmW08NDoUkQLDAyPGOzu4IAF5Dsx-fNvj3ustKYg9EiTvUeZNtrBrC6Ljg9FvtxWvWw9CvAwjqaV5RLn71_zGp9mQ0xLsQZKp-", "width": "0", "height": "0", "credit": "", "caption": "The architecture of TableNet"}, "3": {"item_id": "2844724045", "image_id": "3", "src": "https://lh5.googleusercontent.com/gYzN-1HX_8fbVAQ11CzHplKgGA9iGSUZ74RNfRkbfOep-Mno5mt7XkrvOVisOQkRha5q-6e7kjFZDDRTtlN9KqTAi3WI0h0L3owQEXpdSdjNHqsBLUHv4fE3JyN7w6G6_cZHY9K7", "width": "0", "height": "0", "credit": "", "caption": "Outputs of Table Detection"}, "4": {"item_id": "2844724045", "image_id": "4", "src": "https://lh6.googleusercontent.com/egaTXs01MugcwwdNygLQLYHLpxjzcEqHkzwLJi1weWeG2Tq0jOQbxLJJCXoVRGEeIhk_o89QD0T_7H98bbX7xUH7DPMeos6hJYHMc_OgYSi6ojL4xIBeuR-RnlF1H20-exeaMJ7n", "width": "0", "height": "0", "credit": "6", "caption": "Outputs of Structure Recognition"}, "5": {"item_id": "2844724045", "image_id": "5", "src": "https://nanonets.com/blog/content/images/2019/12/image-2.png", "width": "0", "height": "0", "credit": "", "caption": "Outputs generated by Graph Neural Networks"}, "6": {"item_id": "2844724045", "image_id": "6", "src": "https://lh4.googleusercontent.com/fCBQ5-Vmz9x1cyHdP0drfAM7qwkYNkEdaZuKq5CW-tLKWFFFtjtgHEZnvVk8tCUTi_uEOAc_RNij52fp43kjpHB4LtY_T7nBoCYlb8K3dEMP32ao36WLAULmQQk8ASEjjaNkqIxv", "width": "0", "height": "0", "credit": "", "caption": "General schematic of the approach"}, "7": {"item_id": "2844724045", "image_id": "7", "src": "https://lh4.googleusercontent.com/qh5rnqcWMD8O-eUm4k9h7tiwTx0CkA_WxzwfYMXMtk26MC8ReeMPPRKu7HSXCVuVTuQj-oK8zbVtP1skeYrIjaXQTD8_9Y8o5KVYxwD5wLnPLwRBH9GRA8uX3Q7T9xgK-GgJT1JC", "width": "0", "height": "0", "credit": "", "caption": "Image of the table"}, "8": {"item_id": "2844724045", "image_id": "8", "src": "https://lh6.googleusercontent.com/JJkw69pKVcRvOFeJ6TBhFJO-2P9kMjruz_vcQgWS1NSI8dOwljN8LGc8xbEQeolLX4YZLNVuw_Ontov1yBEKk3h7vZdLbyCX01SsUQ3bNnCyD_brHCOp9XYhl4W_zKUlzXiIlita", "width": "0", "height": "0", "credit": "", "caption": "Outputs"}, "9": {"item_id": "2844724045", "image_id": "9", "src": "https://nanonets.com/blog/content/images/2019/12/Screenshot-2019-12-28-at-4.53.00-PM.png", "width": "0", "height": "0", "credit": "", "caption": "Screenshot of the Items extracted from tables using Regular Expressions"}, "10": {"item_id": "2844724045", "image_id": "10", "src": "https://nanonets.com/blog/content/images/2019/10/Screen-Shot-2019-10-02-at-15.24.13-copy.png", "width": "400", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 2264}, "3483877160": {"item_id": "3483877160", "resolved_id": "3483877160", "given_url": "https://www.gwern.net/docs/ai/2021-jouppi.pdf", "given_title": "Ten Lessons From Three Generations Shaped Google‚Äôs TPUv4i - 2021-jouppi.pdf", "favorite": "0", "status": "1", "time_added": "1641315042", "time_updated": "1641380223", "time_read": "1641380222", "time_favorited": "0", "sort_id": 420, "resolved_title": "", "resolved_url": "https://www.gwern.net/docs/ai/2021-jouppi.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"deep-learning": {"item_id": "3483877160", "tag": "deep-learning"}, "semiconductors": {"item_id": "3483877160", "tag": "semiconductors"}, "tpu": {"item_id": "3483877160", "tag": "tpu"}}, "listen_duration_estimate": 0}, "3366214600": {"item_id": "3366214600", "resolved_id": "3366214600", "given_url": "https://semianalysis.com/tenstorrent-wormhole-analysis-a-scale-out-architecture-for-machine-learning-that-could-put-nvidia-on-their-back-foot/", "given_title": "Tenstorrent Wormhole Analysis ‚Äì A Scale Out Architecture for Machine Learni", "favorite": "0", "status": "1", "time_added": "1624669418", "time_updated": "1638708525", "time_read": "1624715136", "time_favorited": "0", "sort_id": 421, "resolved_title": "Tenstorrent Wormhole Analysis ‚Äì A Scale Out Architecture for Machine Learning That Could Put Nvidia On Their Back Foot", "resolved_url": "https://semianalysis.com/tenstorrent-wormhole-analysis-a-scale-out-architecture-for-machine-learning-that-could-put-nvidia-on-their-back-foot/", "excerpt": "Tenstorrent has had significant media coverage for being one of the foremost AI startups. In addition to promising hardware and software design, a portion of the hype is because they have the semiconductor titan, Jim Keller.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2478", "lang": "en", "time_to_read": 11, "top_image_url": "https://i0.wp.com/semianalysis.com/wp-content/uploads/2021/06/Tenstorrent.jpg?fit=1155%2C605&ssl=1", "tags": {"deep-learning": {"item_id": "3366214600", "tag": "deep-learning"}, "semiconductors": {"item_id": "3366214600", "tag": "semiconductors"}}, "authors": {"134777204": {"item_id": "3366214600", "author_id": "134777204", "name": "Dylan Patel", "url": "https://semianalysis.com/author/dylanspatel/"}}, "image": {"item_id": "3366214600", "src": "https://i1.wp.com/semianalysis.com/wp-content/uploads/2021/06/1-first-chip.jpg?resize=1024%2C527&ssl=1", "width": "1024", "height": "527"}, "images": {"1": {"item_id": "3366214600", "image_id": "1", "src": "https://i1.wp.com/semianalysis.com/wp-content/uploads/2021/06/1-first-chip.jpg?resize=1024%2C527&ssl=1", "width": "1024", "height": "527", "credit": "", "caption": ""}, "2": {"item_id": "3366214600", "image_id": "2", "src": "https://i2.wp.com/semianalysis.com/wp-content/uploads/2021/06/2nd-chip-greyskull.jpg?resize=1024%2C521&ssl=1", "width": "1024", "height": "521", "credit": "", "caption": ""}, "3": {"item_id": "3366214600", "image_id": "3", "src": "https://i0.wp.com/semianalysis.com/wp-content/uploads/2021/06/5-silicon-improvements.jpg?resize=1024%2C461&ssl=1", "width": "1024", "height": "461", "credit": "", "caption": ""}, "4": {"item_id": "3366214600", "image_id": "4", "src": "https://i0.wp.com/semianalysis.com/wp-content/uploads/2021/06/6-Scale-ou.jpg?resize=1024%2C507&ssl=1", "width": "1024", "height": "507", "credit": "", "caption": ""}, "5": {"item_id": "3366214600", "image_id": "5", "src": "https://i0.wp.com/semianalysis.com/wp-content/uploads/2021/06/7-Nebula.jpg?resize=1024%2C557&ssl=1", "width": "1024", "height": "557", "credit": "", "caption": ""}, "6": {"item_id": "3366214600", "image_id": "6", "src": "https://i2.wp.com/semianalysis.com/wp-content/uploads/2021/06/8-Galaxy.jpg?resize=1024%2C533&ssl=1", "width": "1024", "height": "533", "credit": "", "caption": ""}, "7": {"item_id": "3366214600", "image_id": "7", "src": "https://i1.wp.com/semianalysis.com/wp-content/uploads/2021/06/9-Galaxy-2.jpg?resize=1024%2C507&ssl=1", "width": "1024", "height": "507", "credit": "", "caption": ""}, "8": {"item_id": "3366214600", "image_id": "8", "src": "https://i0.wp.com/semianalysis.com/wp-content/uploads/2021/06/11-Topology-2.png?resize=1024%2C493&ssl=1", "width": "1024", "height": "493", "credit": "", "caption": ""}, "9": {"item_id": "3366214600", "image_id": "9", "src": "https://i0.wp.com/semianalysis.com/wp-content/uploads/2021/06/12-how.png?resize=1024%2C582&ssl=1", "width": "1024", "height": "582", "credit": "", "caption": ""}, "10": {"item_id": "3366214600", "image_id": "10", "src": "https://i0.wp.com/semianalysis.com/wp-content/uploads/2021/06/13-history.png?resize=1024%2C394&ssl=1", "width": "1024", "height": "394", "credit": "", "caption": ""}, "11": {"item_id": "3366214600", "image_id": "11", "src": "https://i0.wp.com/semianalysis.com/wp-content/uploads/2021/06/14-history.png?resize=1024%2C454&ssl=1", "width": "1024", "height": "454", "credit": "", "caption": ""}, "12": {"item_id": "3366214600", "image_id": "12", "src": "https://i0.wp.com/semianalysis.com/wp-content/uploads/2021/06/15-libraries.png?resize=1024%2C414&ssl=1", "width": "1024", "height": "414", "credit": "", "caption": ""}, "13": {"item_id": "3366214600", "image_id": "13", "src": "https://i1.wp.com/semianalysis.com/wp-content/uploads/2021/06/16-mini-tensors.png?resize=1024%2C441&ssl=1", "width": "1024", "height": "441", "credit": "", "caption": ""}, "14": {"item_id": "3366214600", "image_id": "14", "src": "https://i1.wp.com/semianalysis.com/wp-content/uploads/2021/06/18-graphs.png?resize=1024%2C470&ssl=1", "width": "1024", "height": "470", "credit": "", "caption": ""}, "15": {"item_id": "3366214600", "image_id": "15", "src": "https://i1.wp.com/semianalysis.com/wp-content/uploads/2021/06/19-primatives.png?resize=1024%2C459&ssl=1", "width": "1024", "height": "459", "credit": "", "caption": ""}, "16": {"item_id": "3366214600", "image_id": "16", "src": "https://i2.wp.com/semianalysis.com/wp-content/uploads/2021/06/21-mapping.png?resize=1024%2C464&ssl=1", "width": "1024", "height": "464", "credit": "", "caption": ""}, "17": {"item_id": "3366214600", "image_id": "17", "src": "https://i2.wp.com/semianalysis.com/wp-content/uploads/2021/06/22-comparison-1.png?resize=1024%2C466&ssl=1", "width": "1024", "height": "466", "credit": "", "caption": ""}, "18": {"item_id": "3366214600", "image_id": "18", "src": "https://i1.wp.com/semianalysis.com/wp-content/uploads/2021/06/23-Summary.png?resize=1024%2C480&ssl=1", "width": "1024", "height": "480", "credit": "", "caption": ""}}, "listen_duration_estimate": 959}, "2918018291": {"item_id": "2918018291", "resolved_id": "2918018322", "given_url": "https://towardsdatascience.com/test-your-skills-26-more-data-science-interview-questions-answers-9e7dfad33353?source=rss----7f60cf5620c9---4", "given_title": "Test Your Skills: 26 (More) Data Science Interview Questions & Answers", "favorite": "0", "status": "1", "time_added": "1584401915", "time_updated": "1638708525", "time_read": "1585739907", "time_favorited": "0", "sort_id": 422, "resolved_title": "Test Your Skills: 26 (More) Data Science Interview Questions & Answers", "resolved_url": "https://towardsdatascience.com/test-your-skills-26-more-data-science-interview-questions-answers-9e7dfad33353", "excerpt": "Here are 26 more data science interview questions and answers (here are the first 26).The questions are organized in a general flow of mathematics and statistics to algorithms to deep learning to NLP, with data organization questions interspersed.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2996", "lang": "en", "time_to_read": 14, "top_image_url": "https://miro.medium.com/max/1200/0*Wh2DnQSsI7FtDLXv.jpg", "tags": {"deep-learning": {"item_id": "2918018291", "tag": "deep-learning"}, "interviewing": {"item_id": "2918018291", "tag": "interviewing"}}, "authors": {"144200356": {"item_id": "2918018291", "author_id": "144200356", "name": "Andre Ye", "url": "https://andre-ye.medium.com"}}, "image": {"item_id": "2918018291", "src": "https://miro.medium.com/max/1400/0*Wh2DnQSsI7FtDLXv.jpg", "width": "700", "height": "472"}, "images": {"1": {"item_id": "2918018291", "image_id": "1", "src": "https://miro.medium.com/max/1400/0*Wh2DnQSsI7FtDLXv.jpg", "width": "700", "height": "472", "credit": "", "caption": "Source: Pixabay"}, "2": {"item_id": "2918018291", "image_id": "2", "src": "https://miro.medium.com/fit/c/56/56/1*agZM8gnrsEIs3InGe8B5EA.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "3": {"item_id": "2918018291", "image_id": "3", "src": "https://miro.medium.com/max/960/0*jPcRZBs1bVO0UJiK.gif", "width": "480", "height": "267", "credit": "", "caption": "Source: Giphy"}, "4": {"item_id": "2918018291", "image_id": "4", "src": "https://miro.medium.com/max/552/0*NzmrJISiNGff-jbj.png", "width": "276", "height": "218", "credit": "", "caption": "Source. Image free to share and use commercially."}, "5": {"item_id": "2918018291", "image_id": "5", "src": "https://miro.medium.com/max/1400/0*pZVLK9VABz9e-InF.jpg", "width": "700", "height": "901", "credit": "", "caption": "Source. Image free to share and use commercially."}, "6": {"item_id": "2918018291", "image_id": "6", "src": "https://miro.medium.com/max/1400/0*W9acU53CNzgkeUiU.png", "width": "700", "height": "212", "credit": "", "caption": "Source. Image free to share and use commercially."}, "7": {"item_id": "2918018291", "image_id": "7", "src": "https://miro.medium.com/max/1400/0*BAmv1XwfeLk0stHh.jpg", "width": "700", "height": "273", "credit": "", "caption": "A decision tree that has overfit to the data. Source. Image free to share and use commercially."}, "8": {"item_id": "2918018291", "image_id": "8", "src": "https://miro.medium.com/max/960/0*Ho7Rd7e85-aosjzH.gif", "width": "480", "height": "341", "credit": "", "caption": "Source: Giphy."}, "9": {"item_id": "2918018291", "image_id": "9", "src": "https://miro.medium.com/max/1052/0*BPrfEUc0HWugSibJ.gif", "width": "526", "height": "384", "credit": "", "caption": "Convolutional Layer. Source: Giphy."}, "10": {"item_id": "2918018291", "image_id": "10", "src": "https://miro.medium.com/max/1400/0*HfNXV-x-3RQNb9M_.png", "width": "700", "height": "412", "credit": "", "caption": "Neural Network before/after applying dropout. Source. Image free to use with credit."}, "11": {"item_id": "2918018291", "image_id": "11", "src": "https://miro.medium.com/max/1248/0*gVKFOFGi22D1NRX4.png", "width": "624", "height": "70", "credit": "", "caption": ""}, "12": {"item_id": "2918018291", "image_id": "12", "src": "https://miro.medium.com/max/1200/0*NYSQHHT5riKB8HX7.gif", "width": "600", "height": "600", "credit": "", "caption": "Source: Giphy"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 1160}, "3795705885": {"item_id": "3795705885", "resolved_id": "3795705891", "given_url": "https://marginalrevolution.com/marginalrevolution/2023/01/text-to-4d-dynamic-scene-generation.html?utm_source=rss&utm_medium=rss&utm_campaign=text-to-4d-dynamic-scene-generation", "given_title": "Text-to-4D dynamic scene generation", "favorite": "0", "status": "1", "time_added": "1674908370", "time_updated": "1675005006", "time_read": "1675005006", "time_favorited": "0", "sort_id": 423, "resolved_title": "Text-to-4D dynamic scene generation", "resolved_url": "https://marginalrevolution.com/marginalrevolution/2023/01/text-to-4d-dynamic-scene-generation.html", "excerpt": "Find it here, via Ryan Watkins.¬† Further improvement is required, but the pace of current breakthroughs is remarkable.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "18", "lang": "en", "top_image_url": "https://marginalrevolution.com/wp-content/uploads/2016/10/MR-logo-thumbnail.png", "tags": {"deep-learning": {"item_id": "3795705885", "tag": "deep-learning"}, "generative": {"item_id": "3795705885", "tag": "generative"}, "storytelling": {"item_id": "3795705885", "tag": "storytelling"}, "video": {"item_id": "3795705885", "tag": "video"}}, "authors": {"87004756": {"item_id": "3795705885", "author_id": "87004756", "name": "Tyler Cowen", "url": "https://marginalrevolution.com/about"}}, "domain_metadata": {"name": "Marginal Revolution", "logo": "https://logo.clearbit.com/marginalrevolution.com?size=800", "greyscale_logo": "https://logo.clearbit.com/marginalrevolution.com?size=800&greyscale=true"}, "listen_duration_estimate": 7}, "3244450683": {"item_id": "3244450683", "resolved_id": "3244450683", "given_url": "https://hgpu.org/?p=24466", "given_title": "Text2Gestures: A Transformer-Based Network for Generating Emotive Body Gest", "favorite": "0", "status": "1", "time_added": "1612094931", "time_updated": "1638708525", "time_read": "1612101637", "time_favorited": "0", "sort_id": 424, "resolved_title": "Text2Gestures: A Transformer-Based Network for Generating Emotive Body Gestures for Virtual Agents", "resolved_url": "https://hgpu.org/?p=24466", "excerpt": "Uttaran Bhattacharya, Nicholas Rewkowski, Abhishek Banerjee, Pooja Guhan, Aniket Bera, Dinesh Manocha We present Text2Gestures, a transformer-based learning method to interactively generate emotive full-body gestures for virtual agents aligned with natural language text inputs.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "189", "lang": "en", "top_image_url": "https://hgpu.org/img/social-logo.png", "tags": {"deep-learning": {"item_id": "3244450683", "tag": "deep-learning"}, "gestures": {"item_id": "3244450683", "tag": "gestures"}}, "authors": {"65333509": {"item_id": "3244450683", "author_id": "65333509", "name": "hgpu", "url": "https://hgpu.org/?author=351"}}, "listen_duration_estimate": 73}, "2018856608": {"item_id": "2018856608", "resolved_id": "2018856608", "given_url": "https://medium.com/@sethweidman/the-3-tricks-that-made-alphago-zero-work-f3d47b6686ef", "given_title": "The 3 Tricks That Made AlphaGo Zero Work", "favorite": "0", "status": "1", "time_added": "1515680908", "time_updated": "1638708525", "time_read": "1515768473", "time_favorited": "0", "sort_id": 425, "resolved_title": "The 3 Tricks That Made AlphaGo Zero¬†Work", "resolved_url": "https://medium.com/@sethweidman/the-3-tricks-that-made-alphago-zero-work-f3d47b6686ef", "excerpt": "There were many advances in Deep Learning and AI in 2017, but few generated as much publicity and interest as DeepMind‚Äôs AlphaGo Zero.", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "2438", "lang": "en", "time_to_read": 11, "top_image_url": "https://cdn-images-1.medium.com/max/1200/1*qpzAxoUR9POLYl__zJhU5g.png", "tags": {"deep-learning": {"item_id": "2018856608", "tag": "deep-learning"}}, "authors": {"72730461": {"item_id": "2018856608", "author_id": "72730461", "name": "Seth Weidman", "url": "https://medium.com/@sethweidman"}}, "image": {"item_id": "2018856608", "src": "https://cdn-images-1.medium.com/max/1600/1*qpzAxoUR9POLYl__zJhU5g.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2018856608", "image_id": "1", "src": "https://cdn-images-1.medium.com/max/1600/1*qpzAxoUR9POLYl__zJhU5g.png", "width": "0", "height": "0", "credit": "", "caption": "The tree of possible positions in Go.¬†Source"}, "2": {"item_id": "2018856608", "image_id": "2", "src": "https://cdn-images-1.medium.com/max/1600/1*rnmOlqtr_bTSpP6i7GuJ4w.png", "width": "0", "height": "0", "credit": "", "caption": "The two neural networks at the core of AlphaGo.¬†Source"}, "3": {"item_id": "2018856608", "image_id": "3", "src": "https://cdn-images-1.medium.com/max/1600/1*s2kMOSdl2AaUwo5QVjpTHA.png", "width": "0", "height": "0", "credit": "", "caption": "Monte Carlo Tree Search in AlphaGo, guided by neural networks. Source"}, "4": {"item_id": "2018856608", "image_id": "4", "src": "https://cdn-images-1.medium.com/max/1600/1*hBzorPuADtitET2SZaLN2A.png", "width": "0", "height": "0", "credit": "", "caption": "How MCTS can always continually improve programs‚Äô evaluations."}, "5": {"item_id": "2018856608", "image_id": "5", "src": "https://cdn-images-1.medium.com/max/1600/1*DB99saQWkvVwPleKaWj-1A.png", "width": "0", "height": "0", "credit": "", "caption": "Self-play in AlphaGo Zero. Diagram courtesy of DeepMind."}, "6": {"item_id": "2018856608", "image_id": "6", "src": "https://cdn-images-1.medium.com/max/1600/1*96DnPFNDD8YyN-GK737bBQ.png", "width": "0", "height": "0", "credit": "", "caption": "AlphaGo Zero‚Äôs two headed neural network architecture. Diagram courtesy of DeepMind."}, "7": {"item_id": "2018856608", "image_id": "7", "src": "https://cdn-images-1.medium.com/max/1600/1*kxeOANM2_4aqGXwGAXsusQ.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2018856608", "image_id": "8", "src": "https://cdn-images-1.medium.com/max/1600/1*Bqt3g_0RlcAJNn6KEICNkQ.png", "width": "0", "height": "0", "credit": "", "caption": "Training the two headed neural network, one head at a¬†time."}, "9": {"item_id": "2018856608", "image_id": "9", "src": "https://cdn-images-1.medium.com/max/1600/1*aJCekYFA3jG0NDBmBEYYPA.png", "width": "0", "height": "0", "credit": "", "caption": "Diagram comparing residual to convolutional architectures, from the original ‚ÄúResNet‚Äù paper.¬†Source"}, "10": {"item_id": "2018856608", "image_id": "10", "src": "https://cdn-images-1.medium.com/max/1600/1*3Yl6HAo-3YVwdbKpSVZY_A.png", "width": "0", "height": "0", "credit": "", "caption": "Improvmenet of AlphaGo Zero‚Ää‚Äî‚Ääwhich used a ‚ÄúDual-Residual‚Äù neural network architecture‚Ää‚Äî‚Ääover AlphaGo, which used a ‚ÄúSeparate-Convolutional‚Äù architecture. Chart courtesy of DeepMind."}, "11": {"item_id": "2018856608", "image_id": "11", "src": "https://cdn-images-1.medium.com/max/1600/1*IRbL8abD_fN4tafR6cfMlg.png", "width": "0", "height": "0", "credit": "", "caption": "One MCTS iteration in AlphaGo Zero. Diagram courtesy of DeepMind."}, "12": {"item_id": "2018856608", "image_id": "12", "src": "https://cdn-images-1.medium.com/max/1600/1*ZFqEYHfcP-8mLAYi2wz8gw.png", "width": "0", "height": "0", "credit": "", "caption": "DeepMind‚Äôs AI learning to solve mazes, using the ‚ÄúDistral‚Äù framework for multitask reinforcement learning. Source"}, "13": {"item_id": "2018856608", "image_id": "13", "src": "https://cdn-images-1.medium.com/max/1600/1*la16q_VbyN_l3iejXSJ3og.jpeg", "width": "0", "height": "0", "credit": "", "caption": "The tricks DeepMind used to train AlphaGo Zero have already been applied to locomotion. Source"}}, "videos": {"1": {"item_id": "2018856608", "video_id": "1", "src": "https://medium.com/media/e2156848f557a6e9e00e209017e486eb?postId=f3d47b6686ef", "width": "500", "height": "185", "type": "7", "vid": "", "length": "0"}}, "domain_metadata": {"name": "Medium", "logo": "https://logo.clearbit.com/medium.com?size=800", "greyscale_logo": "https://logo.clearbit.com/medium.com?size=800&greyscale=true"}, "listen_duration_estimate": 944}, "2957192960": {"item_id": "2957192960", "resolved_id": "2957192966", "given_url": "https://arxiv.org/abs/2004.08900", "given_title": "The Cost of Training NLP Models: A Concise Overview", "favorite": "0", "status": "1", "time_added": "1587721532", "time_updated": "1638708525", "time_read": "1587745451", "time_favorited": "0", "sort_id": 426, "resolved_title": "Title:The Cost of Training NLP Models: A Concise Overview", "resolved_url": "https://arxiv.org/abs/2004.08900v1", "excerpt": "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "77", "lang": "en", "top_image_url": "https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png", "tags": {"deep-learning": {"item_id": "2957192960", "tag": "deep-learning"}, "nlp": {"item_id": "2957192960", "tag": "nlp"}}, "authors": {"63240129": {"item_id": "2957192960", "author_id": "63240129", "name": "cs cs.LG cs.NE", "url": ""}}, "domain_metadata": {"name": "arXiv", "logo": "https://logo.clearbit.com/arxiv.org?size=800", "greyscale_logo": "https://logo.clearbit.com/arxiv.org?size=800&greyscale=true"}, "listen_duration_estimate": 30}, "3294397271": {"item_id": "3294397271", "resolved_id": "3294397292", "given_url": "https://towardsdatascience.com/the-dying-relu-problem-clearly-explained-42d0c54e0d24?source=rss----7f60cf5620c9---4", "given_title": "The Dying ReLU Problem, Clearly Explained", "favorite": "0", "status": "1", "time_added": "1617141536", "time_updated": "1673901884", "time_read": "1617146349", "time_favorited": "0", "sort_id": 427, "resolved_title": "The Dying ReLU Problem, Clearly Explained", "resolved_url": "https://towardsdatascience.com/the-dying-relu-problem-clearly-explained-42d0c54e0d24", "excerpt": "The Dying ReLU Problem, Clearly ExplainedKeep your neural network alive by understanding the downsides of ReLUKenneth LeungMar 30¬∑5 min readContents(1) What is ReLU and what are its advantages? (2) What‚Äôs the Dying ReLU problem? (3) What causes the Dying ReLU problem? (4) How to solve the Dying", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1034", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1200/0*w80ldgn1iri7dhsM", "tags": {"activations": {"item_id": "3294397271", "tag": "activations"}, "deep-learning": {"item_id": "3294397271", "tag": "deep-learning"}}, "authors": {"146363413": {"item_id": "3294397271", "author_id": "146363413", "name": "Medium", "url": "https://kennethleungty.medium.com"}}, "image": {"item_id": "3294397271", "src": "https://miro.medium.com/fit/c/56/56/1*dMs7hqFw5Rbh8d9KsvRogA.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3294397271", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*dMs7hqFw5Rbh8d9KsvRogA.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3294397271", "image_id": "2", "src": "https://miro.medium.com/max/6300/0*w80ldgn1iri7dhsM", "width": "3150", "height": "2100", "credit": "Solen Feyissa on Unsplash", "caption": ""}, "3": {"item_id": "3294397271", "image_id": "3", "src": "https://miro.medium.com/max/3516/1*-DjRsec_Iqe6c2obsLiCxQ.png", "width": "1758", "height": "1004", "credit": "", "caption": "Graphic representation of ReLU activation function"}, "4": {"item_id": "3294397271", "image_id": "4", "src": "https://miro.medium.com/max/3536/1*r_fTwA86CGc6iqFQlVjZ-g.png", "width": "1768", "height": "1002", "credit": "in the negative x range", "caption": "Red outline"}, "5": {"item_id": "3294397271", "image_id": "5", "src": "https://miro.medium.com/max/3732/1*xp_bE0C7le8mNF-JE7OAhA.png", "width": "1866", "height": "568", "credit": "Image by author", "caption": "Equation for update rule"}, "6": {"item_id": "3294397271", "image_id": "6", "src": "https://miro.medium.com/max/3584/1*VmV4xp0m_RXnGD6Ha-3-6Q.png", "width": "1792", "height": "732", "credit": "Image by author", "caption": "Illustration of a simple neural network"}, "7": {"item_id": "3294397271", "image_id": "7", "src": "https://miro.medium.com/max/3516/1*CszCyqBQJPi15PRtAhlXHQ.png", "width": "1758", "height": "1004", "credit": "Image by author", "caption": "Grpahical comparison of ReLU andLeaky ReLU"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 400}, "2407676761": {"item_id": "2407676761", "resolved_id": "2407676761", "given_url": "http://jalammar.github.io/illustrated-bert/", "given_title": "The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) ‚Äì J", "favorite": "0", "status": "1", "time_added": "1584704762", "time_updated": "1638708525", "time_read": "1585739665", "time_favorited": "0", "sort_id": 428, "resolved_title": "The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)", "resolved_url": "https://jalammar.github.io/illustrated-bert/", "excerpt": "Translations: Chinese (Simplified), French 1, French 2, Japanese, Korean, Persian, Russian, Spanish The year 2018 has been an inflection point for machine learning models handling text (or more accurately, Natural Language Processing or NLP for short).", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "2940", "lang": "en", "time_to_read": 13, "tags": {"bert": {"item_id": "2407676761", "tag": "bert"}, "deep-learning": {"item_id": "2407676761", "tag": "deep-learning"}, "nlp": {"item_id": "2407676761", "tag": "nlp"}}, "authors": {"83096926": {"item_id": "2407676761", "author_id": "83096926", "name": "Jay Alammar", "url": ""}}, "image": {"item_id": "2407676761", "src": "https://jalammar.github.io/images/bert-transfer-learning.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2407676761", "image_id": "1", "src": "https://jalammar.github.io/images/bert-transfer-learning.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2407676761", "image_id": "2", "src": "https://jalammar.github.io/images/BERT-classification-spam.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2407676761", "image_id": "3", "src": "https://jalammar.github.io/images/bert-base-bert-large.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2407676761", "image_id": "4", "src": "https://jalammar.github.io/images/bert-base-bert-large-encoders.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2407676761", "image_id": "5", "src": "https://jalammar.github.io/images/bert-input-output.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2407676761", "image_id": "6", "src": "https://jalammar.github.io/images/bert-encoders-input.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2407676761", "image_id": "7", "src": "https://jalammar.github.io/images/bert-output-vector.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2407676761", "image_id": "8", "src": "https://jalammar.github.io/images/bert-classifier.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2407676761", "image_id": "9", "src": "https://jalammar.github.io/images/vgg-net-classifier.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2407676761", "image_id": "10", "src": "https://jalammar.github.io/images/glove-embedding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2407676761", "image_id": "11", "src": "https://jalammar.github.io/images/vector-boxes.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2407676761", "image_id": "12", "src": "https://jalammar.github.io/images/elmo-embedding-robin-williams.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "2407676761", "image_id": "13", "src": "https://jalammar.github.io/images/elmo-word-embedding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "2407676761", "image_id": "14", "src": "https://jalammar.github.io/images/Bert-language-modeling.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "2407676761", "image_id": "15", "src": "https://jalammar.github.io/images/elmo-forward-backward-language-model-embedding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "2407676761", "image_id": "16", "src": "https://jalammar.github.io/images/elmo-embedding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "2407676761", "image_id": "17", "src": "https://jalammar.github.io/images/openai-transformer-1.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "2407676761", "image_id": "18", "src": "https://jalammar.github.io/images/openai-transformer-language-modeling.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "2407676761", "image_id": "19", "src": "https://jalammar.github.io/images/openai-transformer-sentence-classification.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "2407676761", "image_id": "20", "src": "https://jalammar.github.io/images/openai-input%20transformations.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "2407676761", "image_id": "21", "src": "https://jalammar.github.io/images/BERT-language-modeling-masked-lm.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "2407676761", "image_id": "22", "src": "https://jalammar.github.io/images/bert-next-sentence-prediction.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "23": {"item_id": "2407676761", "image_id": "23", "src": "https://jalammar.github.io/images/bert-tasks.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "2407676761", "image_id": "24", "src": "https://jalammar.github.io/images/bert-contexualized-embeddings.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "2407676761", "image_id": "25", "src": "https://jalammar.github.io/images/bert-feature-extraction-contextualized-embeddings.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "2407676761", "video_id": "1", "src": "https://www.youtube.com/embed/ioGry-89gqE", "width": "560", "height": "315", "type": "1", "vid": "ioGry-89gqE", "length": "0"}}, "listen_duration_estimate": 1138}, "2239506919": {"item_id": "2239506919", "resolved_id": "2239506919", "given_url": "https://jalammar.github.io/illustrated-transformer/", "given_title": "The Illustrated Transformer ‚Äì Jay Alammar ‚Äì Visualizing machine learning on", "favorite": "0", "status": "1", "time_added": "1622248175", "time_updated": "1638708525", "time_read": "1622248847", "time_favorited": "0", "sort_id": 429, "resolved_title": "The Illustrated Transformer", "resolved_url": "http://jalammar.github.io/illustrated-transformer/", "excerpt": "Translations: Arabic, Chinese (Simplified) 1, Chinese (Simplified) 2, French 1, French 2, Italian, Japanese, Korean, Persian, Russian, Spanish 1, Spanish 2, Vietnamese Watch: MIT‚Äôs Deep Learning State of the Art lecture referencing this post Featured in courses at Stanford, Harvard, MIT, Princeton", "is_article": "1", "is_index": "0", "has_video": "1", "has_image": "1", "word_count": "3954", "lang": "", "tags": {"deep-learning": {"item_id": "2239506919", "tag": "deep-learning"}, "transformers": {"item_id": "2239506919", "tag": "transformers"}}, "authors": {"91291457": {"item_id": "2239506919", "author_id": "91291457", "name": "Lukasz Kaiser", "url": "https://ai.google/research/people/LukaszKaiser"}}, "image": {"item_id": "2239506919", "src": "https://jalammar.github.io/images/t/the_transformer_3.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2239506919", "image_id": "1", "src": "https://jalammar.github.io/images/t/the_transformer_3.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2239506919", "image_id": "2", "src": "https://jalammar.github.io/images/t/The_transformer_encoders_decoders.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "2239506919", "image_id": "3", "src": "https://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "2239506919", "image_id": "4", "src": "https://jalammar.github.io/images/t/Transformer_encoder.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "2239506919", "image_id": "5", "src": "https://jalammar.github.io/images/t/Transformer_decoder.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "2239506919", "image_id": "6", "src": "https://jalammar.github.io/images/t/embeddings.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "2239506919", "image_id": "7", "src": "https://jalammar.github.io/images/t/encoder_with_tensors.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "2239506919", "image_id": "8", "src": "https://jalammar.github.io/images/t/encoder_with_tensors_2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "2239506919", "image_id": "9", "src": "https://jalammar.github.io/images/t/transformer_self-attention_visualization.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "2239506919", "image_id": "10", "src": "https://jalammar.github.io/images/t/transformer_self_attention_vectors.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "2239506919", "image_id": "11", "src": "https://jalammar.github.io/images/t/transformer_self_attention_score.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "2239506919", "image_id": "12", "src": "https://jalammar.github.io/images/t/self-attention_softmax.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "2239506919", "image_id": "13", "src": "https://jalammar.github.io/images/t/self-attention-output.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "2239506919", "image_id": "14", "src": "https://jalammar.github.io/images/t/self-attention-matrix-calculation.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "2239506919", "image_id": "15", "src": "https://jalammar.github.io/images/t/self-attention-matrix-calculation-2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "16": {"item_id": "2239506919", "image_id": "16", "src": "https://jalammar.github.io/images/t/transformer_attention_heads_qkv.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "17": {"item_id": "2239506919", "image_id": "17", "src": "https://jalammar.github.io/images/t/transformer_attention_heads_z.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "18": {"item_id": "2239506919", "image_id": "18", "src": "https://jalammar.github.io/images/t/transformer_attention_heads_weight_matrix_o.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "19": {"item_id": "2239506919", "image_id": "19", "src": "https://jalammar.github.io/images/t/transformer_multi-headed_self-attention-recap.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "20": {"item_id": "2239506919", "image_id": "20", "src": "https://jalammar.github.io/images/t/transformer_self-attention_visualization_2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "21": {"item_id": "2239506919", "image_id": "21", "src": "https://jalammar.github.io/images/t/transformer_self-attention_visualization_3.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "22": {"item_id": "2239506919", "image_id": "22", "src": "https://jalammar.github.io/images/t/transformer_positional_encoding_vectors.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "23": {"item_id": "2239506919", "image_id": "23", "src": "https://jalammar.github.io/images/t/transformer_positional_encoding_example.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "24": {"item_id": "2239506919", "image_id": "24", "src": "https://jalammar.github.io/images/t/transformer_positional_encoding_large_example.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "25": {"item_id": "2239506919", "image_id": "25", "src": "https://jalammar.github.io/images/t/attention-is-all-you-need-positional-encoding.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "26": {"item_id": "2239506919", "image_id": "26", "src": "https://jalammar.github.io/images/t/transformer_resideual_layer_norm.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "27": {"item_id": "2239506919", "image_id": "27", "src": "https://jalammar.github.io/images/t/transformer_resideual_layer_norm_2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "28": {"item_id": "2239506919", "image_id": "28", "src": "https://jalammar.github.io/images/t/transformer_resideual_layer_norm_3.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "29": {"item_id": "2239506919", "image_id": "29", "src": "https://jalammar.github.io/images/t/transformer_decoder_output_softmax.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "30": {"item_id": "2239506919", "image_id": "30", "src": "https://jalammar.github.io/images/t/vocabulary.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "31": {"item_id": "2239506919", "image_id": "31", "src": "https://jalammar.github.io/images/t/one-hot-vocabulary-example.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "32": {"item_id": "2239506919", "image_id": "32", "src": "https://jalammar.github.io/images/t/transformer_logits_output_and_label.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "33": {"item_id": "2239506919", "image_id": "33", "src": "https://jalammar.github.io/images/t/output_target_probability_distributions.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "34": {"item_id": "2239506919", "image_id": "34", "src": "https://jalammar.github.io/images/t/output_trained_model_probability_distributions.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "2239506919", "video_id": "1", "src": "https://www.youtube.com/embed/-QH8fRhqFHM", "width": "560", "height": "315", "type": "1", "vid": "-QH8fRhqFHM", "length": "0"}}, "listen_duration_estimate": 1531}, "4017016623": {"item_id": "4017016623", "resolved_id": "4017016623", "given_url": "https://freedium.cfd/https://towardsdatascience.com/the-math-behind-adam-optimizer-c41407efe59b", "given_title": "The Math behind Adam Optimizer | by Cristian Leo | in Towards Data Science ", "favorite": "0", "status": "1", "time_added": "1709518055", "time_updated": "1709597871", "time_read": "1709597871", "time_favorited": "0", "sort_id": 430, "resolved_title": "The Math behind Adam Optimizer", "resolved_url": "https://freedium.cfd/https://towardsdatascience.com/the-math-behind-adam-optimizer-c41407efe59b", "excerpt": "If you've clicked on this article, you've likely heard about Adam, a name that has gained notable recognition in many winning Kaggle competitions. It's common to experiment with a few optimizers like SGD, Adagrad, Adam, or AdamW, but truly understanding their mechanics is a different story.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "3484", "lang": "", "tags": {"deep-learning": {"item_id": "4017016623", "tag": "deep-learning"}, "optimization": {"item_id": "4017016623", "tag": "optimization"}}, "authors": {"177171907": {"item_id": "4017016623", "author_id": "177171907", "name": "DALLE-", "url": ""}}, "image": {"item_id": "4017016623", "src": "https://miro.medium.com/v2/resize:fit:700/0*Nb5_uMiNpeb1UIT2", "width": "0", "height": "0"}, "images": {"1": {"item_id": "4017016623", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fit:700/0*Nb5_uMiNpeb1UIT2", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "4017016623", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fit:700/1*0OYueSgvqLinyLy7LLinqw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "4017016623", "image_id": "3", "src": "https://miro.medium.com/v2/resize:fit:700/1*2VY49JzmLxv4_BUzbxEMBw.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "4017016623", "image_id": "4", "src": "https://miro.medium.com/v2/resize:fit:700/1*hMUb_2bTntd1jucZH-BT-w.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "4017016623", "image_id": "5", "src": "https://miro.medium.com/v2/resize:fit:700/1*jh8PX4At-W2DxTkcPovnEg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "4017016623", "image_id": "6", "src": "https://miro.medium.com/v2/resize:fit:700/1*lqrHrHSWkHUFjTYLwbqgsg.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "4017016623", "image_id": "7", "src": "https://miro.medium.com/v2/resize:fit:700/1*ZmUizD7IcSK3diRMk6dCag.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1349}, "2899090346": {"item_id": "2899090346", "resolved_id": "2899090356", "given_url": "https://towardsdatascience.com/the-mechanics-of-attention-mechanism-f6e9805cca66?source=rss----7f60cf5620c9---4", "given_title": "The Mechanics of Attention Mechanism", "favorite": "0", "status": "1", "time_added": "1582892221", "time_updated": "1638708525", "time_read": "1583785007", "time_favorited": "0", "sort_id": 431, "resolved_title": "The Mechanics of Attention Mechanism in Flowcharts", "resolved_url": "https://towardsdatascience.com/the-mechanics-of-attention-mechanism-f6e9805cca66", "excerpt": "Epistemic status: I am trying to understand attention mechanism properly, at a level where I know how to implement it to any kind of data/problem or any modality, and how to tweak it to improve it. This article is like my own notes to teach myself.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1416", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/1*7UDWIX88K5nVHqGJrpeE2w.jpeg", "tags": {"deep-learning": {"item_id": "2899090346", "tag": "deep-learning"}}, "authors": {"146776147": {"item_id": "2899090346", "author_id": "146776147", "name": "Arian Prabowo", "url": "https://arian-prabowo.medium.com"}}, "image": {"item_id": "2899090346", "src": "https://miro.medium.com/max/1400/1*7UDWIX88K5nVHqGJrpeE2w.jpeg", "width": "700", "height": "371"}, "images": {"1": {"item_id": "2899090346", "image_id": "1", "src": "https://miro.medium.com/max/1400/1*7UDWIX88K5nVHqGJrpeE2w.jpeg", "width": "700", "height": "371", "credit": "", "caption": "Attention. Photo by Justin Chrn on Unsplash"}, "2": {"item_id": "2899090346", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*b7FBYUDKjDED9tGsdzW_MA.png", "width": "700", "height": "546", "credit": "", "caption": "Vanilla RNN encoder unit."}, "3": {"item_id": "2899090346", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*BGabK2oqtXVUlx9aU0CN0A.png", "width": "700", "height": "517", "credit": "T_x=4", "caption": "Vanilla RNN encoder"}, "4": {"item_id": "2899090346", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*30vN9_ixWjb9sLWrIObHig.png", "width": "700", "height": "357", "credit": "typeface", "caption": "Structure of a typical encoder-decoder seq2seq RNN with exaggerated example of machine finding difficulties in translation. Different fonts"}, "5": {"item_id": "2899090346", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*1CxWeGB0pbR16_yOHuKldA.png", "width": "700", "height": "332", "credit": "green box", "caption": "Left: Typical RNN decoder. Right"}, "6": {"item_id": "2899090346", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*AS4kik4PIG8Wo5zhuo2HNw.png", "width": "700", "height": "428", "credit": "instead of just general ‚Äúc‚Äù", "caption": "Attention mechanism uses unique CONTEXT VECTOR c_i"}, "7": {"item_id": "2899090346", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*e0Hx7RkwIGtJSzPzCmAY-w.png", "width": "700", "height": "458", "credit": ".", "caption": "Three modules, one for each output: c"}, "8": {"item_id": "2899090346", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*3c0B0_XZNDFYMemxC2PD5w.png", "width": "700", "height": "1060", "credit": "", "caption": "The full model of attention mechanism. The equations transcribed into flowchart."}, "9": {"item_id": "2899090346", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*VTEJ-bm13xZgLBkYkIo1lQ.png", "width": "700", "height": "804", "credit": "", "caption": "Comparing our flowchart with the simplified figure in the original paper."}, "10": {"item_id": "2899090346", "image_id": "10", "src": "https://miro.medium.com/max/1340/1*YtsodA6LcX8a4jFtEBFW9w.png", "width": "670", "height": "694", "credit": "From the original paper", "caption": "Alignment matrix."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 548}, "3042331026": {"item_id": "3042331026", "resolved_id": "3042331026", "given_url": "https://paperswithcode.com/methods", "given_title": "The Methods Corpus | Papers With Code", "favorite": "0", "status": "1", "time_added": "1624584288", "time_updated": "1638708525", "time_read": "1624930362", "time_favorited": "0", "sort_id": 432, "resolved_title": "The Methods Corpus", "resolved_url": "https://paperswithcode.com/methods", "excerpt": "Stay informed on the latest trending ML papers with code, research developments, libraries, methods, and datasets.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "16", "lang": "en", "top_image_url": "https://paperswithcode.com/static/methods.jpeg", "tags": {"deep-learning": {"item_id": "3042331026", "tag": "deep-learning"}, "machine-learning": {"item_id": "3042331026", "tag": "machine-learning"}, "paperswithcode": {"item_id": "3042331026", "tag": "paperswithcode"}}, "listen_duration_estimate": 6}, "3105394082": {"item_id": "3105394082", "resolved_id": "3105394082", "given_url": "https://mlwhiz.com/blog/2020/09/09/pytorch_guide/", "given_title": "The Most Complete Guide to PyTorch for Data Scientists", "favorite": "0", "status": "1", "time_added": "1599595339", "time_updated": "1638708525", "time_read": "1604363865", "time_favorited": "0", "sort_id": 433, "resolved_title": "The Most Complete Guide to PyTorch for Data Scientists", "resolved_url": "https://mlwhiz.com/blog/2020/09/09/pytorch_guide/", "excerpt": "PyTorch has sort of became one of the de facto standards for creating Neural Networks now, and I love its interface. Yet, it is somehow a little difficult for beginners to get a hold of. I remember picking PyTorch up only after some extensive experimentation a couple of years back.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4578", "lang": "en", "time_to_read": 21, "top_image_url": "https://mlwhiz.com/images/pytorch_guide/main.png", "tags": {"deep-learning": {"item_id": "3105394082", "tag": "deep-learning"}, "pytorch": {"item_id": "3105394082", "tag": "pytorch"}}, "authors": {"8623619": {"item_id": "3105394082", "author_id": "8623619", "name": "Rahul Agarwal", "url": ""}}, "image": {"item_id": "3105394082", "src": "https://mlwhiz.com/images/pytorch_guide/0.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3105394082", "image_id": "1", "src": "https://mlwhiz.com/images/pytorch_guide/0.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3105394082", "image_id": "2", "src": "https://mlwhiz.com/images/pytorch_guide/1.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "3105394082", "image_id": "3", "src": "https://mlwhiz.com/images/pytorch_guide/2.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "3105394082", "image_id": "4", "src": "https://mlwhiz.com/images/pytorch_guide/3.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "3105394082", "image_id": "5", "src": "https://mlwhiz.com/images/pytorch_guide/4.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "3105394082", "image_id": "6", "src": "https://mlwhiz.com/images/pytorch_guide/5.png", "width": "0", "height": "0", "credit": "", "caption": "Example of one random sequence and label. Each integer in the sequence corresponds to a word in the sentence."}, "7": {"item_id": "3105394082", "image_id": "7", "src": "https://mlwhiz.com/images/pytorch_guide/6.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "3105394082", "image_id": "8", "src": "https://mlwhiz.com/images/pytorch_guide/7.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "3105394082", "image_id": "9", "src": "https://mlwhiz.com/images/pytorch_guide/8.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "3105394082", "image_id": "10", "src": "https://mlwhiz.com/images/pytorch_guide/9.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1772}, "1413321680": {"item_id": "1413321680", "resolved_id": "1413321680", "given_url": "http://www.asimovinstitute.org/neural-network-zoo/", "given_title": "The Neural Network Zoo - The Asimov Institute", "favorite": "0", "status": "1", "time_added": "1575632015", "time_updated": "1638708525", "time_read": "1576355731", "time_favorited": "0", "sort_id": 434, "resolved_title": "The Neural Network Zoo", "resolved_url": "https://www.asimovinstitute.org/neural-network-zoo/", "excerpt": "With new neural network¬†architectures popping up every now and then, it‚Äôs hard to keep track of them all. Knowing all the abbreviations being thrown around (DCIGN, BiLSTM, DCGAN, anyone?) can be a bit overwhelming at first.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "5277", "lang": "en", "time_to_read": 24, "top_image_url": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/building-922529_1920.jpg", "tags": {"deep-learning": {"item_id": "1413321680", "tag": "deep-learning"}, "dictionary": {"item_id": "1413321680", "tag": "dictionary"}}, "authors": {"74144342": {"item_id": "1413321680", "author_id": "74144342", "name": "Fjodor van Veen", "url": "https://www.asimovinstitute.org/author/fjodorvanveen/"}}, "image": {"item_id": "1413321680", "src": "https://www.asimovinstitute.org/wp-content/uploads/2019/04/NeuralNetworkZoo20042019.png", "width": "2000", "height": "3400"}, "images": {"1": {"item_id": "1413321680", "image_id": "1", "src": "https://www.asimovinstitute.org/wp-content/uploads/2019/04/NeuralNetworkZoo20042019.png", "width": "2000", "height": "3400", "credit": "", "caption": ""}, "2": {"item_id": "1413321680", "image_id": "2", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/ff.png", "width": "427", "height": "124", "credit": "", "caption": ""}, "3": {"item_id": "1413321680", "image_id": "3", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/rbf.png", "width": "196", "height": "125", "credit": "", "caption": ""}, "4": {"item_id": "1413321680", "image_id": "4", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/rnn.png", "width": "272", "height": "211", "credit": "", "caption": ""}, "5": {"item_id": "1413321680", "image_id": "5", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/lstm.png", "width": "271", "height": "215", "credit": "", "caption": ""}, "6": {"item_id": "1413321680", "image_id": "6", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/gru.png", "width": "271", "height": "206", "credit": "", "caption": ""}, "7": {"item_id": "1413321680", "image_id": "7", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/ae.png", "width": "202", "height": "274", "credit": "", "caption": ""}, "8": {"item_id": "1413321680", "image_id": "8", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/vae.png", "width": "203", "height": "269", "credit": "", "caption": ""}, "9": {"item_id": "1413321680", "image_id": "9", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/dae.png", "width": "208", "height": "286", "credit": "", "caption": ""}, "10": {"item_id": "1413321680", "image_id": "10", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/sae.png", "width": "216", "height": "294", "credit": "", "caption": ""}, "11": {"item_id": "1413321680", "image_id": "11", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/mc.png", "width": "300", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "1413321680", "image_id": "12", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/hn.png", "width": "300", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "1413321680", "image_id": "13", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/bm.png", "width": "303", "height": "319", "credit": "", "caption": ""}, "14": {"item_id": "1413321680", "image_id": "14", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/rbm.png", "width": "152", "height": "297", "credit": "", "caption": ""}, "15": {"item_id": "1413321680", "image_id": "15", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/dbn.png", "width": "501", "height": "284", "credit": "", "caption": ""}, "16": {"item_id": "1413321680", "image_id": "16", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/cnn.png", "width": "526", "height": "324", "credit": "", "caption": ""}, "17": {"item_id": "1413321680", "image_id": "17", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/dn.png", "width": "310", "height": "313", "credit": "", "caption": ""}, "18": {"item_id": "1413321680", "image_id": "18", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/dcign.png", "width": "563", "height": "310", "credit": "", "caption": ""}, "19": {"item_id": "1413321680", "image_id": "19", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/gan.png", "width": "436", "height": "178", "credit": "", "caption": ""}, "20": {"item_id": "1413321680", "image_id": "20", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/lsm.png", "width": "309", "height": "249", "credit": "", "caption": ""}, "21": {"item_id": "1413321680", "image_id": "21", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/elm.png", "width": "311", "height": "249", "credit": "", "caption": ""}, "22": {"item_id": "1413321680", "image_id": "22", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/esn.png", "width": "310", "height": "248", "credit": "", "caption": ""}, "23": {"item_id": "1413321680", "image_id": "23", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/drn.png", "width": "530", "height": "135", "credit": "", "caption": ""}, "24": {"item_id": "1413321680", "image_id": "24", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/ntm.png", "width": "376", "height": "271", "credit": "", "caption": ""}, "25": {"item_id": "1413321680", "image_id": "25", "src": "https://www.asimovinstitute.org/wp-content/uploads/2019/04/DMC.png", "width": "563", "height": "355", "credit": "", "caption": ""}, "26": {"item_id": "1413321680", "image_id": "26", "src": "https://www.asimovinstitute.org/wp-content/uploads/2019/04/CN.png", "width": "597", "height": "338", "credit": "", "caption": ""}, "27": {"item_id": "1413321680", "image_id": "27", "src": "https://www.asimovinstitute.org/wp-content/uploads/2016/09/kn.png", "width": "275", "height": "210", "credit": "", "caption": ""}, "28": {"item_id": "1413321680", "image_id": "28", "src": "https://www.asimovinstitute.org/wp-content/uploads/2019/04/AN.png", "width": "597", "height": "300", "credit": "", "caption": ""}}, "listen_duration_estimate": 2043}, "3099352410": {"item_id": "3099352410", "resolved_id": "3099352438", "given_url": "https://towardsdatascience.com/the-ultimate-guide-to-transfer-learning-ebf83b655391?source=rss----7f60cf5620c9---4", "given_title": "The Ultimate Guide to Transfer Learning", "favorite": "0", "status": "1", "time_added": "1599070173", "time_updated": "1638708525", "time_read": "1604958811", "time_favorited": "0", "sort_id": 435, "resolved_title": "The Ultimate Guide to Transfer Learning", "resolved_url": "https://towardsdatascience.com/the-ultimate-guide-to-transfer-learning-ebf83b655391", "excerpt": "Transfer learning is a widely used technique in the Machine Learning world, mostly in Computer Vision and Natural Language Processing. In this post, we will explain what it is in detail, when it should be used, why it is relevant, and show how you can use it in your own projects.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1862", "lang": "en", "time_to_read": 8, "top_image_url": "https://miro.medium.com/max/1200/1*v61IU9MPRuPRWIGX4f1Uew.jpeg", "tags": {"deep-learning": {"item_id": "3099352410", "tag": "deep-learning"}}, "authors": {"152924123": {"item_id": "3099352410", "author_id": "152924123", "name": "z_ai", "url": "https://z-ai.medium.com"}}, "image": {"item_id": "3099352410", "src": "https://miro.medium.com/fit/c/56/56/1*73cd7jMvl7Mj-FEotDLG6g.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3099352410", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*73cd7jMvl7Mj-FEotDLG6g.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3099352410", "image_id": "2", "src": "https://miro.medium.com/max/7928/1*v61IU9MPRuPRWIGX4f1Uew.jpeg", "width": "3964", "height": "2643", "credit": "", "caption": "Image from Unsplash"}, "3": {"item_id": "3099352410", "image_id": "3", "src": "https://miro.medium.com/max/2000/1*eC1NDw1ApoqUcDpGFcJmtw.png", "width": "1000", "height": "314", "credit": "", "caption": "Intuition of transfer learning with an easy example. Image by author."}, "4": {"item_id": "3099352410", "image_id": "4", "src": "https://miro.medium.com/max/1400/1*d0kxRvYRhUsvQJ2giGkGEg.png", "width": "700", "height": "428", "credit": "", "caption": "Using Transfer learning on a network trained on the COCO dataset to detect different sweets. Source Images from Unsplash."}, "5": {"item_id": "3099352410", "image_id": "5", "src": "https://miro.medium.com/max/1400/1*PcLamlXUuEnMvnCwQkiI2g.png", "width": "700", "height": "456", "credit": "", "caption": "Replacing the output layer with new head layers. Source networks from dair.ai"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 721}, "4005466827": {"item_id": "4005466827", "resolved_id": "4005466827", "given_url": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/", "given_title": "Thinking about High-Quality Human Data | Lil'Log", "favorite": "0", "status": "1", "time_added": "1707567381", "time_updated": "1708574631", "time_read": "1708574631", "time_favorited": "0", "sort_id": 436, "resolved_title": "Thinking about High-Quality Human Data", "resolved_url": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/", "excerpt": "High-quality data is the fuel for modern data deep learning model training. Most of the task-specific labeled data comes from human annotation, such as classification task or RLHF labeling (which can be constructed as classification format) for LLM alignment training.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4257", "lang": "en", "time_to_read": 19, "tags": {"deep-learning": {"item_id": "4005466827", "tag": "deep-learning"}, "labeling": {"item_id": "4005466827", "tag": "labeling"}}, "authors": {"76470090": {"item_id": "4005466827", "author_id": "76470090", "name": "Lilian Weng", "url": ""}}, "image": {"item_id": "4005466827", "src": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/overview.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "4005466827", "image_id": "1", "src": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/overview.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "4005466827", "image_id": "2", "src": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/qualit_assurance.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "4005466827", "image_id": "3", "src": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/AMT_exp.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "4005466827", "image_id": "4", "src": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/topic_agreement.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "5": {"item_id": "4005466827", "image_id": "5", "src": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/taxonomy.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "6": {"item_id": "4005466827", "image_id": "6", "src": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/multi_annotator_model.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "7": {"item_id": "4005466827", "image_id": "7", "src": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/jury.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "8": {"item_id": "4005466827", "image_id": "8", "src": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/jury_model.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "9": {"item_id": "4005466827", "image_id": "9", "src": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/jury_exp.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "10": {"item_id": "4005466827", "image_id": "10", "src": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/influence.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "11": {"item_id": "4005466827", "image_id": "11", "src": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/data_map.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "12": {"item_id": "4005466827", "image_id": "12", "src": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/flip_exp.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "13": {"item_id": "4005466827", "image_id": "13", "src": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/AUM_threshold.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "14": {"item_id": "4005466827", "image_id": "14", "src": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/AUM_exp.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "15": {"item_id": "4005466827", "image_id": "15", "src": "https://lilianweng.github.io/posts/2024-02-05-human-data-quality/INCV_algo.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 1648}, "2188057276": {"item_id": "2188057276", "resolved_id": "2188057276", "given_url": "https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515", "given_title": "To Build Truly Intelligent Machines, Teach Them Cause and Effect | Quanta M", "favorite": "0", "status": "1", "time_added": "1672795201", "time_updated": "1709152706", "time_read": "1672923083", "time_favorited": "0", "sort_id": 437, "resolved_title": "To Build Truly Intelligent Machines, Teach Them Cause and Effect", "resolved_url": "https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515/", "excerpt": "Judea Pearl, a pioneering figure in artificial intelligence, argues that AI has been stuck in a decades-long rut. His prescription for progress? Teach machines to understand the question why. Introduction Artificial intelligence owes a lot of its smarts to Judea Pearl.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1960", "lang": "en", "time_to_read": 9, "top_image_url": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2018/05/Pearl_520x292.jpg", "tags": {"books": {"item_id": "2188057276", "tag": "books"}, "deep-learning": {"item_id": "2188057276", "tag": "deep-learning"}, "neurology": {"item_id": "2188057276", "tag": "neurology"}}, "authors": {"33895555": {"item_id": "2188057276", "author_id": "33895555", "name": "Kevin Hartnett", "url": "https://www.quantamagazine.org/authors/kevin-hartnett/"}}, "image": {"item_id": "2188057276", "src": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2018/05/JudeaPearl_02_2880x1820.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2188057276", "image_id": "1", "src": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2018/05/JudeaPearl_02_2880x1820.jpg", "width": "0", "height": "0", "credit": "", "caption": "Monica Almeida for Quanta Magazine"}, "2": {"item_id": "2188057276", "image_id": "2", "src": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2018/05/BookofWhy_2K.jpg", "width": "0", "height": "0", "credit": "", "caption": "Monica Almeida for Quanta Magazine"}, "3": {"item_id": "2188057276", "image_id": "3", "src": "https://d2r55xnwy6nx47.cloudfront.net/uploads/2018/05/Pearl_Library_2880x1920.jpg", "width": "0", "height": "0", "credit": "", "caption": "Monica Almeida for Quanta Magazine"}}, "domain_metadata": {"name": "Quanta Magazine", "logo": "https://logo.clearbit.com/quantamagazine.org?size=800", "greyscale_logo": "https://logo.clearbit.com/quantamagazine.org?size=800&greyscale=true"}, "listen_duration_estimate": 759}, "3324767457": {"item_id": "3324767457", "resolved_id": "3324767457", "given_url": "https://dev.to/stokry/top-5-python-libraries-for-computer-vision-47ga", "given_title": "Top 5 Python libraries for Computer vision", "favorite": "0", "status": "1", "time_added": "1620315321", "time_updated": "1706833159", "time_read": "1620401401", "time_favorited": "0", "sort_id": 438, "resolved_title": "Top 5 Python libraries for Computer vision", "resolved_url": "https://dev.to/stokry/top-5-python-libraries-for-computer-vision-47ga", "excerpt": "Computer vision is the field of computer science that focuses on replicating parts of the complexity of the human visual system and enabling computers to identify and process objects in images and videos in the same way that humans do.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "424", "lang": "en", "top_image_url": "https://res.cloudinary.com/practicaldev/image/fetch/s--HSLkb7Yo--/c_imagga_scale,f_auto,fl_progressive,h_500,q_66,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/0qrkw79dpm95yxooymed.gif", "tags": {"deep-learning": {"item_id": "3324767457", "tag": "deep-learning"}, "machine-vision": {"item_id": "3324767457", "tag": "machine-vision"}, "programming": {"item_id": "3324767457", "tag": "programming"}, "python": {"item_id": "3324767457", "tag": "python"}}, "authors": {"19165162": {"item_id": "3324767457", "author_id": "19165162", "name": "may 6", "url": ""}, "65419642": {"item_id": "3324767457", "author_id": "65419642", "name": "stokry", "url": ""}, "149123214": {"item_id": "3324767457", "author_id": "149123214", "name": "„Éª2 min read", "url": ""}}, "image": {"item_id": "3324767457", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--92Zm0Q6B--/c_imagga_scale,f_auto,fl_progressive,h_420,q_66,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/0qrkw79dpm95yxooymed.gif", "width": "1000", "height": "420"}, "images": {"1": {"item_id": "3324767457", "image_id": "1", "src": "https://res.cloudinary.com/practicaldev/image/fetch/s--92Zm0Q6B--/c_imagga_scale,f_auto,fl_progressive,h_420,q_66,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/0qrkw79dpm95yxooymed.gif", "width": "1000", "height": "420", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The Practical Dev", "logo": "https://logo.clearbit.com/dev.to?size=800", "greyscale_logo": "https://logo.clearbit.com/dev.to?size=800&greyscale=true"}, "listen_duration_estimate": 164}, "2952033401": {"item_id": "2952033401", "resolved_id": "2952025885", "given_url": "https://towardsdatascience.com/topic-modeling-articles-with-nmf-8c6b2a227a45?source=rss----7f60cf5620c9---4", "given_title": "Topic Modeling Articles with NMF", "favorite": "0", "status": "1", "time_added": "1587050425", "time_updated": "1638708525", "time_read": "1587304791", "time_favorited": "0", "sort_id": 439, "resolved_title": "Topic Modeling Articles with NMF", "resolved_url": "https://towardsdatascience.com/topic-modeling-articles-with-nmf-8c6b2a227a45", "excerpt": "Extracting topics is a good unsupervised data-mining technique to discover the underlying relationships between texts. There are many different approaches with the most popular probably being LDA but I‚Äôm going to focus on NMF.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2564", "lang": "en", "time_to_read": 12, "top_image_url": "https://miro.medium.com/max/1200/1*oAwFKQm3DJG_heudbBOY0Q.jpeg", "tags": {"deep-learning": {"item_id": "2952033401", "tag": "deep-learning"}, "nlp": {"item_id": "2952033401", "tag": "nlp"}}, "authors": {"105620742": {"item_id": "2952033401", "author_id": "105620742", "name": "Rob Salgado", "url": "https://medium.com/@robert.salgado"}}, "image": {"item_id": "2952033401", "src": "https://miro.medium.com/fit/c/56/56/1*Xu5jY5MRE7KW8GBlfAhSUA.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2952033401", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*Xu5jY5MRE7KW8GBlfAhSUA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2952033401", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*oAwFKQm3DJG_heudbBOY0Q.jpeg", "width": "700", "height": "465", "credit": "Romain Vignes on Unsplash", "caption": ""}, "3": {"item_id": "2952033401", "image_id": "3", "src": "https://miro.medium.com/max/1400/1*vX2vG1G-6VxCfiWMbCBzOw.png", "width": "700", "height": "113", "credit": "", "caption": ""}, "4": {"item_id": "2952033401", "image_id": "4", "src": "https://miro.medium.com/max/1220/1*4sMcsbQsunalnAXp3roVkw.png", "width": "610", "height": "334", "credit": "", "caption": ""}, "5": {"item_id": "2952033401", "image_id": "5", "src": "https://miro.medium.com/max/566/1*mOK2MrHS1rz7v7sE06mitA.png", "width": "283", "height": "522", "credit": "", "caption": ""}, "6": {"item_id": "2952033401", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*T21E6myryrjVUwiz_-VYNg.png", "width": "700", "height": "294", "credit": "", "caption": ""}, "7": {"item_id": "2952033401", "image_id": "7", "src": "https://miro.medium.com/max/1400/1*F1-YC081ESgrFWDo50zO5Q.png", "width": "700", "height": "321", "credit": "", "caption": ""}, "8": {"item_id": "2952033401", "image_id": "8", "src": "https://miro.medium.com/max/1400/1*fzl-78rF_NwTHyL_69amcg.png", "width": "700", "height": "350", "credit": "", "caption": ""}, "9": {"item_id": "2952033401", "image_id": "9", "src": "https://miro.medium.com/max/1400/1*5soiJmDbTcTTOd1HdeEmJg.png", "width": "700", "height": "154", "credit": "", "caption": ""}, "10": {"item_id": "2952033401", "image_id": "10", "src": "https://miro.medium.com/max/1400/1*vVAKSfQ1seqHUsqfK79Z-g.png", "width": "700", "height": "110", "credit": "", "caption": ""}, "11": {"item_id": "2952033401", "image_id": "11", "src": "https://miro.medium.com/max/1400/1*V_pbHaRBxXXrYgg2C4Hnjw.png", "width": "700", "height": "269", "credit": "", "caption": ""}, "12": {"item_id": "2952033401", "image_id": "12", "src": "https://miro.medium.com/max/1400/1*HYJrhAJURPijbGwLkDb__w.png", "width": "700", "height": "105", "credit": "", "caption": ""}, "13": {"item_id": "2952033401", "image_id": "13", "src": "https://miro.medium.com/max/1400/1*j1pzP4-qAF7Y6twRVL5hAA.png", "width": "700", "height": "105", "credit": "", "caption": ""}, "14": {"item_id": "2952033401", "image_id": "14", "src": "https://miro.medium.com/max/1400/1*Wuep5qPclSYqZZ2AKktvhw.png", "width": "700", "height": "106", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 993}, "2117687217": {"item_id": "2117687217", "resolved_id": "2117687217", "given_url": "https://github.com/topics/computer-vision", "given_title": "Topic: computer-vision", "favorite": "0", "status": "1", "time_added": "1521292788", "time_updated": "1638708525", "time_read": "1526153076", "time_favorited": "0", "sort_id": 440, "resolved_title": "computer-vision", "resolved_url": "https://github.com/topics/computer-vision", "excerpt": "computer-vision Loading‚Ä¶ opencv / opencv 23k Open Source Computer Vision Library opencv c-plus-plus computer-vision deep-learning image-processing C++ Updated Mar 17, 2018 5 issues need help  Developer-Y / cs-video-courses 11.4k List of Computer Science courses with video lectures.", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "798", "lang": "en", "time_to_read": 4, "top_image_url": "https://assets-cdn.github.com/images/modules/open_graph/github-logo.png", "tags": {"deep-learning": {"item_id": "2117687217", "tag": "deep-learning"}, "vision": {"item_id": "2117687217", "tag": "vision"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 309}, "1801210691": {"item_id": "1801210691", "resolved_id": "1801210691", "given_url": "https://hackernoon.com/training-your-deep-model-faster-and-sharper-e85076c3b047", "given_title": "Train your deep model faster and sharper ‚Äî two novel techniques", "favorite": "0", "status": "1", "time_added": "1499210094", "time_updated": "1638708525", "time_read": "1514398144", "time_favorited": "0", "sort_id": 441, "resolved_title": "Train your deep model faster and sharper‚Ää‚Äî‚Äätwo novel techniques", "resolved_url": "https://hackernoon.com/training-your-deep-model-faster-and-sharper-e85076c3b047", "excerpt": "Deep neural networks have many, many learnable parameters that are used to make inferences. Often, this poses a problem in two ways: Sometimes, the model does not make very accurate predictions. It also takes a long time to train them.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1498", "lang": "en", "time_to_read": 7, "top_image_url": "https://cdn.hackernoon.com/Devimg/story-image-default.png", "tags": {"deep-learning": {"item_id": "1801210691", "tag": "deep-learning"}}, "authors": {"42672014": {"item_id": "1801210691", "author_id": "42672014", "name": "harshvardhan gupta", "url": ""}}, "image": {"item_id": "1801210691", "src": "https://hackernoon.com/hn-images/1*4CWM6vRBH8SGLd5ii7zahA.jpeg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "1801210691", "image_id": "1", "src": "https://hackernoon.com/hn-images/1*4CWM6vRBH8SGLd5ii7zahA.jpeg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "1801210691", "image_id": "2", "src": "https://hackernoon.com/hn-images/1*T5WWecP_EaQWk1yDX15h_w.png", "width": "0", "height": "0", "credit": "which are labelled 1,2,3", "caption": "Figure 1.0: Left: standard SGD trying to find the best local minima. Right: SGD is made to fall into a local minima, then brought back up, and the process is repeated. This way you get 3"}, "3": {"item_id": "1801210691", "image_id": "3", "src": "https://hackernoon.com/hn-images/1*XA3yX6VSeAr91WCA-FtJTQ.png", "width": "0", "height": "0", "credit": "", "caption": "Figure1.0"}, "4": {"item_id": "1801210691", "image_id": "4", "src": "https://hackernoon.com/hn-images/1*S3NpdnSPHmfIURoLU-NuDg.png", "width": "0", "height": "0", "credit": "", "caption": "Figure1.1 M=6¬†, and Budget=300 epochs. The vertical dotted lines indicate a model snapshot. After 300 epochs a total of 6 models were added to the ensemble."}, "5": {"item_id": "1801210691", "image_id": "5", "src": "https://hackernoon.com/hn-images/1*Frr5uavuG2jlzgJtBGo59w.png", "width": "0", "height": "0", "credit": "%", "caption": "Figure1.2 Error Rates"}, "6": {"item_id": "1801210691", "image_id": "6", "src": "https://hackernoon.com/hn-images/1*qBDzgj0ZbLEUMbssF5CVag.png", "width": "0", "height": "0", "credit": "", "caption": "Equation 2.0: Œ± is the learning rate. t is the iteration number. i denotes the ith layer of the¬†model"}, "7": {"item_id": "1801210691", "image_id": "7", "src": "https://hackernoon.com/hn-images/1*obqh_b33HU1zJdBFBWE3Rg.png", "width": "0", "height": "0", "credit": "", "caption": "Equation 2.1"}, "8": {"item_id": "1801210691", "image_id": "8", "src": "https://hackernoon.com/hn-images/1*1BjuzHsXGSiWjbrXVElREw.png", "width": "0", "height": "0", "credit": "", "caption": "Figure2.0"}, "9": {"item_id": "1801210691", "image_id": "9", "src": "https://hackernoon.com/hn-images/1*6wDiOD9Y7FGWUAcCfvbZEA.png", "width": "0", "height": "0", "credit": "", "caption": "Figure2.1: Performance vs Error on¬†DenseNet"}}, "domain_metadata": {"name": "Hacker Noon", "logo": "https://logo.clearbit.com/hackernoon.com?size=800", "greyscale_logo": "https://logo.clearbit.com/hackernoon.com?size=800&greyscale=true"}, "listen_duration_estimate": 580}, "2998912099": {"item_id": "2998912099", "resolved_id": "2998912150", "given_url": "https://towardsdatascience.com/transformers-for-multilabel-classification-71a1a0daf5e1?source=rss----7f60cf5620c9---4", "given_title": "Transformers for Multilabel Classification", "favorite": "0", "status": "1", "time_added": "1590746925", "time_updated": "1638708525", "time_read": "1591029781", "time_favorited": "0", "sort_id": 442, "resolved_title": "Transformers for Multilabel Classification made simple.", "resolved_url": "https://towardsdatascience.com/transformers-for-multilabel-classification-71a1a0daf5e1", "excerpt": "As a data scientist who has been learning the state of the art for text classification, I found that there are not many easy examples to adapt transformers (BERT, XLNet, etc.) for multilabel classification‚Ä¶so I decided to try for myself and here it is!", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "859", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/max/1186/1*xHW9r3ijUtTCYDZ7QO5jrg.jpeg", "tags": {"deep-learning": {"item_id": "2998912099", "tag": "deep-learning"}}, "authors": {"134832399": {"item_id": "2998912099", "author_id": "134832399", "name": "Ronak Patel", "url": "https://medium.com/@ronakpatel12391"}}, "image": {"item_id": "2998912099", "src": "https://miro.medium.com/fit/c/56/56/1*GKSv2fY3-Oi69qhgAq8AjQ.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2998912099", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*GKSv2fY3-Oi69qhgAq8AjQ.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2998912099", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*xHW9r3ijUtTCYDZ7QO5jrg.jpeg", "width": "700", "height": "587", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 333}, "2367584405": {"item_id": "2367584405", "resolved_id": "2367584405", "given_url": "http://www.knowablemagazine.org/article/technology/2018/truly-neurally-deeply", "given_title": "Truly, neurally, deeply", "favorite": "0", "status": "1", "time_added": "1540601688", "time_updated": "1709152706", "time_read": "1540695410", "time_favorited": "0", "sort_id": 443, "resolved_title": "", "resolved_url": "https://knowablemagazine.org/article/technology/2018/truly-neurally-deeply", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"deep-learning": {"item_id": "2367584405", "tag": "deep-learning"}, "exercise-health-medicine": {"item_id": "2367584405", "tag": "exercise-health-medicine"}, "neurology": {"item_id": "2367584405", "tag": "neurology"}}, "listen_duration_estimate": 0}, "2880544412": {"item_id": "2880544412", "resolved_id": "2880544412", "given_url": "https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/", "given_title": "Turing-NLG: A 17-billion-parameter language model by Microsoft", "favorite": "0", "status": "1", "time_added": "1581361608", "time_updated": "1638708525", "time_read": "1582142562", "time_favorited": "0", "sort_id": 444, "resolved_title": "Turing-NLG: A 17-billion-parameter language model by Microsoft", "resolved_url": "https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/", "excerpt": "This figure was adapted from a similar image published in DistilBERT. Turing Natural Language Generation (T-NLG) is a 17 billion parameter language model by Microsoft that outperforms the state of the art on many downstream NLP tasks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1875", "lang": "en", "time_to_read": 9, "top_image_url": "https://www.microsoft.com/en-us/research/uploads/prod/2020/02/TurningNGL_Model__1400x788-5e418cff76a2a.png", "tags": {"deep-learning": {"item_id": "2880544412", "tag": "deep-learning"}, "nlp": {"item_id": "2880544412", "tag": "nlp"}}, "authors": {"152310267": {"item_id": "2880544412", "author_id": "152310267", "name": "View", "url": "https://www.microsoft.com/en-us/research/people/corosset/"}}, "image": {"item_id": "2880544412", "src": "https://www.microsoft.com/en-us/research/uploads/prod/2019/01/Ada-Lovelace-PhD-Fellowship_AD_Site_01_2019_1400x788.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "2880544412", "image_id": "1", "src": "https://www.microsoft.com/en-us/research/uploads/prod/2019/01/Ada-Lovelace-PhD-Fellowship_AD_Site_01_2019_1400x788.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "2880544412", "image_id": "2", "src": "https://www.microsoft.com/en-us/research/uploads/prod/2020/02/Turing-Table-4.jpg", "width": "859", "height": "148", "credit": "", "caption": ""}, "3": {"item_id": "2880544412", "image_id": "3", "src": "https://www.microsoft.com/en-us/research/uploads/prod/2020/02/Turing-Table-Update.jpg", "width": "1409", "height": "459", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Microsoft", "logo": "https://logo.clearbit.com/microsoft.com?size=800", "greyscale_logo": "https://logo.clearbit.com/microsoft.com?size=800&greyscale=true"}, "listen_duration_estimate": 726}, "3788268337": {"item_id": "3788268337", "resolved_id": "3788268356", "given_url": "https://towardsdatascience.com/uncovering-anomalies-with-variational-autoencoders-vae-a-deep-dive-into-the-world-of-1b2bce47e2e9?source=rss----7f60cf5620c9---4", "given_title": "Uncovering Anomalies with Variational Autoencoders (VAE): A Deep Dive into ", "favorite": "0", "status": "1", "time_added": "1673946278", "time_updated": "1673966479", "time_read": "1673966479", "time_favorited": "0", "sort_id": 445, "resolved_title": "Uncovering Anomalies with Variational Autoencoders (VAE): A Deep Dive into the World of Unsupervised Learning", "resolved_url": "https://towardsdatascience.com/uncovering-anomalies-with-variational-autoencoders-vae-a-deep-dive-into-the-world-of-1b2bce47e2e9", "excerpt": "In an earlier post, I explained what autoencoders are, what they are used for and how to leverage them in training an anomaly detection model. As a reminder, autoencoders are a type of neural network that are commonly used for dimensionality reduction and learning features.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "2067", "lang": "en", "time_to_read": 9, "top_image_url": "https://miro.medium.com/max/1200/0*M_N58YhhzOwbzxJz", "tags": {"autoencoders": {"item_id": "3788268337", "tag": "autoencoders"}, "deep-learning": {"item_id": "3788268337", "tag": "deep-learning"}, "variational": {"item_id": "3788268337", "tag": "variational"}}, "authors": {"103200589": {"item_id": "3788268337", "author_id": "103200589", "name": "Will Badr", "url": "https://medium.com/@will.badr"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 800}, "3994042168": {"item_id": "3994042168", "resolved_id": "3993994031", "given_url": "https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention?publication_id=1174659&post_id=140464659&isFreemail=true&r=oc5d", "given_title": "Understanding and Coding Self-Attention, Multi-Head Attention, Cross-Attent", "favorite": "0", "status": "1", "time_added": "1705247239", "time_updated": "1706235121", "time_read": "1705394604", "time_favorited": "0", "sort_id": 446, "resolved_title": "Understanding and Coding Self-Attention, Multi-Head Attention, Cross-Attention, and Causal-Attention in LLMs", "resolved_url": "https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention", "excerpt": "This article will teach you about self-attention mechanisms used in transformer architectures and large language models (LLMs) such as GPT-4 and Llama. Self-attention and related mechanisms are core components of LLMs, making them a useful topic to understand when working with these models.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4775", "lang": "en", "time_to_read": 22, "top_image_url": "https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69bfee26-ea3b-42a6-8a1a-6b8187852082_738x564.png", "tags": {"deep-learning": {"item_id": "3994042168", "tag": "deep-learning"}, "llms": {"item_id": "3994042168", "tag": "llms"}}, "authors": {"66098": {"item_id": "3994042168", "author_id": "66098", "name": "DK", "url": ""}}, "image": {"item_id": "3994042168", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97567e7b-f8b9-4dea-a678-162378609a75_1304x1150.png", "width": "426", "height": "376"}, "images": {"1": {"item_id": "3994042168", "image_id": "1", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F97567e7b-f8b9-4dea-a678-162378609a75_1304x1150.png", "width": "426", "height": "376", "credit": "", "caption": "The original transformer architecture from https://arxiv.org/abs/1706.03762"}, "2": {"item_id": "3994042168", "image_id": "2", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d632b81-5bd6-432a-a456-37f20788be20_1180x614.png", "width": "432", "height": "225", "credit": "top", "caption": "An incorrect word-by-word translation"}, "3": {"item_id": "3994042168", "image_id": "3", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecef3e00-4c0e-4c7a-9a9f-42ac4e4ada69_366x786.png", "width": "174", "height": "374", "credit": "", "caption": "Computing the query, key, and value vectors via the input x and weights W."}, "4": {"item_id": "3994042168", "image_id": "4", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9774001-ea9d-48bf-9857-3c911b0a279d_588x962.png", "width": "192", "height": "314", "credit": "2", "caption": "For the following sections below, we focus on the second input, x"}, "5": {"item_id": "3994042168", "image_id": "5", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbaf9e308-223b-429e-8527-a7b868003e8c_814x912.png", "width": "296", "height": "332", "credit": "omega", "caption": "Computing the unnormalized attention weights œâ"}, "6": {"item_id": "3994042168", "image_id": "6", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42da287a-18e8-45c7-860c-46e8a3a534fc_1400x798.png", "width": "578", "height": "329", "credit": "", "caption": "Computing the normalized attention weights Œ±"}, "7": {"item_id": "3994042168", "image_id": "7", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e1dcdeb-e096-4ff9-bdf9-3338e4efa4b4_1916x1048.png", "width": "664", "height": "363", "credit": "2", "caption": "The attention weights are specific to a certain input element. Here, we chose input element x"}, "8": {"item_id": "3994042168", "image_id": "8", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F57269a7a-8ecc-4ed6-b6d7-79a9982dd776_918x1152.png", "width": "384", "height": "482", "credit": "", "caption": "The multi-head attention modules in the original transformer architecture from https://arxiv.org/abs/1706.03762"}, "9": {"item_id": "3994042168", "image_id": "9", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7651e279-01ed-4316-91dc-d6be8ef4e947_1836x1116.png", "width": "500", "height": "304", "credit": "", "caption": "Summarizing the self-attention mechanism implemented previously"}, "10": {"item_id": "3994042168", "image_id": "10", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff406d55e-990a-4e3b-be82-d966eb74a3e7_1766x1154.png", "width": "526", "height": "344", "credit": "", "caption": "Multi-head attention: self-attention with multiple heads"}, "11": {"item_id": "3994042168", "image_id": "11", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb75a8df1-0a82-4f79-8e68-4fe16587063d_1474x1108.png", "width": "636", "height": "478", "credit": "", "caption": "Another view of the self-attention mechanism implemented previously, with a focus on the matrix dimensions"}, "12": {"item_id": "3994042168", "image_id": "12", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9057444e-4934-4253-bc91-9e768d23b0c2_846x972.png", "width": "354", "height": "407", "credit": "", "caption": ""}, "13": {"item_id": "3994042168", "image_id": "13", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa16d2bd0-984d-4224-9c4c-2f0cc144a599_1520x1108.png", "width": "624", "height": "455", "credit": "", "caption": ""}, "14": {"item_id": "3994042168", "image_id": "14", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb4dfd356-1cfa-4601-a05d-57bc15024970_1204x590.png", "width": "620", "height": "304", "credit": "", "caption": ""}, "15": {"item_id": "3994042168", "image_id": "15", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc51bfe11-c2cf-4ce5-95d4-4f8a57eac997_1026x1148.png", "width": "372", "height": "416", "credit": "via ‚ÄúAttention Is All You Need‚Äù, https://arxiv.org/abs/1706.03762", "caption": "The causal self-attention module in the original transformer architecture"}, "16": {"item_id": "3994042168", "image_id": "16", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7dd5ec8-4912-4e0d-8265-b335c08d2958_1760x1126.png", "width": "518", "height": "332", "credit": "", "caption": ""}, "17": {"item_id": "3994042168", "image_id": "17", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe1317a05-3542-4158-94bf-085109a5793a_1220x702.png", "width": "516", "height": "297", "credit": "", "caption": "Attention weights above the diagonal should be masked out"}, "18": {"item_id": "3994042168", "image_id": "18", "src": "https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fffe26c66-1da3-44fa-972b-7a2d4c9c6bf2_355x439.jpeg", "width": "219", "height": "271", "credit": "", "caption": "Build a Large Language Model book cover"}}, "listen_duration_estimate": 1848}, "2965467555": {"item_id": "2965467555", "resolved_id": "2965467574", "given_url": "https://towardsdatascience.com/understanding-associative-embedding-1b22677751f3?source=rss----7f60cf5620c9---4", "given_title": "Understanding Associative Embedding", "favorite": "0", "status": "1", "time_added": "1588088520", "time_updated": "1706233547", "time_read": "1589922083", "time_favorited": "0", "sort_id": 447, "resolved_title": "Understanding Associative Embedding", "resolved_url": "https://towardsdatascience.com/understanding-associative-embedding-1b22677751f3", "excerpt": "In some tasks of computer vision and deep learning, we need to predict all the results first and then split the results to several individual results.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "667", "lang": "en", "time_to_read": 3, "top_image_url": "https://miro.medium.com/max/1200/0*BWknDjcI00-udQlD", "tags": {"algorithms-math": {"item_id": "2965467555", "tag": "algorithms-math"}, "deep-learning": {"item_id": "2965467555", "tag": "deep-learning"}, "machine-learning": {"item_id": "2965467555", "tag": "machine-learning"}, "vision": {"item_id": "2965467555", "tag": "vision"}}, "authors": {"125021155": {"item_id": "2965467555", "author_id": "125021155", "name": "Shuchen Du", "url": "https://towardsdatascience.com/@dushuchen"}}, "image": {"item_id": "2965467555", "src": "https://miro.medium.com/fit/c/96/96/1*4xJpqeNstDW1l3Iae-TaBQ@2x.jpeg", "width": "48", "height": "48"}, "images": {"1": {"item_id": "2965467555", "image_id": "1", "src": "https://miro.medium.com/fit/c/96/96/1*4xJpqeNstDW1l3Iae-TaBQ@2x.jpeg", "width": "48", "height": "48", "credit": "", "caption": ""}, "2": {"item_id": "2965467555", "image_id": "2", "src": "https://miro.medium.com/max/9792/0*BWknDjcI00-udQlD", "width": "4896", "height": "3264", "credit": "Alex Alvarez on Unsplash", "caption": ""}, "3": {"item_id": "2965467555", "image_id": "3", "src": "https://miro.medium.com/max/3998/1*vg0rGk7YzcY5iAInSZkfrA.png", "width": "1999", "height": "752", "credit": "Newell et al.", "caption": "Fig. 1: Pose estimation for multi-people"}, "4": {"item_id": "2965467555", "image_id": "4", "src": "https://miro.medium.com/max/1766/1*7zoUiX4zq8ObBdWsI2PDwA.png", "width": "883", "height": "481", "credit": "Law et al.", "caption": "Fig. 2: CornerNet for object detection"}, "5": {"item_id": "2965467555", "image_id": "5", "src": "https://miro.medium.com/max/3152/1*E8n_uSFtNGLagfk2mCtEfw.png", "width": "1576", "height": "691", "credit": "", "caption": "Equ. 1: loss function for learning tag values for associative embedding"}, "6": {"item_id": "2965467555", "image_id": "6", "src": "https://miro.medium.com/max/2652/1*Fz-IPnKX3QXUfSRgpLkJ7Q.png", "width": "1326", "height": "769", "credit": "", "caption": "Fig. 3: explanation of the second item of Equ. 1"}, "7": {"item_id": "2965467555", "image_id": "7", "src": "https://miro.medium.com/max/3670/1*c8Ielujj8xNyntzj3f2KtA.png", "width": "1835", "height": "669", "credit": "Newell et al.", "caption": "Fig. 4: associative embedding for multi-people pose estimation"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 258}, "3674412296": {"item_id": "3674412296", "resolved_id": "3674412296", "given_url": "https://udlbook.github.io/udlbook/", "given_title": "Understanding Deep Learning", "favorite": "0", "status": "1", "time_added": "1697286933", "time_updated": "1697764680", "time_read": "1697764680", "time_favorited": "0", "sort_id": 448, "resolved_title": "Understanding Deep Learning", "resolved_url": "https://udlbook.github.io/udlbook/", "excerpt": "Instructor answer booklet available with proof of credentials via MIT Press. Request an exam/desk copy via MIT Press.", "is_article": "1", "is_index": "1", "has_video": "0", "has_image": "0", "word_count": "290", "lang": "en", "tags": {"books": {"item_id": "3674412296", "tag": "books"}, "deep-learning": {"item_id": "3674412296", "tag": "deep-learning"}, "jupyter": {"item_id": "3674412296", "tag": "jupyter"}}, "listen_duration_estimate": 112}, "3128502933": {"item_id": "3128502933", "resolved_id": "3128502482", "given_url": "https://www.kdnuggets.com/2020/10/understanding-transformers-data-science-way.html", "given_title": "Understanding Transformers, the Data Science Way", "favorite": "0", "status": "1", "time_added": "1601565921", "time_updated": "1638708525", "time_read": "1604361724", "time_favorited": "0", "sort_id": 449, "resolved_title": "Understanding Transformers, the Data Science Way", "resolved_url": "https://www.kdnuggets.com/understanding-transformers-the-data-science-way.html/", "excerpt": "Read this accessible and conversational article about understanding transformers, the data science way ‚Äî by asking a lot of questions that is. Transformers have become the defacto standard for any NLP tasks nowadays.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "4809", "lang": "en", "time_to_read": 22, "top_image_url": "https://miro.medium.com/max/285/0*JCGfOqUEHCrwxNv2.png", "tags": {"deep-learning": {"item_id": "3128502933", "tag": "deep-learning"}}, "authors": {"135174769": {"item_id": "3128502933", "author_id": "135174769", "name": "Rahul Agarwal", "url": "https://www.kdnuggets.com/author/rahul-agarwal"}}, "image": {"item_id": "3128502933", "src": "https://miro.medium.com/max/281/1*c-Q805O7nXg2qcjxb0As4g.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3128502933", "image_id": "1", "src": "https://miro.medium.com/max/281/1*c-Q805O7nXg2qcjxb0As4g.png", "width": "0", "height": "0", "credit": "", "caption": "Source"}, "2": {"item_id": "3128502933", "image_id": "2", "src": "https://miro.medium.com/max/315/1*AACNCkYiRmf3xmZLQsYhLw.png", "width": "0", "height": "0", "credit": "Image by author", "caption": ""}, "3": {"item_id": "3128502933", "image_id": "3", "src": "https://miro.medium.com/max/485/1*nWQcmJkndGnl1gdwmJ2C1g.png", "width": "0", "height": "0", "credit": "", "caption": "Source:¬†Paper"}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 1862}, "3338137195": {"item_id": "3338137195", "resolved_id": "3338137195", "given_url": "https://thenextweb.com/news/understanding-transformers-the-machine-learning-model-behind-gpt-3-machine-learning-ai-syndication", "given_title": "Understanding Transformers, the machine learning model behind GPT-3", "favorite": "0", "status": "1", "time_added": "1621684487", "time_updated": "1671724937", "time_read": "1621693599", "time_favorited": "0", "sort_id": 450, "resolved_title": "Understanding Transformers, the machine learning model behind GPT-3", "resolved_url": "https://thenextweb.com/news/understanding-transformers-the-machine-learning-model-behind-gpt-3-machine-learning-ai-syndication", "excerpt": "You know that expression¬†When you have a hammer, everything looks like a nail? Well, in machine learning, it seems like we really have discovered a magical hammer for which everything is, in fact, a nail, and they‚Äôre called Transformers.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2012", "lang": "en", "time_to_read": 9, "amp_url": "https://thenextweb.com/news/understanding-transformers-the-machine-learning-model-behind-gpt-3-machine-learning-ai-syndication/amp", "top_image_url": "https://img-cdn.tnwcdn.com/image/neural?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2021%2F05%2FAI-Transformers-abstract-hed.jpg&signature=7dad3d13328b212e6fc49afed1eb2819", "tags": {"chatbots": {"item_id": "3338137195", "tag": "chatbots"}, "deep-learning": {"item_id": "3338137195", "tag": "deep-learning"}, "nlp": {"item_id": "3338137195", "tag": "nlp"}, "transformers": {"item_id": "3338137195", "tag": "transformers"}}, "authors": {"64134674": {"item_id": "3338137195", "author_id": "64134674", "name": "Dale Markowitz", "url": ""}}, "image": {"item_id": "3338137195", "src": "https://img-cdn.tnwcdn.com/image?fit=1280%2C720&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2021%2F05%2FAI-Transformers-abstract-hed.jpg&signature=0bc21b935991e6805f4be8f370556d70", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3338137195", "image_id": "1", "src": "https://img-cdn.tnwcdn.com/image?fit=1280%2C720&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2021%2F05%2FAI-Transformers-abstract-hed.jpg&signature=0bc21b935991e6805f4be8f370556d70", "width": "0", "height": "0", "credit": "", "caption": "Image by: Shutterstock"}, "2": {"item_id": "3338137195", "image_id": "2", "src": "https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2021/05/renn.png", "width": "2880", "height": "960", "credit": "RNN", "caption": "A typical Recurrent Neural Network"}, "3": {"item_id": "3338137195", "image_id": "3", "src": "https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2021/05/screen-shot-2021-05-06-at-12.12.21-pm-1.png", "width": "1024", "height": "1416", "credit": "", "caption": "Transformer diagram from the original paper"}}, "domain_metadata": {"name": "The Next Web", "logo": "https://logo.clearbit.com/thenextweb.com?size=800", "greyscale_logo": "https://logo.clearbit.com/thenextweb.com?size=800&greyscale=true"}, "listen_duration_estimate": 779}, "3331157767": {"item_id": "3331157767", "resolved_id": "3331157767", "given_url": "https://acsweb.ucsd.edu/~sasalama/papers/HyperRec.pdf", "given_title": "untitled - HyperRec.pdf", "favorite": "0", "status": "1", "time_added": "1620942739", "time_updated": "1706631486", "time_read": "1620942795", "time_favorited": "0", "sort_id": 451, "resolved_title": "", "resolved_url": "https://acsweb.ucsd.edu/~sasalama/papers/HyperRec.pdf", "excerpt": "", "is_article": "0", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "0", "lang": "", "tags": {"deep-learning": {"item_id": "3331157767", "tag": "deep-learning"}, "fpgas": {"item_id": "3331157767", "tag": "fpgas"}, "recommenders": {"item_id": "3331157767", "tag": "recommenders"}}, "listen_duration_estimate": 0}, "2914608287": {"item_id": "2914608287", "resolved_id": "2914608372", "given_url": "https://towardsdatascience.com/using-snorkel-for-multi-label-annotation-cc2aa217986a?source=rss----7f60cf5620c9---4", "given_title": "Using Snorkel For Multi-Label Annotation.", "favorite": "0", "status": "1", "time_added": "1584121111", "time_updated": "1706833159", "time_read": "1584560588", "time_favorited": "0", "sort_id": 452, "resolved_title": "Using Snorkel For Multi-Label Annotation.", "resolved_url": "https://towardsdatascience.com/using-snorkel-for-multi-label-annotation-cc2aa217986a", "excerpt": "Snorkel is a nice little package that allows us to use labeling functions (LFs) as simple as heuristics or keywords or as complex as algorithms and human annotators in order to create a labeled dataset for the purpose of training a classifier.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1197", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/400/0*ZtVCOooN2oZdFN8o.jpg", "tags": {"deep-learning": {"item_id": "2914608287", "tag": "deep-learning"}, "labeling": {"item_id": "2914608287", "tag": "labeling"}, "programming": {"item_id": "2914608287", "tag": "programming"}}, "authors": {"144859663": {"item_id": "2914608287", "author_id": "144859663", "name": "Ori Cohen", "url": "https://cohenori.medium.com"}}, "image": {"item_id": "2914608287", "src": "https://miro.medium.com/fit/c/56/56/1*OWhySMs6kPA8dWpmqXXzzw.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2914608287", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*OWhySMs6kPA8dWpmqXXzzw.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2914608287", "image_id": "2", "src": "https://miro.medium.com/max/800/0*ZtVCOooN2oZdFN8o.jpg", "width": "400", "height": "400", "credit": "", "caption": "Snorkel by hazyresearch @ Snorkel.org"}, "3": {"item_id": "2914608287", "image_id": "3", "src": "https://miro.medium.com/max/1196/1*pDgOpMzED1c-4uWGQqwChA.png", "width": "598", "height": "548", "credit": "", "caption": "A Kneed Illustration for the highest probabilities."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 463}, "3917153167": {"item_id": "3917153167", "resolved_id": "3917134072", "given_url": "https://towardsdatascience.com/variational-autoencoder-vae-with-discrete-distribution-using-gumbel-softmax-b3f749b3417e?source=rss----7f60cf5620c9---4", "given_title": "Variational Autoencoder (VAE) with Discrete Distribution using Gumbel Softm", "favorite": "0", "status": "1", "time_added": "1691621740", "time_updated": "1691682640", "time_read": "1691682640", "time_favorited": "0", "sort_id": 453, "resolved_title": "Variational Autoencoder (VAE) with Discrete Distribution using Gumbel Softmax", "resolved_url": "https://towardsdatascience.com/variational-autoencoder-vae-with-discrete-distribution-using-gumbel-softmax-b3f749b3417e", "excerpt": "Generative models have become very popular nowadays thanks to their ability to generate novel samples with inherent variability by learning and capturing the underlying probability distribution of the training data.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "292", "lang": "en", "top_image_url": "https://miro.medium.com/v2/resize:fit:640/1*IB22-8qoNpIITYqKA034lQ.png", "tags": {"autoencoders": {"item_id": "3917153167", "tag": "autoencoders"}, "deep-learning": {"item_id": "3917153167", "tag": "deep-learning"}, "generative": {"item_id": "3917153167", "tag": "generative"}, "pytorch": {"item_id": "3917153167", "tag": "pytorch"}}, "authors": {"160244866": {"item_id": "3917153167", "author_id": "160244866", "name": "Alexey Kravets", "url": "https://medium.com/@alexml0123"}}, "image": {"item_id": "3917153167", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*Sk0BsQAVvq8-jQhT9iVrwQ.jpeg", "width": "44", "height": "44"}, "images": {"1": {"item_id": "3917153167", "image_id": "1", "src": "https://miro.medium.com/v2/resize:fill:88:88/1*Sk0BsQAVvq8-jQhT9iVrwQ.jpeg", "width": "44", "height": "44", "credit": "", "caption": ""}, "2": {"item_id": "3917153167", "image_id": "2", "src": "https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg", "width": "24", "height": "24", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 113}, "2910094699": {"item_id": "2910094699", "resolved_id": "2910094780", "given_url": "https://towardsdatascience.com/variational-autoencoders-63191b75c576?source=rss----7f60cf5620c9---4", "given_title": "Variational Autoencoders", "favorite": "0", "status": "1", "time_added": "1583778357", "time_updated": "1638708525", "time_read": "1583784755", "time_favorited": "0", "sort_id": 454, "resolved_title": "Variational Autoencoders", "resolved_url": "https://towardsdatascience.com/variational-autoencoders-63191b75c576", "excerpt": "So, I have been asked to explain Variational Autoencoders (VAE) about five times in the past two years during machine learning interviews. For a certain company, the question was actually repeated by two separate interviewers in the same day.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1439", "lang": "en", "time_to_read": 7, "tags": {"deep-learning": {"item_id": "2910094699", "tag": "deep-learning"}}, "authors": {"151313629": {"item_id": "2910094699", "author_id": "151313629", "name": "Sean Billings ML", "url": "https://sean-billings-ml.medium.com"}}, "image": {"item_id": "2910094699", "src": "https://miro.medium.com/fit/c/56/56/2*abivbauK-ZseDrJMoev2og.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "2910094699", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*abivbauK-ZseDrJMoev2og.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "2910094699", "image_id": "2", "src": "https://miro.medium.com/max/752/1*U4sgcl6DT6-abPh4cWKqSQ.png", "width": "376", "height": "92", "credit": "", "caption": ""}, "3": {"item_id": "2910094699", "image_id": "3", "src": "https://miro.medium.com/max/1336/1*QezyKqQjLhJ0CZ9pi1-RqQ.png", "width": "668", "height": "102", "credit": "", "caption": ""}, "4": {"item_id": "2910094699", "image_id": "4", "src": "https://miro.medium.com/max/1080/1*FSL16sHoKSBdD-lC-dih-w.png", "width": "540", "height": "94", "credit": "", "caption": ""}, "5": {"item_id": "2910094699", "image_id": "5", "src": "https://miro.medium.com/max/912/1*ZitYiLVgOtvcMjKmAPbprw.png", "width": "456", "height": "70", "credit": "", "caption": ""}, "6": {"item_id": "2910094699", "image_id": "6", "src": "https://miro.medium.com/max/1400/1*mEQJZrJN05h27ElKViCV-w.png", "width": "700", "height": "54", "credit": "", "caption": ""}, "7": {"item_id": "2910094699", "image_id": "7", "src": "https://miro.medium.com/max/1248/1*6XNjDKOPeRokaCHomU9RZg.png", "width": "624", "height": "54", "credit": "", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 557}, "2992941024": {"item_id": "2992941024", "resolved_id": "2992941053", "given_url": "https://towardsdatascience.com/virtual-background-in-webcam-with-body-segmentation-technique-fc8106ca3038?source=rss----7f60cf5620c9---4", "given_title": "Virtual Background in Webcam with Body Segmentation Technique", "favorite": "0", "status": "1", "time_added": "1590233895", "time_updated": "1638708525", "time_read": "1591029912", "time_favorited": "0", "sort_id": 455, "resolved_title": "Virtual Background in webcam with Body Segmentation technique", "resolved_url": "https://towardsdatascience.com/virtual-background-in-webcam-with-body-segmentation-technique-fc8106ca3038", "excerpt": "Have you ever had a moment when browsing those pretty travel selfies on social media, you talk to yourself: ‚ÄúI wish I could be there‚Äù? Guess what, we are going to make it come true today.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1188", "lang": "en", "time_to_read": 5, "top_image_url": "https://miro.medium.com/max/1000/1*7JZFg4utLSm5qSXxDs-hnA.jpeg", "tags": {"deep-learning": {"item_id": "2992941024", "tag": "deep-learning"}, "vision": {"item_id": "2992941024", "tag": "vision"}}, "authors": {"132256372": {"item_id": "2992941024", "author_id": "132256372", "name": "Benson Ruan", "url": "https://medium.com/@bensonruan"}}, "image": {"item_id": "2992941024", "src": "https://miro.medium.com/max/2000/1*7JZFg4utLSm5qSXxDs-hnA.jpeg", "width": "1000", "height": "450"}, "images": {"1": {"item_id": "2992941024", "image_id": "1", "src": "https://miro.medium.com/max/2000/1*7JZFg4utLSm5qSXxDs-hnA.jpeg", "width": "1000", "height": "450", "credit": "", "caption": "source: bensonruan.com"}, "2": {"item_id": "2992941024", "image_id": "2", "src": "https://miro.medium.com/max/2048/1*wI5UkUo1KziqXX2c5ocAaQ.jpeg", "width": "1024", "height": "800", "credit": "", "caption": ""}, "3": {"item_id": "2992941024", "image_id": "3", "src": "https://miro.medium.com/max/14562/1*8fn1OfDPeaoqmSIXrKVrCQ.jpeg", "width": "7281", "height": "4860", "credit": "Julia M Cameron from Pexels", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 460}, "3365044321": {"item_id": "3365044321", "resolved_id": "3365044321", "given_url": "https://www.nextplatform.com/2021/06/24/what-happens-when-multiplication-no-longer-defines-ai-accelerators/", "given_title": "What Happens When Multipliers No Longer Define AI Accelerators?", "favorite": "0", "status": "1", "time_added": "1624556210", "time_updated": "1671277463", "time_read": "1624557305", "time_favorited": "0", "sort_id": 456, "resolved_title": "What Happens When Multipliers No Longer Define AI Accelerators?", "resolved_url": "https://www.nextplatform.com/2021/06/24/what-happens-when-multiplication-no-longer-defines-ai-accelerators/", "excerpt": "Current custom AI hardware devices are built around super-efficient, high performance matrix multiplication. This category of accelerators includes the host of AI chip startups and defines what more mainstream accelerators like GPUs bring to the table.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "883", "lang": "en", "time_to_read": 4, "amp_url": "https://www.nextplatform.com/2021/06/24/what-happens-when-multiplication-no-longer-defines-ai-accelerators/amp/", "top_image_url": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/ab_quantum_general.jpg", "tags": {"deep-learning": {"item_id": "3365044321", "tag": "deep-learning"}, "gpus": {"item_id": "3365044321", "tag": "gpus"}, "linear-algebra": {"item_id": "3365044321", "tag": "linear-algebra"}, "semiconductors": {"item_id": "3365044321", "tag": "semiconductors"}}, "authors": {"58691955": {"item_id": "3365044321", "author_id": "58691955", "name": "Nicole Hemsoth", "url": "https://www.nextplatform.com/author/nicole/"}}, "image": {"item_id": "3365044321", "src": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/ab_quantum_general-1030x438.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3365044321", "image_id": "1", "src": "https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/ab_quantum_general-1030x438.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 342}, "3290428251": {"item_id": "3290428251", "resolved_id": "3290428254", "given_url": "http://offconvex.github.io/2021/03/25/beyondNTK/", "given_title": "When are Neural Networks more powerful than Neural Tangent Kernels?", "favorite": "0", "status": "1", "time_added": "1616752516", "time_updated": "1638708525", "time_read": "1616796186", "time_favorited": "0", "sort_id": 457, "resolved_title": "When are Neural Networks more powerful than Neural Tangent Kernels?", "resolved_url": "http://www.offconvex.org/2021/03/25/beyondNTK/", "excerpt": "The empirical success of deep learning has posed significant challenges to machine learning theory: Why can we efficiently train neural networks with gradient descent despite its highly non-convex optimization landscape? Why do over-parametrized networks generalize well? The recently proposed Neural", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "2085", "lang": "en", "time_to_read": 9, "tags": {"deep-learning": {"item_id": "3290428251", "tag": "deep-learning"}}, "authors": {"22960972": {"item_id": "3290428251", "author_id": "22960972", "name": "Moritz Hardt", "url": ""}}, "image": {"item_id": "3290428251", "src": "http://www.offconvex.org/assets/taylor-plot.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3290428251", "image_id": "1", "src": "http://www.offconvex.org/assets/taylor-plot.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3290428251", "image_id": "2", "src": "http://www.offconvex.org/assets/beyond-ntk.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 807}, "2272181338": {"item_id": "2272181338", "resolved_id": "2272181343", "given_url": "http://offconvex.github.io/2018/07/27/approximating-recurrent/", "given_title": "When Recurrent Models Don't Need to be Recurrent", "favorite": "0", "status": "1", "time_added": "1532725281", "time_updated": "1638708525", "time_read": "1535747328", "time_favorited": "0", "sort_id": 458, "resolved_title": "When Recurrent Models Don't Need to be Recurrent", "resolved_url": "http://www.offconvex.org/2018/07/27/approximating-recurrent/", "excerpt": "In the last few years, deep learning practitioners have proposed a litany of different sequence models. Although recurrent neural networks were once the tool of choice, now models like the autoregressive Wavenet or the Transformer are replacing RNNs on a diverse set of tasks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1446", "lang": "en", "time_to_read": 7, "tags": {"deep-learning": {"item_id": "2272181338", "tag": "deep-learning"}, "rnns": {"item_id": "2272181338", "tag": "rnns"}}, "authors": {"22960972": {"item_id": "2272181338", "author_id": "22960972", "name": "Moritz Hardt", "url": ""}}, "image": {"item_id": "2272181338", "src": "http://www.offconvex.org/assets/approx_recurrent/recurrent_net.png", "width": "500", "height": "250"}, "images": {"1": {"item_id": "2272181338", "image_id": "1", "src": "http://www.offconvex.org/assets/approx_recurrent/recurrent_net.png", "width": "500", "height": "250", "credit": "", "caption": ""}, "2": {"item_id": "2272181338", "image_id": "2", "src": "http://www.offconvex.org/assets/approx_recurrent/truncated_backprop.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "listen_duration_estimate": 560}, "3104226328": {"item_id": "3104226328", "resolved_id": "3104226328", "given_url": "https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/", "given_title": "Which GPUs to get for deep learning", "favorite": "0", "status": "1", "time_added": "1599517507", "time_updated": "1638708872", "time_read": "1604363843", "time_favorited": "0", "sort_id": 459, "resolved_title": "Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning", "resolved_url": "https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/", "excerpt": "Deep learning is a field with intense computational requirements, and your choice of GPU will fundamentally determine your deep learning experience.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "10541", "lang": "en", "time_to_read": 48, "top_image_url": "https://timdettmers.com/wp-content/uploads/2020/09/Normalized-1-and-2-GPU-Performance-per-Dollar-Ampere-1.svg", "tags": {"deep-learning": {"item_id": "3104226328", "tag": "deep-learning"}, "gpus": {"item_id": "3104226328", "tag": "gpus"}}, "authors": {"110561791": {"item_id": "3104226328", "author_id": "110561791", "name": "Tim Dettmers", "url": "https://timdettmers.com/author/tim-dettmers/"}}, "image": {"item_id": "3104226328", "src": "https://i0.wp.com/timdettmers.com/wp-content/uploads/2020/09/sparse_matmul.png?resize=1024%2C619&ssl=1", "width": "1024", "height": "619"}, "images": {"1": {"item_id": "3104226328", "image_id": "1", "src": "https://i0.wp.com/timdettmers.com/wp-content/uploads/2020/09/sparse_matmul.png?resize=1024%2C619&ssl=1", "width": "1024", "height": "619", "credit": "", "caption": ""}, "2": {"item_id": "3104226328", "image_id": "2", "src": "https://i0.wp.com/timdettmers.com/wp-content/uploads/2019/07/sparse_momentum.png?resize=1024%2C493&ssl=1", "width": "1024", "height": "493", "credit": "1", "caption": "Figure 3: The sparse training algorithm that I developed has three stages:"}, "3": {"item_id": "3104226328", "image_id": "3", "src": "https://i0.wp.com/timdettmers.com/wp-content/uploads/2020/09/8-bit_data_types.png?resize=869%2C268&ssl=1", "width": "869", "height": "268", "credit": "0, 0.9", "caption": "Figure 4: Low-precision deep learning 8-bit datatypes that I developed. Deep learning training benefits from highly specialized data types. My dynamic tree datatype uses a dynamic bit that indicates the beginning of a binary bisection tree that quantized the range"}, "4": {"item_id": "3104226328", "image_id": "4", "src": "https://i0.wp.com/timdettmers.com/wp-content/uploads/2020/09/4x_RTX2080Ti_desktop_extenders.jpg?resize=768%2C1024&ssl=1", "width": "768", "height": "1024", "credit": "", "caption": "Figure 5: 4x GPUs with PCIe extenders. It looks like a mess, but it is very effective for cooling. I used this rig for 2 years and cooling is excellent despite problematic RTX 2080 Ti Founders Edition GPUs."}, "5": {"item_id": "3104226328", "image_id": "5", "src": "https://i0.wp.com/timdettmers.com/wp-content/uploads/2020/09/power_limit_nvidia_smi.png?resize=1017%2C1024&ssl=1", "width": "1017", "height": "1024", "credit": "", "caption": "Figure 6: Reducing the power limit has a slight cooling effect. Reducing the RTX 2080 Ti power limit by 50-60 W decreases temperatures slightly and fans run more silent."}, "6": {"item_id": "3104226328", "image_id": "6", "src": "https://timdettmers.com/wp-content/uploads/2020/09/RTX-2080-Ti-Slowdown-vs-Power-Limit.svg", "width": "853", "height": "703", "credit": "excluding softmax layer", "caption": "Figure 7: Measured slowdown for a given power limit on an RTX 2080 Ti. Measurements taken are mean processing times for 500 mini-batches of BERT Large during inference"}, "7": {"item_id": "3104226328", "image_id": "7", "src": "https://timdettmers.com/wp-content/uploads/2020/09/Normalized-GPU-Performance-Ampere-1.svg", "width": "1730", "height": "1685", "credit": "", "caption": ""}, "8": {"item_id": "3104226328", "image_id": "8", "src": "https://timdettmers.com/wp-content/uploads/2020/09/Normalized-1-and-2-GPU-Performance-per-Dollar-Ampere-1.svg", "width": "1703", "height": "1679", "credit": "", "caption": ""}, "9": {"item_id": "3104226328", "image_id": "9", "src": "https://timdettmers.com/wp-content/uploads/2020/09/Normalized-4-GPU-Performance-per-Dollar-Ampere-1.svg", "width": "1717", "height": "1691", "credit": "", "caption": ""}, "10": {"item_id": "3104226328", "image_id": "10", "src": "https://timdettmers.com/wp-content/uploads/2020/09/Normalized-8-GPU-Performance-per-Dollar-Ampere-1.svg", "width": "1703", "height": "1685", "credit": "", "caption": ""}}, "listen_duration_estimate": 4080}, "3840091257": {"item_id": "3840091257", "resolved_id": "3840091257", "given_url": "https://www.nextplatform.com/2023/04/05/why-ai-inference-will-remain-largely-on-the-cpu/", "given_title": "Why AI Inference Will Remain Largely On The CPU", "favorite": "0", "status": "1", "time_added": "1680706674", "time_updated": "1680713685", "time_read": "1680713685", "time_favorited": "0", "sort_id": 460, "resolved_title": "Why AI Inference Will Remain Largely On The CPU", "resolved_url": "https://www.nextplatform.com/2023/04/05/why-ai-inference-will-remain-largely-on-the-cpu/", "excerpt": "Sponsored Feature: Training an AI model takes an enormous amount of compute capacity coupled with high bandwidth memory.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1299", "lang": "en", "time_to_read": 6, "amp_url": "https://www.nextplatform.com/2023/04/05/why-ai-inference-will-remain-largely-on-the-cpu/amp/", "top_image_url": "http://www.nextplatform.com/wp-content/uploads/2023/01/intel-sapphire-rapids-logo-4-1.jpg", "tags": {"cpus": {"item_id": "3840091257", "tag": "cpus"}, "datacenters": {"item_id": "3840091257", "tag": "datacenters"}, "deep-learning": {"item_id": "3840091257", "tag": "deep-learning"}}, "authors": {"58259529": {"item_id": "3840091257", "author_id": "58259529", "name": "Contributors", "url": "https://www.nextplatform.com/contributors/"}}, "image": {"item_id": "3840091257", "src": "https://www.nextplatform.com/wp-content/uploads/2023/01/intel-sapphire-rapids-logo-4-1-1030x438.jpg", "width": "0", "height": "0"}, "images": {"1": {"item_id": "3840091257", "image_id": "1", "src": "https://www.nextplatform.com/wp-content/uploads/2023/01/intel-sapphire-rapids-logo-4-1-1030x438.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "3840091257", "image_id": "2", "src": "http://www.nextplatform.com/wp-content/uploads/2023/04/IntelSRVectorMatrixThroughputFig1.jpg", "width": "479", "height": "217", "credit": "", "caption": ""}, "3": {"item_id": "3840091257", "image_id": "3", "src": "http://www.nextplatform.com/wp-content/uploads/2023/04/IntelXRXeonOverTimeResnetInferenceFig2.jpg", "width": "575", "height": "228", "credit": "", "caption": ""}, "4": {"item_id": "3840091257", "image_id": "4", "src": "http://www.nextplatform.com/wp-content/uploads/2023/04/IntelSRvsIceLakeVarious-InferenceFig3.jpg", "width": "575", "height": "402", "credit": "", "caption": ""}, "5": {"item_id": "3840091257", "image_id": "5", "src": "http://www.nextplatform.com/wp-content/uploads/2023/04/IntelSRvsNvidiaA10VariousInferenceFig4.jpg", "width": "576", "height": "399", "credit": "", "caption": ""}}, "listen_duration_estimate": 503}, "2903801139": {"item_id": "2903801139", "resolved_id": "2903801139", "given_url": "https://www.intel.ai/bert-commercial-environments/", "given_title": "Why BERT Fails in Commercial Environments - Intel AI", "favorite": "0", "status": "1", "time_added": "1585059953", "time_updated": "1638708525", "time_read": "1585062107", "time_favorited": "0", "sort_id": 461, "resolved_title": "Why BERT Fails in Commercial Environments", "resolved_url": "https://www.intel.ai/bert-commercial-environments/", "excerpt": "Large transformer-based neural networks such as BERT, GPT and XLNET have recently achieved state-of-the-art results in many NLP tasks. The success of these models is based on transfer learning between a generic task (for example, language modeling) and a specific downstream task.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1275", "lang": "en", "time_to_read": 6, "top_image_url": "https://simplecore.intel.com/ai/wp-content/uploads/sites/69/AIDM-744_FI.jpg", "tags": {"deep-learning": {"item_id": "2903801139", "tag": "deep-learning"}, "nlp": {"item_id": "2903801139", "tag": "nlp"}}, "authors": {"110753942": {"item_id": "2903801139", "author_id": "110753942", "name": "Oren Pereg", "url": "https://www.intel.ai/bio/oren-pereg/"}}, "listen_duration_estimate": 494}, "3785999411": {"item_id": "3785999411", "resolved_id": "3785999411", "given_url": "https://thenextweb.com/news/why-tensorflow-for-python-is-dying-a-slow-death", "given_title": "Why TensorFlow for Python is dying a slow death", "favorite": "0", "status": "1", "time_added": "1673624332", "time_updated": "1673625815", "time_read": "1673625815", "time_favorited": "0", "sort_id": 462, "resolved_title": "Why TensorFlow for Python is dying a slow death", "resolved_url": "https://thenextweb.com/news/why-tensorflow-for-python-is-dying-a-slow-death", "excerpt": "Religious wars have been a cornerstone in tech. Whether it‚Äôs debating about the pros and cons of different operating systems, cloud providers, or deep learning frameworks ‚Äî a few beers in, the facts slide aside and people start fighting for their technology like it‚Äôs the holy grail.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1203", "lang": "en", "time_to_read": 5, "top_image_url": "https://img-cdn.tnwcdn.com/image/tnw?filter_last=1&fit=1280%2C640&url=https%3A%2F%2Fcdn0.tnwcdn.com%2Fwp-content%2Fblogs.dir%2F1%2Ffiles%2F2023%2F01%2FAdd-a-heading-1.jpg&signature=0118422d6dab7f09d89f3c0b7b7e58df", "tags": {"deep-learning": {"item_id": "3785999411", "tag": "deep-learning"}, "python": {"item_id": "3785999411", "tag": "python"}, "pytorch": {"item_id": "3785999411", "tag": "pytorch"}, "tensorflow": {"item_id": "3785999411", "tag": "tensorflow"}}, "authors": {"159777247": {"item_id": "3785999411", "author_id": "159777247", "name": "Ari Joury", "url": ""}}, "image": {"item_id": "3785999411", "src": "https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2023/01/Screenshot-2023-01-13-at-2.32.32-PM.png", "width": "1390", "height": "942"}, "images": {"1": {"item_id": "3785999411", "image_id": "1", "src": "https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2023/01/Screenshot-2023-01-13-at-2.32.32-PM.png", "width": "1390", "height": "942", "credit": "", "caption": ""}}, "domain_metadata": {"name": "The Next Web", "logo": "https://logo.clearbit.com/thenextweb.com?size=800", "greyscale_logo": "https://logo.clearbit.com/thenextweb.com?size=800&greyscale=true"}, "listen_duration_estimate": 466}, "3785275543": {"item_id": "3785275543", "resolved_id": "3785275543", "given_url": "https://towardsdatascience.com/why-wgans-beat-gans-a-journey-from-kl-divergence-to-wasserstein-loss-9ee5faf10b48", "given_title": "Why WGANs beat GANs: A journey from KL divergence to Wasserstein loss", "favorite": "0", "status": "1", "time_added": "1673532607", "time_updated": "1673640628", "time_read": "1673640628", "time_favorited": "0", "sort_id": 463, "resolved_title": "Why WGANs beat GANs: A journey from KL divergence to Wasserstein loss", "resolved_url": "https://towardsdatascience.com/why-wgans-beat-gans-a-journey-from-kl-divergence-to-wasserstein-loss-9ee5faf10b48", "excerpt": "In 2014, Ian Goodfellow came up with the idea of GAN or vanilla GAN as we call it today. Although impressive, it was notoriously hard to train. Vanilla GAN suffered from an inability to converge, vanishing gradients, and mode collapse.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "1398", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/0*zMReX2xtdjsCHZAU", "tags": {"deep-learning": {"item_id": "3785275543", "tag": "deep-learning"}, "gans": {"item_id": "3785275543", "tag": "gans"}}, "authors": {"141867888": {"item_id": "3785275543", "author_id": "141867888", "name": "shashank kumar", "url": "https://medium.com/@rm12"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 541}, "3888906091": {"item_id": "3888906091", "resolved_id": "3888906095", "given_url": "https://www.kdnuggets.com/2023/06/need-know-autonomous-ai-agents.html", "given_title": "Why You Need To Know About Autonomous AI Agents", "favorite": "0", "status": "1", "time_added": "1687013770", "time_updated": "1706235752", "time_read": "1690158940", "time_favorited": "0", "sort_id": 464, "resolved_title": "Why You Need To Know About Autonomous AI Agents", "resolved_url": "https://www.kdnuggets.com/why-you-need-to-know-about-autonomous-ai-agents.html", "excerpt": "Let‚Äôs start with the obvious - AI. Artificial Intelligence is the ability of a computer to perform tasks that are usually done by humans, using data, machine learning, and more. You can use AI to create content, answer questions, and generate life-like art.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1207", "lang": "en", "time_to_read": 5, "top_image_url": "https://www.kdnuggets.com/wp-content/uploads/arya_need_know_autonomous_ai_agents_14.jpeg", "tags": {"deep-learning": {"item_id": "3888906091", "tag": "deep-learning"}}, "authors": {"161909818": {"item_id": "3888906091", "author_id": "161909818", "name": "Nisha Arya", "url": "https://www.kdnuggets.com/author/nisha-arya"}}, "image": {"item_id": "3888906091", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500"}, "images": {"1": {"item_id": "3888906091", "image_id": "1", "src": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/instagram.svg", "width": "500", "height": "500", "credit": "", "caption": ""}}, "domain_metadata": {"name": "KDnuggets", "logo": "https://logo.clearbit.com/kdnuggets.com?size=800", "greyscale_logo": "https://logo.clearbit.com/kdnuggets.com?size=800&greyscale=true"}, "listen_duration_estimate": 467}, "3253928608": {"item_id": "3253928608", "resolved_id": "3253928629", "given_url": "https://towardsdatascience.com/why-you-should-always-use-feature-embeddings-with-structured-datasets-7f280b40e716?source=rss----7f60cf5620c9---4", "given_title": "Why you should always use feature embeddings with structured datasets", "favorite": "0", "status": "1", "time_added": "1613035669", "time_updated": "1671277184", "time_read": "1613042608", "time_favorited": "0", "sort_id": 465, "resolved_title": "Why You Should Always Use Feature Embeddings With Structured Datasets", "resolved_url": "https://towardsdatascience.com/why-you-should-always-use-feature-embeddings-with-structured-datasets-7f280b40e716", "excerpt": "Feature embeddings are one of the most important steps when training neural networks on tabular data tables. Unfortunately, this technique is seldom taught outside of natural language processing (NLP) settings and is consequently almost completely ignored for structured datasets.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1472", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/1200/1*XJw2acJVl-1XzQ3jB0Vdiw.jpeg", "tags": {"deep-learning": {"item_id": "3253928608", "tag": "deep-learning"}, "feature-engineering": {"item_id": "3253928608", "tag": "feature-engineering"}, "machine-learning": {"item_id": "3253928608", "tag": "machine-learning"}}, "authors": {"146630385": {"item_id": "3253928608", "author_id": "146630385", "name": "Michael Malin", "url": "https://michael-malin.medium.com"}}, "image": {"item_id": "3253928608", "src": "https://miro.medium.com/max/11230/1*XJw2acJVl-1XzQ3jB0Vdiw.jpeg", "width": "5615", "height": "3476"}, "images": {"1": {"item_id": "3253928608", "image_id": "1", "src": "https://miro.medium.com/max/11230/1*XJw2acJVl-1XzQ3jB0Vdiw.jpeg", "width": "5615", "height": "3476", "credit": "", "caption": "Image via iStock under license to Michael Malin"}, "2": {"item_id": "3253928608", "image_id": "2", "src": "https://miro.medium.com/fit/c/56/56/1*mncZFPtiYh1N60tLSrJ_cQ.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "3": {"item_id": "3253928608", "image_id": "3", "src": "https://miro.medium.com/max/794/1*lWExKUMZ8P8XPFyudgSXcw.jpeg", "width": "397", "height": "434", "credit": "the author, created  TensorFlow Embedding Projector", "caption": ""}, "4": {"item_id": "3253928608", "image_id": "4", "src": "https://miro.medium.com/max/1212/1*AjgSGbiszVJ6zBnfvd-3oQ.jpeg", "width": "606", "height": "280", "credit": "", "caption": "Example data frame by author"}, "5": {"item_id": "3253928608", "image_id": "5", "src": "https://miro.medium.com/max/1844/1*3V8VgHllhEHoY302cuxzSg.jpeg", "width": "922", "height": "601", "credit": "", "caption": "Example embedding diagram by author"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 570}, "1601007829": {"item_id": "1601007829", "resolved_id": "1601007829", "given_url": "https://github.com/wiseodd/generative-models", "given_title": "wiseodd/generative-models: Collection of generative models, e.g. GAN, VAE i", "favorite": "0", "status": "1", "time_added": "1492438290", "time_updated": "1638708525", "time_read": "1510366393", "time_favorited": "0", "sort_id": 466, "resolved_title": "Generative Models", "resolved_url": "https://github.com/wiseodd/generative-models", "excerpt": "Collection of generative models, e.g. GAN, VAE in Pytorch and Tensorflow. Also present here are RBM and Helmholtz Machine. Generated samples will be stored in GAN/{gan_model}/out (or VAE/{vae_model}/out, etc) directory during training.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "161", "lang": "en", "top_image_url": "https://opengraph.githubassets.com/8460f0d0de76e5f14c5afd4a41483ec9bb0ea9135da09b2c8142ccae4ee25e55/wiseodd/generative-models", "tags": {"deep-learning": {"item_id": "1601007829", "tag": "deep-learning"}, "pytorch": {"item_id": "1601007829", "tag": "pytorch"}, "tensorflow": {"item_id": "1601007829", "tag": "tensorflow"}}, "domain_metadata": {"name": "GitHub", "logo": "https://logo.clearbit.com/github.com?size=800", "greyscale_logo": "https://logo.clearbit.com/github.com?size=800&greyscale=true"}, "listen_duration_estimate": 62}, "2632918070": {"item_id": "2632918070", "resolved_id": "2632918070", "given_url": "https://graceavery.com/word2vec-fish-music-bass/", "given_title": "Word2vec: fish   music = bass | graceavery", "favorite": "0", "status": "1", "time_added": "1562464581", "time_updated": "1638708525", "time_read": "1566341788", "time_favorited": "0", "sort_id": 467, "resolved_title": "Word2vec: fish + music = bass", "resolved_url": "https://graceavery.com/word2vec-fish-music-bass/", "excerpt": "Everyone seems to overlook how FUNNY word2vec is! GPT-2 has gotten lots of playful attention, but word2vec never had its day in the sun. Everyone mentions the example ‚Äúking ‚Äì man + woman = queen‚Äù, but no one mentions the delightful ‚Äúyeti ‚Äì snow + economics = homo economicus‚Äù.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1807", "lang": "en", "time_to_read": 8, "tags": {"deep-learning": {"item_id": "2632918070", "tag": "deep-learning"}, "nlp": {"item_id": "2632918070", "tag": "nlp"}}, "authors": {"113852009": {"item_id": "2632918070", "author_id": "113852009", "name": "grace", "url": "https://graceavery.com/author/grace/"}}, "image": {"item_id": "2632918070", "src": "https://graceavery.com/wp-content/uploads/word2vec1-1024x453.png", "width": "512", "height": "227"}, "images": {"1": {"item_id": "2632918070", "image_id": "1", "src": "https://graceavery.com/wp-content/uploads/word2vec1-1024x453.png", "width": "512", "height": "227", "credit": "", "caption": ""}, "2": {"item_id": "2632918070", "image_id": "2", "src": "https://graceavery.com/wp-content/uploads/word2vec2-1024x655.png", "width": "512", "height": "328", "credit": "", "caption": ""}}, "listen_duration_estimate": 699}, "3349863342": {"item_id": "3349863342", "resolved_id": "3349859421", "given_url": "https://towardsdatascience.com/gpt-3-scared-you-meet-wu-dao-2-0-a-monster-of-1-75-trillion-parameters-832cd83db484?source=rss----7f60cf5620c9---4", "given_title": "Wu Dao 2.0: A Monster of 1.75 Trillion Parameters | by Alberto Romero | Med", "favorite": "0", "status": "1", "time_added": "1622981802", "time_updated": "1678841327", "time_read": "1623032387", "time_favorited": "0", "sort_id": 468, "resolved_title": "GPT-3 Scared You? Meet Wu Dao 2.0: A Monster of 1.75 Trillion Parameters", "resolved_url": "https://towardsdatascience.com/gpt-3-scared-you-meet-wu-dao-2-0-a-monster-of-1-75-trillion-parameters-832cd83db484", "excerpt": "We‚Äôre living exciting times in AI. OpenAI shocked the world a year ago with GPT-3. Two weeks ago Google presented LaMDA and MUM, two AIs that will revolutionize chatbots and the search engine, respectively.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1283", "lang": "en", "time_to_read": 6, "top_image_url": "https://miro.medium.com/max/1200/0*BMnNj-LkuKhMm-f8", "tags": {"chatbots": {"item_id": "3349863342", "tag": "chatbots"}, "deep-learning": {"item_id": "3349863342", "tag": "deep-learning"}, "nlp": {"item_id": "3349863342", "tag": "nlp"}}, "authors": {"144430834": {"item_id": "3349863342", "author_id": "144430834", "name": "Alberto Romero", "url": "https://albertoromgar.medium.com"}}, "image": {"item_id": "3349863342", "src": "https://miro.medium.com/fit/c/56/56/2*oMdIZBsnK8EFhQLUaAB5ZA.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3349863342", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*oMdIZBsnK8EFhQLUaAB5ZA.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3349863342", "image_id": "2", "src": "https://miro.medium.com/max/1400/0*BMnNj-LkuKhMm-f8", "width": "700", "height": "467", "credit": "GR Stocks on Unsplash", "caption": ""}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 497}, "3088642854": {"item_id": "3088642854", "resolved_id": "3088642869", "given_url": "https://towardsdatascience.com/yolo-v4-or-yolo-v5-or-pp-yolo-dad8e40f7109?source=rss----7f60cf5620c9---4", "given_title": "YOLO v4 or YOLO v5 or PP-YOLO? Which should I use?", "favorite": "0", "status": "1", "time_added": "1598165247", "time_updated": "1638708525", "time_read": "1607569983", "time_favorited": "0", "sort_id": 469, "resolved_title": "YOLO v4 or YOLO v5 or PP-YOLO?", "resolved_url": "https://towardsdatascience.com/yolo-v4-or-yolo-v5-or-pp-yolo-dad8e40f7109", "excerpt": "Object detection is a computer vision task that involves predicting the presence of one or more objects, along with their classes and bounding boxes. YOLO (You Only Look Once) is a state of art Object Detector which can perform object detection in real-time with a good accuracy.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "1552", "lang": "en", "time_to_read": 7, "top_image_url": "https://miro.medium.com/max/1200/1*9jTB1MbpJfvX_OYEvMefuw.jpeg", "tags": {"deep-learning": {"item_id": "3088642854", "tag": "deep-learning"}, "vision": {"item_id": "3088642854", "tag": "vision"}}, "authors": {"137574036": {"item_id": "3088642854", "author_id": "137574036", "name": "Chamidu Supeshala", "url": "https://medium.com/@chamidusupeshala"}}, "image": {"item_id": "3088642854", "src": "https://miro.medium.com/fit/c/56/56/1*nFnfRL7ma-uYF0T8wI-vgA.png", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3088642854", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/1*nFnfRL7ma-uYF0T8wI-vgA.png", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3088642854", "image_id": "2", "src": "https://miro.medium.com/max/3840/1*9jTB1MbpJfvX_OYEvMefuw.jpeg", "width": "1920", "height": "1280", "credit": "Image by author", "caption": "YOLO object detection"}, "3": {"item_id": "3088642854", "image_id": "3", "src": "https://miro.medium.com/max/970/1*AtsoKR91L6LlA4eseQmDNA.jpeg", "width": "485", "height": "465", "credit": "source: pjreddie.com", "caption": "Performance of YOLO on VOC 2007 and COCO datasets"}, "4": {"item_id": "3088642854", "image_id": "4", "src": "https://miro.medium.com/max/1076/1*EVPqmfh38YT5KDGXT950tA.png", "width": "538", "height": "422", "credit": "source: YOLO v4 paper", "caption": "The speed and accuracy of YOLO v4"}, "5": {"item_id": "3088642854", "image_id": "5", "src": "https://miro.medium.com/max/2128/1*AAGWRhZkyLE6Hod9aP8Pqg.png", "width": "1064", "height": "727", "credit": "source: PP-YOLO repo", "caption": "The speed and accuracy of PP-YOLO"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 601}, "3125359544": {"item_id": "3125359544", "resolved_id": "3125359579", "given_url": "https://towardsdatascience.com/yolo-v5-object-detection-tutorial-2e607b9013ef?source=rss----7f60cf5620c9---4", "given_title": "Yolo v5 Object Detection Tutorial", "favorite": "0", "status": "1", "time_added": "1601338609", "time_updated": "1638708525", "time_read": "1604368255", "time_favorited": "0", "sort_id": 470, "resolved_title": "Yolo v5 Object Detection Tutorial", "resolved_url": "https://towardsdatascience.com/yolo-v5-object-detection-tutorial-2e607b9013ef", "excerpt": "Object Detection is a task in Artificial Intelligence that focuses on detecting objects in images. Yolo V5 is one of the best available models for Object Detection at the moment. The great thing about this Deep Neural Network is that it is very easy to retrain the network on your own custom dataset.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "1", "word_count": "979", "lang": "en", "time_to_read": 4, "top_image_url": "https://miro.medium.com/max/876/1*idFzREuCIvlnizQWkwC-2g.jpeg", "tags": {"deep-learning": {"item_id": "3125359544", "tag": "deep-learning"}, "object-detection": {"item_id": "3125359544", "tag": "object-detection"}, "vision": {"item_id": "3125359544", "tag": "vision"}}, "authors": {"119019604": {"item_id": "3125359544", "author_id": "119019604", "name": "Joos Korstanje", "url": "https://medium.com/@jooskorstanje"}}, "image": {"item_id": "3125359544", "src": "https://miro.medium.com/fit/c/56/56/2*X1WxhA1JpeQX6MmmPvTMuQ.jpeg", "width": "28", "height": "28"}, "images": {"1": {"item_id": "3125359544", "image_id": "1", "src": "https://miro.medium.com/fit/c/56/56/2*X1WxhA1JpeQX6MmmPvTMuQ.jpeg", "width": "28", "height": "28", "credit": "", "caption": ""}, "2": {"item_id": "3125359544", "image_id": "2", "src": "https://miro.medium.com/max/1400/1*idFzREuCIvlnizQWkwC-2g.jpeg", "width": "700", "height": "561", "credit": "", "caption": "Yolo v5 Object Detection Tutorial. Photo by Stefan Cosma on Unsplash"}, "3": {"item_id": "3125359544", "image_id": "3", "src": "https://miro.medium.com/max/726/1*tDd09Mjjho35GQk1ycuN-g.png", "width": "363", "height": "437", "credit": "", "caption": "An example of object detection using the pre-trained Yolo V5 model. Source of original. Creative Commons Attribution-Share Alike 4.0 International."}, "4": {"item_id": "3125359544", "image_id": "4", "src": "https://miro.medium.com/max/472/1*XupA8TGTSGdZdjsrs16hkw.png", "width": "236", "height": "183", "credit": "", "caption": "The directory tree for training a Yolo V5 model"}, "5": {"item_id": "3125359544", "image_id": "5", "src": "https://miro.medium.com/max/1008/1*nVcy0L2Xxm-BuedAGcueKw.png", "width": "504", "height": "458", "credit": "", "caption": "Extract of the labels of one training image called ‚Äú00333207‚Äù."}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 379}, "955536225": {"item_id": "955536225", "resolved_id": "955536225", "given_url": "https://pjreddie.com/darknet/yolo/", "given_title": "YOLO: Real-Time Object Detection", "favorite": "0", "status": "1", "time_added": "1554245748", "time_updated": "1638708525", "time_read": "1567116388", "time_favorited": "0", "sort_id": 471, "resolved_title": "YOLO: Real-Time Object Detection", "resolved_url": "https://pjreddie.com/darknet/yolo/", "excerpt": "You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Pascal Titan X it processes images at 30 FPS and has a mAP of 57.9% on COCO test-dev. YOLOv3 is extremely fast and accurate. In mAP measured at .5 IOU YOLOv3 is on par with Focal Loss but about 4x faster.", "is_article": "1", "is_index": "1", "has_video": "1", "has_image": "1", "word_count": "1833", "lang": "en", "time_to_read": 8, "tags": {"deep-learning": {"item_id": "955536225", "tag": "deep-learning"}, "vision": {"item_id": "955536225", "tag": "vision"}}, "authors": {"57511003": {"item_id": "955536225", "author_id": "57511003", "name": "Joseph Redmon", "url": ""}}, "image": {"item_id": "955536225", "src": "https://pjreddie.com/media/image/map50blue.png", "width": "0", "height": "0"}, "images": {"1": {"item_id": "955536225", "image_id": "1", "src": "https://pjreddie.com/media/image/map50blue.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "2": {"item_id": "955536225", "image_id": "2", "src": "https://pjreddie.com/media/image/sayit.jpg", "width": "0", "height": "0", "credit": "", "caption": ""}, "3": {"item_id": "955536225", "image_id": "3", "src": "https://pjreddie.com/media/image/Screen_Shot_2018-03-24_at_10.48.42_PM.png", "width": "0", "height": "0", "credit": "", "caption": ""}, "4": {"item_id": "955536225", "image_id": "4", "src": "https://pjreddie.com/media/image/Screen_Shot_2018-03-24_at_10.53.04_PM.png", "width": "0", "height": "0", "credit": "", "caption": ""}}, "videos": {"1": {"item_id": "955536225", "video_id": "1", "src": "https://www.youtube.com/embed/MPU2HistivI", "width": "100", "height": "415", "type": "1", "vid": "MPU2HistivI", "length": "0"}}, "listen_duration_estimate": 710}, "3753126157": {"item_id": "3753126157", "resolved_id": "3753126181", "given_url": "https://towardsdatascience.com/yolov7-a-deep-dive-into-the-current-state-of-the-art-for-object-detection-ce3ffedeeaeb?source=rss----7f60cf5620c9---4", "given_title": "YOLOv7: A deep dive into the current state-of-the-art for object detection ", "favorite": "0", "status": "1", "time_added": "1669420033", "time_updated": "1669667177", "time_read": "1669667176", "time_favorited": "0", "sort_id": 472, "resolved_title": "YOLOv7: A Deep Dive into the Current State-of-the-Art for Object Detection", "resolved_url": "https://towardsdatascience.com/yolov7-a-deep-dive-into-the-current-state-of-the-art-for-object-detection-ce3ffedeeaeb", "excerpt": "Shortly after its publication, YOLOv7 is the fastest and most accurate real-time object detection model for computer vision tasks.", "is_article": "1", "is_index": "0", "has_video": "0", "has_image": "0", "word_count": "14382", "lang": "en", "time_to_read": 65, "top_image_url": "https://miro.medium.com/max/1200/1*wMUHb5UizMu6QSWRfw8SKw.png", "tags": {"deep-learning": {"item_id": "3753126157", "tag": "deep-learning"}, "machine-vision": {"item_id": "3753126157", "tag": "machine-vision"}, "object-detection": {"item_id": "3753126157", "tag": "object-detection"}}, "authors": {"150596160": {"item_id": "3753126157", "author_id": "150596160", "name": "Chris Hughes", "url": "https://medium.com/@chris.p.hughes10"}}, "domain_metadata": {"name": "Towards Data Science", "logo": "https://logo.clearbit.com/towardsdatascience.com?size=800", "greyscale_logo": "https://logo.clearbit.com/towardsdatascience.com?size=800&greyscale=true"}, "listen_duration_estimate": 5567}}, "error": nil, "search_meta": {"search_type": "normal"}, "since": 1709934559}