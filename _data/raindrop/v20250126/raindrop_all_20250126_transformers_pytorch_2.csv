id,title,note,excerpt,url,folder,tags,created,cover,highlights,favorite
876792736,Optimizing Memory Usage for Training LLMs and Vision Transformers in PyTorc,,This article provides a series of techniques that can lower memory consumption in PyTorch (when training vision transformers and LLMs) by approximately 20x without sacrificing modeling performance and prediction accuracy.,https://lightning.ai/pages/community/tutorial/pytorch-memory-vit-llm,my_library,"llms, pytorch, transformers",2023-07-23T23:59:46.000Z,https://lightningaidev.wpengine.com/wp-content/uploads/2023/07/pytorch-memory-hero.png,,False
876789737,"lucidrains/vit-pytorch: Implementation of Vision Transformer, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch",,"Implementation of Vision Transformer, a simple way to achieve SOTA in vision classification with only a single transformer encoder, in Pytorch - lucidrains/vit-pytorch",https://github.com/lucidrains/vit-pytorch,my_library,"deep-learning, machine-vision, pytorch, transformers",2022-12-18T22:40:22.000Z,https://opengraph.githubassets.com/9edc731f2a99d5a99777494dd7aaa43716ebad2f0f59b90b9e38e48aaecebb2c/lucidrains/vit-pytorch,,False
