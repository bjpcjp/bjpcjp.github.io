id,title,note,excerpt,url,folder,tags,created,cover,highlights,favorite
925962810,Slim-Llama: An Energy-Efficient LLM ASIC Processor Supporting 3-Billion Parameters at Just 4.69mW,,"Large Language Models (LLMs) have become a cornerstone of artificial intelligence, driving advancements in natural language processing and decision-making tasks. However, their extensive power demands, resulting from high computational overhead and frequent external memory access, significantly hinder their scalability and deployment, especially in energy-constrained environments such as edge devices. This escalates the cost of operation while also limiting accessibility to these LLMs, which therefore calls for energy-efficient approaches designed to handle billion-parameter models. Current approaches to reduce the computational and memory needs of LLMs are based either on general-purpose processors or on GPUs, with a combination of weight quantization and",https://www.marktechpost.com/2024/12/20/slim-llama-an-energy-efficient-llm-asic-processor-supporting-3-billion-parameters-at-just-4-69mw/,my_library,"llms, semiconductors, chip-design",2024-12-21T00:43:25.274Z,https://www.marktechpost.com/wp-content/uploads/2024/12/Screenshot-2024-12-20-at-4.36.50%E2%80%AFPM.png,,False
876794057,"Groq Inference Tokenomics: Speed, But At What Cost?",,Faster than Nvidia? Dissecting the economics,https://www.semianalysis.com/p/groq-inference-tokenomics-speed-but,my_library,"inference, llms, semiconductors",2024-02-22T01:46:07.000Z,"https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4aad86a5-7fda-444f-9179-7912e9196547_2156x1100.png",,False
876792005,The Case for Running AI on CPUs Isn’t Dead Yet,,"GPUs may dominate, but CPUs could be perfect for smaller AI models",https://spectrum.ieee.org/ai-cpu,my_library,"cpus, deep-learning, gpus, llms, semiconductors",2023-06-02T00:01:45.000Z,https://spectrum.ieee.org/media-library/an-intel-xeon-processor-on-a-black-backdrop-the-processor-is-shown-from-both-above-and-below-displaying-the-thousands-of-conta.jpg?id=33743986&width=1200&height=600&coordinates=0%2C698%2C0%2C698,,False
876791915,Google dives into the ‘supercomputer’ game by knitting together purpose-bui,,Google's new machines combine Nvidia H100 GPUs with Google’s high-speed interconnections for AI tasks like training very large language models.,https://venturebeat.com/ai/google-dives-into-the-supercomputer-game-knitting-together-purpose-built-gpus-for-llm-training,my_library,"gpus, interconnects, llms, semiconductors",2023-05-12T13:17:16.000Z,https://venturebeat.com/wp-content/uploads/2022/12/VB_dictionary-page_romain-vignes-ywqa9IZB-dU-unsplash.jpg?w=1024?w=1200&strip=all,,False
