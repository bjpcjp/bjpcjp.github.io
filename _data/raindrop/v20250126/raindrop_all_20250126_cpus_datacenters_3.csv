id,title,note,excerpt,url,folder,tags,created,cover,highlights,favorite
876791667,Why AI Inference Will Remain Largely On The CPU,,Sponsored Feature: Training an AI model takes an enormous amount of compute capacity coupled with high bandwidth memory. Because the model training can be,https://www.nextplatform.com/2023/04/05/why-ai-inference-will-remain-largely-on-the-cpu,my_library,"cpus, datacenters, deep-learning",2023-04-05T16:54:45.000Z,https://www.nextplatform.com/wp-content/uploads/2023/01/intel-sapphire-rapids-logo-4-1.jpg,,False
876791661,RISC-V In The Datacenter Is No Risky Proposition,,"It was only a matter of time, perhaps, but the skyrocketing costs of designing chips is colliding with the ever-increasing need for performance,",https://www.nextplatform.com/2023/04/04/risc-v-in-the-datacenter-is-no-risky-proposition,my_library,"cpus, datacenters, riscv, semiconductors",2023-04-05T16:40:17.000Z,https://www.nextplatform.com/wp-content/uploads/2023/02/ventana-square_chip_1-logo-1024x1024.png,,False
876790616,"Google increases server life to six years, will save billions of dollars",,While Meta ups to five years,https://www.datacenterdynamics.com/en/news/google-increases-server-life-to-six-years-will-save-billions-of-dollars,my_library,"cpus, datacenters",2023-02-03T21:01:06.000Z,https://media.datacenterdynamics.com/media/images/Google_TPU_3.0.2e16d0ba.fill-1200x630.jpg,,False
