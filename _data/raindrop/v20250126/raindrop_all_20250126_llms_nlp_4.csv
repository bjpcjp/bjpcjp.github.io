id,title,note,excerpt,url,folder,tags,created,cover,highlights,favorite
944921267,The 2025 AI Engineering Reading List,gist: https://gist.github.com/bjpcjp/117ecf144c062c3c933f2690e7ece5c2,"We picked 50 paper/models/blogs across 10 fields in AI Eng: LLMs, Benchmarks, Prompting, RAG, Agents, CodeGen, Vision, Voice, Diffusion, Finetuning. If you're starting from scratch, start here.",https://www.latent.space/p/2025-papers?utm_campaign=post&utm_medium=web,my_library,"llms, nlp, deep-learning, arxiv",2025-01-14T01:25:14.377Z,"https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9242370c-229f-453d-924a-7a5aa4d20a4c_1090x502.png",,True
948258873,Implementing A Byte Pair Encoding (BPE) Tokenizer From Scratch,,"This is a standalone notebook implementing the popular byte pair encoding (BPE) tokenization algorithm, which is used in models like GPT-2 to GPT-4, Llama 3,...",https://sebastianraschka.com/blog/2025/bpe-from-scratch.html,my_library,"llms, nlp, machine-learning, python",2025-01-18T00:38:14.166Z,https://sebastianraschka.com/images/LLMs-from-scratch-images/bonus/bpe-from-scratch/bpe-overview.jpg,,False
876796884,Cleaning,,"As part of data preparation for an NLP model, it’s common to need to clean up your data prior to passing it into the model. If there’s unwanted content in your output, for example, it could impact the quality of your NLP model. To help with this, the `unstructured` library includes cleaning functions to help users sanitize output before sending it to downstream applications.",https://docs.unstructured.io/open-source/core-functionality/cleaning,my_library,"llms, nlp",2024-05-11T02:39:06.000Z,https://mintlify.com/docs/api/og?division=Documentation&mode=dark&title=Cleaning&description=As+part+of+data+preparation+for+an+NLP+model%2C+it%E2%80%99s+common+to+need+to+clean+up+your+data+prior+to+passing+it+into+the+model.+If+there%E2%80%99s+unwanted+content+in+your+output%2C+for+example%2C+it+could+impact+the+quality+of+your+NLP+model.+To+help+with+this%2C+the+%60unstructured%60+library+includes+cleaning+functions+to+help+users+sanitize+output+before+sending+it+to+downstream+applications.&logoLight=https%3A%2F%2Fmintlify.s3-us-west-1.amazonaws.com%2Funstructured-53%2Flogo%2Flight.png&logoDark=https%3A%2F%2Fmintlify.s3-us-west-1.amazonaws.com%2Funstructured-53%2Flogo%2Fdark.png&primaryColor=%2309C6DE&lightColor=%2309C6DE&darkColor=%2309C6DE,,False
876794097,Beyond Self-Attention: How a Small Language Model Predicts the Next Token,,A deep dive into the internals of a small transformer model to learn how it turns self-attention calculations into accurate predictions for the next token.,https://shyam.blog/posts/beyond-self-attention,my_library,"llms, nlp",2024-02-22T06:19:44.000Z,,,False
