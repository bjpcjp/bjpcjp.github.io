id,title,note,excerpt,url,folder,tags,created,cover,highlights,favorite
925280639,"Year in Review: Containers Get Smaller, Faster, More Secure",,"Containers were a revolutionary jump ahead of virtual machines, and they continue to get faster, lighter and more secure in the years since.",https://thenewstack.io/year-in-review-containers-get-smaller-faster-more-secure/,my_library,"containers, devops, security",2024-12-19T23:21:56.683Z,https://cdn.thenewstack.io/media/2023/12/aec929b1-year-wrapup-1.png,,False
876788444,"gchq/CyberChef: The Cyber Swiss Army Knife - a web app for encryption, encoding, compression and data analysis",,"The Cyber Swiss Army Knife - a web app for encryption, encoding, compression and data analysis - gchq/CyberChef",https://github.com/gchq/CyberChef,my_library,"devops, programming, security, webdev",2022-09-05T01:08:23.000Z,https://repository-images.githubusercontent.com/74962515/137c6d1b-4aac-4408-a361-c2a27f125b04,,False
876787669,Router Security,,Router Security Home Page,https://routersecurity.org,my_library,"devops, security, webdev",2022-07-30T20:25:24.000Z,,,False
876786441,"CSRF, XXE, and 12 Other Security Acronyms Explained",,"Acronyms are shortcuts, and we love using them, specially the catchy ones! Let's decipher some...",https://dev.to/smartscanner/csrf-xxe-and-12-other-security-acronyms-explained-2ma7,my_library,"devops, malware, programming, security",2022-07-13T01:27:34.000Z,"https://media.dev.to/dynamic/image/width=1000,height=500,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fqi7nbmuj8zd0k6hskco4.png",,False
876782670,Intelligent System Security,,We present a novel approach to infiltrate data to air-gapped systems without any additional hardware on-site.,https://intellisec.de/research/lasershark,my_library,"devops, hacking, security",2022-02-12T01:17:27.000Z,https://intellisec.org/research/lasershark/laser.jpg,,False
876782663,Top 10 web hacking techniques of 2021 | PortSwigger Research,,"Welcome to the Top 10 (new) Web Hacking Techniques of 2021, the latest iteration of our annual community-powered effort to identify the most significant web security research released in the last year",https://portswigger.net/research/top-10-web-hacking-techniques-of-2021,my_library,"devops, security",2022-02-10T22:54:44.000Z,https://portswigger.net/cms/images/e1/db/e016-twittercard-web-hacking-techniques-2021-results_twitter.jpg,,False
876781912,Hacksplaining,,,https://www.hacksplaining.com,my_library,"devops, security",2022-01-12T23:31:48.000Z,,,False
876780881,The Basics of Web Application Security,,"Security is both very important and often under-emphasized. While many targeted techniques help, there are some basic clean code habits which every developer can and should be doing",http://martinfowler.com/articles/web-security-basics.html,my_library,"devops, security, webdev",2021-12-13T12:20:48.000Z,https://martinfowler.com/articles/web-security-basics/card.png,,False
876778366,Phishing Tests Are Necessary. But They Don’t Need to Be Evil.,,"Although phishing tests can be helpful to protect users, using questionable tactics has the potential for harming relationships between a company and its employees. The authors suggest that managers avoid this damage by employing phishing tests with three criteria: Test teams, not individuals; don’t embarrass anyone; and gamify and reward.",https://hbr.org/2021/04/phishing-tests-are-necessary-but-they-dont-need-to-be-evil,my_library,"devops, security, webdev",2021-04-02T14:16:50.000Z,https://hbr.org/resources/images/article_assets/2021/04/Apr21_01_464881289_1196219402.jpg,,False
876778316,APT Encounters of the Third Kind - Igor’s Blog,,"A few weeks ago an ordinary security assessment turned into an incident response whirlwind. It was definitely a first for me, and I was kindly granted permission to outline the events in this blog post. This investigation started scary but turned out be quite fun, and I hope reading it will be informative to you too.  I'll be back to posting about my hardware research soon.     How it started   What hell is this?   The NFS Server   2nd malicious binary   Further forensics   Eureka Moment   The GOlang thingy   How the kernel got patched? and why not the golang app?   What we have so far   Q&A   How it started Twice a year I am hired to do security assessments for a specific client. We have been working together for several years, and I had a pretty good understanding of their network and what to look for.  This time my POC, Klaus, asked me to focus on privacy issues and GDPR compliance. However, he asked me to first look at their cluster of reverse gateways / load balancers:    I had some prior knowledge of these gateways, but decided to start by creating my own test environment first. The gateways run a custom Linux stack: basically a monolithic compiled kernel (without any modules), and a static GOlang application on top. The 100+ machines have no internal storage, but rather boot from an external USB media that has the kernel and the application. The GOlang app serves in two capacities: an init replacement and the reverse gateway software. During initialization it mounts /proc, /sys, devfs and so on, then mounts an NFS share hardcoded in the app. The NFS share contains the app's configuration, TLS certificates, blacklist data and a few more. It starts listening on 443, filters incoming communication and passes valid requests on different services in the production segment.    I set up a self contained test environment, and spent a day in black box examination. Having found nothing much I suggested we move on to looking at the production network, but Klaus insisted I continue with the gateways. Specifically he wanted to know if I could develop a methodology for testing if an attacker has gained access to the gateways and is trying to access PII (Personally Identifiable Information) from within the decrypted HTTP stream.  I couldn't SSH into the host (no SSH), so I figured we will have to add some kind of instrumentation to the GO app. Klaus still insisted I start by looking at the traffic before (red) and after the GW (green), and gave me access to a mirrored port on both sides so I could capture traffic to a standalone laptop he prepared for me and I could access through an LTE modem but was not allowed to upload data from:    The problem I faced now was how to find out what HTTPS traffic corresponded to requests with embedded PII. One possible avenue was to try and correlate the encrypted traffic with the decrypted HTTP traffic. This proved impossible using timing alone. However, unspecting the decoded traffic I noticed the GW app adds an 'X-Orig-Connection' with the four-tuple of the TLS connection! Yay!    I wrote a small python program to scan the port 80 traffic capture and create a mapping from each four-tuple TLS connection to a boolean - True for connection with PII and False for all others: 10.4.254.254,443,[Redacted],43404,376106847.319,False 10.4.254.254,443,[Redacted],52064,376106856.146,False 10.4.254.254,443,[Redacted],40946,376106856.295,False 10.4.254.254,443,[Redacted],48366,376106856.593,False 10.4.254.254,443,[Redacted],48362,376106856.623,True 10.4.254.254,443,[Redacted],45872,376106856.645,False 10.4.254.254,443,[Redacted],40124,376106856.675,False  ...   With this in mind I could now extract the data from the PCAPs and do some correlations. After a few long hours getting scapy to actually parse timestamps consistently enough for comparisons, I had a list of connection timing information correlated with PII. A few more fun hours with Excel and I got histogram graphs of time vs count of packets. Everything looked normal for the HTTP traffic, although I expected more of a normal distribution than the power-low type thingy I got. Port 443 initially looked the same, and I got the normal distribution I expected. But when filtering for PII something was seriously wrong. The distribution was skewed and shifted to longer time frames. And there was nothing similar on the port 80 end.    My only explanation was that something was wrong with my testing setup (the blue bars) vs. the real live setup (the orange bars). I wrote on our slack channel 'I think my setup is sh*t, can anyone resend me the config files?', but this was already very late at night, and no one responded. Having a slight OCD I couldn’t let this go. To my rescue came another security? feature of the GWs: Thet restarted daily, staggered one by one, with about 10 minutes between hosts. This means that every ten minutes or so one of them would reboot, and thus reload it’s configuration files over NFS. And since I could see the NFS traffic through the port mirror I had access to, I recokoned I could get the production configuration files from the NFS capture (bottom dotted blue line in the diagram before).  So to cut a long story short I found the NFS read reply packet, and got the data I need. But … why the hack is eof 77685??? Come on people, its 3:34AM!  What's more, the actual data was 77685 bytes, exactly 8192 bytes more then the ‘Read length’. The entropy for that data was pretty uniform, suggesting it was encrypted. The file I had was definitely not encrypted.    Histogram of extra 8192 bytes:    When I mounted the NFS export myself I got a normal EOF value of 1!    What hell is this?  Comparing the capture from my testing machine with the one from the port mirror I saw something else weird:    For other NFS open requests (on all of my test system captures and for other files in the production system) we get:    Spot the difference?  The open id: string became open-id:. Was I dealing with some corrupt packet? But the exact same problem reappeared the next time blacklist.db was send over the wire by another GW host.  Time to look at the kernel source code:    The “open id” string is hardcoded. What's up?  After a good night sleep and no beer this time I repeated the experiment and convincing myself I was not hullucinating I decided to compare the source code of the exact kernel version with the kernel binary I got.  What I expected to see was this (from nfs4xdr.c):  static inline void encode_openhdr(struct xdr_stream *xdr, const struct nfs_openargs *arg) {     __be32 *p;  /*  * opcode 4, seqid 4, share_access 4, share_deny 4, clientid 8, ownerlen 4,  * owner 4 = 32  */     encode_nfs4_seqid(xdr, arg->seqid);     encode_share_access(xdr, arg->share_access);     p = reserve_space(xdr, 36);     p = xdr_encode_hyper(p, arg->clientid);     *p++ = cpu_to_be32(24);     p = xdr_encode_opaque_fixed(p, ""open id:"", 8);     *p++ = cpu_to_be32(arg->server->s_dev);     *p++ = cpu_to_be32(arg->id.uniquifier);     xdr_encode_hyper(p, arg->id.create_time); }   Running binwalk -e -M bzImage I got the internal ELF image, and opened it in IDA. Of course I didn’t have any symbols, but I got nfs4_xdr_enc_open() from /proc/kallsyms, and from there to encode_open() which led me to encode_openhdr(). With some help from hex-rays I got code that looked very similiar, but with one key difference:  static inline void encode_openhdr(struct xdr_stream *xdr, const struct nfs_openargs *arg) {     ...     p = xdr_encode_opaque_fixed(p, unknown_func(""open id:"", arg), 8);     ... }   The function unknown_func was pretty long and complicated but eventually sometimes decided to replace the space between 'open' and 'id' with a hyphen.  Does the NFS server care? Apparently this string it is some opaque client identifier that is ignored by the NFS server, so no one would see the difference. That is unless they were trying to extract something from an NFS stream, and obviously this was not a likely scenario. OK, back to the weird 'eof' thingy from the NFS server.  The NFS Server  The server was running the 'NFS-ganesha-3.3' package. This is a very modular user-space NFS server that is implemented as a series of loadable modules called FSALs. For example support for files on the regular filesystem is implemented through a module called libfsalvfs.so. Having verified all the files on disk had the same SHA1 as the distro package, I decided to dump the process memory. I didn't have any tools on the host, so I used GDB which helpfully was already there. Unexpectadly GDB was suddenly killed, the file I specified as output got erased, and the nfs server process restarted.  I took the dump again but there was nothing special there!  I was pretty suspicious at this time, and wanted to recover the original dump file from the first dump. Fortunately for me I was dumping the file to the laptop, again over NFS. The file had been deleted, but I managed to recover it from the disk on that server.  2nd malicious binary  The memory dump was truncated, but had a corrupt version of NFS-ganesha inside. There were two libfsalvfs.so libraries loaded: the original one and an injected SO file with the same name. The injected file was clearly malicious. The main binary was patched in a few places, and the  function table into libfsalvfs.so as replaced with the alternate libfsalvfs.so. The alternate file was compiled from NFS-ganesha sources, but modified to include new and improved (wink wink) functionality.  The most interesting of the new functionality were two separate implementations of covert channels.  The first one we encountered already:     When an open request comes in with 'open-id' instead of 'open id', the file handle is marked. This change is opaque to the NFS server, so unpatched servers just ignore it and nothing much happens.   For infiltrated NFS server, when the file handle opened this way is read, the NFS server appends the last block with a payload coming from the malwar...",https://igor-blue.github.io/2021/03/24/apt1.html,my_library,"devops, security",2021-03-27T13:13:58.000Z,,,False
876777263,Linux Hardening Guide | Madaidan's Insecurities,,,https://madaidans-insecurities.github.io/guides/linux-hardening.html,my_library,"devops, linux, security",2020-12-31T16:54:30.000Z,,,False
876769562,Certificates for localhost,,"Sometimes people want to get a certificate for the hostname &ldquo;localhost&rdquo;, either for use in local development, or for distribution with a native application that needs to communicate with a web application. Let&rsquo;s Encrypt can&rsquo;t provide certificates for &ldquo;localhost&rdquo; because nobody uniquely owns it, and it&rsquo;s not rooted in a top level domain like &ldquo;.com&rdquo; or &ldquo;.net&rdquo;. It&rsquo;s possible to set up your own domain name that happens to resolve to 127.",https://letsencrypt.org/docs/certificates-for-localhost,my_library,"devops, dns, security",2018-07-15T13:46:24.000Z,https://letsencrypt.org/images/LetsEncrypt-SocialShare.png,,False
876769556,netdev day 1: IPsec!,,,https://jvns.ca/blog/2018/07/11/netdev-day-1--ipsec,my_library,"devops, ipsec, linux, security",2018-07-13T16:37:20.000Z,,,False
