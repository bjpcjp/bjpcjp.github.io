---
title: information theory tutorial (pdf)
layout: default-foundation-20210515
tags: algorithms
date: 2021-06-28 20:38
---

<div class="callout">
	Information Theory Tutorial
</div>

<div class="card">

	<div class="card-divider">
		<a href="/pdfs/math/info-theory-tutorial.pdf" target="_blank">
			original (pdf)</a>
	</div>

	<div class="card-image">
		<img src="/px/math/info-theory-comms-channel.png"/>
	</div>

	<div class="card-section">
		<a href="https://arxiv.org/pdf/1802.05968.pdf">ArXiV 1802.05968</a><br>
		1) Intro<br>
		2) Finding a route, bit by bit<br>
		3) Bits are NOT binary digits<br>
		4) Information & Entropy<br>
		5) Entropy - Continuous Variables<br>
		6) Max Entropy Distributions<br>
		7) Channel Capacity<br>
		8) Shannon's Source Coding Theorem<br>
		9) Noise & Channel Capacity<br>
		10) Mutual Information<br>
		11) Shannon's Noisy Channel Coding Theorem<br>
		12) Gaussian Channels<br>
		13) Fourier Analysis<br>
		14) History (very, very short)<br>
		15) Key Equations<br>
		16) Resources
	</div>

</div>

