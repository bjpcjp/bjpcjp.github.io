<html lang="en"><!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="http://localhost:4000/favicon-32x32.png" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Bandit Algorithms | Obviously Awesome</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="Bandit Algorithms" />
<meta name="author" content="Brian Piercy" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Bandit Algorithms - Booknotes" />
<meta property="og:description" content="Bandit Algorithms - Booknotes" />
<link rel="canonical" href="http://localhost:4000/2020/01/01/bandit-algorithms-booknotes.html" />
<meta property="og:url" content="http://localhost:4000/2020/01/01/bandit-algorithms-booknotes.html" />
<meta property="og:site_name" content="Obviously Awesome" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-01-01T12:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Bandit Algorithms" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Brian Piercy"},"dateModified":"2020-01-01T12:00:00-05:00","datePublished":"2020-01-01T12:00:00-05:00","description":"Bandit Algorithms - Booknotes","headline":"Bandit Algorithms","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2020/01/01/bandit-algorithms-booknotes.html"},"url":"http://localhost:4000/2020/01/01/bandit-algorithms-booknotes.html"}</script>
<!-- End Jekyll SEO tag -->
<!-- Compressed CSS -->
  <link rel="stylesheet" 
  href="https://cdn.jsdelivr.net/npm/foundation-sites@6.6.3/dist/css/foundation.min.css" 
  integrity="sha256-ogmFxjqiTMnZhxCqVmcqTvjfe1Y/ec4WaRj/aQPvn+I=" 
  crossorigin="anonymous"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Obviously Awesome" /></head>
<body>
    <div class="grid-container fluid">

      <div class="grid-x">     

        <div class="text-left">
          <h1><a href="/">Obviously Awesome</a></h1><form action="https://google.com/search" type="GET">
  <div class="input-group">
  	<input class="input-group-field" 
        type="search" name="q" value="site search (Google)" onfocus=this.value=''>
    <div class="input-group-button">
      <input type="submit" class="button" value="Go">
    </div>
  </div>
</form>

<script>
var form = document.querySelector("form");

form.addEventListener("submit", function (e) {
  e.preventDefault();
  var search = form.querySelector("input[type=search]");
  search.value = "site:bjpcjp.github.io " + search.value;
  form.submit();
});
</script>
 </div>

      </div>

      <div class="grid-x">     

        <div class="cell small-4 medium-3 large-2"><ul class="vertical menu"><li>
          <a href="/posts-by-tag.html">
            Posts by Tag</a></li><li>
          <a href="/behaviors/">
            Behaviors</a></li><li>
          <a href="/math/">
            Math</a></li><li>
          <a href="/devops.html">
            DevOps &amp; Linux</a></li><li>
          <a href="/gametheory/">
            Game Theory</a></li><li>
          <a href="/golang.html">
            Golang</a></li><li>
          <a href="/ideas.html">
            Ideas</a></li><li>
          <a href="/language/">
            Language</a></li><li>
          <a href="/prodmgmt/">
            Prod Mgmt</a></li><li>
          <a href="/python/">
            Python</a></li><li>
          <a href="/ruby.html">
            Ruby</a></li><li>
          <a href="/semiconductors.html">
            Chips</a></li><li>
          <a href="/uiux/">
            UI/UX</a></li><li>
          <a href="/webdev/">
            Web Dev Tools</a></li><li>
          <a href="/all-posts.html">
            Index</a></li></ul></div>
        
        <div class="cell small-8 medium-9 large-10">
          <div class="callout">
    <h2>Bandit Algorithms - Booknotes</h2>
</div>

<div style="column-count: 3;">

<div class="card">
    <div class="card-image">
        <a href="https://duckduckgo.com/?q=bandit+algorithms&ia=web">
        <img src="/px/math/bandit-algorithms-book-cover.png"></a>
    </div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-intro-BA.pdf">intro (c1)</a><br>
 language<br>
 applications<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-probability-BA.pdf">probability (c2)</a><br>
 probability spaces<br>
 random elements<br>
 algebras & knowledge<br>
 conditional prob.<br>
 independence<br>
 integration, expectation<br>
 conditional expectation<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-multiarmed-BA.pdf">multi-armed (c2)</a><br>
<!--
<img src="/px/math/bandits-10armed.png" width="95%"><br> -->
 k armed bandits<br>
 action-value methods<br>
 10 armed testbed<br>
 implementation (incremental)<br>
 non-stationary problem tracking<br>
 optimistic initial values<br>
 UCB action selection<br>
 gradient bandit algos<br>
 assoc.search (context.bandits)<br>
 summary<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-stochastic-markov-BA.pdf">stochastic processes, markov chains (c3)</a><br>
 stochastic processes<br>
 markov chains<br>
 martingales<br>
 stopping times<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-stochastic-finite-BA.pdf">finite-armed stochastic bandits (c4)</a><br>
 learning objective<br>
 regret<br>
 decomposing regret<br>
 canonical bandit model<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-concentration-of-measure-BA.pdf">concentration of measure (c5)</a><br>
 markov, chebyshev inequalities<br>
 cramer-chernoff
 subgaussian random vars<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-explore-then-commit-BA.pdf">explore-then-commit algo (c6)</a><br>
 definition<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-upper-confidence-bound-BA.pdf">upper conf bound (UCB) algo (c7)</a><br>
 optimism principle<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-UCB-algorithm-asymptotic-optimality-BA.pdf">UCB algo: asymptotic optimality (c8)</a><br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-UCB-algorithm-minimax-optimality-BA.pdf">UCB algo: minimax optimality (c9)</a><br>
 notes
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-UCB-algorithm-bernoulli-noise-BA.pdf">UCB algo: bernoulli noise (c10)</a><br>
 concentration of sums<br>
 KL-UCB algo<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-exp3.pdf">exp3 algorithm (c11)</a><br>
 importance-weighted estimators<br>
 definition<br>
 regret analysis<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-exp3-IX-BA.pdf">exp3-IX (c12)</a><br>
 regret analysis<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-lower-bounds-BA.pdf">lower bounds (LB) basics (c13)</a><br>
 ideas, notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-info-theory-BA.pdf">info theory (c14)</a><br>
 relative entropy<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-lower-bounds-minimax-BA.pdf">minimax LB (c15)</a><br>
 relative entropy btwn bandits<br>
 minimax LB<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-lower-bounds-instance-dependent-BA.pdf">LB instance dependent (c16)</a><br>
 asymptotic bounds<br>
 finite-time bounds<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-lower-bounds-high-probability-BA.pdf">LB high probability (c17)</a><br>
 stochastic bandits<br>
 adversarial bandits<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-contextual-BA.pdf">contextual (c18)</a><br>
 one bandit per context<br>
 expert advice<br>
 higher? (exp4)<br>
 regret analysis<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-stochastic-linear-BA.pdf">stochastic linear bandits (c19)</a><br>
 st. contextual bandits<br>
 st. linear bandits<br>
 regret analysis<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-least-squares-estimators-confidence-bounds-BA.pdf">LSEs: confidence bounds (c20)</a><br>
 martingale noise<br>
 laplace's method<br>
 notest<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-least-squares-estimators-optimal-design-BA.pdf">LSEs: optimal design (c21)</a><br>
 kiefer-wolfowitz proof<br>
 min volume ellipsoids<br>
 john's theorem<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-stochastic-linear-finite-many-arms-BA.pdf">stochastic finite  many arms (c22)</a><br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-stochastic-linear-sparsity-BA.pdf">SLBs with sparsity (c23)</a><br>
 sparse SLBs<br>
 elimination<br>
 proof<br>
 UCB with sparsity<br>
 online>confidence set conversion<br>
 sparse online linear prediction<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-stochastic-linear-minimax-lower-bounds-BA.pdf">SLBs: minimax lower bounds (c24)</a><br>
 hypercube<br>
 sphere<br>
 sparse param vectors<br>
 unrealizable case<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-stochastic-linear-asymptotic-lower-bounds-BA.pdf">stochastic linear bandits: asympt LBs (c25)</a><br>
 clouds looming, notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-convex-analysis-BA.pdf">convex analysis (c26)</a><br>
 sets & functions<br>
 jensen's inequality<br>
 bregman divergence<br>
 legendre functions<br>
 optimization<br>
 projections<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-exp3-adversarial-linear-BA.pdf">exp3: adversarial/linear (c27)</a><br>
 exponential signals<br>
 regret analysis<br>
 continuous exponential weights<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-follow-the-leader-mirror-descent-BA.pdf">follow-the-leader | mirror descent (c28)</a><br>
 online linear optimization<br>
 regret analysis<br>
 online learning<br>
 the unit ball<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-adversarial-vs-stochastic-linear-BA.pdf">adversarial-vs-stochastic-linear (c29)</a><br>
 reducing SLBs to ALBs<br>
 SLB with noise<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-combinatorial-BA.pdf">combinatorial (c30)</a><br>
 apps<br>
 bandits<br>
 semibandits<br>
 follow the perturbed leader<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-non-stationary-BA.pdf">non-stationary (c31)</a><br>
 adversarial bandits<br>
 stochastic bandits<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-ranking-BA.pdf">ranking (c32)</a><br>
 click models<br>
 policy<br>
 regret analysis<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-pure-exploration-BA.pdf">pure exploration (c33)</a><br>
 simple regret<br>
 best-arm id<br>
 best-arm id with budget<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-bayes-BA.pdf">bayesian (c34)</a><br>
 regret & optimality<br>
 optimal regret, finite-armed bandits<br>
 learning, posterior dists<br>
 conjugate priors<br>
 posterior distributions<br>
 one-armed bandits<br>
 gittins index<br>
 computing the GI<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-thompson-sampling-BA.pdf">thompson sampling (c35)<a><br>
 finite-armed bandits<br>
 linear bandits<br>
 info theoretic analysis<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-partial-monitoring-BA.pdf">partial monitoring (c36)</a><br>
 finite adversarial partial monitoring (FAPM)<br>
 structure<br>
 FAPM classification<br>
 lower bounds<br>
 policy for easy games<br>
 upper bound for easy games<br>
 theorem proof<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-markov-decisions-BA.pdf">markov dcsn prcss (MDP) (c37)</a><br>
 the problem<br>
 optimal policies<br>
 bellman equation<br>
 finding opt policy<br>
 MDP learning<br>
 UCBs for reinf. learning<br>
 proof of UB, LB<br>
 notes<br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/bandits-index-BA.pdf">index</a><br>
</div></div>

<div class="card"><div class="card-section">
<a href="/pdfs/math/book-bandits-BA.pdf">book</a><br>
</div></div>

</div>
        </div>

      </div>

      <hr><footer>

  <a href="/feed.xml">
    <svg>
      <use href="/assets/minima-social-icons.svg#rss"></use>
    </svg></a>

</footer>
</div><!-- Compressed JavaScript -->
<script src="https://cdn.jsdelivr.net/npm/foundation-sites@6.6.3/dist/js/foundation.min.js" 
  integrity="sha256-pRF3zifJRA9jXGv++b06qwtSqX1byFQOLjqa2PTEb2o=" 
  crossorigin="anonymous"></script>
  
</body>
</html>
